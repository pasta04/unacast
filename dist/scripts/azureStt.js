/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/bent/src/browser.js":
/*!******************************************!*\
  !*** ./node_modules/bent/src/browser.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n/* global fetch, btoa, Headers */\nconst core = __webpack_require__(/*! ./core */ \"./node_modules/bent/src/core.js\")\n\nclass StatusError extends Error {\n  constructor (res, ...params) {\n    super(...params)\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, StatusError)\n    }\n\n    this.name = 'StatusError'\n    this.message = res.statusMessage\n    this.statusCode = res.status\n    this.res = res\n    this.json = res.json.bind(res)\n    this.text = res.text.bind(res)\n    this.arrayBuffer = res.arrayBuffer.bind(res)\n    let buffer\n    const get = () => {\n      if (!buffer) buffer = this.arrayBuffer()\n      return buffer\n    }\n    Object.defineProperty(this, 'responseBody', { get })\n    // match Node.js headers object\n    this.headers = {}\n    for (const [key, value] of res.headers.entries()) {\n      this.headers[key.toLowerCase()] = value\n    }\n  }\n}\n\nconst mkrequest = (statusCodes, method, encoding, headers, baseurl) => async (_url, body, _headers = {}) => {\n  _url = baseurl + (_url || '')\n  let parsed = new URL(_url)\n\n  if (!headers) headers = {}\n  if (parsed.username) {\n    headers.Authorization = 'Basic ' + btoa(parsed.username + ':' + parsed.password)\n    parsed = new URL(parsed.protocol + '//' + parsed.host + parsed.pathname + parsed.search)\n  }\n  if (parsed.protocol !== 'https:' && parsed.protocol !== 'http:') {\n    throw new Error(`Unknown protocol, ${parsed.protocol}`)\n  }\n\n  if (body) {\n    if (body instanceof ArrayBuffer ||\n      ArrayBuffer.isView(body) ||\n      typeof body === 'string'\n    ) {\n      // noop\n    } else if (typeof body === 'object') {\n      body = JSON.stringify(body)\n      headers['Content-Type'] = 'application/json'\n    } else {\n      throw new Error('Unknown body type.')\n    }\n  }\n\n  _headers = new Headers({ ...(headers || {}), ..._headers })\n\n  const resp = await fetch(parsed, { method, headers: _headers, body })\n  resp.statusCode = resp.status\n\n  if (!statusCodes.has(resp.status)) {\n    throw new StatusError(resp)\n  }\n\n  if (encoding === 'json') return resp.json()\n  else if (encoding === 'buffer') return resp.arrayBuffer()\n  else if (encoding === 'string') return resp.text()\n  else return resp\n}\n\nmodule.exports = core(mkrequest)\n\n\n//# sourceURL=webpack://unacast/./node_modules/bent/src/browser.js?");

/***/ }),

/***/ "./node_modules/bent/src/core.js":
/*!***************************************!*\
  !*** ./node_modules/bent/src/core.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("\nconst encodings = new Set(['json', 'buffer', 'string'])\n\nmodule.exports = mkrequest => (...args) => {\n  const statusCodes = new Set()\n  let method\n  let encoding\n  let headers\n  let baseurl = ''\n\n  args.forEach(arg => {\n    if (typeof arg === 'string') {\n      if (arg.toUpperCase() === arg) {\n        if (method) {\n          const msg = `Can't set method to ${arg}, already set to ${method}.`\n          throw new Error(msg)\n        } else {\n          method = arg\n        }\n      } else if (arg.startsWith('http:') || arg.startsWith('https:')) {\n        baseurl = arg\n      } else {\n        if (encodings.has(arg)) {\n          encoding = arg\n        } else {\n          throw new Error(`Unknown encoding, ${arg}`)\n        }\n      }\n    } else if (typeof arg === 'number') {\n      statusCodes.add(arg)\n    } else if (typeof arg === 'object') {\n      if (Array.isArray(arg) || arg instanceof Set) {\n        arg.forEach(code => statusCodes.add(code))\n      } else {\n        if (headers) {\n          throw new Error('Cannot set headers twice.')\n        }\n        headers = arg\n      }\n    } else {\n      throw new Error(`Unknown type: ${typeof arg}`)\n    }\n  })\n\n  if (!method) method = 'GET'\n  if (statusCodes.size === 0) {\n    statusCodes.add(200)\n  }\n\n  return mkrequest(statusCodes, method, encoding, headers, baseurl)\n}\n\n\n//# sourceURL=webpack://unacast/./node_modules/bent/src/core.js?");

/***/ }),

/***/ "./node_modules/electron-log/renderer.js":
/*!***********************************************!*\
  !*** ./node_modules/electron-log/renderer.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst renderer = __webpack_require__(/*! ./src/renderer */ \"./node_modules/electron-log/src/renderer/index.js\");\n\nmodule.exports = renderer;\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/renderer.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/core/Buffering.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-log/src/core/Buffering.js ***!
  \*********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nclass Buffering {\n  constructor({ processMessage }) {\n    this.processMessage = processMessage;\n    this.buffer = [];\n    this.enabled = false;\n\n    this.begin = this.begin.bind(this);\n    this.commit = this.commit.bind(this);\n    this.reject = this.reject.bind(this);\n  }\n\n  addMessage(message) {\n    this.buffer.push(message);\n  }\n\n  begin() {\n    this.enabled = [];\n  }\n\n  commit() {\n    this.enabled = false;\n    this.buffer.forEach((item) => this.processMessage(item));\n    this.buffer = [];\n  }\n\n  reject() {\n    this.enabled = false;\n    this.buffer = [];\n  }\n}\n\nmodule.exports = Buffering;\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/src/core/Buffering.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/core/Logger.js":
/*!******************************************************!*\
  !*** ./node_modules/electron-log/src/core/Logger.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst scopeFactory = __webpack_require__(/*! ./scope */ \"./node_modules/electron-log/src/core/scope.js\");\nconst Buffering = __webpack_require__(/*! ./Buffering */ \"./node_modules/electron-log/src/core/Buffering.js\");\n\n/**\n * @property {Function} error\n * @property {Function} warn\n * @property {Function} info\n * @property {Function} verbose\n * @property {Function} debug\n * @property {Function} silly\n */\nclass Logger {\n  static instances = {};\n\n  dependencies = {};\n  errorHandler = null;\n  eventLogger = null;\n  functions = {};\n  hooks = [];\n  isDev = false;\n  levels = null;\n  logId = null;\n  scope = null;\n  transports = {};\n  variables = {};\n\n  constructor({\n    allowUnknownLevel = false,\n    dependencies = {},\n    errorHandler,\n    eventLogger,\n    initializeFn,\n    isDev = false,\n    levels = ['error', 'warn', 'info', 'verbose', 'debug', 'silly'],\n    logId,\n    transportFactories = {},\n    variables,\n  } = {}) {\n    this.addLevel = this.addLevel.bind(this);\n    this.create = this.create.bind(this);\n    this.initialize = this.initialize.bind(this);\n    this.logData = this.logData.bind(this);\n    this.processMessage = this.processMessage.bind(this);\n\n    this.allowUnknownLevel = allowUnknownLevel;\n    this.buffering = new Buffering(this);\n    this.dependencies = dependencies;\n    this.initializeFn = initializeFn;\n    this.isDev = isDev;\n    this.levels = levels;\n    this.logId = logId;\n    this.scope = scopeFactory(this);\n    this.transportFactories = transportFactories;\n    this.variables = variables || {};\n\n    for (const name of this.levels) {\n      this.addLevel(name, false);\n    }\n    this.log = this.info;\n    this.functions.log = this.log;\n\n    this.errorHandler = errorHandler;\n    errorHandler?.setOptions({ ...dependencies, logFn: this.error });\n\n    this.eventLogger = eventLogger;\n    eventLogger?.setOptions({ ...dependencies, logger: this });\n\n    for (const [name, factory] of Object.entries(transportFactories)) {\n      this.transports[name] = factory(this, dependencies);\n    }\n\n    Logger.instances[logId] = this;\n  }\n\n  static getInstance({ logId }) {\n    return this.instances[logId] || this.instances.default;\n  }\n\n  addLevel(level, index = this.levels.length) {\n    if (index !== false) {\n      this.levels.splice(index, 0, level);\n    }\n\n    this[level] = (...args) => this.logData(args, { level });\n    this.functions[level] = this[level];\n  }\n\n  catchErrors(options) {\n    this.processMessage(\n      {\n        data: ['log.catchErrors is deprecated. Use log.errorHandler instead'],\n        level: 'warn',\n      },\n      { transports: ['console'] },\n    );\n    return this.errorHandler.startCatching(options);\n  }\n\n  create(options) {\n    if (typeof options === 'string') {\n      options = { logId: options };\n    }\n\n    return new Logger({\n      dependencies: this.dependencies,\n      errorHandler: this.errorHandler,\n      initializeFn: this.initializeFn,\n      isDev: this.isDev,\n      transportFactories: this.transportFactories,\n      variables: { ...this.variables },\n      ...options,\n    });\n  }\n\n  compareLevels(passLevel, checkLevel, levels = this.levels) {\n    const pass = levels.indexOf(passLevel);\n    const check = levels.indexOf(checkLevel);\n\n    if (check === -1 || pass === -1) {\n      return true;\n    }\n\n    return check <= pass;\n  }\n\n  initialize(options = {}) {\n    this.initializeFn({ logger: this, ...this.dependencies, ...options });\n  }\n\n  logData(data, options = {}) {\n    if (this.buffering.enabled) {\n      this.buffering.addMessage({ data, ...options });\n    } else {\n      this.processMessage({ data, ...options });\n    }\n  }\n\n  processMessage(message, { transports = this.transports } = {}) {\n    if (message.cmd === 'errorHandler') {\n      this.errorHandler.handle(message.error, {\n        errorName: message.errorName,\n        processType: 'renderer',\n        showDialog: Boolean(message.showDialog),\n      });\n      return;\n    }\n\n    let level = message.level;\n    if (!this.allowUnknownLevel) {\n      level = this.levels.includes(message.level) ? message.level : 'info';\n    }\n\n    const normalizedMessage = {\n      date: new Date(),\n      logId: this.logId,\n      ...message,\n      level,\n      variables: {\n        ...this.variables,\n        ...message.variables,\n      },\n    };\n\n    for (const [transName, transFn] of this.transportEntries(transports)) {\n      if (typeof transFn !== 'function' || transFn.level === false) {\n        continue;\n      }\n\n      if (!this.compareLevels(transFn.level, message.level)) {\n        continue;\n      }\n\n      try {\n        // eslint-disable-next-line arrow-body-style\n        const transformedMsg = this.hooks.reduce((msg, hook) => {\n          return msg ? hook(msg, transFn, transName) : msg;\n        }, normalizedMessage);\n\n        if (transformedMsg) {\n          transFn({ ...transformedMsg, data: [...transformedMsg.data] });\n        }\n      } catch (e) {\n        this.processInternalErrorFn(e);\n      }\n    }\n  }\n\n  processInternalErrorFn(_e) {\n    // Do nothing by default\n  }\n\n  transportEntries(transports = this.transports) {\n    const transportArray = Array.isArray(transports)\n      ? transports\n      : Object.entries(transports);\n\n    return transportArray\n      .map((item) => {\n        switch (typeof item) {\n          case 'string':\n            return this.transports[item] ? [item, this.transports[item]] : null;\n          case 'function':\n            return [item.name, item];\n          default:\n            return Array.isArray(item) ? item : null;\n        }\n      })\n      .filter(Boolean);\n  }\n}\n\nmodule.exports = Logger;\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/src/core/Logger.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/core/scope.js":
/*!*****************************************************!*\
  !*** ./node_modules/electron-log/src/core/scope.js ***!
  \*****************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = scopeFactory;\n\nfunction scopeFactory(logger) {\n  return Object.defineProperties(scope, {\n    defaultLabel: { value: '', writable: true },\n    labelPadding: { value: true, writable: true },\n    maxLabelLength: { value: 0, writable: true },\n    labelLength: {\n      get() {\n        switch (typeof scope.labelPadding) {\n          case 'boolean': return scope.labelPadding ? scope.maxLabelLength : 0;\n          case 'number': return scope.labelPadding;\n          default: return 0;\n        }\n      },\n    },\n  });\n\n  function scope(label) {\n    scope.maxLabelLength = Math.max(scope.maxLabelLength, label.length);\n\n    const newScope = {};\n    for (const level of logger.levels) {\n      newScope[level] = (...d) => logger.logData(d, { level, scope: label });\n    }\n    newScope.log = newScope.info;\n    return newScope;\n  }\n}\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/src/core/scope.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/core/transforms/transform.js":
/*!********************************************************************!*\
  !*** ./node_modules/electron-log/src/core/transforms/transform.js ***!
  \********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = { transform };\n\nfunction transform({\n  logger,\n  message,\n  transport,\n\n  initialData = message?.data || [],\n  transforms = transport?.transforms,\n}) {\n  return transforms.reduce((data, trans) => {\n    if (typeof trans === 'function') {\n      return trans({ data, logger, message, transport });\n    }\n\n    return data;\n  }, initialData);\n}\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/src/core/transforms/transform.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/renderer/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-log/src/renderer/index.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Logger = __webpack_require__(/*! ../core/Logger */ \"./node_modules/electron-log/src/core/Logger.js\");\nconst RendererErrorHandler = __webpack_require__(/*! ./lib/RendererErrorHandler */ \"./node_modules/electron-log/src/renderer/lib/RendererErrorHandler.js\");\nconst transportConsole = __webpack_require__(/*! ./lib/transports/console */ \"./node_modules/electron-log/src/renderer/lib/transports/console.js\");\nconst transportIpc = __webpack_require__(/*! ./lib/transports/ipc */ \"./node_modules/electron-log/src/renderer/lib/transports/ipc.js\");\n\nmodule.exports = createLogger();\nmodule.exports.Logger = Logger;\nmodule.exports[\"default\"] = module.exports;\n\nfunction createLogger() {\n  const logger = new Logger({\n    allowUnknownLevel: true,\n    errorHandler: new RendererErrorHandler(),\n    initializeFn: () => {},\n    logId: 'default',\n    transportFactories: {\n      console: transportConsole,\n      ipc: transportIpc,\n    },\n    variables: {\n      processType: 'renderer',\n    },\n  });\n\n  logger.errorHandler.setOptions({\n    logFn({ error, errorName, showDialog }) {\n      logger.transports.console({\n        data: [errorName, error].filter(Boolean),\n        level: 'error',\n      });\n      logger.transports.ipc({\n        cmd: 'errorHandler',\n        error: {\n          cause: error?.cause,\n          code: error?.code,\n          name: error?.name,\n          message: error?.message,\n          stack: error?.stack,\n        },\n        errorName,\n        logId: logger.logId,\n        showDialog,\n      });\n    },\n  });\n\n  if (typeof window === 'object') {\n    window.addEventListener('message', (event) => {\n      const { cmd, logId, ...message } = event.data || {};\n      const instance = Logger.getInstance({ logId });\n\n      if (cmd === 'message') {\n        instance.processMessage(message, { transports: ['console'] });\n      }\n    });\n  }\n\n  // To support custom levels\n  return new Proxy(logger, {\n    get(target, prop) {\n      if (typeof target[prop] !== 'undefined') {\n        return target[prop];\n      }\n\n      return (...data) => logger.logData(data, { level: prop });\n    },\n  });\n}\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/src/renderer/index.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/renderer/lib/RendererErrorHandler.js":
/*!****************************************************************************!*\
  !*** ./node_modules/electron-log/src/renderer/lib/RendererErrorHandler.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// eslint-disable-next-line no-console\nconst consoleError = console.error;\n\nclass RendererErrorHandler {\n  logFn = null;\n  onError = null;\n  showDialog = false;\n  preventDefault = true;\n\n  constructor({ logFn = null } = {}) {\n    this.handleError = this.handleError.bind(this);\n    this.handleRejection = this.handleRejection.bind(this);\n    this.startCatching = this.startCatching.bind(this);\n    this.logFn = logFn;\n  }\n\n  handle(error, {\n    logFn = this.logFn,\n    errorName = '',\n    onError = this.onError,\n    showDialog = this.showDialog,\n  } = {}) {\n    try {\n      if (onError?.({ error, errorName, processType: 'renderer' }) !== false) {\n        logFn({ error, errorName, showDialog });\n      }\n    } catch {\n      consoleError(error);\n    }\n  }\n\n  setOptions({ logFn, onError, preventDefault, showDialog }) {\n    if (typeof logFn === 'function') {\n      this.logFn = logFn;\n    }\n\n    if (typeof onError === 'function') {\n      this.onError = onError;\n    }\n\n    if (typeof preventDefault === 'boolean') {\n      this.preventDefault = preventDefault;\n    }\n\n    if (typeof showDialog === 'boolean') {\n      this.showDialog = showDialog;\n    }\n  }\n\n  startCatching({ onError, showDialog } = {}) {\n    if (this.isActive) {\n      return;\n    }\n\n    this.isActive = true;\n    this.setOptions({ onError, showDialog });\n\n    window.addEventListener('error', (event) => {\n      this.preventDefault && event.preventDefault?.();\n      this.handleError(event.error || event);\n    });\n    window.addEventListener('unhandledrejection', (event) => {\n      this.preventDefault && event.preventDefault?.();\n      this.handleRejection(event.reason || event);\n    });\n  }\n\n  handleError(error) {\n    this.handle(error, { errorName: 'Unhandled' });\n  }\n\n  handleRejection(reason) {\n    const error = reason instanceof Error\n      ? reason\n      : new Error(JSON.stringify(reason));\n    this.handle(error, { errorName: 'Unhandled rejection' });\n  }\n}\n\nmodule.exports = RendererErrorHandler;\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/src/renderer/lib/RendererErrorHandler.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/renderer/lib/transports/console.js":
/*!**************************************************************************!*\
  !*** ./node_modules/electron-log/src/renderer/lib/transports/console.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* eslint-disable no-console */\n\nconst { transform } = __webpack_require__(/*! ../../../core/transforms/transform */ \"./node_modules/electron-log/src/core/transforms/transform.js\");\n\nmodule.exports = consoleTransportRendererFactory;\n\nconst consoleMethods = {\n  error: console.error,\n  warn: console.warn,\n  info: console.info,\n  verbose: console.info,\n  debug: console.debug,\n  silly: console.debug,\n  log: console.log,\n};\n\nfunction consoleTransportRendererFactory(logger) {\n  return Object.assign(transport, {\n    format: '{h}:{i}:{s}.{ms}{scope} â€º {text}',\n    transforms: [formatDataFn],\n\n    writeFn({ message: { level, data } }) {\n      const consoleLogFn = consoleMethods[level] || consoleMethods.info;\n\n      // make an empty call stack\n      setTimeout(() => consoleLogFn(...data));\n    },\n  });\n\n  function transport(message) {\n    transport.writeFn({\n      message: { ...message, data: transform({ logger, message, transport }) },\n    });\n  }\n}\n\nfunction formatDataFn({\n  data = [],\n  logger = {},\n  message = {},\n  transport = {},\n}) {\n  if (typeof transport.format === 'function') {\n    return transport.format({\n      data,\n      level: message?.level || 'info',\n      logger,\n      message,\n      transport,\n    });\n  }\n\n  if (typeof transport.format !== 'string') {\n    return data;\n  }\n\n  data.unshift(transport.format);\n\n  // Concatenate the first two data items to support printf-like templates\n  if (typeof data[1] === 'string' && data[1].match(/%[1cdfiOos]/)) {\n    data = [`${data[0]} ${data[1]}`, ...data.slice(2)];\n  }\n\n  const date = message.date || new Date();\n  data[0] = data[0]\n    .replace(/\\{(\\w+)}/g, (substring, name) => {\n      switch (name) {\n        case 'level': return message.level;\n        case 'logId': return message.logId;\n        case 'scope': {\n          const scope = message.scope || logger.scope?.defaultLabel;\n          return scope ? ` (${scope})` : '';\n        }\n        case 'text': return '';\n\n        case 'y': return date.getFullYear().toString(10);\n        case 'm': return (date.getMonth() + 1).toString(10)\n          .padStart(2, '0');\n        case 'd': return date.getDate().toString(10).padStart(2, '0');\n        case 'h': return date.getHours().toString(10).padStart(2, '0');\n        case 'i': return date.getMinutes().toString(10).padStart(2, '0');\n        case 's': return date.getSeconds().toString(10).padStart(2, '0');\n        case 'ms': return date.getMilliseconds().toString(10)\n          .padStart(3, '0');\n        case 'iso': return date.toISOString();\n\n        default: return message.variables?.[name] || substring;\n      }\n    })\n    .trim();\n\n  return data;\n}\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/src/renderer/lib/transports/console.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/renderer/lib/transports/ipc.js":
/*!**********************************************************************!*\
  !*** ./node_modules/electron-log/src/renderer/lib/transports/ipc.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { transform } = __webpack_require__(/*! ../../../core/transforms/transform */ \"./node_modules/electron-log/src/core/transforms/transform.js\");\n\nmodule.exports = ipcTransportRendererFactory;\n\nconst RESTRICTED_TYPES = new Set([Promise, WeakMap, WeakSet]);\n\nfunction ipcTransportRendererFactory(logger) {\n  return Object.assign(transport, {\n    depth: 5,\n    transforms: [serializeFn],\n  });\n\n  function transport(message) {\n    if (!window.__electronLog) {\n      logger.processMessage(\n        {\n          data: ['electron-log: logger isn\\'t initialized in the main process'],\n          level: 'error',\n        },\n        { transports: ['console'] },\n      );\n      return;\n    }\n\n    try {\n      const serialized = transform({\n        initialData: message,\n        logger,\n        message,\n        transport,\n      });\n\n      __electronLog.sendToMain(serialized);\n    } catch (e) {\n      logger.transports.console({\n        data: ['electronLog.transports.ipc', e, 'data:', message.data],\n        level: 'error',\n      });\n    }\n  }\n}\n\n/**\n * Is type primitive, including null and undefined\n * @param {any} value\n * @returns {boolean}\n */\nfunction isPrimitive(value) {\n  return Object(value) !== value;\n}\n\nfunction serializeFn({\n  data,\n  depth,\n  seen = new WeakSet(),\n  transport = {},\n} = {}) {\n  const actualDepth = depth || transport.depth || 5;\n\n  if (seen.has(data)) {\n    return '[Circular]';\n  }\n\n  if (actualDepth < 1) {\n    if (isPrimitive(data)) {\n      return data;\n    }\n\n    if (Array.isArray(data)) {\n      return '[Array]';\n    }\n\n    return `[${typeof data}]`;\n  }\n\n  if (['function', 'symbol'].includes(typeof data)) {\n    return data.toString();\n  }\n\n  if (isPrimitive(data)) {\n    return data;\n  }\n\n  // Object types\n\n  if (RESTRICTED_TYPES.has(data.constructor)) {\n    return `[${data.constructor.name}]`;\n  }\n\n  if (Array.isArray(data)) {\n    return data.map((item) => serializeFn({\n      data: item,\n      depth: actualDepth - 1,\n      seen,\n    }));\n  }\n\n  if (data instanceof Date) {\n    return data.toISOString();\n  }\n\n  if (data instanceof Error) {\n    return data.stack;\n  }\n\n  if (data instanceof Map) {\n    return new Map(\n      Array\n        .from(data)\n        .map(([key, value]) => [\n          serializeFn({ data: key, depth: actualDepth - 1, seen }),\n          serializeFn({ data: value, depth: actualDepth - 1, seen }),\n        ]),\n    );\n  }\n\n  if (data instanceof Set) {\n    return new Set(\n      Array.from(data).map(\n        (val) => serializeFn({ data: val, depth: actualDepth - 1, seen }),\n      ),\n    );\n  }\n\n  seen.add(data);\n\n  return Object.fromEntries(\n    Object.entries(data).map(\n      ([key, value]) => [\n        key,\n        serializeFn({ data: value, depth: actualDepth - 1, seen }),\n      ],\n    ),\n  );\n}\n\n\n//# sourceURL=webpack://unacast/./node_modules/electron-log/src/renderer/lib/transports/ipc.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/microsoft.cognitiveservices.speech.sdk.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/microsoft.cognitiveservices.speech.sdk.js ***!
  \*******************************************************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n/* eslint-disable @typescript-eslint/no-unused-vars */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst Exports_js_1 = __webpack_require__(/*! ./src/common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\n// Note: this instantiation ensures the above import isn't\n// removed on compile. The import being absent causes an error on running\nvoid new Exports_js_1.AgentConfig();\n// Speech SDK API\n__exportStar(__webpack_require__(/*! ./src/sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\"), exports);\n\n//# sourceMappingURL=microsoft.cognitiveservices.speech.sdk.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/microsoft.cognitiveservices.speech.sdk.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ConsoleLoggingListener.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ConsoleLoggingListener.js ***!
  \**********************************************************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n/* eslint-disable @typescript-eslint/no-unsafe-assignment */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConsoleLoggingListener = void 0;\nconst fs = __importStar(__webpack_require__(/*! fs */ \"fs\"));\nconst LogLevel_js_1 = __webpack_require__(/*! ../sdk/LogLevel.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../sdk/Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nclass ConsoleLoggingListener {\n    constructor(logLevelFilter = LogLevel_js_1.LogLevel.None) {\n        this.privLogPath = undefined;\n        this.privEnableConsoleOutput = true;\n        this.privLogLevelFilter = logLevelFilter;\n    }\n    set logPath(path) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(fs.openSync, \"\\nFile System access not available\");\n        this.privLogPath = path;\n    }\n    set enableConsoleOutput(enableOutput) {\n        this.privEnableConsoleOutput = enableOutput;\n    }\n    onEvent(event) {\n        if (event.eventType >= this.privLogLevelFilter) {\n            const log = this.toString(event);\n            if (!!this.logCallback) {\n                this.logCallback(log);\n            }\n            if (!!this.privLogPath) {\n                fs.writeFileSync(this.privLogPath, log + \"\\n\", { flag: \"a+\" });\n            }\n            if (this.privEnableConsoleOutput) {\n                switch (event.eventType) {\n                    case LogLevel_js_1.LogLevel.Debug:\n                        // eslint-disable-next-line no-console\n                        console.debug(log);\n                        break;\n                    case LogLevel_js_1.LogLevel.Info:\n                        // eslint-disable-next-line no-console\n                        console.info(log);\n                        break;\n                    case LogLevel_js_1.LogLevel.Warning:\n                        // eslint-disable-next-line no-console\n                        console.warn(log);\n                        break;\n                    case LogLevel_js_1.LogLevel.Error:\n                        // eslint-disable-next-line no-console\n                        console.error(log);\n                        break;\n                    default:\n                        // eslint-disable-next-line no-console\n                        console.log(log);\n                        break;\n                }\n            }\n        }\n    }\n    toString(event) {\n        const logFragments = [\n            `${event.eventTime}`,\n            `${event.name}`,\n        ];\n        const e = event;\n        for (const prop in e) {\n            if (prop && event.hasOwnProperty(prop) &&\n                prop !== \"eventTime\" && prop !== \"eventType\" &&\n                prop !== \"eventId\" && prop !== \"name\" &&\n                prop !== \"constructor\") {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n                const value = e[prop];\n                let valueToLog = \"<NULL>\";\n                if (value !== undefined && value !== null) {\n                    if (typeof (value) === \"number\" || typeof (value) === \"string\") {\n                        valueToLog = value.toString();\n                    }\n                    else {\n                        valueToLog = JSON.stringify(value);\n                    }\n                }\n                logFragments.push(`${prop}: ${valueToLog}`);\n            }\n        }\n        return logFragments.join(\" | \");\n    }\n}\nexports.ConsoleLoggingListener = ConsoleLoggingListener;\n\n//# sourceMappingURL=ConsoleLoggingListener.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ConsoleLoggingListener.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js ***!
  \*******************************************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./ConsoleLoggingListener.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ConsoleLoggingListener.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IRecorder.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/IRecorder.js\"), exports);\n__exportStar(__webpack_require__(/*! ./MicAudioSource.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource.js\"), exports);\n__exportStar(__webpack_require__(/*! ./FileAudioSource.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/FileAudioSource.js\"), exports);\n__exportStar(__webpack_require__(/*! ./PCMRecorder.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/PCMRecorder.js\"), exports);\n__exportStar(__webpack_require__(/*! ./WebsocketConnection.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketConnection.js\"), exports);\n__exportStar(__webpack_require__(/*! ./WebsocketMessageAdapter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ReplayableAudioNode.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ReplayableAudioNode.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ProxyInfo.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ProxyInfo.js\"), exports);\n__exportStar(__webpack_require__(/*! ./RestMessageAdapter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestMessageAdapter.js\"), exports);\n__exportStar(__webpack_require__(/*! ./RestConfigBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js\"), exports);\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/FileAudioSource.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/FileAudioSource.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FileAudioSource = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst AudioStreamFormat_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js\");\nclass FileAudioSource {\n    constructor(file, filename, audioSourceId) {\n        this.privStreams = {};\n        this.privHeaderEnd = 44;\n        this.privId = audioSourceId ? audioSourceId : Exports_js_2.createNoDashGuid();\n        this.privEvents = new Exports_js_2.EventSource();\n        this.privSource = file;\n        if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && this.privSource instanceof Blob) {\n            this.privFilename = file.name;\n        }\n        else {\n            this.privFilename = filename || \"unknown.wav\";\n        }\n        // Read the header.\n        this.privAudioFormatPromise = this.readHeader();\n    }\n    get format() {\n        return this.privAudioFormatPromise;\n    }\n    turnOn() {\n        if (this.privFilename.lastIndexOf(\".wav\") !== this.privFilename.length - 4) {\n            const errorMsg = this.privFilename + \" is not supported. Only WAVE files are allowed at the moment.\";\n            this.onEvent(new Exports_js_2.AudioSourceErrorEvent(errorMsg, \"\"));\n            return Promise.reject(errorMsg);\n        }\n        this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id\n        this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));\n        return;\n    }\n    id() {\n        return this.privId;\n    }\n    async attach(audioNodeId) {\n        this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n        const stream = await this.upload(audioNodeId);\n        this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n        return Promise.resolve({\n            detach: async () => {\n                stream.readEnded();\n                delete this.privStreams[audioNodeId];\n                this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n                await this.turnOff();\n            },\n            id: () => audioNodeId,\n            read: () => stream.read(),\n        });\n    }\n    detach(audioNodeId) {\n        if (audioNodeId && this.privStreams[audioNodeId]) {\n            this.privStreams[audioNodeId].close();\n            delete this.privStreams[audioNodeId];\n            this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n        }\n    }\n    turnOff() {\n        for (const streamId in this.privStreams) {\n            if (streamId) {\n                const stream = this.privStreams[streamId];\n                if (stream && !stream.isClosed) {\n                    stream.close();\n                }\n            }\n        }\n        this.onEvent(new Exports_js_2.AudioSourceOffEvent(this.privId)); // no stream now\n        return Promise.resolve();\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return this.privAudioFormatPromise.then((result) => (Promise.resolve({\n            bitspersample: result.bitsPerSample,\n            channelcount: result.channels,\n            connectivity: Exports_js_1.connectivity.Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"File\",\n            samplerate: result.samplesPerSec,\n            type: Exports_js_1.type.File,\n        })));\n    }\n    readHeader() {\n        // Read the wave header.\n        const maxHeaderSize = 4296;\n        const header = this.privSource.slice(0, maxHeaderSize);\n        const headerResult = new Exports_js_2.Deferred();\n        const processHeader = (header) => {\n            const view = new DataView(header);\n            const getWord = (index) => String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));\n            // RIFF 4 bytes.\n            if (\"RIFF\" !== getWord(0)) {\n                headerResult.reject(\"Invalid WAV header in file, RIFF was not found\");\n                return;\n            }\n            // length, 4 bytes\n            // RIFF Type & fmt 8 bytes\n            if (\"WAVE\" !== getWord(8) || \"fmt \" !== getWord(12)) {\n                headerResult.reject(\"Invalid WAV header in file, WAVEfmt was not found\");\n                return;\n            }\n            const formatSize = view.getInt32(16, true);\n            const channelCount = view.getUint16(22, true);\n            const sampleRate = view.getUint32(24, true);\n            const bitsPerSample = view.getUint16(34, true);\n            // Confirm if header is 44 bytes long.\n            let pos = 36 + Math.max(formatSize - 16, 0);\n            for (; getWord(pos) !== \"data\"; pos += 2) {\n                if (pos > maxHeaderSize - 8) {\n                    headerResult.reject(\"Invalid WAV header in file, data block was not found\");\n                    return;\n                }\n            }\n            this.privHeaderEnd = pos + 8;\n            headerResult.resolve(AudioStreamFormat_js_1.AudioStreamFormat.getWaveFormatPCM(sampleRate, bitsPerSample, channelCount));\n        };\n        if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && header instanceof Blob) {\n            const reader = new FileReader();\n            reader.onload = (event) => {\n                const header = event.target.result;\n                processHeader(header);\n            };\n            reader.readAsArrayBuffer(header);\n        }\n        else {\n            const h = header;\n            processHeader(h.buffer.slice(h.byteOffset, h.byteOffset + h.byteLength));\n        }\n        return headerResult.promise;\n    }\n    async upload(audioNodeId) {\n        const onerror = (error) => {\n            const errorMsg = `Error occurred while processing '${this.privFilename}'. ${error}`;\n            this.onEvent(new Exports_js_2.AudioStreamNodeErrorEvent(this.privId, audioNodeId, errorMsg));\n            throw new Error(errorMsg);\n        };\n        try {\n            await this.turnOn();\n            const format = await this.privAudioFormatPromise;\n            const stream = new Exports_js_2.ChunkedArrayBufferStream(format.avgBytesPerSec / 10, audioNodeId);\n            this.privStreams[audioNodeId] = stream;\n            const chunk = this.privSource.slice(this.privHeaderEnd);\n            const processFile = (buff) => {\n                if (stream.isClosed) {\n                    return; // output stream was closed (somebody called TurnOff). We're done here.\n                }\n                stream.writeStreamChunk({\n                    buffer: buff,\n                    isEnd: false,\n                    timeReceived: Date.now(),\n                });\n                stream.close();\n            };\n            if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && chunk instanceof Blob) {\n                const reader = new FileReader();\n                reader.onerror = (ev) => onerror(ev.toString());\n                reader.onload = (event) => {\n                    const fileBuffer = event.target.result;\n                    processFile(fileBuffer);\n                };\n                reader.readAsArrayBuffer(chunk);\n            }\n            else {\n                const c = chunk;\n                processFile(c.buffer.slice(c.byteOffset, c.byteOffset + c.byteLength));\n            }\n            return stream;\n        }\n        catch (e) {\n            onerror(e);\n        }\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        Exports_js_2.Events.instance.onEvent(event);\n    }\n}\nexports.FileAudioSource = FileAudioSource;\n\n//# sourceMappingURL=FileAudioSource.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/FileAudioSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/IRecorder.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/IRecorder.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IRecorder.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/IRecorder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MicAudioSource = exports.AudioWorkletSourceURLPropertyName = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst AudioStreamFormat_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js\");\nexports.AudioWorkletSourceURLPropertyName = \"MICROPHONE-WorkletSourceUrl\";\nclass MicAudioSource {\n    constructor(privRecorder, deviceId, audioSourceId, mediaStream) {\n        this.privRecorder = privRecorder;\n        this.deviceId = deviceId;\n        this.privStreams = {};\n        this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;\n        this.privId = audioSourceId ? audioSourceId : Exports_js_2.createNoDashGuid();\n        this.privEvents = new Exports_js_2.EventSource();\n        this.privMediaStream = mediaStream || null;\n        this.privIsClosing = false;\n    }\n    get format() {\n        return Promise.resolve(MicAudioSource.AUDIOFORMAT);\n    }\n    turnOn() {\n        if (this.privInitializeDeferral) {\n            return this.privInitializeDeferral.promise;\n        }\n        this.privInitializeDeferral = new Exports_js_2.Deferred();\n        try {\n            this.createAudioContext();\n        }\n        catch (error) {\n            if (error instanceof Error) {\n                const typedError = error;\n                this.privInitializeDeferral.reject(typedError.name + \": \" + typedError.message);\n            }\n            else {\n                this.privInitializeDeferral.reject(error);\n            }\n            return this.privInitializeDeferral.promise;\n        }\n        const nav = window.navigator;\n        let getUserMedia = (\n        // eslint-disable-next-line\n        nav.getUserMedia ||\n            nav.webkitGetUserMedia ||\n            nav.mozGetUserMedia ||\n            nav.msGetUserMedia);\n        if (!!nav.mediaDevices) {\n            getUserMedia = (constraints, successCallback, errorCallback) => {\n                nav.mediaDevices\n                    .getUserMedia(constraints)\n                    .then(successCallback)\n                    .catch(errorCallback);\n            };\n        }\n        if (!getUserMedia) {\n            const errorMsg = \"Browser does not support getUserMedia.\";\n            this.privInitializeDeferral.reject(errorMsg);\n            this.onEvent(new Exports_js_2.AudioSourceErrorEvent(errorMsg, \"\")); // mic initialized error - no streamid at this point\n        }\n        else {\n            const next = () => {\n                this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id\n                if (this.privMediaStream && this.privMediaStream.active) {\n                    this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));\n                    this.privInitializeDeferral.resolve();\n                }\n                else {\n                    getUserMedia({ audio: this.deviceId ? { deviceId: this.deviceId } : true, video: false }, (mediaStream) => {\n                        this.privMediaStream = mediaStream;\n                        this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));\n                        this.privInitializeDeferral.resolve();\n                    }, (error) => {\n                        const errorMsg = `Error occurred during microphone initialization: ${error}`;\n                        this.privInitializeDeferral.reject(errorMsg);\n                        this.onEvent(new Exports_js_2.AudioSourceErrorEvent(this.privId, errorMsg));\n                    });\n                }\n            };\n            if (this.privContext.state === \"suspended\") {\n                // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.\n                // https://github.com/WebAudio/web-audio-api/issues/790\n                this.privContext.resume()\n                    .then(next)\n                    .catch((reason) => {\n                    this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);\n                });\n            }\n            else {\n                next();\n            }\n        }\n        return this.privInitializeDeferral.promise;\n    }\n    id() {\n        return this.privId;\n    }\n    attach(audioNodeId) {\n        this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n        return this.listen(audioNodeId).then((stream) => {\n            this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n            return {\n                detach: async () => {\n                    stream.readEnded();\n                    delete this.privStreams[audioNodeId];\n                    this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n                    return this.turnOff();\n                },\n                id: () => audioNodeId,\n                read: () => stream.read(),\n            };\n        });\n    }\n    detach(audioNodeId) {\n        if (audioNodeId && this.privStreams[audioNodeId]) {\n            this.privStreams[audioNodeId].close();\n            delete this.privStreams[audioNodeId];\n            this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n        }\n    }\n    async turnOff() {\n        for (const streamId in this.privStreams) {\n            if (streamId) {\n                const stream = this.privStreams[streamId];\n                if (stream) {\n                    stream.close();\n                }\n            }\n        }\n        this.onEvent(new Exports_js_2.AudioSourceOffEvent(this.privId)); // no stream now\n        if (this.privInitializeDeferral) {\n            // Correctly handle when browser forces mic off before turnOn() completes\n            // eslint-disable-next-line @typescript-eslint/await-thenable\n            await this.privInitializeDeferral;\n            this.privInitializeDeferral = null;\n        }\n        await this.destroyAudioContext();\n        return;\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return this.getMicrophoneLabel().then((label) => ({\n            bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,\n            channelcount: MicAudioSource.AUDIOFORMAT.channels,\n            connectivity: Exports_js_1.connectivity.Unknown,\n            manufacturer: \"Speech SDK\",\n            model: label,\n            samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,\n            type: Exports_js_1.type.Microphones,\n        }));\n    }\n    setProperty(name, value) {\n        if (name === exports.AudioWorkletSourceURLPropertyName) {\n            this.privRecorder.setWorkletUrl(value);\n        }\n        else {\n            throw new Error(\"Property '\" + name + \"' is not supported on Microphone.\");\n        }\n    }\n    getMicrophoneLabel() {\n        const defaultMicrophoneName = \"microphone\";\n        // If we did this already, return the value.\n        if (this.privMicrophoneLabel !== undefined) {\n            return Promise.resolve(this.privMicrophoneLabel);\n        }\n        // If the stream isn't currently running, we can't query devices because security.\n        if (this.privMediaStream === undefined || !this.privMediaStream.active) {\n            return Promise.resolve(defaultMicrophoneName);\n        }\n        // Setup a default\n        this.privMicrophoneLabel = defaultMicrophoneName;\n        // Get the id of the device running the audio track.\n        const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;\n        // If the browser doesn't support getting the device ID, set a default and return.\n        if (undefined === microphoneDeviceId) {\n            return Promise.resolve(this.privMicrophoneLabel);\n        }\n        const deferred = new Exports_js_2.Deferred();\n        // Enumerate the media devices.\n        navigator.mediaDevices.enumerateDevices().then((devices) => {\n            for (const device of devices) {\n                if (device.deviceId === microphoneDeviceId) {\n                    // Found the device\n                    this.privMicrophoneLabel = device.label;\n                    break;\n                }\n            }\n            deferred.resolve(this.privMicrophoneLabel);\n        }, () => deferred.resolve(this.privMicrophoneLabel));\n        return deferred.promise;\n    }\n    async listen(audioNodeId) {\n        await this.turnOn();\n        const stream = new Exports_js_2.ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);\n        this.privStreams[audioNodeId] = stream;\n        try {\n            this.privRecorder.record(this.privContext, this.privMediaStream, stream);\n        }\n        catch (error) {\n            this.onEvent(new Exports_js_2.AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));\n            throw error;\n        }\n        const result = stream;\n        return result;\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        Exports_js_2.Events.instance.onEvent(event);\n    }\n    createAudioContext() {\n        if (!!this.privContext) {\n            return;\n        }\n        this.privContext = AudioStreamFormat_js_1.AudioStreamFormatImpl.getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);\n    }\n    async destroyAudioContext() {\n        if (!this.privContext) {\n            return;\n        }\n        this.privRecorder.releaseMediaResources(this.privContext);\n        // This pattern brought to you by a bug in the TypeScript compiler where it\n        // confuses the (\"close\" in this.privContext) with this.privContext always being null as the alternate.\n        // https://github.com/Microsoft/TypeScript/issues/11498\n        let hasClose = false;\n        if (\"close\" in this.privContext) {\n            hasClose = true;\n        }\n        if (hasClose) {\n            if (!this.privIsClosing) {\n                // The audio context close may take enough time that the close is called twice\n                this.privIsClosing = true;\n                await this.privContext.close();\n                this.privContext = null;\n                this.privIsClosing = false;\n            }\n        }\n        else if (null !== this.privContext && this.privContext.state === \"running\") {\n            // Suspend actually takes a callback, but analogous to the\n            // resume method, it'll be only fired if suspend is called\n            // in a direct response to a user action. The later is not always\n            // the case, as TurnOff is also called, when we receive an\n            // end-of-speech message from the service. So, doing a best effort\n            // fire-and-forget here.\n            await this.privContext.suspend();\n        }\n    }\n}\nexports.MicAudioSource = MicAudioSource;\nMicAudioSource.AUDIOFORMAT = AudioStreamFormat_js_1.AudioStreamFormat.getDefaultInputFormat();\n\n//# sourceMappingURL=MicAudioSource.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/PCMRecorder.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/PCMRecorder.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PcmRecorder = void 0;\nconst Exports_1 = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nclass PcmRecorder {\n    constructor(stopInputOnRelease) {\n        this.privStopInputOnRelease = stopInputOnRelease;\n    }\n    record(context, mediaStream, outputStream) {\n        const desiredSampleRate = 16000;\n        const waveStreamEncoder = new Exports_1.RiffPcmEncoder(context.sampleRate, desiredSampleRate);\n        const micInput = context.createMediaStreamSource(mediaStream);\n        const attachScriptProcessor = () => {\n            // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n            const scriptNode = (() => {\n                let bufferSize = 0;\n                try {\n                    return context.createScriptProcessor(bufferSize, 1, 1);\n                }\n                catch (error) {\n                    // Webkit (<= version 31) requires a valid bufferSize.\n                    bufferSize = 2048;\n                    let audioSampleRate = context.sampleRate;\n                    while (bufferSize < 16384 && audioSampleRate >= (2 * desiredSampleRate)) {\n                        bufferSize <<= 1;\n                        audioSampleRate >>= 1;\n                    }\n                    return context.createScriptProcessor(bufferSize, 1, 1);\n                }\n            })();\n            scriptNode.onaudioprocess = (event) => {\n                const inputFrame = event.inputBuffer.getChannelData(0);\n                if (outputStream && !outputStream.isClosed) {\n                    const waveFrame = waveStreamEncoder.encode(inputFrame);\n                    if (!!waveFrame) {\n                        outputStream.writeStreamChunk({\n                            buffer: waveFrame,\n                            isEnd: false,\n                            timeReceived: Date.now(),\n                        });\n                    }\n                }\n            };\n            micInput.connect(scriptNode);\n            scriptNode.connect(context.destination);\n            this.privMediaResources = {\n                scriptProcessorNode: scriptNode,\n                source: micInput,\n                stream: mediaStream,\n            };\n        };\n        // https://webaudio.github.io/web-audio-api/#audioworklet\n        // Using AudioWorklet to improve audio quality and avoid audio glitches due to blocking the UI thread\n        const skipAudioWorklet = !!this.privSpeechProcessorScript && this.privSpeechProcessorScript.toLowerCase() === \"ignore\";\n        if (!!context.audioWorklet && !skipAudioWorklet) {\n            if (!this.privSpeechProcessorScript) {\n                const workletScript = `class SP extends AudioWorkletProcessor {\r\n                    constructor(options) {\r\n                      super(options);\r\n                    }\r\n                    process(inputs, outputs) {\r\n                      const input = inputs[0];\r\n                      const output = [];\r\n                      for (let channel = 0; channel < input.length; channel += 1) {\r\n                        output[channel] = input[channel];\r\n                      }\r\n                      this.port.postMessage(output[0]);\r\n                      return true;\r\n                    }\r\n                  }\r\n                  registerProcessor('speech-processor', SP);`;\n                const blob = new Blob([workletScript], { type: \"application/javascript; charset=utf-8\" });\n                this.privSpeechProcessorScript = URL.createObjectURL(blob);\n            }\n            context.audioWorklet\n                .addModule(this.privSpeechProcessorScript)\n                .then(() => {\n                const workletNode = new AudioWorkletNode(context, \"speech-processor\");\n                workletNode.port.onmessage = (ev) => {\n                    const inputFrame = ev.data;\n                    if (outputStream && !outputStream.isClosed) {\n                        const waveFrame = waveStreamEncoder.encode(inputFrame);\n                        if (!!waveFrame) {\n                            outputStream.writeStreamChunk({\n                                buffer: waveFrame,\n                                isEnd: false,\n                                timeReceived: Date.now(),\n                            });\n                        }\n                    }\n                };\n                micInput.connect(workletNode);\n                workletNode.connect(context.destination);\n                this.privMediaResources = {\n                    scriptProcessorNode: workletNode,\n                    source: micInput,\n                    stream: mediaStream,\n                };\n            })\n                .catch(() => {\n                attachScriptProcessor();\n            });\n        }\n        else {\n            try {\n                attachScriptProcessor();\n            }\n            catch (err) {\n                throw new Error(`Unable to start audio worklet node for PCMRecorder: ${err}`);\n            }\n        }\n    }\n    releaseMediaResources(context) {\n        if (this.privMediaResources) {\n            if (this.privMediaResources.scriptProcessorNode) {\n                this.privMediaResources.scriptProcessorNode.disconnect(context.destination);\n                this.privMediaResources.scriptProcessorNode = null;\n            }\n            if (this.privMediaResources.source) {\n                this.privMediaResources.source.disconnect();\n                if (this.privStopInputOnRelease) {\n                    this.privMediaResources.stream.getTracks().forEach((track) => track.stop());\n                }\n                this.privMediaResources.source = null;\n            }\n        }\n    }\n    setWorkletUrl(url) {\n        this.privSpeechProcessorScript = url;\n    }\n}\nexports.PcmRecorder = PcmRecorder;\n\n//# sourceMappingURL=PCMRecorder.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/PCMRecorder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ProxyInfo.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ProxyInfo.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ProxyInfo = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass ProxyInfo {\n    constructor(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.privProxyHostName = proxyHostName;\n        this.privProxyPort = proxyPort;\n        this.privProxyUserName = proxyUserName;\n        this.privProxyPassword = proxyPassword;\n    }\n    static fromParameters(parameters) {\n        return new ProxyInfo(parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyHostName), parseInt(parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyPort), 10), parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyUserName), parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyPassword));\n    }\n    static fromRecognizerConfig(config) {\n        return this.fromParameters(config.parameters);\n    }\n    get HostName() {\n        return this.privProxyHostName;\n    }\n    get Port() {\n        return this.privProxyPort;\n    }\n    get UserName() {\n        return this.privProxyUserName;\n    }\n    get Password() {\n        return this.privProxyPassword;\n    }\n}\nexports.ProxyInfo = ProxyInfo;\n\n//# sourceMappingURL=ProxyInfo.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ProxyInfo.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ReplayableAudioNode.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ReplayableAudioNode.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReplayableAudioNode = void 0;\nclass ReplayableAudioNode {\n    constructor(audioSource, bytesPerSecond) {\n        this.privBuffers = [];\n        this.privReplayOffset = 0;\n        this.privLastShrinkOffset = 0;\n        this.privBufferStartOffset = 0;\n        this.privBufferSerial = 0;\n        this.privBufferedBytes = 0;\n        this.privReplay = false;\n        this.privLastChunkAcquiredTime = 0;\n        this.privAudioNode = audioSource;\n        this.privBytesPerSecond = bytesPerSecond;\n    }\n    id() {\n        return this.privAudioNode.id();\n    }\n    // Reads and returns the next chunk of audio buffer.\n    // If replay of existing buffers are needed, read() will first seek and replay\n    // existing content, and upoin completion it will read new content from the underlying\n    // audio node, saving that content into the replayable buffers.\n    read() {\n        // if there is a replay request to honor.\n        if (!!this.privReplay && this.privBuffers.length !== 0) {\n            // Find the start point in the buffers.\n            // Offsets are in 100ns increments.\n            // So how many bytes do we need to seek to get the right offset?\n            const offsetToSeek = this.privReplayOffset - this.privBufferStartOffset;\n            let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);\n            if (0 !== (bytesToSeek % 2)) {\n                bytesToSeek++;\n            }\n            let i = 0;\n            while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {\n                bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;\n            }\n            if (i < this.privBuffers.length) {\n                const retVal = this.privBuffers[i].chunk.buffer.slice(bytesToSeek);\n                this.privReplayOffset += (retVal.byteLength / this.privBytesPerSecond) * 1e+7;\n                // If we've reached the end of the buffers, stop replaying.\n                if (i === this.privBuffers.length - 1) {\n                    this.privReplay = false;\n                }\n                return Promise.resolve({\n                    buffer: retVal,\n                    isEnd: false,\n                    timeReceived: this.privBuffers[i].chunk.timeReceived,\n                });\n            }\n        }\n        return this.privAudioNode.read()\n            .then((result) => {\n            if (result && result.buffer) {\n                this.privBuffers.push(new BufferEntry(result, this.privBufferSerial++, this.privBufferedBytes));\n                this.privBufferedBytes += result.buffer.byteLength;\n            }\n            return result;\n        });\n    }\n    detach() {\n        this.privBuffers = undefined;\n        return this.privAudioNode.detach();\n    }\n    replay() {\n        if (this.privBuffers && 0 !== this.privBuffers.length) {\n            this.privReplay = true;\n            this.privReplayOffset = this.privLastShrinkOffset;\n        }\n    }\n    // Shrinks the existing audio buffers to start at the new offset, or at the\n    // beginning of the buffer closest to the requested offset.\n    // A replay request will start from the last shrink point.\n    shrinkBuffers(offset) {\n        if (this.privBuffers === undefined || this.privBuffers.length === 0) {\n            return;\n        }\n        this.privLastShrinkOffset = offset;\n        // Find the start point in the buffers.\n        // Offsets are in 100ns increments.\n        // So how many bytes do we need to seek to get the right offset?\n        const offsetToSeek = offset - this.privBufferStartOffset;\n        let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);\n        let i = 0;\n        while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {\n            bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;\n        }\n        this.privBufferStartOffset = Math.round(offset - ((bytesToSeek / this.privBytesPerSecond) * 1e+7));\n        this.privBuffers = this.privBuffers.slice(i);\n    }\n    // Finds the time a buffer of audio was first seen by offset.\n    findTimeAtOffset(offset) {\n        if (offset < this.privBufferStartOffset || this.privBuffers === undefined) {\n            return 0;\n        }\n        for (const value of this.privBuffers) {\n            const startOffset = (value.byteOffset / this.privBytesPerSecond) * 1e7;\n            const endOffset = startOffset + ((value.chunk.buffer.byteLength / this.privBytesPerSecond) * 1e7);\n            if (offset >= startOffset && offset <= endOffset) {\n                return value.chunk.timeReceived;\n            }\n        }\n        return 0;\n    }\n}\nexports.ReplayableAudioNode = ReplayableAudioNode;\n// Primary use of this class is to help debugging problems with the replay\n// code. If the memory cost of alloc / dealloc gets too much, drop it and just use\n// the ArrayBuffer directly.\nclass BufferEntry {\n    constructor(chunk, serial, byteOffset) {\n        this.chunk = chunk;\n        this.serial = serial;\n        this.byteOffset = byteOffset;\n    }\n}\n\n//# sourceMappingURL=ReplayableAudioNode.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ReplayableAudioNode.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RestConfigBase = void 0;\nclass RestConfigBase {\n    static get requestOptions() {\n        return RestConfigBase.privDefaultRequestOptions;\n    }\n    static get configParams() {\n        return RestConfigBase.privDefaultParams;\n    }\n    static get restErrors() {\n        return RestConfigBase.privRestErrors;\n    }\n}\nexports.RestConfigBase = RestConfigBase;\nRestConfigBase.privDefaultRequestOptions = {\n    headers: {\n        Accept: \"application/json\",\n    },\n    ignoreCache: false,\n    timeout: 10000,\n};\nRestConfigBase.privRestErrors = {\n    authInvalidSubscriptionKey: \"You must specify either an authentication token to use, or a Cognitive Speech subscription key.\",\n    authInvalidSubscriptionRegion: \"You must specify the Cognitive Speech region to use.\",\n    invalidArgs: \"Required input not found: {arg}.\",\n    invalidCreateJoinConversationResponse: \"Creating/Joining conversation failed with HTTP {status}.\",\n    invalidParticipantRequest: \"The requested participant was not found.\",\n    permissionDeniedConnect: \"Required credentials not found.\",\n    permissionDeniedConversation: \"Invalid operation: only the host can {command} the conversation.\",\n    permissionDeniedParticipant: \"Invalid operation: only the host can {command} a participant.\",\n    permissionDeniedSend: \"Invalid operation: the conversation is not in a connected state.\",\n    permissionDeniedStart: \"Invalid operation: there is already an active conversation.\",\n};\nRestConfigBase.privDefaultParams = {\n    apiVersion: \"api-version\",\n    authorization: \"Authorization\",\n    clientAppId: \"X-ClientAppId\",\n    contentTypeKey: \"Content-Type\",\n    correlationId: \"X-CorrelationId\",\n    languageCode: \"language\",\n    nickname: \"nickname\",\n    profanity: \"profanity\",\n    requestId: \"X-RequestId\",\n    roomId: \"roomid\",\n    sessionToken: \"token\",\n    subscriptionKey: \"Ocp-Apim-Subscription-Key\",\n    subscriptionRegion: \"Ocp-Apim-Subscription-Region\",\n    token: \"X-CapitoToken\",\n};\n\n//# sourceMappingURL=RestConfigBase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestMessageAdapter.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestMessageAdapter.js ***!
  \******************************************************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RestMessageAdapter = exports.RestRequestType = void 0;\nconst bent_1 = __importDefault(__webpack_require__(/*! bent */ \"./node_modules/bent/src/browser.js\"));\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nvar RestRequestType;\n(function (RestRequestType) {\n    RestRequestType[\"Get\"] = \"GET\";\n    RestRequestType[\"Post\"] = \"POST\";\n    RestRequestType[\"Delete\"] = \"DELETE\";\n    RestRequestType[\"File\"] = \"file\";\n})(RestRequestType = exports.RestRequestType || (exports.RestRequestType = {}));\n// accept rest operations via request method and return abstracted objects from server response\nclass RestMessageAdapter {\n    constructor(configParams) {\n        if (!configParams) {\n            throw new Exports_js_1.ArgumentNullError(\"configParams\");\n        }\n        this.privHeaders = configParams.headers;\n        this.privIgnoreCache = configParams.ignoreCache;\n    }\n    static extractHeaderValue(headerKey, headers) {\n        let headerValue = \"\";\n        try {\n            const arr = headers.trim().split(/[\\r\\n]+/);\n            const headerMap = {};\n            arr.forEach((line) => {\n                const parts = line.split(\": \");\n                const header = parts.shift().toLowerCase();\n                const value = parts.join(\": \");\n                headerMap[header] = value;\n            });\n            headerValue = headerMap[headerKey.toLowerCase()];\n        }\n        catch (e) {\n            // ignore the error\n        }\n        return headerValue;\n    }\n    set options(configParams) {\n        this.privHeaders = configParams.headers;\n        this.privIgnoreCache = configParams.ignoreCache;\n    }\n    setHeaders(key, value) {\n        this.privHeaders[key] = value;\n    }\n    request(method, uri, queryParams = {}, body = null) {\n        const responseReceivedDeferral = new Exports_js_1.Deferred();\n        const requestCommand = method === RestRequestType.File ? \"POST\" : method;\n        const handleRestResponse = (data, j = {}) => {\n            const d = data;\n            return {\n                data: JSON.stringify(j),\n                headers: JSON.stringify(data.headers),\n                json: j,\n                ok: data.statusCode >= 200 && data.statusCode < 300,\n                status: data.statusCode,\n                statusText: j.error ? j.error.message : d.statusText ? d.statusText : d.statusMessage\n            };\n        };\n        const send = (postData) => {\n            const sendRequest = bent_1.default(uri, requestCommand, this.privHeaders, 200, 201, 202, 204, 400, 401, 402, 403, 404);\n            const params = this.queryParams(queryParams) === \"\" ? \"\" : `?${this.queryParams(queryParams)}`;\n            sendRequest(params, postData).then(async (data) => {\n                if (method === RestRequestType.Delete || data.statusCode === 204) {\n                    // No JSON from Delete and reset (204) operations\n                    responseReceivedDeferral.resolve(handleRestResponse(data));\n                }\n                else {\n                    try {\n                        const j = await data.json();\n                        responseReceivedDeferral.resolve(handleRestResponse(data, j));\n                    }\n                    catch {\n                        responseReceivedDeferral.resolve(handleRestResponse(data));\n                    }\n                }\n            }).catch((error) => {\n                responseReceivedDeferral.reject(error);\n            });\n        };\n        if (this.privIgnoreCache) {\n            this.privHeaders[\"Cache-Control\"] = \"no-cache\";\n        }\n        if (method === RestRequestType.Post && body) {\n            this.privHeaders[\"content-type\"] = \"application/json\";\n            this.privHeaders[\"Content-Type\"] = \"application/json\";\n        }\n        send(body);\n        return responseReceivedDeferral.promise;\n    }\n    queryParams(params = {}) {\n        return Object.keys(params)\n            .map((k) => encodeURIComponent(k) + \"=\" + encodeURIComponent(params[k]))\n            .join(\"&\");\n    }\n}\nexports.RestMessageAdapter = RestMessageAdapter;\n\n//# sourceMappingURL=RestMessageAdapter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestMessageAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketConnection.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketConnection.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WebsocketConnection = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst WebsocketMessageAdapter_js_1 = __webpack_require__(/*! ./WebsocketMessageAdapter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js\");\nclass WebsocketConnection {\n    constructor(uri, queryParameters, headers, messageFormatter, proxyInfo, enableCompression = false, connectionId) {\n        this.privIsDisposed = false;\n        if (!uri) {\n            throw new Exports_js_1.ArgumentNullError(\"uri\");\n        }\n        if (!messageFormatter) {\n            throw new Exports_js_1.ArgumentNullError(\"messageFormatter\");\n        }\n        this.privMessageFormatter = messageFormatter;\n        let queryParams = \"\";\n        let i = 0;\n        if (queryParameters) {\n            for (const paramName in queryParameters) {\n                if (paramName) {\n                    queryParams += ((i === 0) && (uri.indexOf(\"?\") === -1)) ? \"?\" : \"&\";\n                    const key = encodeURIComponent(paramName);\n                    queryParams += key;\n                    let val = queryParameters[paramName];\n                    if (val) {\n                        val = encodeURIComponent(val);\n                        queryParams += `=${val}`;\n                    }\n                    i++;\n                }\n            }\n        }\n        if (headers) {\n            for (const headerName in headers) {\n                if (headerName) {\n                    queryParams += ((i === 0) && (uri.indexOf(\"?\") === -1)) ? \"?\" : \"&\";\n                    const val = encodeURIComponent(headers[headerName]);\n                    queryParams += `${headerName}=${val}`;\n                    i++;\n                }\n            }\n        }\n        this.privUri = uri + queryParams;\n        this.privId = connectionId ? connectionId : Exports_js_1.createNoDashGuid();\n        this.privConnectionMessageAdapter = new WebsocketMessageAdapter_js_1.WebsocketMessageAdapter(this.privUri, this.id, this.privMessageFormatter, proxyInfo, headers, enableCompression);\n    }\n    async dispose() {\n        this.privIsDisposed = true;\n        if (this.privConnectionMessageAdapter) {\n            await this.privConnectionMessageAdapter.close();\n        }\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    get id() {\n        return this.privId;\n    }\n    get uri() {\n        return this.privUri;\n    }\n    state() {\n        return this.privConnectionMessageAdapter.state;\n    }\n    open() {\n        return this.privConnectionMessageAdapter.open();\n    }\n    send(message) {\n        return this.privConnectionMessageAdapter.send(message);\n    }\n    read() {\n        return this.privConnectionMessageAdapter.read();\n    }\n    get events() {\n        return this.privConnectionMessageAdapter.events;\n    }\n}\nexports.WebsocketConnection = WebsocketConnection;\n\n//# sourceMappingURL=WebsocketConnection.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketConnection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js ***!
  \***********************************************************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WebsocketMessageAdapter = void 0;\nconst net = __importStar(__webpack_require__(/*! net */ \"net\"));\nconst tls = __importStar(__webpack_require__(/*! tls */ \"tls\"));\nconst agent_base_1 = __importDefault(__webpack_require__(/*! agent-base */ \"?875c\"));\nconst https_proxy_agent_1 = __importDefault(__webpack_require__(/*! https-proxy-agent */ \"?a523\"));\nconst ws_1 = __importDefault(__webpack_require__(/*! ws */ \"?3dbe\"));\nconst HeaderNames_js_1 = __webpack_require__(/*! ../common.speech/HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nclass WebsocketMessageAdapter {\n    constructor(uri, connectionId, messageFormatter, proxyInfo, headers, enableCompression) {\n        if (!uri) {\n            throw new Exports_js_1.ArgumentNullError(\"uri\");\n        }\n        if (!messageFormatter) {\n            throw new Exports_js_1.ArgumentNullError(\"messageFormatter\");\n        }\n        this.proxyInfo = proxyInfo;\n        this.privConnectionEvents = new Exports_js_1.EventSource();\n        this.privConnectionId = connectionId;\n        this.privMessageFormatter = messageFormatter;\n        this.privConnectionState = Exports_js_1.ConnectionState.None;\n        this.privUri = uri;\n        this.privHeaders = headers;\n        this.privEnableCompression = enableCompression;\n        // Add the connection ID to the headers\n        this.privHeaders[HeaderNames_js_1.HeaderNames.ConnectionId] = this.privConnectionId;\n        this.privLastErrorReceived = \"\";\n    }\n    get state() {\n        return this.privConnectionState;\n    }\n    open() {\n        if (this.privConnectionState === Exports_js_1.ConnectionState.Disconnected) {\n            return Promise.reject(`Cannot open a connection that is in ${this.privConnectionState} state`);\n        }\n        if (this.privConnectionEstablishDeferral) {\n            return this.privConnectionEstablishDeferral.promise;\n        }\n        this.privConnectionEstablishDeferral = new Exports_js_1.Deferred();\n        this.privCertificateValidatedDeferral = new Exports_js_1.Deferred();\n        this.privConnectionState = Exports_js_1.ConnectionState.Connecting;\n        try {\n            if (typeof WebSocket !== \"undefined\" && !WebsocketMessageAdapter.forceNpmWebSocket) {\n                // Browser handles cert checks.\n                this.privCertificateValidatedDeferral.resolve();\n                this.privWebsocketClient = new WebSocket(this.privUri);\n            }\n            else {\n                const options = { headers: this.privHeaders, perMessageDeflate: this.privEnableCompression };\n                // The ocsp library will handle validation for us and fail the connection if needed.\n                this.privCertificateValidatedDeferral.resolve();\n                options.agent = this.getAgent();\n                // Workaround for https://github.com/microsoft/cognitive-services-speech-sdk-js/issues/465\n                // Which is root caused by https://github.com/TooTallNate/node-agent-base/issues/61\n                const uri = new URL(this.privUri);\n                let protocol = uri.protocol;\n                if (protocol?.toLocaleLowerCase() === \"wss:\") {\n                    protocol = \"https:\";\n                }\n                else if (protocol?.toLocaleLowerCase() === \"ws:\") {\n                    protocol = \"http:\";\n                }\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n                options.agent.protocol = protocol;\n                this.privWebsocketClient = new ws_1.default(this.privUri, options);\n            }\n            this.privWebsocketClient.binaryType = \"arraybuffer\";\n            this.privReceivingMessageQueue = new Exports_js_1.Queue();\n            this.privDisconnectDeferral = new Exports_js_1.Deferred();\n            this.privSendMessageQueue = new Exports_js_1.Queue();\n            this.processSendQueue().catch((reason) => {\n                Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));\n            });\n        }\n        catch (error) {\n            this.privConnectionEstablishDeferral.resolve(new Exports_js_1.ConnectionOpenResponse(500, error));\n            return this.privConnectionEstablishDeferral.promise;\n        }\n        this.onEvent(new Exports_js_1.ConnectionStartEvent(this.privConnectionId, this.privUri));\n        this.privWebsocketClient.onopen = () => {\n            this.privCertificateValidatedDeferral.promise.then(() => {\n                this.privConnectionState = Exports_js_1.ConnectionState.Connected;\n                this.onEvent(new Exports_js_1.ConnectionEstablishedEvent(this.privConnectionId));\n                this.privConnectionEstablishDeferral.resolve(new Exports_js_1.ConnectionOpenResponse(200, \"\"));\n            }, (error) => {\n                this.privConnectionEstablishDeferral.reject(error);\n            });\n        };\n        this.privWebsocketClient.onerror = (e) => {\n            this.onEvent(new Exports_js_1.ConnectionErrorEvent(this.privConnectionId, e.message, e.type));\n            this.privLastErrorReceived = e.message;\n        };\n        this.privWebsocketClient.onclose = (e) => {\n            if (this.privConnectionState === Exports_js_1.ConnectionState.Connecting) {\n                this.privConnectionState = Exports_js_1.ConnectionState.Disconnected;\n                // this.onEvent(new ConnectionEstablishErrorEvent(this.connectionId, e.code, e.reason));\n                this.privConnectionEstablishDeferral.resolve(new Exports_js_1.ConnectionOpenResponse(e.code, e.reason + \" \" + this.privLastErrorReceived));\n            }\n            else {\n                this.privConnectionState = Exports_js_1.ConnectionState.Disconnected;\n                this.privWebsocketClient = null;\n                this.onEvent(new Exports_js_1.ConnectionClosedEvent(this.privConnectionId, e.code, e.reason));\n            }\n            this.onClose(e.code, e.reason).catch((reason) => {\n                Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));\n            });\n        };\n        this.privWebsocketClient.onmessage = (e) => {\n            const networkReceivedTime = new Date().toISOString();\n            if (this.privConnectionState === Exports_js_1.ConnectionState.Connected) {\n                const deferred = new Exports_js_1.Deferred();\n                // let id = ++this.idCounter;\n                this.privReceivingMessageQueue.enqueueFromPromise(deferred.promise);\n                if (e.data instanceof ArrayBuffer) {\n                    const rawMessage = new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Binary, e.data);\n                    this.privMessageFormatter\n                        .toConnectionMessage(rawMessage)\n                        .then((connectionMessage) => {\n                        this.onEvent(new Exports_js_1.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));\n                        deferred.resolve(connectionMessage);\n                    }, (error) => {\n                        // TODO: Events for these ?\n                        deferred.reject(`Invalid binary message format. Error: ${error}`);\n                    });\n                }\n                else {\n                    const rawMessage = new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Text, e.data);\n                    this.privMessageFormatter\n                        .toConnectionMessage(rawMessage)\n                        .then((connectionMessage) => {\n                        this.onEvent(new Exports_js_1.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));\n                        deferred.resolve(connectionMessage);\n                    }, (error) => {\n                        // TODO: Events for these ?\n                        deferred.reject(`Invalid text message format. Error: ${error}`);\n                    });\n                }\n            }\n        };\n        return this.privConnectionEstablishDeferral.promise;\n    }\n    send(message) {\n        if (this.privConnectionState !== Exports_js_1.ConnectionState.Connected) {\n            return Promise.reject(`Cannot send on connection that is in ${Exports_js_1.ConnectionState[this.privConnectionState]} state`);\n        }\n        const messageSendStatusDeferral = new Exports_js_1.Deferred();\n        const messageSendDeferral = new Exports_js_1.Deferred();\n        this.privSendMessageQueue.enqueueFromPromise(messageSendDeferral.promise);\n        this.privMessageFormatter\n            .fromConnectionMessage(message)\n            .then((rawMessage) => {\n            messageSendDeferral.resolve({\n                Message: message,\n                RawWebsocketMessage: rawMessage,\n                sendStatusDeferral: messageSendStatusDeferral,\n            });\n        }, (error) => {\n            messageSendDeferral.reject(`Error formatting the message. ${error}`);\n        });\n        return messageSendStatusDeferral.promise;\n    }\n    read() {\n        if (this.privConnectionState !== Exports_js_1.ConnectionState.Connected) {\n            return Promise.reject(`Cannot read on connection that is in ${this.privConnectionState} state`);\n        }\n        return this.privReceivingMessageQueue.dequeue();\n    }\n    close(reason) {\n        if (this.privWebsocketClient) {\n            if (this.privConnectionState !== Exports_js_1.ConnectionState.Disconnected) {\n                this.privWebsocketClient.close(1000, reason ? reason : \"Normal closure by client\");\n            }\n        }\n        else {\n            return Promise.resolve();\n        }\n        return this.privDisconnectDeferral.promise;\n    }\n    get events() {\n        return this.privConnectionEvents;\n    }\n    sendRawMessage(sendItem) {\n        try {\n            // indicates we are draining the queue and it came with no message;\n            if (!sendItem) {\n                return Promise.resolve();\n            }\n            this.onEvent(new Exports_js_1.ConnectionMessageSentEvent(this.privConnectionId, new Date().toISOString(), sendItem.Message));\n            // add a check for the ws readystate in order to stop the red console error 'WebSocket is already in CLOSING or CLOSED state' appearing\n            if (this.isWebsocketOpen) {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                this.privWebsocketClient.send(sendItem.RawWebsocketMessage.payload);\n            }\n            else {\n                return Promise.reject(\"websocket send error: Websocket not ready \" + this.privConnectionId + \" \" + sendItem.Message.id + \" \" + new Error().stack);\n            }\n            return Promise.resolve();\n        }\n        catch (e) {\n            return Promise.reject(`websocket send error: ${e}`);\n        }\n    }\n    async onClose(code, reason) {\n        const closeReason = `Connection closed. ${code}: ${reason}`;\n        this.privConnectionState = Exports_js_1.ConnectionState.Disconnected;\n        this.privDisconnectDeferral.resolve();\n        await this.privReceivingMessageQueue.drainAndDispose(() => {\n            // TODO: Events for these ?\n            // Logger.instance.onEvent(new LoggingEvent(LogType.Warning, null, `Failed to process received message. Reason: ${closeReason}, Message: ${JSON.stringify(pendingReceiveItem)}`));\n        }, closeReason);\n        await this.privSendMessageQueue.drainAndDispose((pendingSendItem) => {\n            pendingSendItem.sendStatusDeferral.reject(closeReason);\n        }, closeReason);\n    }\n    async processSendQueue() {\n        while (true) {\n            const itemToSend = this.privSendMessageQueue.dequeue();\n            const sendItem = await itemToSend;\n            // indicates we are draining the queue and it came with no message;\n            if (!sendItem) {\n                return;\n            }\n            try {\n                await this.sendRawMessage(sendItem);\n                sendItem.sendStatusDeferral.resolve();\n            }\n            catch (sendError) {\n                sendItem.sendStatusDeferral.reject(sendError);\n            }\n        }\n    }\n    onEvent(event) {\n        this.privConnectionEvents.onEvent(event);\n        Exports_js_1.Events.instance.onEvent(event);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    getAgent() {\n        // eslint-disable-next-line @typescript-eslint/unbound-method\n        const agent = new agent_base_1.default.Agent(this.createConnection);\n        if (this.proxyInfo !== undefined &&\n            this.proxyInfo.HostName !== undefined &&\n            this.proxyInfo.Port > 0) {\n            agent.proxyInfo = this.proxyInfo;\n        }\n        return agent;\n    }\n    static GetProxyAgent(proxyInfo) {\n        const httpProxyOptions = {\n            host: proxyInfo.HostName,\n            port: proxyInfo.Port,\n        };\n        if (!!proxyInfo.UserName) {\n            httpProxyOptions.headers = {\n                \"Proxy-Authentication\": \"Basic \" + new Buffer(`${proxyInfo.UserName}:${(proxyInfo.Password === undefined) ? \"\" : proxyInfo.Password}`).toString(\"base64\"),\n            };\n        }\n        else {\n            httpProxyOptions.headers = {};\n        }\n        httpProxyOptions.headers.requestOCSP = \"true\";\n        const httpProxyAgent = new https_proxy_agent_1.default(httpProxyOptions);\n        return httpProxyAgent;\n    }\n    createConnection(request, options) {\n        let socketPromise;\n        options = {\n            ...options,\n            ...{\n                requestOCSP: true,\n                servername: options.host\n            }\n        };\n        if (!!this.proxyInfo) {\n            const httpProxyAgent = WebsocketMessageAdapter.GetProxyAgent(this.proxyInfo);\n            const baseAgent = httpProxyAgent;\n            socketPromise = new Promise((resolve, reject) => {\n                baseAgent.callback(request, options, (error, socket) => {\n                    if (!!error) {\n                        reject(error);\n                    }\n                    else {\n                        resolve(socket);\n                    }\n                });\n            });\n        }\n        else {\n            if (!!options.secureEndpoint) {\n                socketPromise = Promise.resolve(tls.connect(options));\n            }\n            else {\n                socketPromise = Promise.resolve(net.connect(options));\n            }\n        }\n        return socketPromise;\n    }\n    get isWebsocketOpen() {\n        return this.privWebsocketClient && this.privWebsocketClient.readyState === this.privWebsocketClient.OPEN;\n    }\n}\nexports.WebsocketMessageAdapter = WebsocketMessageAdapter;\nWebsocketMessageAdapter.forceNpmWebSocket = false;\n\n//# sourceMappingURL=WebsocketMessageAdapter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AddedLmIntent.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AddedLmIntent.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AddedLmIntent = void 0;\n/**\n * @class AddedLmIntent\n */\n// eslint-disable-next-line max-classes-per-file\nclass AddedLmIntent {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param modelImpl - The model.\n     * @param intentName - The intent name.\n     */\n    constructor(modelImpl, intentName) {\n        this.modelImpl = modelImpl;\n        this.intentName = intentName;\n    }\n}\nexports.AddedLmIntent = AddedLmIntent;\n\n//# sourceMappingURL=AddedLmIntent.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AddedLmIntent.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AgentConfig.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AgentConfig.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AgentConfig = void 0;\n/**\n * Represents the JSON used in the agent.config message sent to the speech service.\n */\nclass AgentConfig {\n    toJsonString() {\n        return JSON.stringify(this.iPrivConfig);\n    }\n    get() {\n        return this.iPrivConfig;\n    }\n    /**\n     * Setter for the agent.config object.\n     * @param value a JSON serializable object.\n     */\n    set(value) {\n        this.iPrivConfig = value;\n    }\n}\nexports.AgentConfig = AgentConfig;\n\n//# sourceMappingURL=AgentConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AgentConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AvatarSynthesisAdapter.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AvatarSynthesisAdapter.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AvatarSynthesisAdapter = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass AvatarSynthesisAdapter extends Exports_js_2.SynthesisAdapterBase {\n    constructor(authentication, connectionFactory, synthesizerConfig, avatarSynthesizer, avatarConfig) {\n        super(authentication, connectionFactory, synthesizerConfig, undefined);\n        this.privAvatarSynthesizer = avatarSynthesizer;\n        this.privSynthesizer = avatarSynthesizer;\n        this.privAvatarConfig = avatarConfig;\n    }\n    setSynthesisContextSynthesisSection() {\n        this.privSynthesisContext.setSynthesisSection(undefined);\n    }\n    setSpeechConfigSynthesisSection() {\n        this.privSynthesizerConfig.synthesisVideoSection = {\n            format: {\n                bitrate: this.privAvatarConfig.videoFormat?.bitrate,\n                codec: this.privAvatarConfig.videoFormat?.codec,\n                crop: {\n                    bottomRight: {\n                        x: this.privAvatarConfig.videoFormat?.cropRange?.bottomRight?.x,\n                        y: this.privAvatarConfig.videoFormat?.cropRange?.bottomRight?.y,\n                    },\n                    topLeft: {\n                        x: this.privAvatarConfig.videoFormat?.cropRange?.topLeft?.x,\n                        y: this.privAvatarConfig.videoFormat?.cropRange?.topLeft?.y,\n                    },\n                },\n                resolution: {\n                    height: this.privAvatarConfig.videoFormat?.height,\n                    width: this.privAvatarConfig.videoFormat?.width,\n                },\n            },\n            protocol: {\n                name: \"WebRTC\",\n                webrtcConfig: {\n                    clientDescription: btoa(this.privSynthesizerConfig.parameters.getProperty(Exports_js_1.PropertyId.TalkingAvatarService_WebRTC_SDP)),\n                    iceServers: this.privAvatarConfig.remoteIceServers ?? this.privAvatarSynthesizer.iceServers,\n                },\n            },\n            talkingAvatar: {\n                background: {\n                    color: this.privAvatarConfig.backgroundColor,\n                    image: {\n                        url: this.privAvatarConfig.backgroundImage?.toString(),\n                    }\n                },\n                character: this.privAvatarConfig.character,\n                customized: this.privAvatarConfig.customized,\n                style: this.privAvatarConfig.style,\n            }\n        };\n    }\n    onAvatarEvent(metadata) {\n        if (!!this.privAvatarSynthesizer.avatarEventReceived) {\n            const avatarEventArgs = new Exports_js_1.AvatarEventArgs(metadata.Data.Offset, metadata.Data.Name);\n            try {\n                this.privAvatarSynthesizer.avatarEventReceived(this.privAvatarSynthesizer, avatarEventArgs);\n            }\n            catch (error) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n}\nexports.AvatarSynthesisAdapter = AvatarSynthesisAdapter;\n\n//# sourceMappingURL=AvatarSynthesisAdapter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AvatarSynthesisAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveSubscriptionKeyAuthentication.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveSubscriptionKeyAuthentication.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CognitiveSubscriptionKeyAuthentication = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst IAuthentication_js_1 = __webpack_require__(/*! ./IAuthentication.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js\");\n/**\n * @class\n */\nclass CognitiveSubscriptionKeyAuthentication {\n    /**\n     * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.\n     * @constructor\n     * @param {string} subscriptionKey - The subscription key\n     */\n    constructor(subscriptionKey) {\n        if (!subscriptionKey) {\n            throw new Exports_js_1.ArgumentNullError(\"subscriptionKey\");\n        }\n        this.privAuthInfo = new IAuthentication_js_1.AuthInfo(HeaderNames_js_1.HeaderNames.AuthKey, subscriptionKey);\n    }\n    /**\n     * Fetches the subscription key.\n     * @member\n     * @function\n     * @public\n     * @param {string} authFetchEventId - The id to fetch.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    fetch(authFetchEventId) {\n        return Promise.resolve(this.privAuthInfo);\n    }\n    /**\n     * Fetches the subscription key.\n     * @member\n     * @function\n     * @public\n     * @param {string} authFetchEventId - The id to fetch.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    fetchOnExpiry(authFetchEventId) {\n        return Promise.resolve(this.privAuthInfo);\n    }\n}\nexports.CognitiveSubscriptionKeyAuthentication = CognitiveSubscriptionKeyAuthentication;\n\n//# sourceMappingURL=CognitiveSubscriptionKeyAuthentication.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveSubscriptionKeyAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveTokenAuthentication.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveTokenAuthentication.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CognitiveTokenAuthentication = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst IAuthentication_js_1 = __webpack_require__(/*! ./IAuthentication.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nclass CognitiveTokenAuthentication {\n    constructor(fetchCallback, fetchOnExpiryCallback) {\n        if (!fetchCallback) {\n            throw new Exports_js_1.ArgumentNullError(\"fetchCallback\");\n        }\n        if (!fetchOnExpiryCallback) {\n            throw new Exports_js_1.ArgumentNullError(\"fetchOnExpiryCallback\");\n        }\n        this.privFetchCallback = fetchCallback;\n        this.privFetchOnExpiryCallback = fetchOnExpiryCallback;\n    }\n    fetch(authFetchEventId) {\n        return this.privFetchCallback(authFetchEventId).then((token) => new IAuthentication_js_1.AuthInfo(HeaderNames_js_1.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));\n    }\n    fetchOnExpiry(authFetchEventId) {\n        return this.privFetchOnExpiryCallback(authFetchEventId).then((token) => new IAuthentication_js_1.AuthInfo(HeaderNames_js_1.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));\n    }\n}\nexports.CognitiveTokenAuthentication = CognitiveTokenAuthentication;\nCognitiveTokenAuthentication.privTokenPrefix = \"Bearer \";\n\n//# sourceMappingURL=CognitiveTokenAuthentication.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveTokenAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionFactoryBase = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js\");\nclass ConnectionFactoryBase {\n    static getHostSuffix(region) {\n        if (!!region) {\n            if (region.toLowerCase().startsWith(\"china\")) {\n                return \".azure.cn\";\n            }\n            if (region.toLowerCase().startsWith(\"usgov\")) {\n                return \".azure.us\";\n            }\n        }\n        return \".microsoft.com\";\n    }\n    setCommonUrlParams(config, queryParams, endpoint) {\n        const propertyIdToParameterMap = new Map([\n            [Exports_js_2.PropertyId.Speech_SegmentationSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.SegmentationSilenceTimeoutMs],\n            [Exports_js_2.PropertyId.SpeechServiceConnection_EnableAudioLogging, QueryParameterNames_js_1.QueryParameterNames.EnableAudioLogging],\n            [Exports_js_2.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.EndSilenceTimeoutMs],\n            [Exports_js_2.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.InitialSilenceTimeoutMs],\n            [Exports_js_2.PropertyId.SpeechServiceResponse_PostProcessingOption, QueryParameterNames_js_1.QueryParameterNames.Postprocessing],\n            [Exports_js_2.PropertyId.SpeechServiceResponse_ProfanityOption, QueryParameterNames_js_1.QueryParameterNames.Profanity],\n            [Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, QueryParameterNames_js_1.QueryParameterNames.EnableWordLevelTimestamps],\n            [Exports_js_2.PropertyId.SpeechServiceResponse_StablePartialResultThreshold, QueryParameterNames_js_1.QueryParameterNames.StableIntermediateThreshold],\n        ]);\n        propertyIdToParameterMap.forEach((parameterName, propertyId) => {\n            this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);\n        });\n        const serviceProperties = JSON.parse(config.parameters.getProperty(Exports_js_1.ServicePropertiesPropertyName, \"{}\"));\n        Object.keys(serviceProperties).forEach((value) => {\n            queryParams[value] = serviceProperties[value];\n        });\n    }\n    setUrlParameter(propId, parameterName, config, queryParams, endpoint) {\n        const value = config.parameters.getProperty(propId, undefined);\n        // FIXME: The .search() check will incorrectly match parameter name anywhere in the string\n        //        including e.g. the path portion, or even as a substring of other query parameters\n        if (value && (!endpoint || endpoint.search(parameterName) === -1)) {\n            queryParams[parameterName] = value.toLocaleLowerCase();\n        }\n    }\n}\nexports.ConnectionFactoryBase = ConnectionFactoryBase;\n\n//# sourceMappingURL=ConnectionFactoryBase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationServiceRecognizer.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationServiceRecognizer.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationServiceRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass ConversationServiceRecognizer extends Exports_js_2.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.handleSpeechPhraseMessage = async (textBody) => this.handleSpeechPhrase(textBody);\n        this.handleSpeechHypothesisMessage = (textBody) => this.handleSpeechHypothesis(textBody);\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        void connectionMessage;\n        return;\n    }\n    handleRecognizedCallback(result, offset, sessionId) {\n        void result;\n        void offset;\n        void sessionId;\n        return;\n    }\n    handleRecognizingCallback(result, duration, sessionId) {\n        void result;\n        void duration;\n        void sessionId;\n        return;\n    }\n    async processSpeechMessages(connectionMessage) {\n        let processed = false;\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.hypothesis\":\n            case \"speech.fragment\":\n                if (!!this.handleSpeechHypothesisMessage) {\n                    this.handleSpeechHypothesisMessage(connectionMessage.textBody);\n                }\n                processed = true;\n                break;\n            case \"speech.phrase\":\n                if (!!this.handleSpeechPhraseMessage) {\n                    await this.handleSpeechPhraseMessage(connectionMessage.textBody);\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        return processed;\n    }\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        // Implementing to allow inheritance\n        void sessionId;\n        void requestId;\n        void cancellationReason;\n        void errorCode;\n        void error;\n    }\n    async handleSpeechPhrase(textBody) {\n        const simple = Exports_js_2.SimpleSpeechPhrase.fromJSON(textBody, this.privRequestSession.currentTurnAudioOffset);\n        const resultReason = Exports_js_2.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\n        let result;\n        const resultProps = new Exports_js_1.PropertyCollection();\n        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, textBody);\n        this.privRequestSession.onPhraseRecognized(simple.Offset + simple.Duration);\n        if (Exports_js_1.ResultReason.Canceled === resultReason) {\n            const cancelReason = Exports_js_2.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n            const cancellationErrorCode = Exports_js_2.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n            await this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_2.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n        }\n        else {\n            if (simple.RecognitionStatus !== Exports_js_2.RecognitionStatus.EndOfDictation) {\n                if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.OutputFormatPropertyName) === Exports_js_1.OutputFormat[Exports_js_1.OutputFormat.Simple]) {\n                    result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, simple.asJson(), resultProps);\n                }\n                else {\n                    const detailed = Exports_js_2.DetailedSpeechPhrase.fromJSON(textBody, this.privRequestSession.currentTurnAudioOffset);\n                    result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.Text, detailed.Duration, detailed.Offset, detailed.Language, detailed.LanguageDetectionConfidence, detailed.SpeakerId, undefined, detailed.asJson(), resultProps);\n                }\n                this.handleRecognizedCallback(result, result.offset, this.privRequestSession.sessionId);\n            }\n        }\n    }\n    handleSpeechHypothesis(textBody) {\n        const hypothesis = Exports_js_2.SpeechHypothesis.fromJSON(textBody, this.privRequestSession.currentTurnAudioOffset);\n        const resultProps = new Exports_js_1.PropertyCollection();\n        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, textBody);\n        const result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, Exports_js_1.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, hypothesis.Offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, hypothesis.asJson(), resultProps);\n        this.privRequestSession.onHypothesis(hypothesis.Offset);\n        this.handleRecognizingCallback(result, hypothesis.Duration, this.privRequestSession.sessionId);\n    }\n}\nexports.ConversationServiceRecognizer = ConversationServiceRecognizer;\n\n//# sourceMappingURL=ConversationServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriberConnectionFactory.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriberConnectionFactory.js ***!
  \***************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranscriberConnectionFactory = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js\");\nclass ConversationTranscriberConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    constructor() {\n        super(...arguments);\n        this.universalUri = \"/speech/universal/v2\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, undefined);\n        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n        const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".stt.speech\" + hostSuffix);\n        const queryParams = {};\n        const endpointId = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n        const language = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);\n        if (endpointId) {\n            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId) === -1) {\n                queryParams[QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;\n            }\n        }\n        else if (language) {\n            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.Language) === -1) {\n                queryParams[QueryParameterNames_js_1.QueryParameterNames.Language] = language;\n            }\n        }\n        if (config.autoDetectSourceLanguages !== undefined) {\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.EnableLanguageId] = \"true\";\n        }\n        this.setV2UrlParams(config, queryParams, endpoint);\n        if (!endpoint) {\n            endpoint = `${host}${this.universalUri}`;\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        const webSocketConnection = new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_4.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n        // Set the value of SpeechServiceConnection_Url to webSocketConnection.uri (and not to `endpoint`), since this value is the final\n        // URI that was used to make the connection (including query parameters).\n        const uri = webSocketConnection.uri;\n        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, uri);\n        return webSocketConnection;\n    }\n    setV2UrlParams(config, queryParams, endpoint) {\n        const propertyIdToParameterMap = new Map([\n            [Exports_js_2.PropertyId.Speech_SegmentationSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.SegmentationSilenceTimeoutMs],\n            [Exports_js_2.PropertyId.SpeechServiceConnection_EnableAudioLogging, QueryParameterNames_js_1.QueryParameterNames.EnableAudioLogging],\n            [Exports_js_2.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.EndSilenceTimeoutMs],\n            [Exports_js_2.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.InitialSilenceTimeoutMs],\n            [Exports_js_2.PropertyId.SpeechServiceResponse_PostProcessingOption, QueryParameterNames_js_1.QueryParameterNames.Postprocessing],\n            [Exports_js_2.PropertyId.SpeechServiceResponse_ProfanityOption, QueryParameterNames_js_1.QueryParameterNames.Profanity],\n            [Exports_js_2.PropertyId.SpeechServiceResponse_StablePartialResultThreshold, QueryParameterNames_js_1.QueryParameterNames.StableIntermediateThreshold],\n        ]);\n        propertyIdToParameterMap.forEach((parameterName, propertyId) => {\n            this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);\n        });\n        const serviceProperties = JSON.parse(config.parameters.getProperty(Exports_js_3.ServicePropertiesPropertyName, \"{}\"));\n        Object.keys(serviceProperties).forEach((value) => {\n            queryParams[value] = serviceProperties[value];\n        });\n    }\n}\nexports.ConversationTranscriberConnectionFactory = ConversationTranscriberConnectionFactory;\n\n//# sourceMappingURL=ConversationTranscriberConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriberConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriptionServiceRecognizer.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriptionServiceRecognizer.js ***!
  \*****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranscriptionServiceRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\n// eslint-disable-next-line max-classes-per-file\nclass ConversationTranscriptionServiceRecognizer extends Exports_js_2.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationTranscriber) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, conversationTranscriber);\n        this.privConversationTranscriber = conversationTranscriber;\n        this.setSpeakerDiarizationJson();\n    }\n    setSpeakerDiarizationJson() {\n        if (this.privEnableSpeakerId) {\n            const phraseDetection = this.privSpeechContext.getSection(\"phraseDetection\");\n            phraseDetection.mode = \"Conversation\";\n            const speakerDiarization = {};\n            speakerDiarization.mode = \"Anonymous\";\n            speakerDiarization.audioSessionId = this.privDiarizationSessionId;\n            speakerDiarization.audioOffsetMs = 0;\n            speakerDiarization.diarizeIntermediates = this.privRecognizerConfig.parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_DiarizeIntermediateResults, \"false\") === \"true\";\n            phraseDetection.speakerDiarization = speakerDiarization;\n            this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n        }\n    }\n    async processTypeSpecificMessages(connectionMessage) {\n        let result;\n        const resultProps = new Exports_js_1.PropertyCollection();\n        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        let processed = false;\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.hypothesis\":\n            case \"speech.fragment\":\n                const hypothesis = Exports_js_2.SpeechHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, Exports_js_1.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, hypothesis.Offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, hypothesis.asJson(), resultProps);\n                this.privRequestSession.onHypothesis(hypothesis.Offset);\n                const ev = new Exports_js_1.ConversationTranscriptionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);\n                if (!!this.privConversationTranscriber.transcribing) {\n                    try {\n                        this.privConversationTranscriber.transcribing(this.privConversationTranscriber, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.phrase\":\n                const simple = Exports_js_2.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                const resultReason = Exports_js_2.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\n                this.privRequestSession.onPhraseRecognized(simple.Offset + simple.Duration);\n                if (Exports_js_1.ResultReason.Canceled === resultReason) {\n                    const cancelReason = Exports_js_2.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n                    const cancellationErrorCode = Exports_js_2.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n                    await this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_2.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n                }\n                else {\n                    if (!(this.privRequestSession.isSpeechEnded && resultReason === Exports_js_1.ResultReason.NoMatch && simple.RecognitionStatus !== Exports_js_2.RecognitionStatus.InitialSilenceTimeout)) {\n                        if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.OutputFormatPropertyName) === Exports_js_1.OutputFormat[Exports_js_1.OutputFormat.Simple]) {\n                            result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, simple.asJson(), resultProps);\n                        }\n                        else {\n                            const detailed = Exports_js_2.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                            result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === Exports_js_2.RecognitionStatus.Success ? detailed.NBest[0].Display : undefined, detailed.Duration, detailed.Offset, detailed.Language, detailed.LanguageDetectionConfidence, simple.SpeakerId, undefined, detailed.asJson(), resultProps);\n                        }\n                        const event = new Exports_js_1.ConversationTranscriptionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n                        if (!!this.privConversationTranscriber.transcribed) {\n                            try {\n                                this.privConversationTranscriber.transcribed(this.privConversationTranscriber, event);\n                                /* eslint-disable no-empty */\n                            }\n                            catch (error) {\n                                // Not going to let errors in the event handler\n                                // trip things up.\n                            }\n                        }\n                    }\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        return processed;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new Exports_js_1.PropertyCollection();\n        properties.setProperty(Exports_js_2.CancellationErrorCodePropertyName, Exports_js_1.CancellationErrorCode[errorCode]);\n        if (!!this.privConversationTranscriber.canceled) {\n            const cancelEvent = new Exports_js_1.ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n            try {\n                this.privConversationTranscriber.canceled(this.privConversationTranscriber, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n    }\n}\nexports.ConversationTranscriptionServiceRecognizer = ConversationTranscriptionServiceRecognizer;\n\n//# sourceMappingURL=ConversationTranscriptionServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriptionServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogConnectorFactory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogConnectorFactory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DialogConnectionFactory = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js\");\nclass DialogConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        const applicationId = config.parameters.getProperty(Exports_js_3.PropertyId.Conversation_ApplicationId, \"\");\n        const dialogType = config.parameters.getProperty(Exports_js_3.PropertyId.Conversation_DialogType);\n        const region = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Region);\n        const language = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage, \"en-US\");\n        const requestTurnStatus = config.parameters.getProperty(Exports_js_3.PropertyId.Conversation_Request_Bot_Status_Messages, \"true\");\n        const queryParams = {};\n        queryParams[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = config.parameters.getProperty(Exports_js_2.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]).toLowerCase();\n        queryParams[QueryParameterNames_js_1.QueryParameterNames.Language] = language;\n        queryParams[QueryParameterNames_js_1.QueryParameterNames.RequestBotStatusMessages] = requestTurnStatus;\n        if (applicationId) {\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.BotId] = applicationId;\n            if (dialogType === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands) {\n                queryParams[HeaderNames_js_1.HeaderNames.CustomCommandsAppId] = applicationId;\n            }\n        }\n        const resourceInfix = dialogType === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands ? \"commands/\"\n            : \"\";\n        const version = dialogType === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands ? \"v1\"\n            : dialogType === Exports_js_3.DialogServiceConfig.DialogTypes.BotFramework ? \"v3\"\n                : \"v0\";\n        const headers = {};\n        if (authInfo.token != null && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        // The URL used for connection is chosen in a priority order of specification:\n        //  1. If a custom endpoint is provided, that URL is used verbatim.\n        //  2. If a custom host is provided (e.g. \"wss://my.custom.endpoint.com:1123\"), a URL is constructed from it.\n        //  3. If no custom connection details are provided, a URL is constructed from default values.\n        let endpoint = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint, \"\");\n        if (!endpoint) {\n            const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n            const host = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Host, `wss://${region}.${DialogConnectionFactory.BaseUrl}${hostSuffix}`);\n            const standardizedHost = host.endsWith(\"/\") ? host : host + \"/\";\n            endpoint = `${standardizedHost}${resourceInfix}${DialogConnectionFactory.ApiKey}/${version}`;\n        }\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_4.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\nexports.DialogConnectionFactory = DialogConnectionFactory;\nDialogConnectionFactory.ApiKey = \"api\";\nDialogConnectionFactory.BaseUrl = \"convai.speech\";\n\n//# sourceMappingURL=DialogConnectorFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogConnectorFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceAdapter.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceAdapter.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DialogServiceAdapter = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst DialogEvents_js_1 = __webpack_require__(/*! ../common/DialogEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst AudioOutputFormat_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst DialogServiceTurnStateManager_js_1 = __webpack_require__(/*! ./DialogServiceTurnStateManager.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnStateManager.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst ActivityResponsePayload_js_1 = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js\");\nconst SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js\");\nclass DialogServiceAdapter extends Exports_js_4.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);\n        this.privEvents = new Exports_js_2.EventSource();\n        this.privDialogServiceConnector = dialogServiceConnector;\n        this.receiveMessageOverride = () => this.receiveDialogMessageOverride();\n        this.privTurnStateManager = new DialogServiceTurnStateManager_js_1.DialogServiceTurnStateManager();\n        this.recognizeOverride =\n            (recoMode, successCallback, errorCallback) => this.listenOnce(recoMode, successCallback, errorCallback);\n        this.postConnectImplOverride = (connection) => this.dialogConnectImpl(connection);\n        this.configConnectionOverride = (connection) => this.configConnection(connection);\n        this.disconnectOverride = () => this.privDisconnect();\n        this.privDialogAudioSource = audioSource;\n        this.agentConfigSent = false;\n        this.privLastResult = null;\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                this.terminateMessageLoop = true;\n            }\n        });\n    }\n    async sendMessage(message) {\n        const interactionGuid = Exports_js_2.createGuid();\n        const requestId = Exports_js_2.createNoDashGuid();\n        const agentMessage = {\n            context: {\n                interactionId: interactionGuid\n            },\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n            messagePayload: JSON.parse(message),\n            version: 0.5\n        };\n        const agentMessageJson = JSON.stringify(agentMessage);\n        const connection = await this.fetchConnection();\n        await connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"agent\", requestId, \"application/json\", agentMessageJson));\n    }\n    async privDisconnect() {\n        await this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.NoError, \"Disconnecting\");\n        this.terminateMessageLoop = true;\n        this.agentConfigSent = false;\n        return;\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        const resultProps = new Exports_js_3.PropertyCollection();\n        if (connectionMessage.messageType === Exports_js_2.MessageType.Text) {\n            resultProps.setProperty(Exports_js_3.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        let result;\n        let processed;\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.phrase\":\n                const speechPhrase = Exports_js_4.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                this.privRequestSession.onPhraseRecognized(speechPhrase.Offset + speechPhrase.Duration);\n                if (speechPhrase.RecognitionStatus !== Exports_js_4.RecognitionStatus.TooManyRequests && speechPhrase.RecognitionStatus !== Exports_js_4.RecognitionStatus.Error) {\n                    const args = this.fireEventForResult(speechPhrase, resultProps);\n                    this.privLastResult = args.result;\n                    if (!!this.privDialogServiceConnector.recognized) {\n                        try {\n                            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.hypothesis\":\n                const hypothesis = Exports_js_4.SpeechHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, Exports_js_3.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, hypothesis.Offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, undefined, hypothesis.asJson(), resultProps);\n                this.privRequestSession.onHypothesis(hypothesis.Offset);\n                const ev = new Exports_js_3.SpeechRecognitionEventArgs(result, hypothesis.Offset, this.privRequestSession.sessionId);\n                if (!!this.privDialogServiceConnector.recognizing) {\n                    try {\n                        this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.keyword\":\n                const keyword = Exports_js_4.SpeechKeyword.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, keyword.Status === \"Accepted\" ? Exports_js_3.ResultReason.RecognizedKeyword : Exports_js_3.ResultReason.NoMatch, keyword.Text, keyword.Duration, keyword.Offset, undefined, undefined, undefined, undefined, keyword.asJson(), resultProps);\n                if (keyword.Status !== \"Accepted\") {\n                    this.privLastResult = result;\n                }\n                const event = new Exports_js_3.SpeechRecognitionEventArgs(result, result.duration, result.resultId);\n                if (!!this.privDialogServiceConnector.recognized) {\n                    try {\n                        this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"audio\":\n                {\n                    const audioRequestId = connectionMessage.requestId.toUpperCase();\n                    const turn = this.privTurnStateManager.GetTurn(audioRequestId);\n                    try {\n                        // Empty binary message signals end of stream.\n                        if (!connectionMessage.binaryBody) {\n                            turn.endAudioStream();\n                        }\n                        else {\n                            turn.audioStream.write(connectionMessage.binaryBody);\n                        }\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"response\":\n                {\n                    this.handleResponseMessage(connectionMessage);\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new Exports_js_2.Deferred();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n    // Cancels recognition.\n    async cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        this.terminateMessageLoop = true;\n        if (!!this.privRequestSession.isRecognizing) {\n            await this.privRequestSession.onStopRecognizing();\n        }\n        if (!!this.privDialogServiceConnector.canceled) {\n            const properties = new Exports_js_3.PropertyCollection();\n            properties.setProperty(Exports_js_4.CancellationErrorCodePropertyName, Exports_js_3.CancellationErrorCode[errorCode]);\n            const cancelEvent = new Exports_js_3.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n            try {\n                this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch { }\n            if (!!this.privSuccessCallback) {\n                const result = new Exports_js_3.SpeechRecognitionResult(undefined, // ResultId\n                Exports_js_3.ResultReason.Canceled, undefined, // Text\n                undefined, // Duration\n                undefined, // Offset\n                undefined, // Language\n                undefined, // Language Detection Confidence\n                undefined, // Speaker Id\n                error, undefined, // Json\n                properties);\n                try {\n                    this.privSuccessCallback(result);\n                    this.privSuccessCallback = undefined;\n                    /* eslint-disable no-empty */\n                }\n                catch { }\n            }\n        }\n    }\n    async listenOnce(recoMode, successCallback, errorCallback) {\n        this.privRecognizerConfig.recognitionMode = recoMode;\n        this.privSuccessCallback = successCallback;\n        this.privErrorCallback = errorCallback;\n        this.privRequestSession.startNewRecognition();\n        this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);\n        this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);\n        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n        const conPromise = this.connectImpl();\n        const preAudioPromise = this.sendPreAudioMessages();\n        const node = await this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);\n        const format = await this.privDialogAudioSource.format;\n        const deviceInfo = await this.privDialogAudioSource.deviceInfo;\n        const audioNode = new Exports_js_1.ReplayableAudioNode(node, format.avgBytesPerSec);\n        await this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n        try {\n            await conPromise;\n            await preAudioPromise;\n        }\n        catch (error) {\n            await this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.ConnectionFailure, error);\n            return Promise.resolve();\n        }\n        const sessionStartEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n        if (!!this.privRecognizer.sessionStarted) {\n            this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n        }\n        const audioSendPromise = this.sendAudio(audioNode);\n        // /* eslint-disable no-empty */\n        audioSendPromise.then(() => { }, async (error) => {\n            await this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);\n        });\n    }\n    // Establishes a websocket connection to the end point.\n    dialogConnectImpl(connection) {\n        this.privConnectionLoop = this.startMessageLoop();\n        return connection;\n    }\n    receiveDialogMessageOverride() {\n        // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n        const communicationCustodian = new Exports_js_2.Deferred();\n        const loop = async () => {\n            try {\n                const isDisposed = this.isDisposed();\n                const terminateMessageLoop = (!this.isDisposed() && this.terminateMessageLoop);\n                if (isDisposed || terminateMessageLoop) {\n                    // We're done.\n                    communicationCustodian.resolve(undefined);\n                    return;\n                }\n                const connection = await this.fetchConnection();\n                const message = await connection.read();\n                if (!message) {\n                    return loop();\n                }\n                const connectionMessage = SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage.fromConnectionMessage(message);\n                switch (connectionMessage.path.toLowerCase()) {\n                    case \"turn.start\":\n                        {\n                            const turnRequestId = connectionMessage.requestId.toUpperCase();\n                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n                            // turn started by the service\n                            if (turnRequestId !== audioSessionReqId) {\n                                this.privTurnStateManager.StartTurn(turnRequestId);\n                            }\n                            else {\n                                this.privRequestSession.onServiceTurnStartResponse();\n                            }\n                        }\n                        break;\n                    case \"speech.startdetected\":\n                        const speechStartDetected = Exports_js_4.SpeechDetected.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                        const speechStartEventArgs = new Exports_js_3.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);\n                        if (!!this.privRecognizer.speechStartDetected) {\n                            this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n                        }\n                        break;\n                    case \"speech.enddetected\":\n                        let json;\n                        if (connectionMessage.textBody.length > 0) {\n                            json = connectionMessage.textBody;\n                        }\n                        else {\n                            // If the request was empty, the JSON returned is empty.\n                            json = \"{ Offset: 0 }\";\n                        }\n                        const speechStopDetected = Exports_js_4.SpeechDetected.fromJSON(json, this.privRequestSession.currentTurnAudioOffset);\n                        this.privRequestSession.onServiceRecognized(speechStopDetected.Offset);\n                        const speechStopEventArgs = new Exports_js_3.RecognitionEventArgs(speechStopDetected.Offset, this.privRequestSession.sessionId);\n                        if (!!this.privRecognizer.speechEndDetected) {\n                            this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n                        }\n                        break;\n                    case \"turn.end\":\n                        {\n                            const turnEndRequestId = connectionMessage.requestId.toUpperCase();\n                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n                            // turn started by the service\n                            if (turnEndRequestId !== audioSessionReqId) {\n                                this.privTurnStateManager.CompleteTurn(turnEndRequestId);\n                            }\n                            else {\n                                // Audio session turn\n                                const sessionStopEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n                                await this.privRequestSession.onServiceTurnEndResponse(false);\n                                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                                    if (!!this.privRecognizer.sessionStopped) {\n                                        this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                                    }\n                                }\n                                // report result to promise.\n                                if (!!this.privSuccessCallback && this.privLastResult) {\n                                    try {\n                                        this.privSuccessCallback(this.privLastResult);\n                                        this.privLastResult = null;\n                                    }\n                                    catch (e) {\n                                        if (!!this.privErrorCallback) {\n                                            this.privErrorCallback(e);\n                                        }\n                                    }\n                                    // Only invoke the call back once.\n                                    // and if it's successful don't invoke the\n                                    // error after that.\n                                    this.privSuccessCallback = undefined;\n                                    this.privErrorCallback = undefined;\n                                }\n                            }\n                        }\n                        break;\n                    default:\n                        try {\n                            const processed = await this.processTypeSpecificMessages(connectionMessage);\n                            if (!processed) {\n                                if (!!this.serviceEvents) {\n                                    this.serviceEvents.onEvent(new Exports_js_2.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                                }\n                            }\n                        }\n                        catch (e) {\n                            //\n                        }\n                }\n                const ret = loop();\n                return ret;\n            }\n            catch (error) {\n                this.terminateMessageLoop = true;\n                communicationCustodian.resolve();\n            }\n        };\n        loop().catch((reason) => {\n            Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(reason));\n        });\n        return communicationCustodian.promise;\n    }\n    async startMessageLoop() {\n        this.terminateMessageLoop = false;\n        try {\n            await this.receiveDialogMessageOverride();\n        }\n        catch (error) {\n            await this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);\n        }\n        return Promise.resolve();\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    async configConnection(connection) {\n        if (this.terminateMessageLoop) {\n            this.terminateMessageLoop = false;\n            return Promise.reject(\"Connection to service terminated.\");\n        }\n        await this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n        await this.sendAgentConfig(connection);\n        return connection;\n    }\n    async sendPreAudioMessages() {\n        const connection = await this.fetchConnection();\n        this.addKeywordContextData();\n        await this.sendSpeechContext(connection, true);\n        await this.sendAgentContext(connection);\n        await this.sendWaveHeader(connection);\n    }\n    sendAgentConfig(connection) {\n        if (this.agentConfig && !this.agentConfigSent) {\n            if (this.privRecognizerConfig\n                .parameters\n                .getProperty(Exports_js_3.PropertyId.Conversation_DialogType) === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands) {\n                const config = this.agentConfig.get();\n                config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage, \"en-us\");\n                this.agentConfig.set(config);\n            }\n            this.onEvent(new DialogEvents_js_1.SendingAgentContextMessageEvent(this.agentConfig));\n            const agentConfigJson = this.agentConfig.toJsonString();\n            // guard against sending this multiple times on one connection\n            this.agentConfigSent = true;\n            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"agent.config\", this.privRequestSession.requestId, \"application/json\", agentConfigJson));\n        }\n        return;\n    }\n    sendAgentContext(connection) {\n        const guid = Exports_js_2.createGuid();\n        const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(Exports_js_3.PropertyId.Conversation_Speech_Activity_Template);\n        const agentContext = {\n            channelData: \"\",\n            context: {\n                interactionId: guid\n            },\n            messagePayload: typeof speechActivityTemplate === undefined ? undefined : speechActivityTemplate,\n            version: 0.5\n        };\n        const agentContextJson = JSON.stringify(agentContext);\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speech.agent.context\", this.privRequestSession.requestId, \"application/json\", agentContextJson));\n    }\n    fireEventForResult(serviceResult, properties) {\n        const resultReason = Exports_js_4.EnumTranslation.implTranslateRecognitionResult(serviceResult.RecognitionStatus);\n        const result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, serviceResult.Offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, undefined, undefined, serviceResult.asJson(), properties);\n        const ev = new Exports_js_3.SpeechRecognitionEventArgs(result, serviceResult.Offset, this.privRequestSession.sessionId);\n        return ev;\n    }\n    handleResponseMessage(responseMessage) {\n        // \"response\" messages can contain either \"message\" (activity) or \"MessageStatus\" data. Fire the appropriate\n        // event according to the message type that's specified.\n        const responsePayload = JSON.parse(responseMessage.textBody);\n        switch (responsePayload.messageType.toLowerCase()) {\n            case \"message\":\n                const responseRequestId = responseMessage.requestId.toUpperCase();\n                const activityPayload = ActivityResponsePayload_js_1.ActivityPayloadResponse.fromJSON(responseMessage.textBody);\n                const turn = this.privTurnStateManager.GetTurn(responseRequestId);\n                // update the conversation Id\n                if (activityPayload.conversationId) {\n                    const updateAgentConfig = this.agentConfig.get();\n                    updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;\n                    this.agentConfig.set(updateAgentConfig);\n                }\n                const pullAudioOutputStream = turn.processActivityPayload(activityPayload, AudioOutputFormat_js_1.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)));\n                const activity = new Exports_js_3.ActivityReceivedEventArgs(activityPayload.messagePayload, pullAudioOutputStream);\n                if (!!this.privDialogServiceConnector.activityReceived) {\n                    try {\n                        this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);\n                        /* eslint-disable-next-line no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                break;\n            case \"messagestatus\":\n                if (!!this.privDialogServiceConnector.turnStatusReceived) {\n                    try {\n                        this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new Exports_js_3.TurnStatusReceivedEventArgs(responseMessage.textBody));\n                        /* eslint-disable-next-line no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                break;\n            default:\n                Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));\n                break;\n        }\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        Exports_js_2.Events.instance.onEvent(event);\n    }\n    addKeywordContextData() {\n        const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect\");\n        if (keywordPropertyValue === undefined) {\n            return;\n        }\n        const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters\n            .getProperty(\"SPEECH-KeywordsToDetect-Offsets\");\n        const keywordDurationPropertyValue = this.privRecognizerConfig.parameters\n            .getProperty(\"SPEECH-KeywordsToDetect-Durations\");\n        const keywords = keywordPropertyValue.split(\";\");\n        const keywordOffsets = keywordOffsetPropertyValue === undefined ? [] : keywordOffsetPropertyValue.split(\";\");\n        const keywordDurations = keywordDurationPropertyValue === undefined ? [] : keywordDurationPropertyValue.split(\";\");\n        const keywordDefinitionArray = [];\n        for (let i = 0; i < keywords.length; i++) {\n            const definition = {};\n            definition.text = keywords[i];\n            if (i < keywordOffsets.length) {\n                definition.offset = Number(keywordOffsets[i]);\n            }\n            if (i < keywordDurations.length) {\n                definition.duration = Number(keywordDurations[i]);\n            }\n            keywordDefinitionArray.push(definition);\n        }\n        this.speechContext.setSection(\"invocationSource\", \"VoiceActivationWithKeyword\");\n        this.speechContext.setSection(\"keywordDetection\", [{\n                clientDetectedKeywords: keywordDefinitionArray,\n                onReject: { action: \"EndOfTurn\" },\n                type: \"startTrigger\"\n            }]);\n    }\n}\nexports.DialogServiceAdapter = DialogServiceAdapter;\n\n//# sourceMappingURL=DialogServiceAdapter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnState.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnState.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DialogServiceTurnState = void 0;\nconst AudioOutputFormat_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js\");\nconst AudioOutputStream_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js\");\nconst ActivityResponsePayload_js_1 = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js\");\nclass DialogServiceTurnState {\n    constructor(manager, requestId) {\n        this.privRequestId = requestId;\n        this.privIsCompleted = false;\n        this.privAudioStream = null;\n        this.privTurnManager = manager;\n        this.resetTurnEndTimeout();\n    }\n    get audioStream() {\n        // Called when is needed to stream.\n        this.resetTurnEndTimeout();\n        return this.privAudioStream;\n    }\n    processActivityPayload(payload, audioFormat) {\n        if (payload.messageDataStreamType === ActivityResponsePayload_js_1.MessageDataStreamType.TextToSpeechAudio) {\n            this.privAudioStream = AudioOutputStream_js_1.AudioOutputStream.createPullStream();\n            this.privAudioStream.format = (audioFormat !== undefined) ? audioFormat : AudioOutputFormat_js_1.AudioOutputFormatImpl.getDefaultOutputFormat();\n        }\n        return this.privAudioStream;\n    }\n    endAudioStream() {\n        if (this.privAudioStream !== null && !this.privAudioStream.isClosed) {\n            this.privAudioStream.close();\n        }\n    }\n    complete() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            clearTimeout(this.privTimeoutToken);\n        }\n        this.endAudioStream();\n    }\n    resetTurnEndTimeout() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            clearTimeout(this.privTimeoutToken);\n        }\n        this.privTimeoutToken = setTimeout(() => {\n            this.privTurnManager.CompleteTurn(this.privRequestId);\n            return;\n        }, 2000);\n    }\n}\nexports.DialogServiceTurnState = DialogServiceTurnState;\n\n//# sourceMappingURL=DialogServiceTurnState.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnState.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnStateManager.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnStateManager.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DialogServiceTurnStateManager = void 0;\nconst Error_js_1 = __webpack_require__(/*! ../common/Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nconst DialogServiceTurnState_js_1 = __webpack_require__(/*! ./DialogServiceTurnState.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnState.js\");\nclass DialogServiceTurnStateManager {\n    constructor() {\n        this.privTurnMap = new Map();\n        return;\n    }\n    StartTurn(id) {\n        if (this.privTurnMap.has(id)) {\n            throw new Error_js_1.InvalidOperationError(\"Service error: There is already a turn with id:\" + id);\n        }\n        const turnState = new DialogServiceTurnState_js_1.DialogServiceTurnState(this, id);\n        this.privTurnMap.set(id, turnState);\n        return this.privTurnMap.get(id);\n    }\n    GetTurn(id) {\n        return this.privTurnMap.get(id);\n    }\n    CompleteTurn(id) {\n        if (!this.privTurnMap.has(id)) {\n            throw new Error_js_1.InvalidOperationError(\"Service error: Received turn end for an unknown turn id:\" + id);\n        }\n        const turnState = this.privTurnMap.get(id);\n        turnState.complete();\n        this.privTurnMap.delete(id);\n        return turnState;\n    }\n}\nexports.DialogServiceTurnStateManager = DialogServiceTurnStateManager;\n\n//# sourceMappingURL=DialogServiceTurnStateManager.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnStateManager.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarBuilder.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarBuilder.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DynamicGrammarBuilder = void 0;\n/**\n * Responsible for building the object to be sent to the speech service to support dynamic grammars.\n * @class DynamicGrammarBuilder\n */\nclass DynamicGrammarBuilder {\n    // Adds one more reference phrases to the dynamic grammar to send.\n    // All added phrases are generic phrases.\n    addPhrase(phrase) {\n        if (!this.privPhrases) {\n            this.privPhrases = [];\n        }\n        if (phrase instanceof Array) {\n            this.privPhrases = this.privPhrases.concat(phrase);\n        }\n        else {\n            this.privPhrases.push(phrase);\n        }\n    }\n    // Clears all phrases stored in the current object.\n    clearPhrases() {\n        this.privPhrases = undefined;\n    }\n    // Adds one or more reference grammars to the current grammar.\n    addReferenceGrammar(grammar) {\n        if (!this.privGrammars) {\n            this.privGrammars = [];\n        }\n        if (grammar instanceof Array) {\n            this.privGrammars = this.privGrammars.concat(grammar);\n        }\n        else {\n            this.privGrammars.push(grammar);\n        }\n    }\n    // clears all grammars stored on the recognizer.\n    clearGrammars() {\n        this.privGrammars = undefined;\n    }\n    // Generates an object that represents the dynamic grammar used by the Speech Service.\n    // This is done by building an object with the correct layout based on the phrases and reference grammars added to this instance\n    // of a DynamicGrammarBuilder\n    generateGrammarObject() {\n        if (this.privGrammars === undefined && this.privPhrases === undefined) {\n            return undefined;\n        }\n        const retObj = {};\n        retObj.ReferenceGrammars = this.privGrammars;\n        if (undefined !== this.privPhrases && 0 !== this.privPhrases.length) {\n            const retPhrases = [];\n            this.privPhrases.forEach((value) => {\n                retPhrases.push({\n                    Text: value,\n                });\n            });\n            retObj.Groups = [{ Type: \"Generic\", Items: retPhrases }];\n        }\n        return retObj;\n    }\n}\nexports.DynamicGrammarBuilder = DynamicGrammarBuilder;\n\n//# sourceMappingURL=DynamicGrammarBuilder.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarBuilder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarInterfaces.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarInterfaces.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=DynamicGrammarInterfaces.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/EnumTranslation.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/EnumTranslation.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EnumTranslation = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass EnumTranslation {\n    static implTranslateRecognitionResult(recognitionStatus, expectEndOfDictation = false) {\n        let reason = Exports_js_1.ResultReason.Canceled;\n        switch (recognitionStatus) {\n            case Exports_js_2.RecognitionStatus.Success:\n                reason = Exports_js_1.ResultReason.RecognizedSpeech;\n                break;\n            case Exports_js_2.RecognitionStatus.EndOfDictation:\n                // If we need the result in EndOfDictation (typically some session level result),\n                // translate into RecognizedSpeech, otherwise NoMatch\n                reason = expectEndOfDictation ? Exports_js_1.ResultReason.RecognizedSpeech : Exports_js_1.ResultReason.NoMatch;\n                break;\n            case Exports_js_2.RecognitionStatus.NoMatch:\n            case Exports_js_2.RecognitionStatus.InitialSilenceTimeout:\n            case Exports_js_2.RecognitionStatus.BabbleTimeout:\n                reason = Exports_js_1.ResultReason.NoMatch;\n                break;\n            case Exports_js_2.RecognitionStatus.Error:\n            case Exports_js_2.RecognitionStatus.BadRequest:\n            case Exports_js_2.RecognitionStatus.Forbidden:\n            default:\n                reason = Exports_js_1.ResultReason.Canceled;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateCancelResult(recognitionStatus) {\n        let reason = Exports_js_1.CancellationReason.EndOfStream;\n        switch (recognitionStatus) {\n            case Exports_js_2.RecognitionStatus.Success:\n            case Exports_js_2.RecognitionStatus.EndOfDictation:\n            case Exports_js_2.RecognitionStatus.NoMatch:\n                reason = Exports_js_1.CancellationReason.EndOfStream;\n                break;\n            case Exports_js_2.RecognitionStatus.InitialSilenceTimeout:\n            case Exports_js_2.RecognitionStatus.BabbleTimeout:\n            case Exports_js_2.RecognitionStatus.Error:\n            case Exports_js_2.RecognitionStatus.BadRequest:\n            case Exports_js_2.RecognitionStatus.Forbidden:\n            default:\n                reason = Exports_js_1.CancellationReason.Error;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateCancelErrorCode(recognitionStatus) {\n        let reason = Exports_js_1.CancellationErrorCode.NoError;\n        switch (recognitionStatus) {\n            case Exports_js_2.RecognitionStatus.Error:\n                reason = Exports_js_1.CancellationErrorCode.ServiceError;\n                break;\n            case Exports_js_2.RecognitionStatus.TooManyRequests:\n                reason = Exports_js_1.CancellationErrorCode.TooManyRequests;\n                break;\n            case Exports_js_2.RecognitionStatus.BadRequest:\n                reason = Exports_js_1.CancellationErrorCode.BadRequestParameters;\n                break;\n            case Exports_js_2.RecognitionStatus.Forbidden:\n                reason = Exports_js_1.CancellationErrorCode.Forbidden;\n                break;\n            default:\n                reason = Exports_js_1.CancellationErrorCode.NoError;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateErrorDetails(cancellationErrorCode) {\n        let errorDetails = \"The speech service encountered an internal error and could not continue.\";\n        switch (cancellationErrorCode) {\n            case Exports_js_1.CancellationErrorCode.Forbidden:\n                errorDetails = \"The recognizer is using a free subscription that ran out of quota.\";\n                break;\n            case Exports_js_1.CancellationErrorCode.BadRequestParameters:\n                errorDetails = \"Invalid parameter or unsupported audio format in the request.\";\n                break;\n            case Exports_js_1.CancellationErrorCode.TooManyRequests:\n                errorDetails = \"The number of parallel requests exceeded the number of allowed concurrent transcriptions.\";\n                break;\n            default:\n                break;\n        }\n        return errorDetails;\n    }\n}\nexports.EnumTranslation = EnumTranslation;\n\n//# sourceMappingURL=EnumTranslation.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/EnumTranslation.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js ***!
  \******************************************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AutoDetectSourceLanguagesOpenRangeOptionName = exports.ForceDictationPropertyName = exports.ServicePropertiesPropertyName = exports.CancellationErrorCodePropertyName = exports.OutputFormatPropertyName = void 0;\n// Make sure not to export internal modules.\n//\n__exportStar(__webpack_require__(/*! ./CognitiveSubscriptionKeyAuthentication.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveSubscriptionKeyAuthentication.js\"), exports);\n__exportStar(__webpack_require__(/*! ./CognitiveTokenAuthentication.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveTokenAuthentication.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IAuthentication.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ISynthesisConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ISynthesisConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IntentConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IntentConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeakerRecognitionConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerRecognitionConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./RecognitionEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceRecognizerBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceRecognizerBase.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ConversationServiceRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationServiceRecognizer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./RecognizerConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognizerConfig.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeechServiceInterfaces.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceInterfaces.js\"), exports);\n__exportStar(__webpack_require__(/*! ./WebsocketMessageFormatter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/WebsocketMessageFormatter.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeechConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ConversationTranscriberConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriberConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./TranscriberConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriberConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./TranslationConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeechSynthesisConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./EnumTranslation.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/EnumTranslation.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/Enums.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Enums.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/TranslationSynthesisEnd.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/TranslationHypothesis.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationHypothesis.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/TranslationPhrase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationPhrase.js\"), exports);\n__exportStar(__webpack_require__(/*! ./TranslationServiceRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationServiceRecognizer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/SpeechDetected.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechDetected.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/SpeechHypothesis.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechHypothesis.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/SpeechKeyword.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechKeyword.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeechServiceRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceRecognizer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ConversationTranscriptionServiceRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriptionServiceRecognizer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./TranscriptionServiceRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriptionServiceRecognizer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/DetailedSpeechPhrase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/SimpleSpeechPhrase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\"), exports);\n__exportStar(__webpack_require__(/*! ./AddedLmIntent.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AddedLmIntent.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IntentServiceRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IntentServiceRecognizer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/IntentResponse.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/IntentResponse.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/SpeakerResponse.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeakerResponse.js\"), exports);\n__exportStar(__webpack_require__(/*! ./RequestSession.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RequestSession.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeechContext.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechContext.js\"), exports);\n__exportStar(__webpack_require__(/*! ./DynamicGrammarBuilder.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarBuilder.js\"), exports);\n__exportStar(__webpack_require__(/*! ./DynamicGrammarInterfaces.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarInterfaces.js\"), exports);\n__exportStar(__webpack_require__(/*! ./DialogServiceAdapter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceAdapter.js\"), exports);\n__exportStar(__webpack_require__(/*! ./AgentConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AgentConfig.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Transcription/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/Exports.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SynthesisTurn.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisTurn.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SynthesisAdapterBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisAdapterBase.js\"), exports);\nvar AvatarSynthesisAdapter_js_1 = __webpack_require__(/*! ./AvatarSynthesisAdapter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AvatarSynthesisAdapter.js\");\nObject.defineProperty(exports, \"AvatarSynthesisAdapter\", ({ enumerable: true, get: function () { return AvatarSynthesisAdapter_js_1.AvatarSynthesisAdapter; } }));\nvar SpeechSynthesisAdapter_js_1 = __webpack_require__(/*! ./SpeechSynthesisAdapter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisAdapter.js\");\nObject.defineProperty(exports, \"SpeechSynthesisAdapter\", ({ enumerable: true, get: function () { return SpeechSynthesisAdapter_js_1.SpeechSynthesisAdapter; } }));\n__exportStar(__webpack_require__(/*! ./SynthesisRestAdapter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisRestAdapter.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SynthesizerConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesizerConfig.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SynthesisContext.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeakerRecognitionConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerRecognitionConfig.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeakerServiceRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerServiceRecognizer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./VoiceServiceRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/VoiceServiceRecognizer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SpeechServiceConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceConfig.js\"), exports);\nexports.OutputFormatPropertyName = \"OutputFormat\";\nexports.CancellationErrorCodePropertyName = \"CancellationErrorCode\";\nexports.ServicePropertiesPropertyName = \"ServiceProperties\";\nexports.ForceDictationPropertyName = \"ForceDictation\";\nexports.AutoDetectSourceLanguagesOpenRangeOptionName = \"OpenRange\";\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.HeaderNames = void 0;\nclass HeaderNames {\n}\nexports.HeaderNames = HeaderNames;\nHeaderNames.AuthKey = \"Ocp-Apim-Subscription-Key\";\nHeaderNames.Authorization = \"Authorization\";\nHeaderNames.SpIDAuthKey = \"Apim-Subscription-Id\";\nHeaderNames.ConnectionId = \"X-ConnectionId\";\nHeaderNames.ContentType = \"Content-Type\";\nHeaderNames.CustomCommandsAppId = \"X-CommandsAppId\";\nHeaderNames.Path = \"Path\";\nHeaderNames.RequestId = \"X-RequestId\";\nHeaderNames.RequestStreamId = \"X-StreamId\";\nHeaderNames.RequestTimestamp = \"X-Timestamp\";\n\n//# sourceMappingURL=HeaderNames.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AuthInfo = void 0;\nclass AuthInfo {\n    constructor(headerName, token) {\n        this.privHeaderName = headerName;\n        this.privToken = token;\n    }\n    get headerName() {\n        return this.privHeaderName;\n    }\n    get token() {\n        return this.privToken;\n    }\n}\nexports.AuthInfo = AuthInfo;\n\n//# sourceMappingURL=IAuthentication.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IConnectionFactory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IConnectionFactory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ISynthesisConnectionFactory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ISynthesisConnectionFactory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=ISynthesisConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ISynthesisConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IntentConnectionFactory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IntentConnectionFactory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IntentConnectionFactory = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nclass IntentConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_IntentRegion);\n            const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n            const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".sr.speech\" + hostSuffix);\n            endpoint = host + \"/speech/recognition/interactive/cognitiveservices/v1\";\n        }\n        const queryParams = {\n            format: \"simple\",\n            language: config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage),\n        };\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n    getSpeechRegionFromIntentRegion(intentRegion) {\n        switch (intentRegion) {\n            case \"West US\":\n            case \"US West\":\n            case \"westus\":\n                return \"uswest\";\n            case \"West US 2\":\n            case \"US West 2\":\n            case \"westus2\":\n                return \"uswest2\";\n            case \"South Central US\":\n            case \"US South Central\":\n            case \"southcentralus\":\n                return \"ussouthcentral\";\n            case \"West Central US\":\n            case \"US West Central\":\n            case \"westcentralus\":\n                return \"uswestcentral\";\n            case \"East US\":\n            case \"US East\":\n            case \"eastus\":\n                return \"useast\";\n            case \"East US 2\":\n            case \"US East 2\":\n            case \"eastus2\":\n                return \"useast2\";\n            case \"West Europe\":\n            case \"Europe West\":\n            case \"westeurope\":\n                return \"europewest\";\n            case \"North Europe\":\n            case \"Europe North\":\n            case \"northeurope\":\n                return \"europenorth\";\n            case \"Brazil South\":\n            case \"South Brazil\":\n            case \"southbrazil\":\n                return \"brazilsouth\";\n            case \"Australia East\":\n            case \"East Australia\":\n            case \"eastaustralia\":\n                return \"australiaeast\";\n            case \"Southeast Asia\":\n            case \"Asia Southeast\":\n            case \"southeastasia\":\n                return \"asiasoutheast\";\n            case \"East Asia\":\n            case \"Asia East\":\n            case \"eastasia\":\n                return \"asiaeast\";\n            default:\n                return intentRegion;\n        }\n    }\n}\nexports.IntentConnectionFactory = IntentConnectionFactory;\n\n//# sourceMappingURL=IntentConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IntentConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IntentServiceRecognizer.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IntentServiceRecognizer.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IntentServiceRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\n// eslint-disable-next-line max-classes-per-file\nclass IntentServiceRecognizer extends Exports_js_3.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.privIntentRecognizer = recognizer;\n        this.privIntentDataSent = false;\n    }\n    setIntents(addedIntents, umbrellaIntent) {\n        this.privAddedLmIntents = addedIntents;\n        this.privUmbrellaIntent = umbrellaIntent;\n        this.privIntentDataSent = true;\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        let result;\n        let ev;\n        let processed = false;\n        const resultProps = new Exports_js_2.PropertyCollection();\n        if (connectionMessage.messageType === Exports_js_1.MessageType.Text) {\n            resultProps.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.hypothesis\":\n                const speechHypothesis = Exports_js_3.SpeechHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                result = new Exports_js_2.IntentRecognitionResult(undefined, this.privRequestSession.requestId, Exports_js_2.ResultReason.RecognizingIntent, speechHypothesis.Text, speechHypothesis.Duration, speechHypothesis.Offset, speechHypothesis.Language, speechHypothesis.LanguageDetectionConfidence, undefined, speechHypothesis.asJson(), resultProps);\n                this.privRequestSession.onHypothesis(result.offset);\n                ev = new Exports_js_2.IntentRecognitionEventArgs(result, speechHypothesis.Offset, this.privRequestSession.sessionId);\n                if (!!this.privIntentRecognizer.recognizing) {\n                    try {\n                        this.privIntentRecognizer.recognizing(this.privIntentRecognizer, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.phrase\":\n                const simple = Exports_js_3.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                result = new Exports_js_2.IntentRecognitionResult(undefined, this.privRequestSession.requestId, Exports_js_3.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus), simple.DisplayText, simple.Duration, simple.Offset, simple.Language, simple.LanguageDetectionConfidence, undefined, simple.asJson(), resultProps);\n                ev = new Exports_js_2.IntentRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n                const sendEvent = () => {\n                    if (!!this.privIntentRecognizer.recognized) {\n                        try {\n                            this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    // report result to promise.\n                    if (!!this.privSuccessCallback) {\n                        try {\n                            this.privSuccessCallback(result);\n                        }\n                        catch (e) {\n                            if (!!this.privErrorCallback) {\n                                this.privErrorCallback(e);\n                            }\n                        }\n                        // Only invoke the call back once.\n                        // and if it's successful don't invoke the\n                        // error after that.\n                        this.privSuccessCallback = undefined;\n                        this.privErrorCallback = undefined;\n                    }\n                };\n                // If intent data was sent, the terminal result for this recognizer is an intent being found.\n                // If no intent data was sent, the terminal event is speech recognition being successful.\n                if (false === this.privIntentDataSent || Exports_js_2.ResultReason.NoMatch === ev.result.reason) {\n                    // Advance the buffers.\n                    this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);\n                    sendEvent();\n                }\n                else {\n                    // Squirrel away the args, when the response event arrives it will build upon them\n                    // and then return\n                    this.privPendingIntentArgs = ev;\n                }\n                processed = true;\n                break;\n            case \"response\":\n                // Response from LUIS\n                ev = this.privPendingIntentArgs;\n                this.privPendingIntentArgs = undefined;\n                if (undefined === ev) {\n                    if (\"\" === connectionMessage.textBody) {\n                        // This condition happens if there is nothing but silence in the\n                        // audio sent to the service.\n                        return;\n                    }\n                    // Odd... Not sure this can happen\n                    ev = new Exports_js_2.IntentRecognitionEventArgs(new Exports_js_2.IntentRecognitionResult(), 0, this.privRequestSession.sessionId);\n                }\n                const intentResponse = Exports_js_3.IntentResponse.fromJSON(connectionMessage.textBody);\n                // If LUIS didn't return anything, send the existing event, else\n                // modify it to show the match.\n                // See if the intent found is in the list of intents asked for.\n                if (null !== intentResponse && !!intentResponse.topScoringIntent && !!intentResponse.topScoringIntent.intent) {\n                    let addedIntent = this.privAddedLmIntents[intentResponse.topScoringIntent.intent];\n                    if (this.privUmbrellaIntent !== undefined) {\n                        addedIntent = this.privUmbrellaIntent;\n                    }\n                    if (!!addedIntent) {\n                        const intentId = addedIntent === undefined || addedIntent.intentName === undefined ? intentResponse.topScoringIntent.intent : addedIntent.intentName;\n                        let reason = ev.result.reason;\n                        if (undefined !== intentId) {\n                            reason = Exports_js_2.ResultReason.RecognizedIntent;\n                        }\n                        // make sure, properties is set.\n                        const properties = (undefined !== ev.result.properties) ?\n                            ev.result.properties : new Exports_js_2.PropertyCollection();\n                        properties.setProperty(Exports_js_2.PropertyId.LanguageUnderstandingServiceResponse_JsonResult, connectionMessage.textBody);\n                        ev = new Exports_js_2.IntentRecognitionEventArgs(new Exports_js_2.IntentRecognitionResult(intentId, ev.result.resultId, reason, ev.result.text, ev.result.duration, ev.result.offset, undefined, undefined, ev.result.errorDetails, ev.result.json, properties), ev.offset, ev.sessionId);\n                    }\n                }\n                this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);\n                if (!!this.privIntentRecognizer.recognized) {\n                    try {\n                        this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                // report result to promise.\n                if (!!this.privSuccessCallback) {\n                    try {\n                        this.privSuccessCallback(ev.result);\n                    }\n                    catch (e) {\n                        if (!!this.privErrorCallback) {\n                            this.privErrorCallback(e);\n                        }\n                    }\n                    // Only invoke the call back once.\n                    // and if it's successful don't invoke the\n                    // error after that.\n                    this.privSuccessCallback = undefined;\n                    this.privErrorCallback = undefined;\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new Exports_js_1.Deferred();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new Exports_js_2.PropertyCollection();\n        properties.setProperty(Exports_js_3.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[errorCode]);\n        if (!!this.privIntentRecognizer.canceled) {\n            const cancelEvent = new Exports_js_2.IntentRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, undefined, sessionId);\n            try {\n                this.privIntentRecognizer.canceled(this.privIntentRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new Exports_js_2.IntentRecognitionResult(undefined, // Intent Id\n            requestId, Exports_js_2.ResultReason.Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // LanguageDetectionConfidence\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n    }\n}\nexports.IntentServiceRecognizer = IntentServiceRecognizer;\n\n//# sourceMappingURL=IntentServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IntentServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.QueryParameterNames = void 0;\nclass QueryParameterNames {\n}\nexports.QueryParameterNames = QueryParameterNames;\nQueryParameterNames.BotId = \"botid\";\nQueryParameterNames.CustomSpeechDeploymentId = \"cid\";\nQueryParameterNames.CustomVoiceDeploymentId = \"deploymentId\";\nQueryParameterNames.EnableAudioLogging = \"storeAudio\";\nQueryParameterNames.EnableLanguageId = \"lidEnabled\";\nQueryParameterNames.EnableWordLevelTimestamps = \"wordLevelTimestamps\";\nQueryParameterNames.EndSilenceTimeoutMs = \"endSilenceTimeoutMs\";\nQueryParameterNames.SegmentationSilenceTimeoutMs = \"segmentationSilenceTimeoutMs\";\nQueryParameterNames.SegmentationMaximumTimeMs = \"segmentationMaximumTimeMs\";\nQueryParameterNames.SegmentationStrategy = \"segmentationStrategy\";\nQueryParameterNames.Format = \"format\";\nQueryParameterNames.InitialSilenceTimeoutMs = \"initialSilenceTimeoutMs\";\nQueryParameterNames.Language = \"language\";\nQueryParameterNames.Profanity = \"profanity\";\nQueryParameterNames.RequestBotStatusMessages = \"enableBotMessageStatus\";\nQueryParameterNames.StableIntermediateThreshold = \"stableIntermediateThreshold\";\nQueryParameterNames.StableTranslation = \"stableTranslation\";\nQueryParameterNames.TestHooks = \"testhooks\";\nQueryParameterNames.Postprocessing = \"postprocessing\";\nQueryParameterNames.CtsMeetingId = \"meetingId\";\nQueryParameterNames.CtsDeviceId = \"deviceId\";\nQueryParameterNames.CtsIsParticipant = \"isParticipant\";\nQueryParameterNames.EnableAvatar = \"enableTalkingAvatar\";\n\n//# sourceMappingURL=QueryParameterNames.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RecognitionEndedEvent = exports.RecognitionCompletionStatus = exports.RecognitionStartedEvent = exports.ConnectingToServiceEvent = exports.ListeningStartedEvent = exports.RecognitionTriggeredEvent = exports.SpeechRecognitionEvent = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nclass SpeechRecognitionEvent extends Exports_js_1.PlatformEvent {\n    constructor(eventName, requestId, sessionId, eventType = Exports_js_1.EventType.Info) {\n        super(eventName, eventType);\n        this.privRequestId = requestId;\n        this.privSessionId = sessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\nexports.SpeechRecognitionEvent = SpeechRecognitionEvent;\nclass RecognitionTriggeredEvent extends SpeechRecognitionEvent {\n    constructor(requestId, sessionId, audioSourceId, audioNodeId) {\n        super(\"RecognitionTriggeredEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nexports.RecognitionTriggeredEvent = RecognitionTriggeredEvent;\nclass ListeningStartedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, sessionId, audioSourceId, audioNodeId) {\n        super(\"ListeningStartedEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nexports.ListeningStartedEvent = ListeningStartedEvent;\nclass ConnectingToServiceEvent extends SpeechRecognitionEvent {\n    constructor(requestId, authFetchEventid, sessionId) {\n        super(\"ConnectingToServiceEvent\", requestId, sessionId);\n        this.privAuthFetchEventid = authFetchEventid;\n    }\n    get authFetchEventid() {\n        return this.privAuthFetchEventid;\n    }\n}\nexports.ConnectingToServiceEvent = ConnectingToServiceEvent;\nclass RecognitionStartedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId) {\n        super(\"RecognitionStartedEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\nexports.RecognitionStartedEvent = RecognitionStartedEvent;\nvar RecognitionCompletionStatus;\n(function (RecognitionCompletionStatus) {\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"Success\"] = 0] = \"Success\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AudioSourceError\"] = 1] = \"AudioSourceError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AudioSourceTimeout\"] = 2] = \"AudioSourceTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AuthTokenFetchError\"] = 3] = \"AuthTokenFetchError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AuthTokenFetchTimeout\"] = 4] = \"AuthTokenFetchTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"UnAuthorized\"] = 5] = \"UnAuthorized\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ConnectTimeout\"] = 6] = \"ConnectTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ConnectError\"] = 7] = \"ConnectError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ClientRecognitionActivityTimeout\"] = 8] = \"ClientRecognitionActivityTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"UnknownError\"] = 9] = \"UnknownError\";\n})(RecognitionCompletionStatus = exports.RecognitionCompletionStatus || (exports.RecognitionCompletionStatus = {}));\nclass RecognitionEndedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId, serviceTag, status, error) {\n        super(\"RecognitionEndedEvent\", requestId, sessionId, status === RecognitionCompletionStatus.Success ? Exports_js_1.EventType.Info : Exports_js_1.EventType.Error);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privAuthFetchEventId = authFetchEventId;\n        this.privStatus = status;\n        this.privError = error;\n        this.privServiceTag = serviceTag;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n    get serviceTag() {\n        return this.privServiceTag;\n    }\n    get status() {\n        return this.privStatus;\n    }\n    get error() {\n        return this.privError;\n    }\n}\nexports.RecognitionEndedEvent = RecognitionEndedEvent;\n\n//# sourceMappingURL=RecognitionEvents.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognizerConfig.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognizerConfig.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RecognizerConfig = exports.SpeechResultFormat = exports.RecognitionMode = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nvar RecognitionMode;\n(function (RecognitionMode) {\n    RecognitionMode[RecognitionMode[\"Interactive\"] = 0] = \"Interactive\";\n    RecognitionMode[RecognitionMode[\"Conversation\"] = 1] = \"Conversation\";\n    RecognitionMode[RecognitionMode[\"Dictation\"] = 2] = \"Dictation\";\n})(RecognitionMode = exports.RecognitionMode || (exports.RecognitionMode = {}));\nvar SpeechResultFormat;\n(function (SpeechResultFormat) {\n    SpeechResultFormat[SpeechResultFormat[\"Simple\"] = 0] = \"Simple\";\n    SpeechResultFormat[SpeechResultFormat[\"Detailed\"] = 1] = \"Detailed\";\n})(SpeechResultFormat = exports.SpeechResultFormat || (exports.SpeechResultFormat = {}));\nclass RecognizerConfig {\n    constructor(speechServiceConfig, parameters) {\n        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new Exports_js_2.SpeechServiceConfig(new Exports_js_2.Context(null));\n        this.privParameters = parameters;\n        this.privMaxRetryCount = parseInt(parameters.getProperty(\"SPEECH-Error-MaxRetryCount\", \"4\"), 10);\n        this.privLanguageIdMode = parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_LanguageIdMode, undefined);\n        this.privEnableSpeakerId = false;\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get recognitionMode() {\n        return this.privRecognitionMode;\n    }\n    set recognitionMode(value) {\n        this.privRecognitionMode = value;\n        this.privRecognitionActivityTimeout = value === RecognitionMode.Interactive ? 8000 : 25000;\n        this.privSpeechServiceConfig.Recognition = RecognitionMode[value];\n    }\n    get SpeechServiceConfig() {\n        return this.privSpeechServiceConfig;\n    }\n    get recognitionActivityTimeout() {\n        return this.privRecognitionActivityTimeout;\n    }\n    get isContinuousRecognition() {\n        return this.privRecognitionMode !== RecognitionMode.Interactive;\n    }\n    get languageIdMode() {\n        return this.privLanguageIdMode;\n    }\n    get autoDetectSourceLanguages() {\n        return this.parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, undefined);\n    }\n    get recognitionEndpointVersion() {\n        return this.parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, undefined);\n    }\n    get sourceLanguageModels() {\n        const models = [];\n        let modelsExist = false;\n        if (this.autoDetectSourceLanguages !== undefined) {\n            for (const language of this.autoDetectSourceLanguages.split(\",\")) {\n                const customProperty = language + Exports_js_1.PropertyId.SpeechServiceConnection_EndpointId.toString();\n                const modelId = this.parameters.getProperty(customProperty, undefined);\n                if (modelId !== undefined) {\n                    models.push({ language, endpoint: modelId });\n                    modelsExist = true;\n                }\n                else {\n                    models.push({ language, endpoint: \"\" });\n                }\n            }\n        }\n        return modelsExist ? models : undefined;\n    }\n    get maxRetryCount() {\n        return this.privMaxRetryCount;\n    }\n    get isSpeakerDiarizationEnabled() {\n        return this.privEnableSpeakerId;\n    }\n    set isSpeakerDiarizationEnabled(value) {\n        this.privEnableSpeakerId = value;\n    }\n}\nexports.RecognizerConfig = RecognizerConfig;\n\n//# sourceMappingURL=RecognizerConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognizerConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RequestSession.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RequestSession.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RequestSession = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst RecognitionEvents_js_1 = __webpack_require__(/*! ./RecognitionEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js\");\nconst ServiceTelemetryListener_Internal_js_1 = __webpack_require__(/*! ./ServiceTelemetryListener.Internal.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceTelemetryListener.Internal.js\");\nclass RequestSession {\n    constructor(audioSourceId) {\n        this.privIsDisposed = false;\n        this.privDetachables = new Array();\n        this.privIsAudioNodeDetached = false;\n        this.privIsRecognizing = false;\n        this.privIsSpeechEnded = false;\n        this.privTurnStartAudioOffset = 0;\n        this.privLastRecoOffset = 0;\n        this.privHypothesisReceived = false;\n        this.privBytesSent = 0;\n        this.privRecognitionBytesSent = 0;\n        this.privRecogNumber = 0;\n        this.privInTurn = false;\n        this.privConnectionAttempts = 0;\n        this.privAudioSourceId = audioSourceId;\n        this.privRequestId = Exports_js_1.createNoDashGuid();\n        this.privAudioNodeId = Exports_js_1.createNoDashGuid();\n        this.privTurnDeferral = new Exports_js_1.Deferred();\n        // We're not in a turn, so resolve.\n        this.privTurnDeferral.resolve();\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get turnCompletionPromise() {\n        return this.privTurnDeferral.promise;\n    }\n    get isSpeechEnded() {\n        return this.privIsSpeechEnded;\n    }\n    get isRecognizing() {\n        return this.privIsRecognizing;\n    }\n    get currentTurnAudioOffset() {\n        return this.privTurnStartAudioOffset;\n    }\n    get recogNumber() {\n        return this.privRecogNumber;\n    }\n    get numConnectionAttempts() {\n        return this.privConnectionAttempts;\n    }\n    // The number of bytes sent for the current connection.\n    // Counter is reset to 0 each time a connection is established.\n    get bytesSent() {\n        return this.privBytesSent;\n    }\n    // The number of bytes sent for the current recognition.\n    // Counter is reset to 0 each time recognition is started.\n    get recognitionBytesSent() {\n        return this.privRecognitionBytesSent;\n    }\n    listenForServiceTelemetry(eventSource) {\n        if (!!this.privServiceTelemetryListener) {\n            this.privDetachables.push(eventSource.attachListener(this.privServiceTelemetryListener));\n        }\n    }\n    startNewRecognition() {\n        this.privRecognitionBytesSent = 0;\n        this.privIsSpeechEnded = false;\n        this.privIsRecognizing = true;\n        this.privTurnStartAudioOffset = 0;\n        this.privLastRecoOffset = 0;\n        this.privRecogNumber++;\n        this.privServiceTelemetryListener = new ServiceTelemetryListener_Internal_js_1.ServiceTelemetryListener(this.privRequestId, this.privAudioSourceId, this.privAudioNodeId);\n        this.onEvent(new RecognitionEvents_js_1.RecognitionTriggeredEvent(this.requestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));\n    }\n    async onAudioSourceAttachCompleted(audioNode, isError) {\n        this.privAudioNode = audioNode;\n        this.privIsAudioNodeDetached = false;\n        if (isError) {\n            await this.onComplete();\n        }\n        else {\n            this.onEvent(new RecognitionEvents_js_1.ListeningStartedEvent(this.privRequestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));\n        }\n    }\n    onPreConnectionStart(authFetchEventId, connectionId) {\n        this.privAuthFetchEventId = authFetchEventId;\n        this.privSessionId = connectionId;\n        this.onEvent(new RecognitionEvents_js_1.ConnectingToServiceEvent(this.privRequestId, this.privAuthFetchEventId, this.privSessionId));\n    }\n    async onAuthCompleted(isError) {\n        if (isError) {\n            await this.onComplete();\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async onConnectionEstablishCompleted(statusCode, reason) {\n        if (statusCode === 200) {\n            this.onEvent(new RecognitionEvents_js_1.RecognitionStartedEvent(this.requestId, this.privAudioSourceId, this.privAudioNodeId, this.privAuthFetchEventId, this.privSessionId));\n            if (!!this.privAudioNode) {\n                this.privAudioNode.replay();\n            }\n            this.privTurnStartAudioOffset = this.privLastRecoOffset;\n            this.privBytesSent = 0;\n            return;\n        }\n        else if (statusCode === 403) {\n            await this.onComplete();\n        }\n    }\n    async onServiceTurnEndResponse(continuousRecognition) {\n        this.privTurnDeferral.resolve();\n        if (!continuousRecognition || this.isSpeechEnded) {\n            await this.onComplete();\n            this.privInTurn = false;\n        }\n        else {\n            // Start a new request set.\n            this.privTurnStartAudioOffset = this.privLastRecoOffset;\n            this.privAudioNode.replay();\n        }\n    }\n    onSpeechContext() {\n        this.privRequestId = Exports_js_1.createNoDashGuid();\n    }\n    onServiceTurnStartResponse() {\n        if (!!this.privTurnDeferral && !!this.privInTurn) {\n            // What? How are we starting a turn with another not done?\n            this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n            // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            this.privTurnDeferral.promise.then().catch(() => { });\n        }\n        this.privInTurn = true;\n        this.privTurnDeferral = new Exports_js_1.Deferred();\n    }\n    onHypothesis(offset) {\n        if (!this.privHypothesisReceived) {\n            this.privHypothesisReceived = true;\n            this.privServiceTelemetryListener.hypothesisReceived(this.privAudioNode.findTimeAtOffset(offset));\n        }\n    }\n    onPhraseRecognized(offset) {\n        this.privServiceTelemetryListener.phraseReceived(this.privAudioNode.findTimeAtOffset(offset));\n        this.onServiceRecognized(offset);\n    }\n    onServiceRecognized(offset) {\n        this.privLastRecoOffset = offset;\n        this.privHypothesisReceived = false;\n        this.privAudioNode.shrinkBuffers(offset);\n        this.privConnectionAttempts = 0;\n    }\n    onAudioSent(bytesSent) {\n        this.privBytesSent += bytesSent;\n        this.privRecognitionBytesSent += bytesSent;\n    }\n    onRetryConnection() {\n        this.privConnectionAttempts++;\n    }\n    async dispose() {\n        if (!this.privIsDisposed) {\n            // we should have completed by now. If we did not its an unknown error.\n            this.privIsDisposed = true;\n            for (const detachable of this.privDetachables) {\n                await detachable.detach();\n            }\n            if (!!this.privServiceTelemetryListener) {\n                this.privServiceTelemetryListener.dispose();\n            }\n            this.privIsRecognizing = false;\n        }\n    }\n    getTelemetry() {\n        if (this.privServiceTelemetryListener.hasTelemetry) {\n            return this.privServiceTelemetryListener.getTelemetry();\n        }\n        else {\n            return null;\n        }\n    }\n    async onStopRecognizing() {\n        await this.onComplete();\n    }\n    // Should be called with the audioNode for this session has indicated that it is out of speech.\n    onSpeechEnded() {\n        this.privIsSpeechEnded = true;\n    }\n    onEvent(event) {\n        if (!!this.privServiceTelemetryListener) {\n            this.privServiceTelemetryListener.onEvent(event);\n        }\n        Exports_js_1.Events.instance.onEvent(event);\n    }\n    async onComplete() {\n        if (!!this.privIsRecognizing) {\n            this.privIsRecognizing = false;\n            await this.detachAudioNode();\n        }\n    }\n    async detachAudioNode() {\n        if (!this.privIsAudioNodeDetached) {\n            this.privIsAudioNodeDetached = true;\n            if (this.privAudioNode) {\n                await this.privAudioNode.detach();\n            }\n        }\n    }\n}\nexports.RequestSession = RequestSession;\n\n//# sourceMappingURL=RequestSession.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RequestSession.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// response\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MessageDataStreamType = exports.ActivityPayloadResponse = void 0;\nclass ActivityPayloadResponse {\n    constructor(json) {\n        this.privActivityResponse = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new ActivityPayloadResponse(json);\n    }\n    get conversationId() {\n        return this.privActivityResponse.conversationId;\n    }\n    get messageDataStreamType() {\n        return this.privActivityResponse.messageDataStreamType;\n    }\n    get messagePayload() {\n        return this.privActivityResponse.messagePayload;\n    }\n    get version() {\n        return this.privActivityResponse.version;\n    }\n}\nexports.ActivityPayloadResponse = ActivityPayloadResponse;\nvar MessageDataStreamType;\n(function (MessageDataStreamType) {\n    MessageDataStreamType[MessageDataStreamType[\"None\"] = 0] = \"None\";\n    MessageDataStreamType[MessageDataStreamType[\"TextToSpeechAudio\"] = 1] = \"TextToSpeechAudio\";\n})(MessageDataStreamType = exports.MessageDataStreamType || (exports.MessageDataStreamType = {}));\n\n//# sourceMappingURL=ActivityResponsePayload.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DetailedSpeechPhrase = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass DetailedSpeechPhrase {\n    constructor(json, baseOffset) {\n        this.privDetailedSpeechPhrase = JSON.parse(json);\n        this.privDetailedSpeechPhrase.RecognitionStatus = this.mapRecognitionStatus(this.privDetailedSpeechPhrase.RecognitionStatus);\n        this.updateOffsets(baseOffset);\n    }\n    static fromJSON(json, baseOffset) {\n        return new DetailedSpeechPhrase(json, baseOffset);\n    }\n    updateOffsets(baseOffset) {\n        this.privDetailedSpeechPhrase.Offset += baseOffset;\n        if (!!this.privDetailedSpeechPhrase.NBest) {\n            for (const phrase of this.privDetailedSpeechPhrase.NBest) {\n                if (!!phrase.Words) {\n                    for (const word of phrase.Words) {\n                        word.Offset += baseOffset;\n                    }\n                }\n                if (!!phrase.DisplayWords) {\n                    for (const word of phrase.DisplayWords) {\n                        word.Offset += baseOffset;\n                    }\n                }\n            }\n        }\n    }\n    asJson() {\n        const jsonObj = { ...this.privDetailedSpeechPhrase };\n        // Convert the enum value to its string representation for serialization purposes.\n        return JSON.stringify({\n            ...jsonObj,\n            RecognitionStatus: Exports_js_1.RecognitionStatus[jsonObj.RecognitionStatus]\n        });\n    }\n    get RecognitionStatus() {\n        return this.privDetailedSpeechPhrase.RecognitionStatus;\n    }\n    get NBest() {\n        return this.privDetailedSpeechPhrase.NBest;\n    }\n    get Duration() {\n        return this.privDetailedSpeechPhrase.Duration;\n    }\n    get Offset() {\n        return this.privDetailedSpeechPhrase.Offset;\n    }\n    get Language() {\n        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Confidence;\n    }\n    get Text() {\n        if (!!this.privDetailedSpeechPhrase.NBest && this.privDetailedSpeechPhrase.NBest[0]) {\n            return this.privDetailedSpeechPhrase.NBest[0].Display || this.privDetailedSpeechPhrase.NBest[0].DisplayText;\n        }\n        return this.privDetailedSpeechPhrase.DisplayText;\n    }\n    get SpeakerId() {\n        return this.privDetailedSpeechPhrase.SpeakerId;\n    }\n    mapRecognitionStatus(status) {\n        if (typeof status === \"string\") {\n            return Exports_js_1.RecognitionStatus[status];\n        }\n        else if (typeof status === \"number\") {\n            return status;\n        }\n    }\n}\nexports.DetailedSpeechPhrase = DetailedSpeechPhrase;\n\n//# sourceMappingURL=DetailedSpeechPhrase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Enums.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Enums.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RecognitionStatus = exports.SynthesisStatus = void 0;\n/**\n * @class SynthesisStatus\n * @private\n */\nvar SynthesisStatus;\n(function (SynthesisStatus) {\n    /**\n     * The response contains valid audio data.\n     * @member SynthesisStatus.Success\n     */\n    SynthesisStatus[SynthesisStatus[\"Success\"] = 0] = \"Success\";\n    /**\n     * Indicates the end of audio data. No valid audio data is included in the message.\n     * @member SynthesisStatus.SynthesisEnd\n     */\n    SynthesisStatus[SynthesisStatus[\"SynthesisEnd\"] = 1] = \"SynthesisEnd\";\n    /**\n     * Indicates an error occurred during synthesis data processing.\n     * @member SynthesisStatus.Error\n     */\n    SynthesisStatus[SynthesisStatus[\"Error\"] = 2] = \"Error\";\n})(SynthesisStatus = exports.SynthesisStatus || (exports.SynthesisStatus = {}));\nvar RecognitionStatus;\n(function (RecognitionStatus) {\n    RecognitionStatus[RecognitionStatus[\"Success\"] = 0] = \"Success\";\n    RecognitionStatus[RecognitionStatus[\"NoMatch\"] = 1] = \"NoMatch\";\n    RecognitionStatus[RecognitionStatus[\"InitialSilenceTimeout\"] = 2] = \"InitialSilenceTimeout\";\n    RecognitionStatus[RecognitionStatus[\"BabbleTimeout\"] = 3] = \"BabbleTimeout\";\n    RecognitionStatus[RecognitionStatus[\"Error\"] = 4] = \"Error\";\n    RecognitionStatus[RecognitionStatus[\"EndOfDictation\"] = 5] = \"EndOfDictation\";\n    RecognitionStatus[RecognitionStatus[\"TooManyRequests\"] = 6] = \"TooManyRequests\";\n    RecognitionStatus[RecognitionStatus[\"BadRequest\"] = 7] = \"BadRequest\";\n    RecognitionStatus[RecognitionStatus[\"Forbidden\"] = 8] = \"Forbidden\";\n})(RecognitionStatus = exports.RecognitionStatus || (exports.RecognitionStatus = {}));\n\n//# sourceMappingURL=Enums.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Enums.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/IntentResponse.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/IntentResponse.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// response\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IntentResponse = void 0;\nclass IntentResponse {\n    constructor(json) {\n        if (json === \"\") {\n            this.privIntentResponse = {};\n        }\n        else {\n            this.privIntentResponse = JSON.parse(json);\n        }\n    }\n    static fromJSON(json) {\n        return new IntentResponse(json);\n    }\n    get query() {\n        return this.privIntentResponse.query;\n    }\n    get topScoringIntent() {\n        return this.privIntentResponse.topScoringIntent;\n    }\n    get entities() {\n        return this.privIntentResponse.entities;\n    }\n}\nexports.IntentResponse = IntentResponse;\n\n//# sourceMappingURL=IntentResponse.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/IntentResponse.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js ***!
  \*********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SimpleSpeechPhrase = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass SimpleSpeechPhrase {\n    constructor(json, baseOffset = 0) {\n        this.privSimpleSpeechPhrase = JSON.parse(json);\n        this.privSimpleSpeechPhrase.RecognitionStatus = this.mapRecognitionStatus(this.privSimpleSpeechPhrase.RecognitionStatus); // RecognitionStatus[this.privSimpleSpeechPhrase.RecognitionStatus as unknown as keyof typeof RecognitionStatus];\n        this.updateOffset(baseOffset);\n    }\n    static fromJSON(json, baseOffset) {\n        return new SimpleSpeechPhrase(json, baseOffset);\n    }\n    updateOffset(baseOffset) {\n        this.privSimpleSpeechPhrase.Offset += baseOffset;\n    }\n    asJson() {\n        const jsonObj = { ...this.privSimpleSpeechPhrase };\n        // Convert the enum value to its string representation for serialization purposes.\n        return JSON.stringify({\n            ...jsonObj,\n            RecognitionStatus: Exports_js_1.RecognitionStatus[jsonObj.RecognitionStatus]\n        });\n    }\n    get RecognitionStatus() {\n        return this.privSimpleSpeechPhrase.RecognitionStatus;\n    }\n    get DisplayText() {\n        return this.privSimpleSpeechPhrase.DisplayText;\n    }\n    get Offset() {\n        return this.privSimpleSpeechPhrase.Offset;\n    }\n    get Duration() {\n        return this.privSimpleSpeechPhrase.Duration;\n    }\n    get Language() {\n        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Confidence;\n    }\n    get SpeakerId() {\n        return this.privSimpleSpeechPhrase.SpeakerId;\n    }\n    mapRecognitionStatus(status) {\n        if (typeof status === \"string\") {\n            return Exports_js_1.RecognitionStatus[status];\n        }\n        else if (typeof status === \"number\") {\n            return status;\n        }\n    }\n}\nexports.SimpleSpeechPhrase = SimpleSpeechPhrase;\n\n//# sourceMappingURL=SimpleSpeechPhrase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeakerResponse.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeakerResponse.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=SpeakerResponse.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeakerResponse.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechDetected.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechDetected.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechDetected = void 0;\nclass SpeechDetected {\n    constructor(json, baseOffset) {\n        this.privSpeechStartDetected = JSON.parse(json);\n        this.privSpeechStartDetected.Offset += baseOffset;\n    }\n    static fromJSON(json, baseOffset) {\n        return new SpeechDetected(json, baseOffset);\n    }\n    get Offset() {\n        return this.privSpeechStartDetected.Offset;\n    }\n}\nexports.SpeechDetected = SpeechDetected;\n\n//# sourceMappingURL=SpeechDetected.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechDetected.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechHypothesis.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechHypothesis.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechHypothesis = void 0;\nclass SpeechHypothesis {\n    constructor(json, baseOffset) {\n        this.privSpeechHypothesis = JSON.parse(json);\n        this.updateOffset(baseOffset);\n    }\n    static fromJSON(json, baseOffset) {\n        return new SpeechHypothesis(json, baseOffset);\n    }\n    updateOffset(baseOffset) {\n        this.privSpeechHypothesis.Offset += baseOffset;\n    }\n    asJson() {\n        return JSON.stringify(this.privSpeechHypothesis);\n    }\n    get Text() {\n        return this.privSpeechHypothesis.Text;\n    }\n    get Offset() {\n        return this.privSpeechHypothesis.Offset;\n    }\n    get Duration() {\n        return this.privSpeechHypothesis.Duration;\n    }\n    get Language() {\n        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Confidence;\n    }\n    get SpeakerId() {\n        return this.privSpeechHypothesis.SpeakerId;\n    }\n}\nexports.SpeechHypothesis = SpeechHypothesis;\n\n//# sourceMappingURL=SpeechHypothesis.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechHypothesis.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechKeyword.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechKeyword.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechKeyword = void 0;\nclass SpeechKeyword {\n    constructor(json, baseOffset) {\n        this.privSpeechKeyword = JSON.parse(json);\n        this.privSpeechKeyword.Offset += baseOffset;\n    }\n    static fromJSON(json, baseOffset) {\n        return new SpeechKeyword(json, baseOffset);\n    }\n    get Status() {\n        return this.privSpeechKeyword.Status;\n    }\n    get Text() {\n        return this.privSpeechKeyword.Text;\n    }\n    get Offset() {\n        return this.privSpeechKeyword.Offset;\n    }\n    get Duration() {\n        return this.privSpeechKeyword.Duration;\n    }\n    asJson() {\n        return JSON.stringify(this.privSpeechKeyword);\n    }\n}\nexports.SpeechKeyword = SpeechKeyword;\n\n//# sourceMappingURL=SpeechKeyword.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechKeyword.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisAudioMetadata = exports.MetadataType = void 0;\nvar MetadataType;\n(function (MetadataType) {\n    MetadataType[\"WordBoundary\"] = \"WordBoundary\";\n    MetadataType[\"Bookmark\"] = \"Bookmark\";\n    MetadataType[\"Viseme\"] = \"Viseme\";\n    MetadataType[\"SentenceBoundary\"] = \"SentenceBoundary\";\n    MetadataType[\"SessionEnd\"] = \"SessionEnd\";\n    MetadataType[\"AvatarSignal\"] = \"TalkingAvatarSignal\";\n})(MetadataType = exports.MetadataType || (exports.MetadataType = {}));\nclass SynthesisAudioMetadata {\n    constructor(json) {\n        this.privSynthesisAudioMetadata = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SynthesisAudioMetadata(json);\n    }\n    get Metadata() {\n        return this.privSynthesisAudioMetadata.Metadata;\n    }\n}\nexports.SynthesisAudioMetadata = SynthesisAudioMetadata;\n\n//# sourceMappingURL=SynthesisAudioMetadata.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationHypothesis.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationHypothesis.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationHypothesis = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst TranslationStatus_js_1 = __webpack_require__(/*! ../TranslationStatus.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js\");\nclass TranslationHypothesis {\n    constructor(hypothesis, baseOffset) {\n        this.privTranslationHypothesis = hypothesis;\n        this.privTranslationHypothesis.Offset += baseOffset;\n        this.privTranslationHypothesis.Translation.TranslationStatus = this.mapTranslationStatus(this.privTranslationHypothesis.Translation.TranslationStatus);\n    }\n    static fromJSON(json, baseOffset) {\n        return new TranslationHypothesis(JSON.parse(json), baseOffset);\n    }\n    static fromTranslationResponse(translationHypothesis, baseOffset) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(translationHypothesis, \"translationHypothesis\");\n        const hypothesis = translationHypothesis.SpeechHypothesis;\n        translationHypothesis.SpeechHypothesis = undefined;\n        hypothesis.Translation = translationHypothesis;\n        return new TranslationHypothesis(hypothesis, baseOffset);\n    }\n    get Duration() {\n        return this.privTranslationHypothesis.Duration;\n    }\n    get Offset() {\n        return this.privTranslationHypothesis.Offset;\n    }\n    get Text() {\n        return this.privTranslationHypothesis.Text;\n    }\n    get Translation() {\n        return this.privTranslationHypothesis.Translation;\n    }\n    get Language() {\n        return this.privTranslationHypothesis.PrimaryLanguage?.Language;\n    }\n    asJson() {\n        const jsonObj = { ...this.privTranslationHypothesis };\n        // Convert the enum value to its string representation for serialization purposes.\n        return jsonObj.Translation !== undefined ? JSON.stringify({\n            ...jsonObj,\n            TranslationStatus: TranslationStatus_js_1.TranslationStatus[jsonObj.Translation.TranslationStatus]\n        }) : JSON.stringify(jsonObj);\n    }\n    mapTranslationStatus(status) {\n        if (typeof status === \"string\") {\n            return TranslationStatus_js_1.TranslationStatus[status];\n        }\n        else if (typeof status === \"number\") {\n            return status;\n        }\n    }\n}\nexports.TranslationHypothesis = TranslationHypothesis;\n\n//# sourceMappingURL=TranslationHypothesis.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationHypothesis.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationPhrase.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationPhrase.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationPhrase = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst TranslationStatus_js_1 = __webpack_require__(/*! ../TranslationStatus.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js\");\nclass TranslationPhrase {\n    constructor(phrase, baseOffset) {\n        this.privTranslationPhrase = phrase;\n        this.privTranslationPhrase.Offset += baseOffset;\n        this.privTranslationPhrase.RecognitionStatus = this.mapRecognitionStatus(this.privTranslationPhrase.RecognitionStatus);\n        if (this.privTranslationPhrase.Translation !== undefined) {\n            this.privTranslationPhrase.Translation.TranslationStatus = this.mapTranslationStatus(this.privTranslationPhrase.Translation.TranslationStatus);\n        }\n    }\n    static fromJSON(json, baseOffset) {\n        return new TranslationPhrase(JSON.parse(json), baseOffset);\n    }\n    static fromTranslationResponse(translationResponse, baseOffset) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(translationResponse, \"translationResponse\");\n        const phrase = translationResponse.SpeechPhrase;\n        translationResponse.SpeechPhrase = undefined;\n        phrase.Translation = translationResponse;\n        phrase.Text = phrase.DisplayText;\n        return new TranslationPhrase(phrase, baseOffset);\n    }\n    get RecognitionStatus() {\n        return this.privTranslationPhrase.RecognitionStatus;\n    }\n    get Offset() {\n        return this.privTranslationPhrase.Offset;\n    }\n    get Duration() {\n        return this.privTranslationPhrase.Duration;\n    }\n    get Text() {\n        return this.privTranslationPhrase.Text;\n    }\n    get Language() {\n        return this.privTranslationPhrase.PrimaryLanguage?.Language;\n    }\n    get Confidence() {\n        return this.privTranslationPhrase.PrimaryLanguage?.Confidence;\n    }\n    get Translation() {\n        return this.privTranslationPhrase.Translation;\n    }\n    asJson() {\n        const jsonObj = { ...this.privTranslationPhrase };\n        // Convert the enum values to their string representations for serialization\n        const serializedObj = {\n            ...jsonObj,\n            RecognitionStatus: Exports_js_1.RecognitionStatus[jsonObj.RecognitionStatus]\n        };\n        if (jsonObj.Translation) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n            serializedObj.Translation = {\n                ...jsonObj.Translation,\n                TranslationStatus: TranslationStatus_js_1.TranslationStatus[jsonObj.Translation.TranslationStatus]\n            };\n        }\n        return JSON.stringify(serializedObj);\n    }\n    mapRecognitionStatus(status) {\n        if (typeof status === \"string\") {\n            return Exports_js_1.RecognitionStatus[status];\n        }\n        else if (typeof status === \"number\") {\n            return status;\n        }\n    }\n    mapTranslationStatus(status) {\n        if (typeof status === \"string\") {\n            return TranslationStatus_js_1.TranslationStatus[status];\n        }\n        else if (typeof status === \"number\") {\n            return status;\n        }\n    }\n}\nexports.TranslationPhrase = TranslationPhrase;\n\n//# sourceMappingURL=TranslationPhrase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationSynthesisEnd = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass TranslationSynthesisEnd {\n    constructor(json) {\n        this.privSynthesisEnd = JSON.parse(json);\n        if (!!this.privSynthesisEnd.SynthesisStatus) {\n            this.privSynthesisEnd.SynthesisStatus = Exports_js_1.SynthesisStatus[this.privSynthesisEnd.SynthesisStatus];\n        }\n        if (!!this.privSynthesisEnd.Status) {\n            this.privSynthesisEnd.SynthesisStatus = Exports_js_1.SynthesisStatus[this.privSynthesisEnd.Status];\n        }\n    }\n    static fromJSON(json) {\n        return new TranslationSynthesisEnd(json);\n    }\n    get SynthesisStatus() {\n        return this.privSynthesisEnd.SynthesisStatus;\n    }\n    get FailureReason() {\n        return this.privSynthesisEnd.FailureReason;\n    }\n}\nexports.TranslationSynthesisEnd = TranslationSynthesisEnd;\n\n//# sourceMappingURL=TranslationSynthesisEnd.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TurnStatusPayload.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TurnStatusPayload.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TurnStatusResponsePayload = void 0;\nclass TurnStatusResponsePayload {\n    constructor(json) {\n        this.privMessageStatusResponse = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new TurnStatusResponsePayload(json);\n    }\n    get interactionId() {\n        return this.privMessageStatusResponse.interactionId;\n    }\n    get conversationId() {\n        return this.privMessageStatusResponse.conversationId;\n    }\n    get statusCode() {\n        // Payloads may contain a limited set of textual representations or a numeric status\n        // code. The textual values are here converted into numeric ones.\n        switch (this.privMessageStatusResponse.statusCode) {\n            case \"Success\":\n                return 200;\n            case \"Failed\":\n                return 400;\n            case \"TimedOut\":\n                return 429;\n            default:\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n                return this.privMessageStatusResponse.statusCode;\n        }\n    }\n}\nexports.TurnStatusResponsePayload = TurnStatusResponsePayload;\n\n//# sourceMappingURL=TurnStatusPayload.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TurnStatusPayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceRecognizerBase.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceRecognizerBase.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServiceRecognizerBase = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js\");\nclass ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        // A promise for a configured connection.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionConfigurationPromise = undefined;\n        // A promise for a connection, but one that has not had the speech context sent yet.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionPromise = undefined;\n        this.privSetTimeout = setTimeout;\n        this.privIsLiveAudio = false;\n        this.privAverageBytesPerMs = 0;\n        this.privEnableSpeakerId = false;\n        this.privExpectContentAssessmentResponse = false;\n        this.recognizeOverride = undefined;\n        this.recognizeSpeaker = undefined;\n        this.disconnectOverride = undefined;\n        this.receiveMessageOverride = undefined;\n        this.sendPrePayloadJSONOverride = undefined;\n        this.postConnectImplOverride = undefined;\n        this.configConnectionOverride = undefined;\n        this.handleSpeechPhraseMessage = undefined;\n        this.handleSpeechHypothesisMessage = undefined;\n        if (!authentication) {\n            throw new Exports_js_2.ArgumentNullError(\"authentication\");\n        }\n        if (!connectionFactory) {\n            throw new Exports_js_2.ArgumentNullError(\"connectionFactory\");\n        }\n        if (!audioSource) {\n            throw new Exports_js_2.ArgumentNullError(\"audioSource\");\n        }\n        if (!recognizerConfig) {\n            throw new Exports_js_2.ArgumentNullError(\"recognizerConfig\");\n        }\n        this.privEnableSpeakerId = recognizerConfig.isSpeakerDiarizationEnabled;\n        this.privMustReportEndOfStream = false;\n        this.privAuthentication = authentication;\n        this.privConnectionFactory = connectionFactory;\n        this.privAudioSource = audioSource;\n        this.privRecognizerConfig = recognizerConfig;\n        this.privIsDisposed = false;\n        this.privRecognizer = recognizer;\n        this.privRequestSession = new Exports_js_4.RequestSession(this.privAudioSource.id());\n        this.privConnectionEvents = new Exports_js_2.EventSource();\n        this.privServiceEvents = new Exports_js_2.EventSource();\n        this.privDynamicGrammar = new Exports_js_4.DynamicGrammarBuilder();\n        this.privSpeechContext = new Exports_js_4.SpeechContext(this.privDynamicGrammar);\n        this.privAgentConfig = new Exports_js_4.AgentConfig();\n        const webWorkerLoadType = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.WebWorkerLoadType, \"on\").toLowerCase();\n        if (webWorkerLoadType === \"on\" && typeof (Blob) !== \"undefined\" && typeof (Worker) !== \"undefined\") {\n            this.privSetTimeout = Exports_js_2.Timeout.setTimeout;\n        }\n        else {\n            if (typeof window !== \"undefined\") {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                this.privSetTimeout = window.setTimeout.bind(window);\n            }\n            if (typeof globalThis !== \"undefined\") {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                this.privSetTimeout = globalThis.setTimeout.bind(globalThis);\n            }\n        }\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                const connectionClosedEvent = connectionEvent;\n                if (connectionClosedEvent.statusCode === 1003 ||\n                    connectionClosedEvent.statusCode === 1007 ||\n                    connectionClosedEvent.statusCode === 1002 ||\n                    connectionClosedEvent.statusCode === 4000 ||\n                    this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {\n                    void this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? Exports_js_3.CancellationErrorCode.BadRequestParameters : Exports_js_3.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n                }\n            }\n        });\n        if (this.privEnableSpeakerId) {\n            this.privDiarizationSessionId = Exports_js_2.createNoDashGuid();\n        }\n        this.setLanguageIdJson();\n        this.setOutputDetailLevelJson();\n    }\n    setTranslationJson() {\n        const targetLanguages = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined);\n        if (targetLanguages !== undefined) {\n            const languages = targetLanguages.split(\",\");\n            const translationVoice = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);\n            const action = (translationVoice !== undefined) ? \"Synthesize\" : \"None\";\n            this.privSpeechContext.setSection(\"translation\", {\n                onSuccess: { action },\n                output: { interimResults: { mode: \"Always\" } },\n                targetLanguages: languages,\n            });\n            if (translationVoice !== undefined) {\n                const languageToVoiceMap = {};\n                for (const lang of languages) {\n                    languageToVoiceMap[lang] = translationVoice;\n                }\n                this.privSpeechContext.setSection(\"synthesis\", {\n                    defaultVoices: languageToVoiceMap\n                });\n            }\n        }\n    }\n    setSpeechSegmentationTimeoutJson() {\n        const speechSegmentationSilenceTimeoutMs = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Speech_SegmentationSilenceTimeoutMs, undefined);\n        const speechSegmentationMaximumTimeMs = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Speech_SegmentationMaximumTimeMs, undefined);\n        const speechSegmentationStrategy = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Speech_SegmentationStrategy, undefined);\n        const segmentation = {\n            segmentation: {\n                mode: \"\"\n            }\n        };\n        let configuredSegment = false;\n        if (speechSegmentationStrategy !== undefined) {\n            configuredSegment = true;\n            let segMode = \"\";\n            switch (speechSegmentationStrategy.toLowerCase()) {\n                case \"default\":\n                    break;\n                case \"time\":\n                    segMode = \"Custom\";\n                    break;\n                case \"semantic\":\n                    segMode = \"Semantic\";\n                    break;\n            }\n            segmentation.segmentation.mode = segMode;\n        }\n        if (speechSegmentationSilenceTimeoutMs !== undefined) {\n            configuredSegment = true;\n            const segmentationSilenceTimeoutMs = parseInt(speechSegmentationSilenceTimeoutMs, 10);\n            segmentation.segmentation.mode = \"Custom\";\n            segmentation.segmentation.segmentationSilenceTimeoutMs = segmentationSilenceTimeoutMs;\n        }\n        if (speechSegmentationMaximumTimeMs !== undefined) {\n            configuredSegment = true;\n            const segmentationMaximumTimeMs = parseInt(speechSegmentationMaximumTimeMs, 10);\n            segmentation.segmentation.mode = \"Custom\";\n            segmentation.segmentation.segmentationForcedTimeoutMs = segmentationMaximumTimeMs;\n        }\n        if (configuredSegment) {\n            const recoMode = this.recognitionMode === Exports_js_4.RecognitionMode.Conversation ? \"CONVERSATION\" :\n                this.recognitionMode === Exports_js_4.RecognitionMode.Dictation ? \"DICTATION\" : \"INTERACTIVE\";\n            const phraseDetection = this.privSpeechContext.getSection(\"phraseDetection\");\n            phraseDetection.mode = recoMode;\n            phraseDetection[recoMode] = segmentation;\n            this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n        }\n    }\n    setLanguageIdJson() {\n        const phraseDetection = this.privSpeechContext.getSection(\"phraseDetection\");\n        if (this.privRecognizerConfig.autoDetectSourceLanguages !== undefined) {\n            const sourceLanguages = this.privRecognizerConfig.autoDetectSourceLanguages.split(\",\");\n            let speechContextLidMode;\n            if (this.privRecognizerConfig.languageIdMode === \"Continuous\") {\n                speechContextLidMode = \"DetectContinuous\";\n            }\n            else { // recognizerConfig.languageIdMode === \"AtStart\"\n                speechContextLidMode = \"DetectAtAudioStart\";\n            }\n            this.privSpeechContext.setSection(\"languageId\", {\n                Priority: \"PrioritizeLatency\",\n                languages: sourceLanguages,\n                mode: speechContextLidMode,\n                onSuccess: { action: \"Recognize\" },\n                onUnknown: { action: \"None\" }\n            });\n            this.privSpeechContext.setSection(\"phraseOutput\", {\n                interimResults: {\n                    resultType: \"Auto\"\n                },\n                phraseResults: {\n                    resultType: \"Always\"\n                }\n            });\n            const customModels = this.privRecognizerConfig.sourceLanguageModels;\n            if (customModels !== undefined) {\n                phraseDetection.customModels = customModels;\n                phraseDetection.onInterim = { action: \"None\" };\n                phraseDetection.onSuccess = { action: \"None\" };\n            }\n        }\n        const targetLanguages = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined);\n        if (targetLanguages !== undefined) {\n            phraseDetection.onInterim = { action: \"Translate\" };\n            phraseDetection.onSuccess = { action: \"Translate\" };\n            this.privSpeechContext.setSection(\"phraseOutput\", {\n                interimResults: {\n                    resultType: \"None\"\n                },\n                phraseResults: {\n                    resultType: \"None\"\n                }\n            });\n        }\n        this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n    }\n    setOutputDetailLevelJson() {\n        if (this.privEnableSpeakerId) {\n            const requestWordLevelTimestamps = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"false\").toLowerCase();\n            if (requestWordLevelTimestamps === \"true\") {\n                this.privSpeechContext.setWordLevelTimings();\n            }\n            else {\n                const outputFormat = this.privRecognizerConfig.parameters.getProperty(Exports_js_4.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]).toLowerCase();\n                if (outputFormat === Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Detailed].toLocaleLowerCase()) {\n                    this.privSpeechContext.setDetailedOutputFormat();\n                }\n            }\n        }\n    }\n    get isSpeakerDiarizationEnabled() {\n        return this.privEnableSpeakerId;\n    }\n    get audioSource() {\n        return this.privAudioSource;\n    }\n    get speechContext() {\n        return this.privSpeechContext;\n    }\n    get dynamicGrammar() {\n        return this.privDynamicGrammar;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n    set conversationTranslatorToken(token) {\n        this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.ConversationTranslator_Token, token);\n    }\n    set voiceProfileType(type) {\n        this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SpeakerIdMode, type);\n    }\n    set authentication(auth) {\n        this.privAuthentication = auth;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    async dispose(reason) {\n        this.privIsDisposed = true;\n        if (this.privConnectionConfigurationPromise !== undefined) {\n            try {\n                const connection = await this.privConnectionConfigurationPromise;\n                await connection.dispose(reason);\n            }\n            catch (error) {\n                // The connection is in a bad state. But we're trying to kill it, so...\n                return;\n            }\n        }\n    }\n    get connectionEvents() {\n        return this.privConnectionEvents;\n    }\n    get serviceEvents() {\n        return this.privServiceEvents;\n    }\n    get recognitionMode() {\n        return this.privRecognizerConfig.recognitionMode;\n    }\n    async recognize(recoMode, successCallback, errorCallBack) {\n        if (this.recognizeOverride !== undefined) {\n            await this.recognizeOverride(recoMode, successCallback, errorCallBack);\n            return;\n        }\n        // Clear the existing configuration promise to force a re-transmission of config and context.\n        this.privConnectionConfigurationPromise = undefined;\n        this.privRecognizerConfig.recognitionMode = recoMode;\n        this.setSpeechSegmentationTimeoutJson();\n        this.setTranslationJson();\n        this.privSuccessCallback = successCallback;\n        this.privErrorCallback = errorCallBack;\n        this.privRequestSession.startNewRecognition();\n        this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);\n        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n        const conPromise = this.connectImpl();\n        let audioNode;\n        try {\n            const audioStreamNode = await this.audioSource.attach(this.privRequestSession.audioNodeId);\n            const format = await this.audioSource.format;\n            const deviceInfo = await this.audioSource.deviceInfo;\n            this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === Exports_js_4.type.Microphones;\n            audioNode = new Exports_js_1.ReplayableAudioNode(audioStreamNode, format.avgBytesPerSec);\n            await this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n            this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n        }\n        catch (error) {\n            await this.privRequestSession.onStopRecognizing();\n            throw error;\n        }\n        try {\n            await conPromise;\n        }\n        catch (error) {\n            await this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.ConnectionFailure, error);\n            return;\n        }\n        const sessionStartEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n        if (!!this.privRecognizer.sessionStarted) {\n            this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n        }\n        void this.receiveMessage();\n        const audioSendPromise = this.sendAudio(audioNode);\n        audioSendPromise.catch(async (error) => {\n            await this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);\n        });\n        return;\n    }\n    async stopRecognizing() {\n        if (this.privRequestSession.isRecognizing) {\n            try {\n                await this.audioSource.turnOff();\n                await this.sendFinalAudio();\n                await this.privRequestSession.onStopRecognizing();\n                await this.privRequestSession.turnCompletionPromise;\n            }\n            finally {\n                await this.privRequestSession.dispose();\n            }\n        }\n        return;\n    }\n    async connect() {\n        await this.connectImpl();\n        return Promise.resolve();\n    }\n    connectAsync(cb, err) {\n        this.connectImpl().then(() => {\n            try {\n                if (!!cb) {\n                    cb();\n                }\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n        }, (reason) => {\n            try {\n                if (!!err) {\n                    err(reason);\n                }\n                /* eslint-disable no-empty */\n            }\n            catch (error) {\n            }\n        });\n    }\n    async disconnect() {\n        await this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.NoError, \"Disconnecting\");\n        if (this.disconnectOverride !== undefined) {\n            await this.disconnectOverride();\n        }\n        if (this.privConnectionPromise !== undefined) {\n            try {\n                await (await this.privConnectionPromise).dispose();\n            }\n            catch (error) {\n            }\n        }\n        this.privConnectionPromise = undefined;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    sendMessage(message) {\n        return;\n    }\n    async sendNetworkMessage(path, payload) {\n        const type = typeof payload === \"string\" ? Exports_js_2.MessageType.Text : Exports_js_2.MessageType.Binary;\n        const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n        const connection = await this.fetchConnection();\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(type, path, this.privRequestSession.requestId, contentType, payload));\n    }\n    set activityTemplate(messagePayload) {\n        this.privActivityTemplate = messagePayload;\n    }\n    get activityTemplate() {\n        return this.privActivityTemplate;\n    }\n    set expectContentAssessmentResponse(value) {\n        this.privExpectContentAssessmentResponse = value;\n    }\n    async sendTelemetryData() {\n        const telemetryData = this.privRequestSession.getTelemetry();\n        if (ServiceRecognizerBase.telemetryDataEnabled !== true ||\n            this.privIsDisposed ||\n            null === telemetryData) {\n            return;\n        }\n        if (!!ServiceRecognizerBase.telemetryData) {\n            try {\n                ServiceRecognizerBase.telemetryData(telemetryData);\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n        const connection = await this.fetchConnection();\n        await connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"telemetry\", this.privRequestSession.requestId, \"application/json\", telemetryData));\n    }\n    // Cancels recognition.\n    async cancelRecognitionLocal(cancellationReason, errorCode, error) {\n        if (!!this.privRequestSession.isRecognizing) {\n            await this.privRequestSession.onStopRecognizing();\n            this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);\n        }\n    }\n    async receiveMessage() {\n        try {\n            if (this.privIsDisposed) {\n                // We're done.\n                return;\n            }\n            let connection = await this.fetchConnection();\n            const message = await connection.read();\n            if (this.receiveMessageOverride !== undefined) {\n                return this.receiveMessageOverride();\n            }\n            // indicates we are draining the queue and it came with no message;\n            if (!message) {\n                return this.receiveMessage();\n            }\n            this.privServiceHasSentMessage = true;\n            const connectionMessage = SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage.fromConnectionMessage(message);\n            if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {\n                switch (connectionMessage.path.toLowerCase()) {\n                    case \"turn.start\":\n                        this.privMustReportEndOfStream = true;\n                        this.privRequestSession.onServiceTurnStartResponse();\n                        break;\n                    case \"speech.startdetected\":\n                        const speechStartDetected = Exports_js_4.SpeechDetected.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                        const speechStartEventArgs = new Exports_js_3.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);\n                        if (!!this.privRecognizer.speechStartDetected) {\n                            this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n                        }\n                        break;\n                    case \"speech.enddetected\":\n                        let json;\n                        if (connectionMessage.textBody.length > 0) {\n                            json = connectionMessage.textBody;\n                        }\n                        else {\n                            // If the request was empty, the JSON returned is empty.\n                            json = \"{ Offset: 0 }\";\n                        }\n                        const speechStopDetected = Exports_js_4.SpeechDetected.fromJSON(json, this.privRequestSession.currentTurnAudioOffset);\n                        const speechStopEventArgs = new Exports_js_3.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n                        if (!!this.privRecognizer.speechEndDetected) {\n                            this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n                        }\n                        break;\n                    case \"turn.end\":\n                        await this.sendTelemetryData();\n                        if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {\n                            this.privMustReportEndOfStream = false;\n                            await this.cancelRecognitionLocal(Exports_js_3.CancellationReason.EndOfStream, Exports_js_3.CancellationErrorCode.NoError, undefined);\n                        }\n                        const sessionStopEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n                        await this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);\n                        if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                            if (!!this.privRecognizer.sessionStopped) {\n                                this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                            }\n                            return;\n                        }\n                        else {\n                            connection = await this.fetchConnection();\n                            await this.sendPrePayloadJSON(connection);\n                        }\n                        break;\n                    default:\n                        if (!await this.processTypeSpecificMessages(connectionMessage)) {\n                            // here are some messages that the derived class has not processed, dispatch them to connect class\n                            if (!!this.privServiceEvents) {\n                                this.serviceEvents.onEvent(new Exports_js_2.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                            }\n                        }\n                }\n            }\n            return this.receiveMessage();\n        }\n        catch (error) {\n            return null;\n        }\n    }\n    updateSpeakerDiarizationAudioOffset() {\n        const bytesSent = this.privRequestSession.recognitionBytesSent;\n        const audioOffsetMs = this.privAverageBytesPerMs !== 0 ? bytesSent / this.privAverageBytesPerMs : 0;\n        this.privSpeechContext.setSpeakerDiarizationAudioOffsetMs(audioOffsetMs);\n    }\n    sendSpeechContext(connection, generateNewRequestId) {\n        if (this.privEnableSpeakerId) {\n            this.updateSpeakerDiarizationAudioOffset();\n        }\n        const speechContextJson = this.speechContext.toJSON();\n        if (generateNewRequestId) {\n            this.privRequestSession.onSpeechContext();\n        }\n        if (speechContextJson) {\n            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speech.context\", this.privRequestSession.requestId, \"application/json\", speechContextJson));\n        }\n        return;\n    }\n    noOp() {\n        // operation not supported\n        return;\n    }\n    // Encapsulated for derived service recognizers that need to send additional JSON\n    async sendPrePayloadJSON(connection, generateNewRequestId = true) {\n        if (this.sendPrePayloadJSONOverride !== undefined) {\n            return this.sendPrePayloadJSONOverride(connection);\n        }\n        await this.sendSpeechContext(connection, generateNewRequestId);\n        await this.sendWaveHeader(connection);\n        return;\n    }\n    async sendWaveHeader(connection) {\n        const format = await this.audioSource.format;\n        // this.writeBufferToConsole(format.header);\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, \"audio\", this.privRequestSession.requestId, \"audio/x-wav\", format.header));\n    }\n    // Establishes a websocket connection to the end point.\n    connectImpl() {\n        if (this.privConnectionPromise !== undefined) {\n            return this.privConnectionPromise.then((connection) => {\n                if (connection.state() === Exports_js_2.ConnectionState.Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionPromise = undefined;\n                    this.privServiceHasSentMessage = false;\n                    return this.connectImpl();\n                }\n                return this.privConnectionPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionPromise = undefined;\n                this.privServiceHasSentMessage = false;\n                return this.connectImpl();\n            });\n        }\n        this.privConnectionPromise = this.retryableConnect();\n        // Attach an empty handler to allow the promise to run in the background while\n        // other startup events happen. It'll eventually be awaited on.\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        this.privConnectionPromise.catch(() => { });\n        if (this.postConnectImplOverride !== undefined) {\n            return this.postConnectImplOverride(this.privConnectionPromise);\n        }\n        return this.privConnectionPromise;\n    }\n    sendSpeechServiceConfig(connection, requestSession, SpeechServiceConfigJson) {\n        requestSession.onSpeechContext();\n        // filter out anything that is not required for the service to work.\n        if (ServiceRecognizerBase.telemetryDataEnabled !== true) {\n            const withTelemetry = JSON.parse(SpeechServiceConfigJson);\n            const replacement = {\n                context: {\n                    system: withTelemetry.context.system,\n                },\n            };\n            SpeechServiceConfigJson = JSON.stringify(replacement);\n        }\n        if (this.privRecognizerConfig.parameters.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() === \"true\") {\n            const json = JSON.parse(SpeechServiceConfigJson);\n            json.context.DisableReferenceChannel = \"True\";\n            json.context.MicSpec = \"1_0_0\";\n            SpeechServiceConfigJson = JSON.stringify(json);\n        }\n        if (SpeechServiceConfigJson) {\n            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speech.config\", requestSession.requestId, \"application/json\", SpeechServiceConfigJson));\n        }\n        return;\n    }\n    async fetchConnection() {\n        if (this.privConnectionConfigurationPromise !== undefined) {\n            return this.privConnectionConfigurationPromise.then((connection) => {\n                if (connection.state() === Exports_js_2.ConnectionState.Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigurationPromise = undefined;\n                    this.privServiceHasSentMessage = false;\n                    return this.fetchConnection();\n                }\n                return this.privConnectionConfigurationPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionConfigurationPromise = undefined;\n                this.privServiceHasSentMessage = false;\n                return this.fetchConnection();\n            });\n        }\n        this.privConnectionConfigurationPromise = this.configureConnection();\n        return await this.privConnectionConfigurationPromise;\n    }\n    async sendAudio(audioStreamNode) {\n        const audioFormat = await this.audioSource.format;\n        this.privAverageBytesPerMs = audioFormat.avgBytesPerSec / 1000;\n        // The time we last sent data to the service.\n        let nextSendTime = Date.now();\n        // Max amount to send before we start to throttle\n        const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-TransmitLengthBeforThrottleMs\", \"5000\");\n        const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1000 * parseInt(fastLaneSizeMs, 10);\n        const startRecogNumber = this.privRequestSession.recogNumber;\n        const readAndUploadCycle = async () => {\n            // If speech is done, stop sending audio.\n            if (!this.privIsDisposed &&\n                !this.privRequestSession.isSpeechEnded &&\n                this.privRequestSession.isRecognizing &&\n                this.privRequestSession.recogNumber === startRecogNumber) {\n                const connection = await this.fetchConnection();\n                const audioStreamChunk = await audioStreamNode.read();\n                // we have a new audio chunk to upload.\n                if (this.privRequestSession.isSpeechEnded) {\n                    // If service already recognized audio end then don't send any more audio\n                    return;\n                }\n                let payload;\n                let sendDelay;\n                if (!audioStreamChunk || audioStreamChunk.isEnd) {\n                    payload = null;\n                    sendDelay = 0;\n                }\n                else {\n                    payload = audioStreamChunk.buffer;\n                    this.privRequestSession.onAudioSent(payload.byteLength);\n                    if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {\n                        sendDelay = 0;\n                    }\n                    else {\n                        sendDelay = Math.max(0, nextSendTime - Date.now());\n                    }\n                }\n                if (0 !== sendDelay) {\n                    await this.delay(sendDelay);\n                }\n                if (payload !== null) {\n                    nextSendTime = Date.now() + (payload.byteLength * 1000 / (audioFormat.avgBytesPerSec * 2));\n                }\n                // Are we still alive?\n                if (!this.privIsDisposed &&\n                    !this.privRequestSession.isSpeechEnded &&\n                    this.privRequestSession.isRecognizing &&\n                    this.privRequestSession.recogNumber === startRecogNumber) {\n                    connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, \"audio\", this.privRequestSession.requestId, null, payload)).catch(() => {\n                        // eslint-disable-next-line @typescript-eslint/no-empty-function\n                        this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => { });\n                    });\n                    if (!audioStreamChunk?.isEnd) {\n                        // this.writeBufferToConsole(payload);\n                        // Regardless of success or failure, schedule the next upload.\n                        // If the underlying connection was broken, the next cycle will\n                        // get a new connection and re-transmit missing audio automatically.\n                        return readAndUploadCycle();\n                    }\n                    else {\n                        // the audio stream has been closed, no need to schedule next\n                        // read-upload cycle.\n                        if (!this.privIsLiveAudio) {\n                            this.privRequestSession.onSpeechEnded();\n                        }\n                    }\n                }\n            }\n        };\n        return readAndUploadCycle();\n    }\n    async retryableConnect() {\n        let isUnAuthorized = false;\n        this.privAuthFetchEventId = Exports_js_2.createNoDashGuid();\n        const sessionId = this.privRequestSession.sessionId;\n        this.privConnectionId = (sessionId !== undefined) ? sessionId : Exports_js_2.createNoDashGuid();\n        this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);\n        let lastStatusCode = 0;\n        let lastReason = \"\";\n        while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {\n            // Get the auth information for the connection. This is a bit of overkill for the current API surface, but leaving the plumbing in place to be able to raise a developer-customer\n            // facing event when a connection fails to let them try and provide new auth information.\n            const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n            const auth = await authPromise;\n            await this.privRequestSession.onAuthCompleted(false);\n            // Create the connection\n            const connection = this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);\n            // Attach the telemetry handlers.\n            this.privRequestSession.listenForServiceTelemetry(connection.events);\n            // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n            // it'll stop sending events.\n            connection.events.attach((event) => {\n                this.connectionEvents.onEvent(event);\n            });\n            const response = await connection.open();\n            // 200 == everything is fine.\n            if (response.statusCode === 200) {\n                await this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);\n                return Promise.resolve(connection);\n            }\n            else if (response.statusCode === 1006) {\n                isUnAuthorized = true;\n            }\n            lastStatusCode = response.statusCode;\n            lastReason = response.reason;\n            this.privRequestSession.onRetryConnection();\n        }\n        await this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);\n        return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);\n    }\n    delay(delayMs) {\n        return new Promise((resolve) => this.privSetTimeout(resolve, delayMs));\n    }\n    writeBufferToConsole(buffer) {\n        let out = \"Buffer Size: \";\n        if (null === buffer) {\n            out += \"null\";\n        }\n        else {\n            const readView = new Uint8Array(buffer);\n            out += `${buffer.byteLength}\\r\\n`;\n            for (let i = 0; i < buffer.byteLength; i++) {\n                out += readView[i].toString(16).padStart(2, \"0\") + \" \";\n                if (((i + 1) % 16) === 0) {\n                    // eslint-disable-next-line no-console\n                    console.info(out);\n                    out = \"\";\n                }\n            }\n        }\n        // eslint-disable-next-line no-console\n        console.info(out);\n    }\n    async sendFinalAudio() {\n        const connection = await this.fetchConnection();\n        await connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, \"audio\", this.privRequestSession.requestId, null, null));\n        return;\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    async configureConnection() {\n        const connection = await this.connectImpl();\n        if (this.configConnectionOverride !== undefined) {\n            return this.configConnectionOverride(connection);\n        }\n        await this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n        await this.sendPrePayloadJSON(connection, false);\n        return connection;\n    }\n}\nexports.ServiceRecognizerBase = ServiceRecognizerBase;\nServiceRecognizerBase.telemetryDataEnabled = true;\n\n//# sourceMappingURL=ServiceRecognizerBase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceRecognizerBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceTelemetryListener.Internal.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceTelemetryListener.Internal.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServiceTelemetryListener = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst RecognitionEvents_js_1 = __webpack_require__(/*! ./RecognitionEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js\");\nclass ServiceTelemetryListener {\n    constructor(requestId, audioSourceId, audioNodeId) {\n        this.privIsDisposed = false;\n        this.privListeningTriggerMetric = null;\n        this.privMicMetric = null;\n        this.privConnectionEstablishMetric = null;\n        this.privRequestId = requestId;\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privReceivedMessages = {};\n        this.privPhraseLatencies = [];\n        this.privHypothesisLatencies = [];\n    }\n    phraseReceived(audioReceivedTime) {\n        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.\n            this.privPhraseLatencies.push(Date.now() - audioReceivedTime);\n        }\n    }\n    hypothesisReceived(audioReceivedTime) {\n        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.\n            this.privHypothesisLatencies.push(Date.now() - audioReceivedTime);\n        }\n    }\n    onEvent(e) {\n        if (this.privIsDisposed) {\n            return;\n        }\n        if (e instanceof RecognitionEvents_js_1.RecognitionTriggeredEvent && e.requestId === this.privRequestId) {\n            this.privListeningTriggerMetric = {\n                End: e.eventTime,\n                Name: \"ListeningTrigger\",\n                Start: e.eventTime,\n            };\n        }\n        if (e instanceof Exports_js_1.AudioStreamNodeAttachingEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            this.privMicStartTime = e.eventTime;\n        }\n        if (e instanceof Exports_js_1.AudioStreamNodeAttachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            this.privMicStartTime = e.eventTime;\n        }\n        if (e instanceof Exports_js_1.AudioSourceErrorEvent && e.audioSourceId === this.privAudioSourceId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Error: e.error,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof Exports_js_1.AudioStreamNodeErrorEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Error: e.error,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof Exports_js_1.AudioStreamNodeDetachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof RecognitionEvents_js_1.ConnectingToServiceEvent && e.requestId === this.privRequestId) {\n            this.privConnectionId = e.sessionId;\n        }\n        if (e instanceof Exports_js_1.ConnectionStartEvent && e.connectionId === this.privConnectionId) {\n            this.privConnectionStartTime = e.eventTime;\n        }\n        if (e instanceof Exports_js_1.ConnectionEstablishedEvent && e.connectionId === this.privConnectionId) {\n            if (!this.privConnectionEstablishMetric) {\n                this.privConnectionEstablishMetric = {\n                    End: e.eventTime,\n                    Id: this.privConnectionId,\n                    Name: \"Connection\",\n                    Start: this.privConnectionStartTime,\n                };\n            }\n        }\n        if (e instanceof Exports_js_1.ConnectionEstablishErrorEvent && e.connectionId === this.privConnectionId) {\n            if (!this.privConnectionEstablishMetric) {\n                this.privConnectionEstablishMetric = {\n                    End: e.eventTime,\n                    Error: this.getConnectionError(e.statusCode),\n                    Id: this.privConnectionId,\n                    Name: \"Connection\",\n                    Start: this.privConnectionStartTime,\n                };\n            }\n        }\n        if (e instanceof Exports_js_1.ConnectionMessageReceivedEvent && e.connectionId === this.privConnectionId) {\n            if (e.message && e.message.headers && e.message.headers.path) {\n                if (!this.privReceivedMessages[e.message.headers.path]) {\n                    this.privReceivedMessages[e.message.headers.path] = new Array();\n                }\n                const maxMessagesToSend = 50;\n                if (this.privReceivedMessages[e.message.headers.path].length < maxMessagesToSend) {\n                    this.privReceivedMessages[e.message.headers.path].push(e.networkReceivedTime);\n                }\n            }\n        }\n    }\n    getTelemetry() {\n        const metrics = new Array();\n        if (this.privListeningTriggerMetric) {\n            metrics.push(this.privListeningTriggerMetric);\n        }\n        if (this.privMicMetric) {\n            metrics.push(this.privMicMetric);\n        }\n        if (this.privConnectionEstablishMetric) {\n            metrics.push(this.privConnectionEstablishMetric);\n        }\n        if (this.privPhraseLatencies.length > 0) {\n            metrics.push({\n                PhraseLatencyMs: this.privPhraseLatencies,\n            });\n        }\n        if (this.privHypothesisLatencies.length > 0) {\n            metrics.push({\n                FirstHypothesisLatencyMs: this.privHypothesisLatencies,\n            });\n        }\n        const telemetry = {\n            Metrics: metrics,\n            ReceivedMessages: this.privReceivedMessages,\n        };\n        const json = JSON.stringify(telemetry);\n        // We dont want to send the same telemetry again. So clean those out.\n        this.privReceivedMessages = {};\n        this.privListeningTriggerMetric = null;\n        this.privMicMetric = null;\n        this.privConnectionEstablishMetric = null;\n        this.privPhraseLatencies = [];\n        this.privHypothesisLatencies = [];\n        return json;\n    }\n    // Determines if there are any telemetry events to send to the service.\n    get hasTelemetry() {\n        return (Object.keys(this.privReceivedMessages).length !== 0 ||\n            this.privListeningTriggerMetric !== null ||\n            this.privMicMetric !== null ||\n            this.privConnectionEstablishMetric !== null ||\n            this.privPhraseLatencies.length !== 0 ||\n            this.privHypothesisLatencies.length !== 0);\n    }\n    dispose() {\n        this.privIsDisposed = true;\n    }\n    getConnectionError(statusCode) {\n        /*\n        -- Websocket status codes --\n        NormalClosure = 1000,\n        EndpointUnavailable = 1001,\n        ProtocolError = 1002,\n        InvalidMessageType = 1003,\n        Empty = 1005,\n        InvalidPayloadData = 1007,\n        PolicyViolation = 1008,\n        MessageTooBig = 1009,\n        MandatoryExtension = 1010,\n        InternalServerError = 1011\n        */\n        switch (statusCode) {\n            case 400:\n            case 1002:\n            case 1003:\n            case 1005:\n            case 1007:\n            case 1008:\n            case 1009: return \"BadRequest\";\n            case 401: return \"Unauthorized\";\n            case 403: return \"Forbidden\";\n            case 503:\n            case 1001: return \"ServerUnavailable\";\n            case 500:\n            case 1011: return \"ServerError\";\n            case 408:\n            case 504: return \"Timeout\";\n            default: return \"statuscode:\" + statusCode.toString();\n        }\n    }\n}\nexports.ServiceTelemetryListener = ServiceTelemetryListener;\n\n//# sourceMappingURL=ServiceTelemetryListener.Internal.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceTelemetryListener.Internal.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerRecognitionConfig.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerRecognitionConfig.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeakerRecognitionConfig = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass SpeakerRecognitionConfig {\n    constructor(context, parameters) {\n        this.privContext = context ? context : new Exports_js_1.Context(null);\n        this.privParameters = parameters;\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get Context() {\n        return this.privContext;\n    }\n}\nexports.SpeakerRecognitionConfig = SpeakerRecognitionConfig;\n\n//# sourceMappingURL=SpeakerRecognitionConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerRecognitionConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerRecognitionConnectionFactory.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerRecognitionConnectionFactory.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceProfileConnectionFactory = exports.SpeakerRecognitionConnectionFactory = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nclass SpeakerRecognitionConnectionFactoryBase extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    create(config, authInfo, endpointPath, connectionId) {\n        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);\n            const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n            const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, `wss://${region}.spr-frontend.speech${hostSuffix}`);\n            const scenario = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SpeakerIdMode, \"TextIndependentIdentification\");\n            endpoint = `${host}/speaker/ws/${this.scenarioToPath(scenario)}/${endpointPath}`;\n        }\n        const queryParams = {\n            format: \"simple\",\n            language: config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage),\n        };\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        headers[HeaderNames_js_1.HeaderNames.SpIDAuthKey] = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key);\n        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n    scenarioToPath(mode) {\n        switch (mode) {\n            case \"TextIndependentVerification\":\n            case \"2\":\n                return \"verification/text-independent\";\n            case \"TextDependentVerification\":\n            case \"1\":\n                return \"verification/text-dependent\";\n            default:\n                return \"identification/text-independent\";\n        }\n    }\n}\nclass SpeakerRecognitionConnectionFactory extends SpeakerRecognitionConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        return super.create(config, authInfo, \"recognition\", connectionId);\n    }\n}\nexports.SpeakerRecognitionConnectionFactory = SpeakerRecognitionConnectionFactory;\nclass VoiceProfileConnectionFactory extends SpeakerRecognitionConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        return super.create(config, authInfo, \"profile\", connectionId);\n    }\n}\nexports.VoiceProfileConnectionFactory = VoiceProfileConnectionFactory;\n\n//# sourceMappingURL=SpeakerRecognitionConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerRecognitionConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerServiceRecognizer.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerServiceRecognizer.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeakerServiceRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// eslint-disable-next-line max-classes-per-file\nclass SpeakerServiceRecognizer extends Exports_js_4.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.privSpeakerRecognizer = recognizer;\n        this.privSpeakerAudioSource = audioSource;\n        this.recognizeSpeaker = (model) => this.recognizeSpeakerOnce(model);\n        this.sendPrePayloadJSONOverride = () => this.noOp();\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        let processed = false;\n        const resultProps = new Exports_js_3.PropertyCollection();\n        if (connectionMessage.messageType === Exports_js_2.MessageType.Text) {\n            resultProps.setProperty(Exports_js_3.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speaker.response\":\n                const response = JSON.parse(connectionMessage.textBody);\n                let result;\n                if (response.status.statusCode.toLowerCase() !== \"success\") {\n                    result = new Exports_js_3.SpeakerRecognitionResult(response, Exports_js_3.ResultReason.Canceled, Exports_js_3.CancellationErrorCode.ServiceError, response.status.reason);\n                }\n                else {\n                    result = new Exports_js_3.SpeakerRecognitionResult(response, Exports_js_3.ResultReason.RecognizedSpeaker);\n                }\n                if (!!this.privResultDeferral) {\n                    this.privResultDeferral.resolve(result);\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new Exports_js_2.Deferred();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new Exports_js_3.PropertyCollection();\n        properties.setProperty(Exports_js_4.CancellationErrorCodePropertyName, Exports_js_3.CancellationErrorCode[errorCode]);\n        if (!!this.privResultDeferral) {\n            const result = new Exports_js_3.SpeakerRecognitionResult({\n                scenario: this.privSpeakerModel.scenario,\n                status: { statusCode: error, reason: error }\n            }, Exports_js_3.ResultReason.Canceled, errorCode, error);\n            try {\n                this.privResultDeferral.resolve(result);\n            }\n            catch (error) {\n                this.privResultDeferral.reject(error);\n            }\n        }\n    }\n    async recognizeSpeakerOnce(model) {\n        this.privSpeakerModel = model;\n        this.voiceProfileType = model.scenario;\n        if (!this.privResultDeferral) {\n            this.privResultDeferral = new Exports_js_2.Deferred();\n        }\n        this.privRequestSession.startNewRecognition();\n        this.privRequestSession.listenForServiceTelemetry(this.privSpeakerAudioSource.events);\n        this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);\n        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n        const conPromise = this.connectImpl();\n        const preAudioPromise = this.sendPreAudioMessages(this.extractSpeakerContext(model));\n        const node = await this.privSpeakerAudioSource.attach(this.privRequestSession.audioNodeId);\n        const format = await this.privSpeakerAudioSource.format;\n        const deviceInfo = await this.privSpeakerAudioSource.deviceInfo;\n        const audioNode = new Exports_js_1.ReplayableAudioNode(node, format.avgBytesPerSec);\n        await this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n        try {\n            await conPromise;\n            await preAudioPromise;\n        }\n        catch (err) {\n            this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.ConnectionFailure, err);\n        }\n        const sessionStartEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n        if (!!this.privRecognizer.sessionStarted) {\n            this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n        }\n        void this.receiveMessage();\n        const audioSendPromise = this.sendAudio(audioNode);\n        // /* eslint-disable no-empty */\n        audioSendPromise.then(() => { }, (error) => {\n            this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);\n        });\n        return this.privResultDeferral.promise;\n    }\n    async sendPreAudioMessages(context) {\n        const connection = await this.fetchConnection();\n        await this.sendSpeakerRecognition(connection, context);\n        // await this.sendWaveHeader(connection);\n    }\n    async sendSpeakerRecognition(connection, context) {\n        const speakerContextJson = JSON.stringify(context);\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speaker.context\", this.privRequestSession.requestId, \"application/json; charset=utf-8\", speakerContextJson));\n    }\n    extractSpeakerContext(model) {\n        return {\n            features: {\n                interimResult: \"enabled\",\n                progressiveDetection: \"disabled\",\n            },\n            profileIds: model.profileIds,\n            scenario: model.scenario,\n        };\n    }\n}\nexports.SpeakerServiceRecognizer = SpeakerServiceRecognizer;\n\n//# sourceMappingURL=SpeakerServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeakerServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionFactory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionFactory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechConnectionFactory = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js\");\nclass SpeechConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    constructor() {\n        super(...arguments);\n        this.interactiveRelativeUri = \"/speech/recognition/interactive/cognitiveservices/v1\";\n        this.conversationRelativeUri = \"/speech/recognition/conversation/cognitiveservices/v1\";\n        this.dictationRelativeUri = \"/speech/recognition/dictation/cognitiveservices/v1\";\n        this.universalUri = \"/speech/universal/v\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Region, undefined);\n        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n        const host = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".stt.speech\" + hostSuffix);\n        const queryParams = {};\n        const endpointId = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n        const language = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);\n        if (endpointId) {\n            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId) === -1) {\n                queryParams[QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;\n            }\n        }\n        else if (language) {\n            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.Language) === -1) {\n                queryParams[QueryParameterNames_js_1.QueryParameterNames.Language] = language;\n            }\n        }\n        if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.Format) === -1) {\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = config.parameters.getProperty(Exports_js_2.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]).toLowerCase();\n        }\n        if (config.autoDetectSourceLanguages !== undefined) {\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.EnableLanguageId] = \"true\";\n        }\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        if (!endpoint) {\n            switch (config.recognitionMode) {\n                case Exports_js_4.RecognitionMode.Conversation:\n                    if (config.parameters.getProperty(Exports_js_2.ForceDictationPropertyName, \"false\") === \"true\") {\n                        endpoint = host + this.dictationRelativeUri;\n                    }\n                    else {\n                        if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n                            endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n                        }\n                        else {\n                            endpoint = host + this.conversationRelativeUri;\n                        }\n                    }\n                    break;\n                case Exports_js_4.RecognitionMode.Dictation:\n                    endpoint = host + this.dictationRelativeUri;\n                    break;\n                default:\n                    if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n                        endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n                    }\n                    else {\n                        endpoint = host + this.interactiveRelativeUri; // default is interactive\n                    }\n                    break;\n            }\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        const webSocketConnection = new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_4.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n        // Set the value of SpeechServiceConnection_Url to webSocketConnection.uri (and not to `endpoint`), since this value is the final\n        // URI that was used to make the connection (including query parameters).\n        const uri = webSocketConnection.uri;\n        config.parameters.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Url, uri);\n        return webSocketConnection;\n    }\n}\nexports.SpeechConnectionFactory = SpeechConnectionFactory;\n\n//# sourceMappingURL=SpeechConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechConnectionMessage = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nclass SpeechConnectionMessage extends Exports_js_1.ConnectionMessage {\n    constructor(messageType, path, requestId, contentType, body, streamId, additionalHeaders, id) {\n        if (!path) {\n            throw new Exports_js_1.ArgumentNullError(\"path\");\n        }\n        if (!requestId) {\n            throw new Exports_js_1.ArgumentNullError(\"requestId\");\n        }\n        const headers = {};\n        headers[HeaderNames_js_1.HeaderNames.Path] = path;\n        headers[HeaderNames_js_1.HeaderNames.RequestId] = requestId;\n        headers[HeaderNames_js_1.HeaderNames.RequestTimestamp] = new Date().toISOString();\n        if (contentType) {\n            headers[HeaderNames_js_1.HeaderNames.ContentType] = contentType;\n        }\n        if (streamId) {\n            headers[HeaderNames_js_1.HeaderNames.RequestStreamId] = streamId;\n        }\n        if (additionalHeaders) {\n            for (const headerName in additionalHeaders) {\n                if (headerName) {\n                    headers[headerName] = additionalHeaders[headerName];\n                }\n            }\n        }\n        if (id) {\n            super(messageType, body, headers, id);\n        }\n        else {\n            super(messageType, body, headers);\n        }\n        this.privPath = path;\n        this.privRequestId = requestId;\n        this.privContentType = contentType;\n        this.privStreamId = streamId;\n        this.privAdditionalHeaders = additionalHeaders;\n    }\n    get path() {\n        return this.privPath;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get contentType() {\n        return this.privContentType;\n    }\n    get streamId() {\n        return this.privStreamId;\n    }\n    get additionalHeaders() {\n        return this.privAdditionalHeaders;\n    }\n    static fromConnectionMessage(message) {\n        let path = null;\n        let requestId = null;\n        let contentType = null;\n        // let requestTimestamp = null;\n        let streamId = null;\n        const additionalHeaders = {};\n        if (message.headers) {\n            for (const headerName in message.headers) {\n                if (headerName) {\n                    if (headerName.toLowerCase() === HeaderNames_js_1.HeaderNames.Path.toLowerCase()) {\n                        path = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === HeaderNames_js_1.HeaderNames.RequestId.toLowerCase()) {\n                        requestId = message.headers[headerName];\n                        // } else if (headerName.toLowerCase() === HeaderNames.RequestTimestamp.toLowerCase()) {\n                        //  requestTimestamp = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === HeaderNames_js_1.HeaderNames.ContentType.toLowerCase()) {\n                        contentType = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === HeaderNames_js_1.HeaderNames.RequestStreamId.toLowerCase()) {\n                        streamId = message.headers[headerName];\n                    }\n                    else {\n                        additionalHeaders[headerName] = message.headers[headerName];\n                    }\n                }\n            }\n        }\n        return new SpeechConnectionMessage(message.messageType, path, requestId, contentType, message.body, streamId, additionalHeaders, message.id);\n    }\n}\nexports.SpeechConnectionMessage = SpeechConnectionMessage;\n\n//# sourceMappingURL=SpeechConnectionMessage.Internal.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechContext.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechContext.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechContext = void 0;\n/**\n * Represents the JSON used in the speech.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nclass SpeechContext {\n    constructor(dynamicGrammar) {\n        this.privContext = {};\n        this.privDynamicGrammar = dynamicGrammar;\n    }\n    /**\n     * Gets a section of the speech.context object.\n     * @param sectionName Name of the section to get.\n     * @return string or Context JSON serializable object that represents the value.\n     */\n    getSection(sectionName) {\n        return (this.privContext[sectionName] || {});\n    }\n    /**\n     * Adds a section to the speech.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    setSection(sectionName, value) {\n        this.privContext[sectionName] = value;\n    }\n    /**\n     * @Internal\n     * This is only used by pronunciation assessment config.\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    setPronunciationAssessmentParams(params, contentAssessmentTopic, isSpeakerDiarizationEnabled = false) {\n        if (this.privContext.phraseDetection === undefined) {\n            this.privContext.phraseDetection = {\n                enrichment: {\n                    pronunciationAssessment: {}\n                }\n            };\n        }\n        if (this.privContext.phraseDetection.enrichment === undefined) {\n            this.privContext.phraseDetection.enrichment = {\n                pronunciationAssessment: {}\n            };\n        }\n        this.privContext.phraseDetection.enrichment.pronunciationAssessment = JSON.parse(params);\n        if (isSpeakerDiarizationEnabled) {\n            this.privContext.phraseDetection.mode = \"Conversation\";\n        }\n        this.setWordLevelTimings();\n        this.privContext.phraseOutput.detailed.options.push(\"PronunciationAssessment\");\n        if (this.privContext.phraseOutput.detailed.options.indexOf(\"SNR\") === -1) {\n            this.privContext.phraseOutput.detailed.options.push(\"SNR\");\n        }\n        if (!!contentAssessmentTopic) {\n            this.privContext.phraseDetection.enrichment.contentAssessment = {\n                topic: contentAssessmentTopic\n            };\n            this.privContext.phraseOutput.detailed.options.push(\"ContentAssessment\");\n        }\n    }\n    setDetailedOutputFormat() {\n        if (this.privContext.phraseOutput === undefined) {\n            this.privContext.phraseOutput = {\n                detailed: {\n                    options: []\n                },\n                format: {}\n            };\n        }\n        if (this.privContext.phraseOutput.detailed === undefined) {\n            this.privContext.phraseOutput.detailed = {\n                options: []\n            };\n        }\n        this.privContext.phraseOutput.format = \"Detailed\";\n    }\n    setWordLevelTimings() {\n        if (this.privContext.phraseOutput === undefined) {\n            this.privContext.phraseOutput = {\n                detailed: {\n                    options: []\n                },\n                format: {}\n            };\n        }\n        if (this.privContext.phraseOutput.detailed === undefined) {\n            this.privContext.phraseOutput.detailed = {\n                options: []\n            };\n        }\n        this.privContext.phraseOutput.format = \"Detailed\";\n        if (this.privContext.phraseOutput.detailed.options.indexOf(\"WordTimings\") === -1) {\n            this.privContext.phraseOutput.detailed.options.push(\"WordTimings\");\n        }\n    }\n    setSpeakerDiarizationAudioOffsetMs(audioOffsetMs) {\n        this.privContext.phraseDetection.speakerDiarization.audioOffsetMs = audioOffsetMs;\n    }\n    toJSON() {\n        const dgi = this.privDynamicGrammar.generateGrammarObject();\n        this.setSection(\"dgi\", dgi);\n        const ret = JSON.stringify(this.privContext);\n        return ret;\n    }\n}\nexports.SpeechContext = SpeechContext;\n\n//# sourceMappingURL=SpeechContext.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechContext.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceConfig.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceConfig.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.type = exports.connectivity = exports.Device = exports.OS = exports.System = exports.Context = exports.SpeechServiceConfig = void 0;\n/* eslint-disable max-classes-per-file */\n// The config is serialized and sent as the Speech.Config\nclass SpeechServiceConfig {\n    constructor(context) {\n        this.context = context;\n    }\n    serialize() {\n        return JSON.stringify(this, (key, value) => {\n            if (value && typeof value === \"object\" && !Array.isArray(value)) {\n                const replacement = {};\n                for (const k in value) {\n                    if (Object.hasOwnProperty.call(value, k)) {\n                        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                        replacement[k && k.charAt(0).toLowerCase() + k.substring(1)] = value[k];\n                    }\n                }\n                return replacement;\n            }\n            return value;\n        });\n    }\n    get Context() {\n        return this.context;\n    }\n    get Recognition() {\n        return this.recognition;\n    }\n    set Recognition(value) {\n        this.recognition = value.toLowerCase();\n    }\n}\nexports.SpeechServiceConfig = SpeechServiceConfig;\nclass Context {\n    constructor(os) {\n        this.system = new System();\n        this.os = os;\n    }\n}\nexports.Context = Context;\nclass System {\n    constructor() {\n        // Note: below will be patched for official builds.\n        const SPEECHSDK_CLIENTSDK_VERSION = \"1.42.0\";\n        this.name = \"SpeechSDK\";\n        this.version = SPEECHSDK_CLIENTSDK_VERSION;\n        this.build = \"JavaScript\";\n        this.lang = \"JavaScript\";\n    }\n}\nexports.System = System;\nclass OS {\n    constructor(platform, name, version) {\n        this.platform = platform;\n        this.name = name;\n        this.version = version;\n    }\n}\nexports.OS = OS;\nclass Device {\n    constructor(manufacturer, model, version) {\n        this.manufacturer = manufacturer;\n        this.model = model;\n        this.version = version;\n    }\n}\nexports.Device = Device;\nvar connectivity;\n(function (connectivity) {\n    connectivity[\"Bluetooth\"] = \"Bluetooth\";\n    connectivity[\"Wired\"] = \"Wired\";\n    connectivity[\"WiFi\"] = \"WiFi\";\n    connectivity[\"Cellular\"] = \"Cellular\";\n    connectivity[\"InBuilt\"] = \"InBuilt\";\n    connectivity[\"Unknown\"] = \"Unknown\";\n})(connectivity = exports.connectivity || (exports.connectivity = {}));\nvar type;\n(function (type) {\n    type[\"Phone\"] = \"Phone\";\n    type[\"Speaker\"] = \"Speaker\";\n    type[\"Car\"] = \"Car\";\n    type[\"Headset\"] = \"Headset\";\n    type[\"Thermostat\"] = \"Thermostat\";\n    type[\"Microphones\"] = \"Microphones\";\n    type[\"Deskphone\"] = \"Deskphone\";\n    type[\"RemoteControl\"] = \"RemoteControl\";\n    type[\"Unknown\"] = \"Unknown\";\n    type[\"File\"] = \"File\";\n    type[\"Stream\"] = \"Stream\";\n})(type = exports.type || (exports.type = {}));\n\n//# sourceMappingURL=SpeechServiceConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceInterfaces.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceInterfaces.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=SpeechServiceInterfaces.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceRecognizer.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceRecognizer.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechServiceRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\n// eslint-disable-next-line max-classes-per-file\nclass SpeechServiceRecognizer extends Exports_js_2.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer);\n        this.privSpeechRecognizer = speechRecognizer;\n    }\n    async processTypeSpecificMessages(connectionMessage) {\n        let result;\n        const resultProps = new Exports_js_1.PropertyCollection();\n        let processed = false;\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.hypothesis\":\n            case \"speech.fragment\":\n                const hypothesis = Exports_js_2.SpeechHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, hypothesis.asJson());\n                result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, Exports_js_1.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, hypothesis.Offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, // Speaker Id\n                undefined, hypothesis.asJson(), resultProps);\n                this.privRequestSession.onHypothesis(hypothesis.Offset);\n                const ev = new Exports_js_1.SpeechRecognitionEventArgs(result, hypothesis.Offset, this.privRequestSession.sessionId);\n                if (!!this.privSpeechRecognizer.recognizing) {\n                    try {\n                        this.privSpeechRecognizer.recognizing(this.privSpeechRecognizer, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.phrase\":\n                const simple = Exports_js_2.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, simple.asJson());\n                const resultReason = Exports_js_2.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus, this.privExpectContentAssessmentResponse);\n                this.privRequestSession.onPhraseRecognized(simple.Offset + simple.Duration);\n                if (Exports_js_1.ResultReason.Canceled === resultReason) {\n                    const cancelReason = Exports_js_2.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n                    const cancellationErrorCode = Exports_js_2.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n                    await this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_2.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n                }\n                else {\n                    // Like the native SDK's, don't event / return an EndOfDictation message.\n                    if (simple.RecognitionStatus === Exports_js_2.RecognitionStatus.EndOfDictation) {\n                        break;\n                    }\n                    if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.OutputFormatPropertyName) === Exports_js_1.OutputFormat[Exports_js_1.OutputFormat.Simple]) {\n                        result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset, simple.Language, simple.LanguageDetectionConfidence, undefined, // Speaker Id\n                        undefined, simple.asJson(), resultProps);\n                    }\n                    else {\n                        const detailed = Exports_js_2.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);\n                        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, detailed.asJson());\n                        result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === Exports_js_2.RecognitionStatus.Success ? detailed.NBest[0].Display : \"\", detailed.Duration, detailed.Offset, detailed.Language, detailed.LanguageDetectionConfidence, undefined, // Speaker Id\n                        undefined, detailed.asJson(), resultProps);\n                    }\n                    const event = new Exports_js_1.SpeechRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n                    if (!!this.privSpeechRecognizer.recognized) {\n                        try {\n                            this.privSpeechRecognizer.recognized(this.privSpeechRecognizer, event);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    if (!!this.privSuccessCallback) {\n                        try {\n                            this.privSuccessCallback(result);\n                        }\n                        catch (e) {\n                            if (!!this.privErrorCallback) {\n                                this.privErrorCallback(e);\n                            }\n                        }\n                        // Only invoke the call back once.\n                        // and if it's successful don't invoke the\n                        // error after that.\n                        this.privSuccessCallback = undefined;\n                        this.privErrorCallback = undefined;\n                    }\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        return processed;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new Exports_js_1.PropertyCollection();\n        properties.setProperty(Exports_js_2.CancellationErrorCodePropertyName, Exports_js_1.CancellationErrorCode[errorCode]);\n        if (!!this.privSpeechRecognizer.canceled) {\n            const cancelEvent = new Exports_js_1.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n            try {\n                this.privSpeechRecognizer.canceled(this.privSpeechRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new Exports_js_1.SpeechRecognitionResult(requestId, Exports_js_1.ResultReason.Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // Language Detection Confidence\n            undefined, // Speaker Id\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n    }\n}\nexports.SpeechServiceRecognizer = SpeechServiceRecognizer;\n\n//# sourceMappingURL=SpeechServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisAdapter.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisAdapter.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisAdapter = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass SpeechSynthesisAdapter extends Exports_js_2.SynthesisAdapterBase {\n    constructor(authentication, connectionFactory, synthesizerConfig, speechSynthesizer, audioDestination) {\n        super(authentication, connectionFactory, synthesizerConfig, audioDestination);\n        this.privSpeechSynthesizer = speechSynthesizer;\n        this.privSynthesizer = speechSynthesizer;\n    }\n    setSynthesisContextSynthesisSection() {\n        this.privSynthesisContext.setSynthesisSection(this.privSpeechSynthesizer);\n    }\n    onSynthesisStarted(requestId) {\n        const synthesisStartEventArgs = new Exports_js_1.SpeechSynthesisEventArgs(new Exports_js_1.SpeechSynthesisResult(requestId, Exports_js_1.ResultReason.SynthesizingAudioStarted));\n        if (!!this.privSpeechSynthesizer.synthesisStarted) {\n            this.privSpeechSynthesizer.synthesisStarted(this.privSpeechSynthesizer, synthesisStartEventArgs);\n        }\n    }\n    onSynthesizing(audio) {\n        if (!!this.privSpeechSynthesizer.synthesizing) {\n            try {\n                const audioWithHeader = this.privSynthesisTurn.audioOutputFormat.addHeader(audio);\n                const ev = new Exports_js_1.SpeechSynthesisEventArgs(new Exports_js_1.SpeechSynthesisResult(this.privSynthesisTurn.requestId, Exports_js_1.ResultReason.SynthesizingAudio, audioWithHeader));\n                this.privSpeechSynthesizer.synthesizing(this.privSpeechSynthesizer, ev);\n            }\n            catch (error) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n    onSynthesisCancelled(result) {\n        if (!!this.privSpeechSynthesizer.SynthesisCanceled) {\n            const cancelEvent = new Exports_js_1.SpeechSynthesisEventArgs(result);\n            try {\n                this.privSpeechSynthesizer.SynthesisCanceled(this.privSpeechSynthesizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n    }\n    onSynthesisCompleted(result) {\n        if (this.privSpeechSynthesizer.synthesisCompleted) {\n            try {\n                this.privSpeechSynthesizer.synthesisCompleted(this.privSpeechSynthesizer, new Exports_js_1.SpeechSynthesisEventArgs(result));\n            }\n            catch (e) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n    onWordBoundary(wordBoundaryEventArgs) {\n        if (!!this.privSpeechSynthesizer.wordBoundary) {\n            try {\n                this.privSpeechSynthesizer.wordBoundary(this.privSpeechSynthesizer, wordBoundaryEventArgs);\n            }\n            catch (error) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n    onVisemeReceived(visemeEventArgs) {\n        if (!!this.privSpeechSynthesizer.visemeReceived) {\n            try {\n                this.privSpeechSynthesizer.visemeReceived(this.privSpeechSynthesizer, visemeEventArgs);\n            }\n            catch (error) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n    onBookmarkReached(bookmarkEventArgs) {\n        if (!!this.privSpeechSynthesizer.bookmarkReached) {\n            try {\n                this.privSpeechSynthesizer.bookmarkReached(this.privSpeechSynthesizer, bookmarkEventArgs);\n            }\n            catch (error) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n}\nexports.SpeechSynthesisAdapter = SpeechSynthesisAdapter;\n\n//# sourceMappingURL=SpeechSynthesisAdapter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisConnectionFactory = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js\");\nclass SpeechSynthesisConnectionFactory {\n    constructor() {\n        this.synthesisUri = \"/cognitiveservices/websocket/v1\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, undefined);\n        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n        const endpointId = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n        const hostPrefix = (endpointId === undefined) ? \"tts\" : \"voice\";\n        const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".\" + hostPrefix + \".speech\" + hostSuffix);\n        const queryParams = {};\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        if (endpointId !== undefined && endpointId !== \"\") {\n            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.CustomVoiceDeploymentId) === -1) {\n                queryParams[QueryParameterNames_js_1.QueryParameterNames.CustomVoiceDeploymentId] = endpointId;\n            }\n        }\n        if (config.avatarEnabled) {\n            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.EnableAvatar) === -1) {\n                queryParams[QueryParameterNames_js_1.QueryParameterNames.EnableAvatar] = \"true\";\n            }\n        }\n        if (!endpoint) {\n            endpoint = host + this.synthesisUri;\n        }\n        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromParameters(config.parameters), enableCompression, connectionId);\n    }\n}\nexports.SpeechSynthesisConnectionFactory = SpeechSynthesisConnectionFactory;\n\n//# sourceMappingURL=SpeechSynthesisConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisAdapterBase.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisAdapterBase.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisAdapterBase = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js\");\nclass SynthesisAdapterBase {\n    constructor(authentication, connectionFactory, synthesizerConfig, audioDestination) {\n        this.speakOverride = undefined;\n        this.receiveMessageOverride = undefined;\n        this.connectImplOverride = undefined;\n        this.configConnectionOverride = undefined;\n        // A promise for a configured connection.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionConfigurationPromise = undefined;\n        if (!authentication) {\n            throw new Exports_js_1.ArgumentNullError(\"authentication\");\n        }\n        if (!connectionFactory) {\n            throw new Exports_js_1.ArgumentNullError(\"connectionFactory\");\n        }\n        if (!synthesizerConfig) {\n            throw new Exports_js_1.ArgumentNullError(\"synthesizerConfig\");\n        }\n        this.privAuthentication = authentication;\n        this.privConnectionFactory = connectionFactory;\n        this.privSynthesizerConfig = synthesizerConfig;\n        this.privIsDisposed = false;\n        this.privSessionAudioDestination = audioDestination;\n        this.privSynthesisTurn = new Exports_js_3.SynthesisTurn();\n        this.privConnectionEvents = new Exports_js_1.EventSource();\n        this.privServiceEvents = new Exports_js_1.EventSource();\n        this.privSynthesisContext = new Exports_js_3.SynthesisContext();\n        this.privAgentConfig = new Exports_js_3.AgentConfig();\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                const connectionClosedEvent = connectionEvent;\n                if (connectionClosedEvent.statusCode !== 1000) {\n                    this.cancelSynthesisLocal(Exports_js_2.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? Exports_js_2.CancellationErrorCode.BadRequestParameters : Exports_js_2.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n                }\n            }\n        });\n    }\n    get synthesisContext() {\n        return this.privSynthesisContext;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n    get connectionEvents() {\n        return this.privConnectionEvents;\n    }\n    get serviceEvents() {\n        return this.privServiceEvents;\n    }\n    set activityTemplate(messagePayload) {\n        this.privActivityTemplate = messagePayload;\n    }\n    get activityTemplate() {\n        return this.privActivityTemplate;\n    }\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n        this.privSynthesisTurn.audioOutputFormat = format;\n        if (this.privSessionAudioDestination !== undefined) {\n            this.privSessionAudioDestination.format = format;\n        }\n        if (this.synthesisContext !== undefined) {\n            this.synthesisContext.audioOutputFormat = format;\n        }\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    async dispose(reason) {\n        this.privIsDisposed = true;\n        if (this.privSessionAudioDestination !== undefined) {\n            this.privSessionAudioDestination.close();\n        }\n        if (this.privConnectionConfigurationPromise !== undefined) {\n            const connection = await this.privConnectionConfigurationPromise;\n            await connection.dispose(reason);\n        }\n    }\n    async connect() {\n        await this.connectImpl();\n    }\n    async sendNetworkMessage(path, payload) {\n        const type = typeof payload === \"string\" ? Exports_js_1.MessageType.Text : Exports_js_1.MessageType.Binary;\n        const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n        const connection = await this.fetchConnection();\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(type, path, this.privSynthesisTurn.requestId, contentType, payload));\n    }\n    async Speak(text, isSSML, requestId, successCallback, errorCallBack, audioDestination) {\n        let ssml;\n        if (isSSML) {\n            ssml = text;\n        }\n        else {\n            ssml = this.privSynthesizer.buildSsml(text);\n        }\n        if (this.speakOverride !== undefined) {\n            return this.speakOverride(ssml, requestId, successCallback, errorCallBack);\n        }\n        this.privSuccessCallback = successCallback;\n        this.privErrorCallback = errorCallBack;\n        this.privSynthesisTurn.startNewSynthesis(requestId, text, isSSML, audioDestination);\n        try {\n            await this.connectImpl();\n            const connection = await this.fetchConnection();\n            await this.sendSynthesisContext(connection);\n            await this.sendSsmlMessage(connection, ssml, requestId);\n            this.onSynthesisStarted(requestId);\n            void this.receiveMessage();\n        }\n        catch (e) {\n            this.cancelSynthesisLocal(Exports_js_2.CancellationReason.Error, Exports_js_2.CancellationErrorCode.ConnectionFailure, e);\n            return Promise.reject(e);\n        }\n    }\n    async stopSpeaking() {\n        await this.connectImpl();\n        const connection = await this.fetchConnection();\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, \"synthesis.control\", this.privSynthesisTurn.requestId, \"application/json\", JSON.stringify({\n            action: \"stop\"\n        })));\n    }\n    // Cancels synthesis.\n    cancelSynthesis(requestId, _cancellationReason, errorCode, error) {\n        const properties = new Exports_js_2.PropertyCollection();\n        properties.setProperty(Exports_js_3.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[errorCode]);\n        const result = new Exports_js_2.SpeechSynthesisResult(requestId, Exports_js_2.ResultReason.Canceled, undefined, error, properties);\n        this.onSynthesisCancelled(result);\n        if (!!this.privSuccessCallback) {\n            try {\n                this.privSuccessCallback(result);\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n    }\n    // Cancels synthesis.\n    cancelSynthesisLocal(cancellationReason, errorCode, error) {\n        if (!!this.privSynthesisTurn.isSynthesizing) {\n            this.privSynthesisTurn.onStopSynthesizing();\n            this.cancelSynthesis(this.privSynthesisTurn.requestId, cancellationReason, errorCode, error);\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    processTypeSpecificMessages(_connectionMessage) {\n        return true;\n    }\n    async receiveMessage() {\n        try {\n            const connection = await this.fetchConnection();\n            const message = await connection.read();\n            if (this.receiveMessageOverride !== undefined) {\n                return this.receiveMessageOverride();\n            }\n            if (this.privIsDisposed) {\n                // We're done.\n                return;\n            }\n            // indicates we are draining the queue and it came with no message;\n            if (!message) {\n                if (!this.privSynthesisTurn.isSynthesizing) {\n                    return;\n                }\n                else {\n                    return this.receiveMessage();\n                }\n            }\n            const connectionMessage = SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage.fromConnectionMessage(message);\n            if (connectionMessage.requestId.toLowerCase() === this.privSynthesisTurn.requestId.toLowerCase()) {\n                switch (connectionMessage.path.toLowerCase()) {\n                    case \"turn.start\":\n                        this.privSynthesisTurn.onServiceTurnStartResponse(connectionMessage.textBody);\n                        break;\n                    case \"response\":\n                        this.privSynthesisTurn.onServiceResponseMessage(connectionMessage.textBody);\n                        break;\n                    case \"audio\":\n                        if (this.privSynthesisTurn.streamId.toLowerCase() === connectionMessage.streamId.toLowerCase()\n                            && !!connectionMessage.binaryBody) {\n                            this.privSynthesisTurn.onAudioChunkReceived(connectionMessage.binaryBody);\n                            this.onSynthesizing(connectionMessage.binaryBody);\n                            if (this.privSessionAudioDestination !== undefined) {\n                                this.privSessionAudioDestination.write(connectionMessage.binaryBody);\n                            }\n                        }\n                        break;\n                    case \"audio.metadata\":\n                        const metadataList = Exports_js_3.SynthesisAudioMetadata.fromJSON(connectionMessage.textBody).Metadata;\n                        for (const metadata of metadataList) {\n                            switch (metadata.Type) {\n                                case Exports_js_3.MetadataType.WordBoundary:\n                                case Exports_js_3.MetadataType.SentenceBoundary:\n                                    this.privSynthesisTurn.onTextBoundaryEvent(metadata);\n                                    const wordBoundaryEventArgs = new Exports_js_2.SpeechSynthesisWordBoundaryEventArgs(metadata.Data.Offset, metadata.Data.Duration, metadata.Data.text.Text, metadata.Data.text.Length, metadata.Type === Exports_js_3.MetadataType.WordBoundary\n                                        ? this.privSynthesisTurn.currentTextOffset : this.privSynthesisTurn.currentSentenceOffset, metadata.Data.text.BoundaryType);\n                                    this.onWordBoundary(wordBoundaryEventArgs);\n                                    break;\n                                case Exports_js_3.MetadataType.Bookmark:\n                                    const bookmarkEventArgs = new Exports_js_2.SpeechSynthesisBookmarkEventArgs(metadata.Data.Offset, metadata.Data.Bookmark);\n                                    this.onBookmarkReached(bookmarkEventArgs);\n                                    break;\n                                case Exports_js_3.MetadataType.Viseme:\n                                    this.privSynthesisTurn.onVisemeMetadataReceived(metadata);\n                                    if (metadata.Data.IsLastAnimation) {\n                                        const visemeEventArgs = new Exports_js_2.SpeechSynthesisVisemeEventArgs(metadata.Data.Offset, metadata.Data.VisemeId, this.privSynthesisTurn.getAndClearVisemeAnimation());\n                                        this.onVisemeReceived(visemeEventArgs);\n                                    }\n                                    break;\n                                case Exports_js_3.MetadataType.AvatarSignal:\n                                    this.onAvatarEvent(metadata);\n                                    break;\n                                case Exports_js_3.MetadataType.SessionEnd:\n                                    this.privSynthesisTurn.onSessionEnd(metadata);\n                                    break;\n                            }\n                        }\n                        break;\n                    case \"turn.end\":\n                        this.privSynthesisTurn.onServiceTurnEndResponse();\n                        let result;\n                        try {\n                            result = await this.privSynthesisTurn.constructSynthesisResult();\n                            if (!!this.privSuccessCallback) {\n                                this.privSuccessCallback(result);\n                            }\n                        }\n                        catch (error) {\n                            if (!!this.privErrorCallback) {\n                                this.privErrorCallback(error);\n                            }\n                        }\n                        this.onSynthesisCompleted(result);\n                        break;\n                    default:\n                        if (!this.processTypeSpecificMessages(connectionMessage)) {\n                            // here are some messages that the derived class has not processed, dispatch them to connect class\n                            if (!!this.privServiceEvents) {\n                                this.serviceEvents.onEvent(new Exports_js_1.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                            }\n                        }\n                }\n            }\n            return this.receiveMessage();\n        }\n        catch (e) {\n            // TODO: What goes here?\n        }\n    }\n    sendSynthesisContext(connection) {\n        this.setSynthesisContextSynthesisSection();\n        const synthesisContextJson = this.synthesisContext.toJSON();\n        if (synthesisContextJson) {\n            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, \"synthesis.context\", this.privSynthesisTurn.requestId, \"application/json\", synthesisContextJson));\n        }\n        return;\n    }\n    setSpeechConfigSynthesisSection() {\n        return;\n    }\n    connectImpl(isUnAuthorized = false) {\n        if (this.privConnectionPromise != null) {\n            return this.privConnectionPromise.then((connection) => {\n                if (connection.state() === Exports_js_1.ConnectionState.Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionPromise = null;\n                    return this.connectImpl();\n                }\n                return this.privConnectionPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionPromise = null;\n                return this.connectImpl();\n            });\n        }\n        this.privAuthFetchEventId = Exports_js_1.createNoDashGuid();\n        this.privConnectionId = Exports_js_1.createNoDashGuid();\n        this.privSynthesisTurn.onPreConnectionStart(this.privAuthFetchEventId);\n        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n        this.privConnectionPromise = authPromise.then(async (result) => {\n            this.privSynthesisTurn.onAuthCompleted(false);\n            const connection = this.privConnectionFactory.create(this.privSynthesizerConfig, result, this.privConnectionId);\n            // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n            // it'll stop sending events.\n            connection.events.attach((event) => {\n                this.connectionEvents.onEvent(event);\n            });\n            const response = await connection.open();\n            if (response.statusCode === 200) {\n                this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);\n                return Promise.resolve(connection);\n            }\n            else if (response.statusCode === 403 && !isUnAuthorized) {\n                return this.connectImpl(true);\n            }\n            else {\n                this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);\n                return Promise.reject(`Unable to contact server. StatusCode: ${response.statusCode},\r\n                    ${this.privSynthesizerConfig.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url)} Reason: ${response.reason}`);\n            }\n        }, (error) => {\n            this.privSynthesisTurn.onAuthCompleted(true);\n            throw new Error(error);\n        });\n        // Attach an empty handler to allow the promise to run in the background while\n        // other startup events happen. It'll eventually be awaited on.\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        this.privConnectionPromise.catch(() => { });\n        return this.privConnectionPromise;\n    }\n    sendSpeechServiceConfig(connection, SpeechServiceConfigJson) {\n        if (SpeechServiceConfigJson) {\n            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, \"speech.config\", this.privSynthesisTurn.requestId, \"application/json\", SpeechServiceConfigJson));\n        }\n    }\n    sendSsmlMessage(connection, ssml, requestId) {\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, \"ssml\", requestId, \"application/ssml+xml\", ssml));\n    }\n    async fetchConnection() {\n        if (this.privConnectionConfigurationPromise !== undefined) {\n            return this.privConnectionConfigurationPromise.then((connection) => {\n                if (connection.state() === Exports_js_1.ConnectionState.Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigurationPromise = undefined;\n                    return this.fetchConnection();\n                }\n                return this.privConnectionConfigurationPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionConfigurationPromise = undefined;\n                return this.fetchConnection();\n            });\n        }\n        this.privConnectionConfigurationPromise = this.configureConnection();\n        return await this.privConnectionConfigurationPromise;\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    async configureConnection() {\n        const connection = await this.connectImpl();\n        if (this.configConnectionOverride !== undefined) {\n            return this.configConnectionOverride(connection);\n        }\n        this.setSpeechConfigSynthesisSection();\n        await this.sendSpeechServiceConfig(connection, this.privSynthesizerConfig.SpeechServiceConfig.serialize());\n        return connection;\n    }\n    onAvatarEvent(_metadata) {\n        return;\n    }\n    onSynthesisStarted(_requestId) {\n        return;\n    }\n    onSynthesizing(_audio) {\n        return;\n    }\n    onSynthesisCancelled(_result) {\n        return;\n    }\n    onSynthesisCompleted(_result) {\n        return;\n    }\n    onWordBoundary(_wordBoundaryEventArgs) {\n        return;\n    }\n    onVisemeReceived(_visemeEventArgs) {\n        return;\n    }\n    onBookmarkReached(_bookmarkEventArgs) {\n        return;\n    }\n}\nexports.SynthesisAdapterBase = SynthesisAdapterBase;\nSynthesisAdapterBase.telemetryDataEnabled = true;\n\n//# sourceMappingURL=SynthesisAdapterBase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisAdapterBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisContext = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nclass SynthesisContext {\n    constructor() {\n        this.privContext = {};\n    }\n    /**\n     * Adds a section to the synthesis.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    setSection(sectionName, value) {\n        this.privContext[sectionName] = value;\n    }\n    /**\n     * Sets the audio output format for synthesis context generation.\n     * @param format {AudioOutputFormatImpl} the output format\n     */\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n    }\n    toJSON() {\n        return JSON.stringify(this.privContext);\n    }\n    setSynthesisSection(speechSynthesizer) {\n        const synthesisSection = this.buildSynthesisContext(speechSynthesizer);\n        this.setSection(\"synthesis\", synthesisSection);\n    }\n    buildSynthesisContext(speechSynthesizer) {\n        return {\n            audio: {\n                metadataOptions: {\n                    bookmarkEnabled: (!!speechSynthesizer?.bookmarkReached),\n                    punctuationBoundaryEnabled: speechSynthesizer?.properties.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, (!!speechSynthesizer?.wordBoundary)),\n                    sentenceBoundaryEnabled: speechSynthesizer?.properties.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),\n                    sessionEndEnabled: true,\n                    visemeEnabled: (!!speechSynthesizer?.visemeReceived),\n                    wordBoundaryEnabled: speechSynthesizer?.properties.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_RequestWordBoundary, (!!speechSynthesizer?.wordBoundary)),\n                },\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\n            },\n            language: {\n                autoDetection: speechSynthesizer?.autoDetectSourceLanguage\n            }\n        };\n    }\n}\nexports.SynthesisContext = SynthesisContext;\n\n//# sourceMappingURL=SynthesisContext.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisEvents.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisEvents.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisStartedEvent = exports.ConnectingToSynthesisServiceEvent = exports.SynthesisTriggeredEvent = exports.SpeechSynthesisEvent = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nclass SpeechSynthesisEvent extends Exports_js_1.PlatformEvent {\n    constructor(eventName, requestId, eventType = Exports_js_1.EventType.Info) {\n        super(eventName, eventType);\n        this.privRequestId = requestId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n}\nexports.SpeechSynthesisEvent = SpeechSynthesisEvent;\nclass SynthesisTriggeredEvent extends SpeechSynthesisEvent {\n    constructor(requestId, sessionAudioDestinationId, turnAudioDestinationId) {\n        super(\"SynthesisTriggeredEvent\", requestId);\n        this.privSessionAudioDestinationId = sessionAudioDestinationId;\n        this.privTurnAudioDestinationId = turnAudioDestinationId;\n    }\n    get audioSessionDestinationId() {\n        return this.privSessionAudioDestinationId;\n    }\n    get audioTurnDestinationId() {\n        return this.privTurnAudioDestinationId;\n    }\n}\nexports.SynthesisTriggeredEvent = SynthesisTriggeredEvent;\nclass ConnectingToSynthesisServiceEvent extends SpeechSynthesisEvent {\n    constructor(requestId, authFetchEventId) {\n        super(\"ConnectingToSynthesisServiceEvent\", requestId);\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\nexports.ConnectingToSynthesisServiceEvent = ConnectingToSynthesisServiceEvent;\nclass SynthesisStartedEvent extends SpeechSynthesisEvent {\n    constructor(requestId, authFetchEventId) {\n        super(\"SynthesisStartedEvent\", requestId);\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\nexports.SynthesisStartedEvent = SynthesisStartedEvent;\n\n//# sourceMappingURL=SynthesisEvents.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisRestAdapter.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisRestAdapter.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisRestAdapter = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\n/**\n * Implements methods for speaker recognition classes, sending requests to endpoint\n * and parsing response into expected format\n * @class SynthesisRestAdapter\n */\nclass SynthesisRestAdapter {\n    constructor(config, authentication) {\n        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, \"westus\");\n            const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n            endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, `https://${region}.tts.speech${hostSuffix}`);\n        }\n        this.privUri = `${endpoint}/cognitiveservices/voices/list`;\n        const options = Exports_js_1.RestConfigBase.requestOptions;\n        this.privRestAdapter = new Exports_js_1.RestMessageAdapter(options);\n        this.privAuthentication = authentication;\n    }\n    /**\n     * Sends list voices request to endpoint.\n     * @function\n     * @public\n     * @param connectionId - guid for connectionId\n     * @returns {Promise<IRestResponse>} rest response to status request\n     */\n    getVoicesList(connectionId) {\n        this.privRestAdapter.setHeaders(HeaderNames_js_1.HeaderNames.ConnectionId, connectionId);\n        return this.privAuthentication.fetch(connectionId).then((authInfo) => {\n            this.privRestAdapter.setHeaders(authInfo.headerName, authInfo.token);\n            return this.privRestAdapter.request(Exports_js_1.RestRequestType.Get, this.privUri);\n        });\n    }\n}\nexports.SynthesisRestAdapter = SynthesisRestAdapter;\n\n//# sourceMappingURL=SynthesisRestAdapter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisRestAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisTurn.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisTurn.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisTurn = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst AudioOutputStream_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst SynthesisAudioMetadata_js_1 = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\nconst SynthesisEvents_js_1 = __webpack_require__(/*! ./SynthesisEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisEvents.js\");\nclass SynthesisTurn {\n    constructor() {\n        this.privIsDisposed = false;\n        this.privIsSynthesizing = false;\n        this.privIsSynthesisEnded = false;\n        this.privBytesReceived = 0;\n        this.privInTurn = false;\n        this.privTextOffset = 0;\n        this.privNextSearchTextIndex = 0;\n        this.privSentenceOffset = 0;\n        this.privNextSearchSentenceIndex = 0;\n        this.privRequestId = Exports_js_1.createNoDashGuid();\n        this.privTurnDeferral = new Exports_js_1.Deferred();\n        // We're not in a turn, so resolve.\n        this.privTurnDeferral.resolve();\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get streamId() {\n        return this.privStreamId;\n    }\n    set streamId(value) {\n        this.privStreamId = value;\n    }\n    get audioOutputFormat() {\n        return this.privAudioOutputFormat;\n    }\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n    }\n    get turnCompletionPromise() {\n        return this.privTurnDeferral.promise;\n    }\n    get isSynthesisEnded() {\n        return this.privIsSynthesisEnded;\n    }\n    get isSynthesizing() {\n        return this.privIsSynthesizing;\n    }\n    get currentTextOffset() {\n        return this.privTextOffset;\n    }\n    get currentSentenceOffset() {\n        return this.privSentenceOffset;\n    }\n    // The number of bytes received for current turn\n    get bytesReceived() {\n        return this.privBytesReceived;\n    }\n    get audioDuration() {\n        return this.privAudioDuration;\n    }\n    get extraProperties() {\n        if (!!this.privWebRTCSDP) {\n            const properties = new Exports_js_2.PropertyCollection();\n            properties.setProperty(Exports_js_2.PropertyId.TalkingAvatarService_WebRTC_SDP, this.privWebRTCSDP);\n            return properties;\n        }\n        return undefined;\n    }\n    async getAllReceivedAudio() {\n        if (!!this.privReceivedAudio) {\n            return Promise.resolve(this.privReceivedAudio);\n        }\n        if (!this.privIsSynthesisEnded) {\n            return null;\n        }\n        await this.readAllAudioFromStream();\n        return Promise.resolve(this.privReceivedAudio);\n    }\n    async getAllReceivedAudioWithHeader() {\n        if (!!this.privReceivedAudioWithHeader) {\n            return this.privReceivedAudioWithHeader;\n        }\n        if (!this.privIsSynthesisEnded) {\n            return null;\n        }\n        if (this.audioOutputFormat.hasHeader) {\n            const audio = await this.getAllReceivedAudio();\n            this.privReceivedAudioWithHeader = this.audioOutputFormat.addHeader(audio);\n            return this.privReceivedAudioWithHeader;\n        }\n        else {\n            return this.getAllReceivedAudio();\n        }\n    }\n    startNewSynthesis(requestId, rawText, isSSML, audioDestination) {\n        this.privIsSynthesisEnded = false;\n        this.privIsSynthesizing = true;\n        this.privRequestId = requestId;\n        this.privRawText = rawText;\n        this.privIsSSML = isSSML;\n        this.privAudioOutputStream = new AudioOutputStream_js_1.PullAudioOutputStreamImpl();\n        this.privAudioOutputStream.format = this.privAudioOutputFormat;\n        this.privReceivedAudio = null;\n        this.privReceivedAudioWithHeader = null;\n        this.privBytesReceived = 0;\n        this.privTextOffset = 0;\n        this.privNextSearchTextIndex = 0;\n        this.privSentenceOffset = 0;\n        this.privNextSearchSentenceIndex = 0;\n        this.privPartialVisemeAnimation = \"\";\n        this.privWebRTCSDP = \"\";\n        if (audioDestination !== undefined) {\n            this.privTurnAudioDestination = audioDestination;\n            this.privTurnAudioDestination.format = this.privAudioOutputFormat;\n        }\n        this.onEvent(new SynthesisEvents_js_1.SynthesisTriggeredEvent(this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));\n    }\n    onPreConnectionStart(authFetchEventId) {\n        this.privAuthFetchEventId = authFetchEventId;\n        this.onEvent(new SynthesisEvents_js_1.ConnectingToSynthesisServiceEvent(this.privRequestId, this.privAuthFetchEventId));\n    }\n    onAuthCompleted(isError) {\n        if (isError) {\n            this.onComplete();\n        }\n    }\n    onConnectionEstablishCompleted(statusCode) {\n        if (statusCode === 200) {\n            this.onEvent(new SynthesisEvents_js_1.SynthesisStartedEvent(this.requestId, this.privAuthFetchEventId));\n            this.privBytesReceived = 0;\n            return;\n        }\n        else if (statusCode === 403) {\n            this.onComplete();\n        }\n    }\n    onServiceResponseMessage(responseJson) {\n        const response = JSON.parse(responseJson);\n        this.streamId = response.audio.streamId;\n    }\n    onServiceTurnEndResponse() {\n        this.privInTurn = false;\n        this.privTurnDeferral.resolve();\n        this.onComplete();\n    }\n    onServiceTurnStartResponse(responseJson) {\n        if (!!this.privTurnDeferral && !!this.privInTurn) {\n            // What? How are we starting a turn with another not done?\n            this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n            // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            this.privTurnDeferral.promise.then().catch(() => { });\n        }\n        this.privInTurn = true;\n        this.privTurnDeferral = new Exports_js_1.Deferred();\n        const response = JSON.parse(responseJson);\n        if (!!response.webrtc) {\n            this.privWebRTCSDP = response.webrtc.connectionString;\n        }\n    }\n    onAudioChunkReceived(data) {\n        if (this.isSynthesizing) {\n            this.privAudioOutputStream.write(data);\n            this.privBytesReceived += data.byteLength;\n            if (this.privTurnAudioDestination !== undefined) {\n                this.privTurnAudioDestination.write(data);\n            }\n        }\n    }\n    onTextBoundaryEvent(metadata) {\n        this.updateTextOffset(metadata.Data.text.Text, metadata.Type);\n    }\n    onVisemeMetadataReceived(metadata) {\n        if (metadata.Data.AnimationChunk !== undefined) {\n            this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;\n        }\n    }\n    onSessionEnd(metadata) {\n        this.privAudioDuration = metadata.Data.Offset;\n    }\n    async constructSynthesisResult() {\n        const audioBuffer = await this.getAllReceivedAudioWithHeader();\n        return new Exports_js_2.SpeechSynthesisResult(this.requestId, Exports_js_2.ResultReason.SynthesizingAudioCompleted, audioBuffer, undefined, this.extraProperties, this.audioDuration);\n    }\n    dispose() {\n        if (!this.privIsDisposed) {\n            // we should have completed by now. If we did not its an unknown error.\n            this.privIsDisposed = true;\n        }\n    }\n    onStopSynthesizing() {\n        this.onComplete();\n    }\n    /**\n     * Gets the viseme animation string (merged from animation chunk), and clears the internal\n     * partial animation.\n     */\n    getAndClearVisemeAnimation() {\n        const animation = this.privPartialVisemeAnimation;\n        this.privPartialVisemeAnimation = \"\";\n        return animation;\n    }\n    onEvent(event) {\n        Exports_js_1.Events.instance.onEvent(event);\n    }\n    /**\n     * Check if the text is an XML(SSML) tag\n     * @param text\n     * @private\n     */\n    static isXmlTag(text) {\n        return text.length >= 2 && text[0] === \"<\" && text[text.length - 1] === \">\";\n    }\n    updateTextOffset(text, type) {\n        if (type === SynthesisAudioMetadata_js_1.MetadataType.WordBoundary) {\n            this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);\n            if (this.privTextOffset >= 0) {\n                this.privNextSearchTextIndex = this.privTextOffset + text.length;\n                if (this.privIsSSML) {\n                    if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {\n                        this.updateTextOffset(text, type);\n                    }\n                }\n            }\n        }\n        else {\n            this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);\n            if (this.privSentenceOffset >= 0) {\n                this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;\n                if (this.privIsSSML) {\n                    if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {\n                        this.updateTextOffset(text, type);\n                    }\n                }\n            }\n        }\n    }\n    onComplete() {\n        if (this.privIsSynthesizing) {\n            this.privIsSynthesizing = false;\n            this.privIsSynthesisEnded = true;\n            this.privAudioOutputStream.close();\n            this.privInTurn = false;\n            if (this.privTurnAudioDestination !== undefined) {\n                this.privTurnAudioDestination.close();\n                this.privTurnAudioDestination = undefined;\n            }\n        }\n    }\n    async readAllAudioFromStream() {\n        if (this.privIsSynthesisEnded) {\n            this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);\n            try {\n                await this.privAudioOutputStream.read(this.privReceivedAudio);\n            }\n            catch (e) {\n                this.privReceivedAudio = new ArrayBuffer(0);\n            }\n        }\n    }\n    /**\n     * Check if current idx is in XML(SSML) tag\n     * @param idx\n     * @private\n     */\n    withinXmlTag(idx) {\n        return this.privRawText.indexOf(\"<\", idx + 1) > this.privRawText.indexOf(\">\", idx + 1);\n    }\n}\nexports.SynthesisTurn = SynthesisTurn;\n\n//# sourceMappingURL=SynthesisTurn.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisTurn.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesizerConfig.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesizerConfig.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesizerConfig = exports.SynthesisServiceType = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nvar SynthesisServiceType;\n(function (SynthesisServiceType) {\n    SynthesisServiceType[SynthesisServiceType[\"Standard\"] = 0] = \"Standard\";\n    SynthesisServiceType[SynthesisServiceType[\"Custom\"] = 1] = \"Custom\";\n})(SynthesisServiceType = exports.SynthesisServiceType || (exports.SynthesisServiceType = {}));\nclass SynthesizerConfig {\n    constructor(speechServiceConfig, parameters) {\n        this.privSynthesisServiceType = SynthesisServiceType.Standard;\n        this.avatarEnabled = false;\n        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new Exports_js_1.SpeechServiceConfig(new Exports_js_1.Context(null));\n        this.privParameters = parameters;\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get synthesisServiceType() {\n        return this.privSynthesisServiceType;\n    }\n    set synthesisServiceType(value) {\n        this.privSynthesisServiceType = value;\n    }\n    set synthesisVideoSection(value) {\n        this.privSpeechServiceConfig.Context.synthesis = {\n            video: value\n        };\n    }\n    get SpeechServiceConfig() {\n        return this.privSpeechServiceConfig;\n    }\n}\nexports.SynthesizerConfig = SynthesizerConfig;\n\n//# sourceMappingURL=SynthesizerConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesizerConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriberConnectionFactory.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriberConnectionFactory.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranscriberConnectionFactory = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js\");\nclass TranscriberConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    constructor() {\n        super(...arguments);\n        this.multiaudioRelativeUri = \"/speech/recognition/multiaudio\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, \"centralus\");\n        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n        const hostDefault = \"wss://transcribe.\" + region + \".cts.speech\" + hostSuffix + this.multiaudioRelativeUri;\n        const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, hostDefault);\n        const queryParams = {};\n        this.setQueryParams(queryParams, config, endpoint);\n        if (!endpoint) {\n            endpoint = host;\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n    setQueryParams(queryParams, config, endpointUrl) {\n        const endpointId = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n        const language = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);\n        if (endpointId && !(QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId in queryParams)) {\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;\n        }\n        if (language && !(QueryParameterNames_js_1.QueryParameterNames.Language in queryParams)) {\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.Language] = language;\n        }\n        const wordLevelTimings = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"false\").toLowerCase() === \"true\";\n        const detailed = config.parameters.getProperty(Exports_js_3.OutputFormatPropertyName, Exports_js_2.OutputFormat[Exports_js_2.OutputFormat.Simple]) !== Exports_js_2.OutputFormat[Exports_js_2.OutputFormat.Simple];\n        if (wordLevelTimings || detailed) {\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = Exports_js_2.OutputFormat[Exports_js_2.OutputFormat.Detailed].toLowerCase();\n        }\n        this.setCommonUrlParams(config, queryParams, endpointUrl);\n    }\n}\nexports.TranscriberConnectionFactory = TranscriberConnectionFactory;\n\n//# sourceMappingURL=TranscriberConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriberConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js ***!
  \*****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationConnectionConfig = void 0;\nconst RestConfigBase_js_1 = __webpack_require__(/*! ../../common.browser/RestConfigBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js\");\nclass ConversationConnectionConfig extends RestConfigBase_js_1.RestConfigBase {\n    static get host() {\n        return ConversationConnectionConfig.privHost;\n    }\n    static get apiVersion() {\n        return ConversationConnectionConfig.privApiVersion;\n    }\n    static get clientAppId() {\n        return ConversationConnectionConfig.privClientAppId;\n    }\n    static get defaultLanguageCode() {\n        return ConversationConnectionConfig.privDefaultLanguageCode;\n    }\n    static get restPath() {\n        return ConversationConnectionConfig.privRestPath;\n    }\n    static get webSocketPath() {\n        return ConversationConnectionConfig.privWebSocketPath;\n    }\n    static get transcriptionEventKeys() {\n        return ConversationConnectionConfig.privTranscriptionEventKeys;\n    }\n}\nexports.ConversationConnectionConfig = ConversationConnectionConfig;\nConversationConnectionConfig.privHost = \"dev.microsofttranslator.com\";\nConversationConnectionConfig.privRestPath = \"/capito/room\";\nConversationConnectionConfig.privApiVersion = \"2.0\";\nConversationConnectionConfig.privDefaultLanguageCode = \"en-US\";\nConversationConnectionConfig.privClientAppId = \"FC539C22-1767-4F1F-84BC-B4D811114F15\";\nConversationConnectionConfig.privWebSocketPath = \"/capito/translate\";\nConversationConnectionConfig.privTranscriptionEventKeys = [\"iCalUid\", \"callId\", \"organizer\", \"FLAC\", \"MTUri\", \"DifferentiateGuestSpeakers\", \"audiorecording\", \"Threadid\", \"OrganizerMri\", \"OrganizerTenantId\", \"UserToken\"];\n\n//# sourceMappingURL=ConversationConnectionConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionFactory.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionFactory.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationConnectionFactory = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ../ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst ConversationConnectionConfig_js_1 = __webpack_require__(/*! ./ConversationConnectionConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js\");\nconst ConversationWebsocketMessageFormatter_js_1 = __webpack_require__(/*! ./ConversationWebsocketMessageFormatter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js\");\n/**\n * Create a connection to the Conversation Translator websocket for sending instant messages and commands, and for receiving translated messages.\n * The conversation must already have been started or joined.\n */\nclass ConversationConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        const endpointHost = config.parameters.getProperty(Exports_js_3.PropertyId.ConversationTranslator_Host, ConversationConnectionConfig_js_1.ConversationConnectionConfig.host);\n        const correlationId = config.parameters.getProperty(Exports_js_3.PropertyId.ConversationTranslator_CorrelationId, Exports_js_2.createGuid());\n        const endpoint = `wss://${endpointHost}${ConversationConnectionConfig_js_1.ConversationConnectionConfig.webSocketPath}`;\n        const token = config.parameters.getProperty(Exports_js_3.PropertyId.ConversationTranslator_Token, undefined);\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(token, \"token\");\n        const queryParams = {};\n        queryParams[ConversationConnectionConfig_js_1.ConversationConnectionConfig.configParams.apiVersion] = ConversationConnectionConfig_js_1.ConversationConnectionConfig.apiVersion;\n        queryParams[ConversationConnectionConfig_js_1.ConversationConnectionConfig.configParams.token] = token;\n        queryParams[ConversationConnectionConfig_js_1.ConversationConnectionConfig.configParams.correlationId] = correlationId;\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new Exports_js_1.WebsocketConnection(endpoint, queryParams, {}, new ConversationWebsocketMessageFormatter_js_1.ConversationWebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\nexports.ConversationConnectionFactory = ConversationConnectionFactory;\n\n//# sourceMappingURL=ConversationConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationConnectionMessage = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nclass ConversationConnectionMessage extends Exports_js_1.ConnectionMessage {\n    constructor(messageType, body, headers, id) {\n        super(messageType, body, headers, id);\n        const json = JSON.parse(this.textBody);\n        if (json.type !== undefined) {\n            this.privConversationMessageType = json.type;\n        }\n    }\n    get conversationMessageType() {\n        return this.privConversationMessageType;\n    }\n}\nexports.ConversationConnectionMessage = ConversationConnectionMessage;\n\n//# sourceMappingURL=ConversationConnectionMessage.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationManager.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationManager.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationManager = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConversationConnectionConfig_js_1 = __webpack_require__(/*! ./ConversationConnectionConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js\");\nclass ConversationManager {\n    constructor() {\n        //\n        this.privRequestParams = ConversationConnectionConfig_js_1.ConversationConnectionConfig.configParams;\n        this.privErrors = ConversationConnectionConfig_js_1.ConversationConnectionConfig.restErrors;\n        this.privHost = ConversationConnectionConfig_js_1.ConversationConnectionConfig.host;\n        this.privApiVersion = ConversationConnectionConfig_js_1.ConversationConnectionConfig.apiVersion;\n        this.privRestPath = ConversationConnectionConfig_js_1.ConversationConnectionConfig.restPath;\n        this.privRestAdapter = new Exports_js_1.RestMessageAdapter({});\n    }\n    /**\n     * Make a POST request to the Conversation Manager service endpoint to create or join a conversation.\n     * @param args\n     * @param conversationCode\n     * @param callback\n     * @param errorCallback\n     */\n    createOrJoin(args, conversationCode, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(args, \"args\");\n            const languageCode = args.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, ConversationConnectionConfig_js_1.ConversationConnectionConfig.defaultLanguageCode);\n            const nickname = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_Name, \"conversation_host\");\n            const endpointHost = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_Host, this.privHost);\n            const correlationId = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_CorrelationId);\n            const subscriptionKey = args.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key);\n            const subscriptionRegion = args.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);\n            const authToken = args.getProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token);\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(languageCode, \"languageCode\");\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, \"nickname\");\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(endpointHost, \"endpointHost\");\n            const queryParams = {};\n            queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;\n            queryParams[this.privRequestParams.languageCode] = languageCode;\n            queryParams[this.privRequestParams.nickname] = nickname;\n            const headers = {};\n            if (correlationId) {\n                headers[this.privRequestParams.correlationId] = correlationId;\n            }\n            headers[this.privRequestParams.clientAppId] = ConversationConnectionConfig_js_1.ConversationConnectionConfig.clientAppId;\n            if (conversationCode !== undefined) {\n                queryParams[this.privRequestParams.roomId] = conversationCode;\n            }\n            else {\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(subscriptionRegion, this.privErrors.authInvalidSubscriptionRegion);\n                headers[this.privRequestParams.subscriptionRegion] = subscriptionRegion;\n                if (subscriptionKey) {\n                    headers[this.privRequestParams.subscriptionKey] = subscriptionKey;\n                }\n                else if (authToken) {\n                    headers[this.privRequestParams.authorization] = `Bearer ${authToken}`;\n                }\n                else {\n                    Contracts_js_1.Contracts.throwIfNullOrUndefined(subscriptionKey, this.privErrors.authInvalidSubscriptionKey);\n                }\n            }\n            const config = {};\n            config.headers = headers;\n            this.privRestAdapter.options = config;\n            const endpoint = `https://${endpointHost}${this.privRestPath}`;\n            // TODO: support a proxy and certificate validation\n            this.privRestAdapter.request(Exports_js_1.RestRequestType.Post, endpoint, queryParams, null).then((response) => {\n                const requestId = Exports_js_1.RestMessageAdapter.extractHeaderValue(this.privRequestParams.requestId, response.headers);\n                if (!response.ok) {\n                    if (!!err) {\n                        // get the error\n                        let errorMessage = this.privErrors.invalidCreateJoinConversationResponse.replace(\"{status}\", response.status.toString());\n                        let errMessageRaw;\n                        try {\n                            errMessageRaw = JSON.parse(response.data);\n                            errorMessage += ` [${errMessageRaw.error.code}: ${errMessageRaw.error.message}]`;\n                        }\n                        catch (e) {\n                            errorMessage += ` [${response.data}]`;\n                        }\n                        if (requestId) {\n                            errorMessage += ` ${requestId}`;\n                        }\n                        err(errorMessage);\n                    }\n                    return;\n                }\n                const conversation = JSON.parse(response.data);\n                if (conversation) {\n                    conversation.requestId = requestId;\n                }\n                if (!!cb) {\n                    try {\n                        cb(conversation);\n                    }\n                    catch (e) {\n                        if (!!err) {\n                            err(e);\n                        }\n                    }\n                    cb = undefined;\n                }\n                // eslint-disable-next-line @typescript-eslint/no-empty-function\n            }).catch(() => { });\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n        }\n    }\n    /**\n     * Make a DELETE request to the Conversation Manager service endpoint to leave the conversation.\n     * @param args\n     * @param sessionToken\n     * @param callback\n     */\n    leave(args, sessionToken) {\n        return new Promise((resolve, reject) => {\n            try {\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(args, this.privErrors.invalidArgs.replace(\"{arg}\", \"config\"));\n                Contracts_js_1.Contracts.throwIfNullOrWhitespace(sessionToken, this.privErrors.invalidArgs.replace(\"{arg}\", \"token\"));\n                const endpointHost = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_Host, this.privHost);\n                const correlationId = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_CorrelationId);\n                const queryParams = {};\n                queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;\n                queryParams[this.privRequestParams.sessionToken] = sessionToken;\n                const headers = {};\n                if (correlationId) {\n                    headers[this.privRequestParams.correlationId] = correlationId;\n                }\n                const config = {};\n                config.headers = headers;\n                this.privRestAdapter.options = config;\n                const endpoint = `https://${endpointHost}${this.privRestPath}`;\n                // TODO: support a proxy and certificate validation\n                this.privRestAdapter.request(Exports_js_1.RestRequestType.Delete, endpoint, queryParams, null).then((response) => {\n                    if (!response.ok) {\n                        // ignore errors on delete\n                    }\n                    resolve();\n                    // eslint-disable-next-line @typescript-eslint/no-empty-function\n                }).catch(() => { });\n            }\n            catch (error) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    reject(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    reject(error);\n                }\n            }\n        });\n    }\n}\nexports.ConversationManager = ConversationManager;\n\n//# sourceMappingURL=ConversationManager.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationManager.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationRequestSession.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationRequestSession.js ***!
  \***************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationRequestSession = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\n/**\n * Placeholder class for the Conversation Request Session. Based off RequestSession.\n * TODO: define what telemetry is required.\n */\nclass ConversationRequestSession {\n    constructor(sessionId) {\n        this.privIsDisposed = false;\n        this.privDetachables = new Array();\n        this.privSessionId = sessionId;\n        this.privRequestId = Exports_js_1.createNoDashGuid();\n        this.privRequestCompletionDeferral = new Exports_js_1.Deferred();\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get completionPromise() {\n        return this.privRequestCompletionDeferral.promise;\n    }\n    onPreConnectionStart(authFetchEventId, connectionId) {\n        this.privSessionId = connectionId;\n    }\n    onAuthCompleted(isError) {\n        if (isError) {\n            this.onComplete();\n        }\n    }\n    onConnectionEstablishCompleted(statusCode) {\n        if (statusCode === 200) {\n            return;\n        }\n        else if (statusCode === 403) {\n            this.onComplete();\n        }\n    }\n    onServiceTurnEndResponse(continuousRecognition) {\n        if (!continuousRecognition) {\n            this.onComplete();\n        }\n        else {\n            this.privRequestId = Exports_js_1.createNoDashGuid();\n        }\n    }\n    async dispose() {\n        if (!this.privIsDisposed) {\n            // we should have completed by now. If we did not its an unknown error.\n            this.privIsDisposed = true;\n            for (const detachable of this.privDetachables) {\n                await detachable.detach();\n            }\n        }\n    }\n    onComplete() {\n        //\n    }\n}\nexports.ConversationRequestSession = ConversationRequestSession;\n\n//# sourceMappingURL=ConversationRequestSession.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationRequestSession.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationServiceAdapter.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationServiceAdapter.js ***!
  \***************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationServiceAdapter = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst ConversationConnectionMessage_js_1 = __webpack_require__(/*! ./ConversationConnectionMessage.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js\");\nconst ConversationRequestSession_js_1 = __webpack_require__(/*! ./ConversationRequestSession.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationRequestSession.js\");\nconst ConversationTranslatorEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranslatorEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js\");\nconst ConversationTranslatorInterfaces_js_1 = __webpack_require__(/*! ./ConversationTranslatorInterfaces.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./ServiceMessages/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/Exports.js\");\n/**\n * The service adapter handles sending and receiving messages to the Conversation Translator websocket.\n */\nclass ConversationServiceAdapter extends Exports_js_3.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector);\n        this.privConnectionConfigPromise = undefined;\n        this.privLastPartialUtteranceId = \"\";\n        this.privConversationServiceConnector = conversationServiceConnector;\n        this.privConversationAuthentication = authentication;\n        this.receiveMessageOverride = () => this.receiveConversationMessageOverride();\n        this.recognizeOverride = () => this.noOp();\n        this.postConnectImplOverride = (connection) => this.conversationConnectImpl(connection);\n        this.configConnectionOverride = () => this.configConnection();\n        this.disconnectOverride = () => this.privDisconnect();\n        this.privConversationRequestSession = new ConversationRequestSession_js_1.ConversationRequestSession(Exports_js_1.createNoDashGuid());\n        this.privConversationConnectionFactory = connectionFactory;\n        this.privConversationIsDisposed = false;\n    }\n    isDisposed() {\n        return super.isDisposed() || this.privConversationIsDisposed;\n    }\n    async dispose(reason) {\n        this.privConversationIsDisposed = true;\n        if (this.privConnectionConfigPromise !== undefined) {\n            const connection = await this.privConnectionConfigPromise;\n            await connection.dispose(reason);\n        }\n        await super.dispose(reason);\n    }\n    async sendMessage(message) {\n        const connection = await this.fetchConnection();\n        return connection.send(new ConversationConnectionMessage_js_1.ConversationConnectionMessage(Exports_js_1.MessageType.Text, message));\n    }\n    async sendMessageAsync(message) {\n        const connection = await this.fetchConnection();\n        await connection.send(new ConversationConnectionMessage_js_1.ConversationConnectionMessage(Exports_js_1.MessageType.Text, message));\n    }\n    privDisconnect() {\n        if (this.terminateMessageLoop) {\n            return;\n        }\n        this.cancelRecognition(this.privConversationRequestSession.sessionId, this.privConversationRequestSession.requestId, Exports_js_2.CancellationReason.Error, Exports_js_2.CancellationErrorCode.NoError, \"Disconnecting\");\n        this.terminateMessageLoop = true;\n        return Promise.resolve();\n    }\n    // eslint-disable-next-line @typescript-eslint/require-await\n    async processTypeSpecificMessages() {\n        return true;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        this.terminateMessageLoop = true;\n        const cancelEvent = new Exports_js_2.ConversationTranslationCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n        try {\n            if (!!this.privConversationServiceConnector.canceled) {\n                this.privConversationServiceConnector.canceled(this.privConversationServiceConnector, cancelEvent);\n            }\n        }\n        catch {\n            // continue on error\n        }\n    }\n    /**\n     * Establishes a websocket connection to the end point.\n     */\n    async conversationConnectImpl(connection) {\n        this.privConnectionLoop = this.startMessageLoop();\n        return connection;\n    }\n    /**\n     * Process incoming websocket messages\n     */\n    async receiveConversationMessageOverride() {\n        if (this.isDisposed() || this.terminateMessageLoop) {\n            return Promise.resolve();\n        }\n        // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n        const communicationCustodian = new Exports_js_1.Deferred();\n        try {\n            const connection = await this.fetchConnection();\n            const message = await connection.read();\n            if (this.isDisposed() || this.terminateMessageLoop) {\n                // We're done.\n                communicationCustodian.resolve();\n                return Promise.resolve();\n            }\n            if (!message) {\n                return this.receiveConversationMessageOverride();\n            }\n            const sessionId = this.privConversationRequestSession.sessionId;\n            const conversationMessageType = message.conversationMessageType.toLowerCase();\n            let sendFinal = false;\n            try {\n                switch (conversationMessageType) {\n                    case \"info\":\n                    case \"participant_command\":\n                    case \"command\":\n                        const commandPayload = Exports_js_4.CommandResponsePayload.fromJSON(message.textBody);\n                        switch (commandPayload.command.toLowerCase()) {\n                            /**\n                             * 'ParticpantList' is the first message sent to the user after the websocket connection has opened.\n                             * The consuming client must wait for this message to arrive\n                             * before starting to send their own data.\n                             */\n                            case \"participantlist\":\n                                const participantsPayload = Exports_js_4.ParticipantsListPayloadResponse.fromJSON(message.textBody);\n                                const participantsResult = participantsPayload.participants.map((p) => {\n                                    const participant = {\n                                        avatar: p.avatar,\n                                        displayName: p.nickname,\n                                        id: p.participantId,\n                                        isHost: p.ishost,\n                                        isMuted: p.ismuted,\n                                        isUsingTts: p.usetts,\n                                        preferredLanguage: p.locale\n                                    };\n                                    return participant;\n                                });\n                                if (!!this.privConversationServiceConnector.participantsListReceived) {\n                                    this.privConversationServiceConnector.participantsListReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantsListEventArgs(participantsPayload.roomid, participantsPayload.token, participantsPayload.translateTo, participantsPayload.profanityFilter, participantsPayload.roomProfanityFilter, participantsPayload.roomLocked, participantsPayload.muteAll, participantsResult, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'SetTranslateToLanguages' represents the list of languages being used in the Conversation by all users(?).\n                             * This is sent at the start of the Conversation\n                             */\n                            case \"settranslatetolanguages\":\n                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages, commandPayload.value, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'SetProfanityFiltering' lets the client set the level of profanity filtering.\n                             * If sent by the participant the setting will effect only their own profanity level.\n                             * If sent by the host, the setting will effect all participants including the host.\n                             * Note: the profanity filters differ from Speech Service (?): 'marked', 'raw', 'removed', 'tagged'\n                             */\n                            case \"setprofanityfiltering\":\n                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.setProfanityFiltering, commandPayload.value, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'SetMute' is sent if the participant has been muted by the host.\n                             * Check the 'participantId' to determine if the current user has been muted.\n                             */\n                            case \"setmute\":\n                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.setMute, commandPayload.value, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'SetMuteAll' is sent if the Conversation has been muted by the host.\n                             */\n                            case \"setmuteall\":\n                                if (!!this.privConversationServiceConnector.muteAllCommandReceived) {\n                                    this.privConversationServiceConnector.muteAllCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.MuteAllEventArgs(commandPayload.value, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'RoomExpirationWarning' is sent towards the end of the Conversation session to give a timeout warning.\n                             */\n                            case \"roomexpirationwarning\":\n                                if (!!this.privConversationServiceConnector.conversationExpiration) {\n                                    this.privConversationServiceConnector.conversationExpiration(this.privConversationServiceConnector, new Exports_js_2.ConversationExpirationEventArgs(commandPayload.value, this.privConversationRequestSession.sessionId));\n                                }\n                                break;\n                            /**\n                             * 'SetUseTts' is sent as a confirmation if the user requests TTS to be turned on or off.\n                             */\n                            case \"setusetts\":\n                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.setUseTTS, commandPayload.value, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'SetLockState' is set if the host has locked or unlocked the Conversation.\n                             */\n                            case \"setlockstate\":\n                                if (!!this.privConversationServiceConnector.lockRoomCommandReceived) {\n                                    this.privConversationServiceConnector.lockRoomCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.LockRoomEventArgs(commandPayload.value, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'ChangeNickname' is received if a user changes their display name.\n                             * Any cached particpiants list should be updated to reflect the display name.\n                             */\n                            case \"changenickname\":\n                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.changeNickname, commandPayload.value, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'JoinSession' is sent when a user joins the Conversation.\n                             */\n                            case \"joinsession\":\n                                const joinParticipantPayload = Exports_js_4.ParticipantPayloadResponse.fromJSON(message.textBody);\n                                const joiningParticipant = {\n                                    avatar: joinParticipantPayload.avatar,\n                                    displayName: joinParticipantPayload.nickname,\n                                    id: joinParticipantPayload.participantId,\n                                    isHost: joinParticipantPayload.ishost,\n                                    isMuted: joinParticipantPayload.ismuted,\n                                    isUsingTts: joinParticipantPayload.usetts,\n                                    preferredLanguage: joinParticipantPayload.locale,\n                                };\n                                if (!!this.privConversationServiceConnector.participantJoinCommandReceived) {\n                                    this.privConversationServiceConnector.participantJoinCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantEventArgs(joiningParticipant, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'LeaveSession' is sent when a user leaves the Conversation'.\n                             */\n                            case \"leavesession\":\n                                const leavingParticipant = {\n                                    id: commandPayload.participantId\n                                };\n                                if (!!this.privConversationServiceConnector.participantLeaveCommandReceived) {\n                                    this.privConversationServiceConnector.participantLeaveCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantEventArgs(leavingParticipant, sessionId));\n                                }\n                                break;\n                            /**\n                             * 'DisconnectSession' is sent when a user is disconnected from the session (e.g. network problem).\n                             * Check the 'ParticipantId' to check whether the message is for the current user.\n                             */\n                            case \"disconnectsession\":\n                                // eslint-disable-next-line @typescript-eslint/no-unused-vars\n                                const disconnectParticipant = {\n                                    id: commandPayload.participantId\n                                };\n                                break;\n                            case \"token\":\n                                const token = new Exports_js_3.CognitiveTokenAuthentication(() => {\n                                    const authorizationToken = commandPayload.token;\n                                    return Promise.resolve(authorizationToken);\n                                }, () => {\n                                    const authorizationToken = commandPayload.token;\n                                    return Promise.resolve(authorizationToken);\n                                });\n                                this.authentication = token;\n                                this.privConversationServiceConnector.onToken(token);\n                                break;\n                            /**\n                             * Message not recognized.\n                             */\n                            default:\n                                break;\n                        }\n                        break;\n                    /**\n                     * 'partial' (or 'hypothesis') represents a unfinalized speech message.\n                     */\n                    case \"partial\":\n                    /**\n                     * 'final' (or 'phrase') represents a finalized speech message.\n                     */\n                    case \"final\":\n                        const speechPayload = Exports_js_4.SpeechResponsePayload.fromJSON(message.textBody);\n                        const conversationResultReason = (conversationMessageType === \"final\") ? Exports_js_2.ResultReason.TranslatedParticipantSpeech : Exports_js_2.ResultReason.TranslatingParticipantSpeech;\n                        const speechResult = new Exports_js_2.ConversationTranslationResult(speechPayload.participantId, this.getTranslations(speechPayload.translations), speechPayload.language, speechPayload.id, conversationResultReason, speechPayload.recognition, undefined, undefined, message.textBody, undefined);\n                        if (speechPayload.isFinal) {\n                            // check the length, sometimes empty finals are returned\n                            if (speechResult.text !== undefined && speechResult.text.length > 0) {\n                                sendFinal = true;\n                            }\n                            else if (speechPayload.id === this.privLastPartialUtteranceId) {\n                                // send final as normal. We had a non-empty partial for this same utterance\n                                // so sending the empty final is important\n                                sendFinal = true;\n                            }\n                            else {\n                                // suppress unneeded final\n                            }\n                            if (sendFinal) {\n                                if (!!this.privConversationServiceConnector.translationReceived) {\n                                    this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ConversationReceivedTranslationEventArgs(ConversationTranslatorInterfaces_js_1.ConversationTranslatorMessageTypes.final, speechResult, sessionId));\n                                }\n                            }\n                        }\n                        else if (speechResult.text !== undefined) {\n                            this.privLastPartialUtteranceId = speechPayload.id;\n                            if (!!this.privConversationServiceConnector.translationReceived) {\n                                this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ConversationReceivedTranslationEventArgs(ConversationTranslatorInterfaces_js_1.ConversationTranslatorMessageTypes.partial, speechResult, sessionId));\n                            }\n                        }\n                        break;\n                    /**\n                     * \"translated_message\" is a text message or instant message (IM).\n                     */\n                    case \"translated_message\":\n                        const textPayload = Exports_js_4.TextResponsePayload.fromJSON(message.textBody);\n                        // TODO: (Native parity) a result reason should be set based whether the participantId is ours or not\n                        const textResult = new Exports_js_2.ConversationTranslationResult(textPayload.participantId, this.getTranslations(textPayload.translations), textPayload.language, undefined, undefined, textPayload.originalText, undefined, undefined, undefined, message.textBody, undefined);\n                        if (!!this.privConversationServiceConnector.translationReceived) {\n                            this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ConversationReceivedTranslationEventArgs(ConversationTranslatorInterfaces_js_1.ConversationTranslatorMessageTypes.instantMessage, textResult, sessionId));\n                        }\n                        break;\n                    default:\n                        // ignore any unsupported message types\n                        break;\n                }\n            }\n            catch (e) {\n                // continue\n            }\n            return this.receiveConversationMessageOverride();\n        }\n        catch (e) {\n            this.terminateMessageLoop = true;\n        }\n        return communicationCustodian.promise;\n    }\n    async startMessageLoop() {\n        if (this.isDisposed()) {\n            return Promise.resolve();\n        }\n        this.terminateMessageLoop = false;\n        const messageRetrievalPromise = this.receiveConversationMessageOverride();\n        try {\n            const r = await messageRetrievalPromise;\n            return r;\n        }\n        catch (error) {\n            this.cancelRecognition(this.privRequestSession ? this.privRequestSession.sessionId : \"\", this.privRequestSession ? this.privRequestSession.requestId : \"\", Exports_js_2.CancellationReason.Error, Exports_js_2.CancellationErrorCode.RuntimeError, error);\n            return null;\n        }\n    }\n    // Takes an established websocket connection to the endpoint\n    configConnection() {\n        if (this.isDisposed()) {\n            return Promise.resolve(undefined);\n        }\n        if (this.privConnectionConfigPromise !== undefined) {\n            return this.privConnectionConfigPromise.then((connection) => {\n                if (connection.state() === Exports_js_1.ConnectionState.Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigPromise = undefined;\n                    return this.configConnection();\n                }\n                return this.privConnectionConfigPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionConfigPromise = undefined;\n                return this.configConnection();\n            });\n        }\n        if (this.terminateMessageLoop) {\n            return Promise.resolve(undefined);\n        }\n        this.privConnectionConfigPromise = this.connectImpl().then((connection) => connection);\n        return this.privConnectionConfigPromise;\n    }\n    getTranslations(serviceResultTranslations) {\n        let translations;\n        if (undefined !== serviceResultTranslations) {\n            translations = new Exports_js_2.Translations();\n            for (const translation of serviceResultTranslations) {\n                translations.set(translation.lang, translation.translation);\n            }\n        }\n        return translations;\n    }\n}\nexports.ConversationServiceAdapter = ConversationServiceAdapter;\n\n//# sourceMappingURL=ConversationServiceAdapter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationServiceAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js":
/*!****************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js ***!
  \****************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranslatorConnectionFactory = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst StringUtils_js_1 = __webpack_require__(/*! ../../common/StringUtils.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ../HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst QueryParameterNames_js_1 = __webpack_require__(/*! ../QueryParameterNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./../ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\n/**\n * Connection factory for the conversation translator. Handles connecting to the regular translator endpoint,\n * as well as the virtual microphone array transcription endpoint\n */\nclass ConversationTranslatorConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    constructor(convGetter) {\n        super();\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(convGetter, \"convGetter\");\n        this.privConvGetter = convGetter;\n    }\n    create(config, authInfo, connectionId) {\n        const isVirtMicArrayEndpoint = config.parameters.getProperty(\"ConversationTranslator_MultiChannelAudio\", \"\").toUpperCase() === \"TRUE\";\n        const convInfo = this.privConvGetter().room;\n        const region = convInfo.cognitiveSpeechRegion || config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, \"\");\n        const replacementValues = {\n            hostSuffix: ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region),\n            path: ConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH,\n            region: encodeURIComponent(region)\n        };\n        replacementValues[QueryParameterNames_js_1.QueryParameterNames.Language] = encodeURIComponent(config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, \"\"));\n        replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId] = encodeURIComponent(convInfo.roomId);\n        replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId] = encodeURIComponent(convInfo.participantId);\n        replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant] = convInfo.isHost ? \"\" : (\"&\" + QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant);\n        let endpointUrl = \"\";\n        const queryParams = {};\n        const headers = {};\n        if (isVirtMicArrayEndpoint) {\n            // connecting to the conversation transcription virtual microphone array endpoint\n            endpointUrl = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint);\n            if (!endpointUrl) {\n                const hostName = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, \"transcribe.{region}.cts.speech{hostSuffix}\");\n                endpointUrl = \"wss://\" + hostName + \"{path}\";\n            }\n            // because the region can change during a session, we support being passed a format string which we can then\n            // replace with the correct information.\n            endpointUrl = StringUtils_js_1.StringUtils.formatString(endpointUrl, replacementValues);\n            const parsedUrl = new URL(endpointUrl);\n            parsedUrl.searchParams.forEach((val, key) => {\n                queryParams[key] = val;\n            });\n            const connFactory = new Exports_js_3.TranscriberConnectionFactory();\n            connFactory.setQueryParams(queryParams, config, endpointUrl);\n            // Some query parameters are required for the CTS endpoint, let's explicity set them here\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId] = replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId];\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId] = replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId];\n            if (!convInfo.isHost) {\n                queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant] = \"\"; // this doesn't have a value so set to an empty string\n            }\n            if (!(QueryParameterNames_js_1.QueryParameterNames.Format in queryParams)) {\n                queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = \"simple\";\n            }\n            parsedUrl.searchParams.forEach((val, key) => {\n                parsedUrl.searchParams.set(key, queryParams[key]);\n                delete queryParams[key];\n            });\n            endpointUrl = parsedUrl.toString();\n        }\n        else {\n            // connecting to regular translation endpoint\n            const connFactory = new Exports_js_3.TranslationConnectionFactory();\n            endpointUrl = connFactory.getEndpointUrl(config, true);\n            endpointUrl = StringUtils_js_1.StringUtils.formatString(endpointUrl, replacementValues);\n            connFactory.setQueryParams(queryParams, config, endpointUrl);\n        }\n        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        headers[Exports_js_1.RestConfigBase.configParams.token] = convInfo.token;\n        if (!!authInfo.token) {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"\").toUpperCase() === \"TRUE\";\n        return new Exports_js_1.WebsocketConnection(endpointUrl, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\nexports.ConversationTranslatorConnectionFactory = ConversationTranslatorConnectionFactory;\nConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH = \"/speech/recognition/dynamicaudio\";\n\n//# sourceMappingURL=ConversationTranslatorConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js ***!
  \********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationReceivedTranslationEventArgs = exports.ParticipantsListEventArgs = exports.ParticipantAttributeEventArgs = exports.ParticipantEventArgs = exports.LockRoomEventArgs = exports.MuteAllEventArgs = void 0;\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass MuteAllEventArgs extends Exports_js_1.SessionEventArgs {\n    constructor(isMuted, sessionId) {\n        super(sessionId);\n        this.privIsMuted = isMuted;\n    }\n    get isMuted() {\n        return this.privIsMuted;\n    }\n}\nexports.MuteAllEventArgs = MuteAllEventArgs;\nclass LockRoomEventArgs extends Exports_js_1.SessionEventArgs {\n    constructor(isLocked, sessionId) {\n        super(sessionId);\n        this.privIsLocked = isLocked;\n    }\n    get isMuted() {\n        return this.privIsLocked;\n    }\n}\nexports.LockRoomEventArgs = LockRoomEventArgs;\nclass ParticipantEventArgs extends Exports_js_1.SessionEventArgs {\n    constructor(participant, sessionId) {\n        super(sessionId);\n        this.privParticipant = participant;\n    }\n    get participant() {\n        return this.privParticipant;\n    }\n}\nexports.ParticipantEventArgs = ParticipantEventArgs;\nclass ParticipantAttributeEventArgs extends Exports_js_1.SessionEventArgs {\n    constructor(participantId, key, value, sessionId) {\n        super(sessionId);\n        this.privKey = key;\n        this.privValue = value;\n        this.privParticipantId = participantId;\n    }\n    get value() {\n        return this.privValue;\n    }\n    get key() {\n        return this.privKey;\n    }\n    get id() {\n        return this.privParticipantId;\n    }\n}\nexports.ParticipantAttributeEventArgs = ParticipantAttributeEventArgs;\nclass ParticipantsListEventArgs extends Exports_js_1.SessionEventArgs {\n    constructor(conversationId, token, translateTo, profanityFilter, roomProfanityFilter, isRoomLocked, isMuteAll, participants, sessionId) {\n        super(sessionId);\n        this.privRoomId = conversationId;\n        this.privSessionToken = token;\n        this.privTranslateTo = translateTo;\n        this.privProfanityFilter = profanityFilter;\n        this.privRoomProfanityFilter = roomProfanityFilter;\n        this.privIsRoomLocked = isRoomLocked;\n        this.privIsRoomLocked = isMuteAll;\n        this.privParticipants = participants;\n    }\n    get sessionToken() {\n        return this.privSessionToken;\n    }\n    get conversationId() {\n        return this.privRoomId;\n    }\n    get translateTo() {\n        return this.privTranslateTo;\n    }\n    get profanityFilter() {\n        return this.privProfanityFilter;\n    }\n    get roomProfanityFilter() {\n        return this.privRoomProfanityFilter;\n    }\n    get isRoomLocked() {\n        return this.privIsRoomLocked;\n    }\n    get isMuteAll() {\n        return this.privIsMuteAll;\n    }\n    get participants() {\n        return this.privParticipants;\n    }\n}\nexports.ParticipantsListEventArgs = ParticipantsListEventArgs;\nclass ConversationReceivedTranslationEventArgs {\n    constructor(command, payload, sessionId) {\n        this.privPayload = payload;\n        this.privCommand = command;\n        this.privSessionId = sessionId;\n    }\n    get payload() {\n        return this.privPayload;\n    }\n    get command() {\n        return this.privCommand;\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\nexports.ConversationReceivedTranslationEventArgs = ConversationReceivedTranslationEventArgs;\n\n//# sourceMappingURL=ConversationTranslatorEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js ***!
  \*********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranslatorCommandTypes = exports.ConversationTranslatorMessageTypes = exports.InternalParticipants = void 0;\n/** Users participating in the conversation */\nclass InternalParticipants {\n    constructor(participants = [], meId) {\n        this.participants = participants;\n        this.meId = meId;\n    }\n    /**\n     * Add or update a participant\n     * @param value\n     */\n    addOrUpdateParticipant(value) {\n        if (value === undefined) {\n            return;\n        }\n        const exists = this.getParticipantIndex(value.id);\n        if (exists > -1) {\n            this.participants.splice(exists, 1, value);\n        }\n        else {\n            this.participants.push(value);\n        }\n        // ensure it was added ok\n        return this.getParticipant(value.id);\n    }\n    /**\n     * Find the participant's position in the participants list.\n     * @param id\n     */\n    getParticipantIndex(id) {\n        return this.participants.findIndex((p) => p.id === id);\n    }\n    /**\n     * Find the participant by id.\n     * @param id\n     */\n    getParticipant(id) {\n        return this.participants.find((p) => p.id === id);\n    }\n    /**\n     * Remove a participant from the participants list.\n     */\n    deleteParticipant(id) {\n        this.participants = this.participants.filter((p) => p.id !== id);\n    }\n    /**\n     * Helper to return the conversation host.\n     */\n    get host() {\n        return this.participants.find((p) => p.isHost === true);\n    }\n    /**\n     * Helper to return the current user.\n     */\n    get me() {\n        return this.getParticipant(this.meId);\n    }\n}\nexports.InternalParticipants = InternalParticipants;\n/**\n * List of command message types\n */\nexports.ConversationTranslatorMessageTypes = {\n    command: \"command\",\n    final: \"final\",\n    info: \"info\",\n    instantMessage: \"instant_message\",\n    keepAlive: \"keep_alive\",\n    partial: \"partial\",\n    participantCommand: \"participant_command\",\n    translatedMessage: \"translated_message\"\n};\n/**\n * List of command types\n */\nexports.ConversationTranslatorCommandTypes = {\n    changeNickname: \"ChangeNickname\",\n    disconnectSession: \"DisconnectSession\",\n    ejectParticipant: \"EjectParticipant\",\n    instant_message: \"instant_message\",\n    joinSession: \"JoinSession\",\n    leaveSession: \"LeaveSession\",\n    participantList: \"ParticipantList\",\n    roomExpirationWarning: \"RoomExpirationWarning\",\n    setLockState: \"SetLockState\",\n    setMute: \"SetMute\",\n    setMuteAll: \"SetMuteAll\",\n    setProfanityFiltering: \"SetProfanityFiltering\",\n    setTranslateToLanguages: \"SetTranslateToLanguages\",\n    setUseTTS: \"SetUseTTS\"\n};\n\n//# sourceMappingURL=ConversationTranslatorInterfaces.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorRecognizer.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorRecognizer.js ***!
  \*********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranslatorRecognizer = exports.ConversationRecognizerFactory = void 0;\n// eslint-disable-next-line max-classes-per-file\nconst Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConversationConnectionFactory_js_1 = __webpack_require__(/*! ./ConversationConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionFactory.js\");\nconst ConversationServiceAdapter_js_1 = __webpack_require__(/*! ./ConversationServiceAdapter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationServiceAdapter.js\");\nclass ConversationRecognizerFactory {\n    static fromConfig(conversation, speechConfig, audioConfig) {\n        return new ConversationTranslatorRecognizer(conversation, speechConfig, audioConfig);\n    }\n}\nexports.ConversationRecognizerFactory = ConversationRecognizerFactory;\n/**\n * Sends messages to the Conversation Translator websocket and listens for incoming events containing websocket messages.\n * Based off the recognizers in the SDK folder.\n */\nclass ConversationTranslatorRecognizer extends Exports_js_3.Recognizer {\n    constructor(conversation, speechConfig, audioConfig) {\n        const serviceConfigImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNull(serviceConfigImpl, \"speechConfig\");\n        const conversationImpl = conversation;\n        Contracts_js_1.Contracts.throwIfNull(conversationImpl, \"conversationImpl\");\n        super(audioConfig, serviceConfigImpl.properties, new ConversationConnectionFactory_js_1.ConversationConnectionFactory());\n        this.privConversation = conversationImpl;\n        this.privIsDisposed = false;\n        this.privProperties = serviceConfigImpl.properties.clone();\n        this.privConnection = Exports_js_3.Connection.fromRecognizer(this);\n        const webWorkerLoadType = this.privProperties.getProperty(Exports_js_3.PropertyId.WebWorkerLoadType, \"on\").toLowerCase();\n        if (webWorkerLoadType === \"on\" && typeof (Blob) !== \"undefined\" && typeof (Worker) !== \"undefined\") {\n            this.privSetTimeout = Exports_js_2.Timeout.setTimeout;\n            this.privClearTimeout = Exports_js_2.Timeout.clearTimeout;\n        }\n        else {\n            if (typeof window !== \"undefined\") {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                this.privSetTimeout = window.setTimeout.bind(window);\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                this.privClearTimeout = window.clearTimeout.bind(window);\n            }\n            else {\n                this.privSetTimeout = setTimeout;\n                this.privClearTimeout = clearTimeout;\n            }\n        }\n    }\n    set connected(cb) {\n        this.privConnection.connected = cb;\n    }\n    set disconnected(cb) {\n        this.privConnection.disconnected = cb;\n    }\n    /**\n     * Return the speech language used by the recognizer\n     */\n    get speechRecognitionLanguage() {\n        return this.privSpeechRecognitionLanguage;\n    }\n    /**\n     * Return the properties for the recognizer\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    /**\n     * Connect to the recognizer\n     * @param token\n     */\n    connect(token, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n            this.privReco.conversationTranslatorToken = token;\n            this.resetConversationTimeout();\n            this.privReco.connectAsync(cb, err);\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n        }\n    }\n    /**\n     * Disconnect from the recognizer\n     */\n    disconnect(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            if (this.privTimeoutToken !== undefined) {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                this.privClearTimeout(this.privTimeoutToken);\n            }\n            this.privReco.disconnect().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n            // Destroy the recognizer.\n            this.dispose(true).catch((reason) => {\n                Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(reason));\n            });\n        }\n    }\n    /**\n     * Send the mute all participants command to the websocket\n     * @param conversationId\n     * @param participantId\n     * @param isMuted\n     */\n    sendRequest(command, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            this.sendMessage(command, cb, err);\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n            // Destroy the recognizer.\n            this.dispose(true).catch((reason) => {\n                Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(reason));\n            });\n        }\n    }\n    /**\n     * Handle update of service auth token (#694)\n     */\n    onToken(token) {\n        this.privConversation.onToken(token);\n    }\n    /**\n     * Close and dispose the recognizer\n     */\n    async close() {\n        if (!this.privIsDisposed) {\n            if (!!this.privConnection) {\n                this.privConnection.closeConnection();\n                this.privConnection.close();\n            }\n            this.privConnection = undefined;\n            await this.dispose(true);\n        }\n    }\n    /**\n     * Dispose the recognizer\n     * @param disposing\n     */\n    async dispose(disposing) {\n        if (this.privIsDisposed) {\n            return;\n        }\n        if (disposing) {\n            if (this.privTimeoutToken !== undefined) {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                this.privClearTimeout(this.privTimeoutToken);\n            }\n            this.privIsDisposed = true;\n            if (!!this.privConnection) {\n                this.privConnection.closeConnection();\n                this.privConnection.close();\n                this.privConnection = undefined;\n            }\n            await super.dispose(disposing);\n        }\n    }\n    /**\n     * Create the config for the recognizer\n     * @param speechConfig\n     */\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);\n    }\n    /**\n     * Create the service recognizer.\n     * The audio source is redundnant here but is required by the implementation.\n     * @param authentication\n     * @param connectionFactory\n     * @param audioConfig\n     * @param recognizerConfig\n     */\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioSource = audioConfig;\n        return new ConversationServiceAdapter_js_1.ConversationServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);\n    }\n    sendMessage(msg, cb, err) {\n        const withAsync = this.privReco;\n        const PromiseToEmptyCallback = (promise, cb, err) => {\n            if (promise !== undefined) {\n                promise.then(() => {\n                    try {\n                        if (!!cb) {\n                            cb();\n                        }\n                    }\n                    catch (e) {\n                        if (!!err) {\n                            err(`'Unhandled error on promise callback: ${e}'`);\n                        }\n                    }\n                }, (reason) => {\n                    try {\n                        if (!!err) {\n                            err(reason);\n                        }\n                        // eslint-disable-next-line no-empty\n                    }\n                    catch (error) { }\n                });\n            }\n            else {\n                if (!!err) {\n                    err(\"Null promise\");\n                }\n            }\n        };\n        PromiseToEmptyCallback(withAsync.sendMessageAsync(msg), cb, err);\n        this.resetConversationTimeout();\n    }\n    resetConversationTimeout() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            this.privClearTimeout(this.privTimeoutToken);\n        }\n        this.privTimeoutToken = this.privSetTimeout(() => {\n            this.sendRequest(this.privConversation.getKeepAlive());\n        }, 60000);\n    }\n}\nexports.ConversationTranslatorRecognizer = ConversationTranslatorRecognizer;\n\n//# sourceMappingURL=ConversationTranslatorRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js":
/*!**************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js ***!
  \**************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationWebsocketMessageFormatter = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst ConversationConnectionMessage_js_1 = __webpack_require__(/*! ./ConversationConnectionMessage.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js\");\n/**\n * Based off WebsocketMessageFormatter. The messages for Conversation Translator have some variations from the Speech messages.\n */\nclass ConversationWebsocketMessageFormatter {\n    /**\n     * Format incoming messages: text (speech partial/final, IM) or binary (tts)\n     */\n    toConnectionMessage(message) {\n        const deferral = new Exports_js_1.Deferred();\n        try {\n            if (message.messageType === Exports_js_1.MessageType.Text) {\n                const incomingMessage = new ConversationConnectionMessage_js_1.ConversationConnectionMessage(message.messageType, message.textContent, {}, message.id);\n                deferral.resolve(incomingMessage);\n            }\n            else if (message.messageType === Exports_js_1.MessageType.Binary) {\n                deferral.resolve(new ConversationConnectionMessage_js_1.ConversationConnectionMessage(message.messageType, message.binaryContent, undefined, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. Error: ${e}`);\n        }\n        return deferral.promise;\n    }\n    /**\n     * Format outgoing messages: text (commands or IM)\n     */\n    fromConnectionMessage(message) {\n        const deferral = new Exports_js_1.Deferred();\n        try {\n            if (message.messageType === Exports_js_1.MessageType.Text) {\n                const payload = `${message.textBody ? message.textBody : \"\"}`;\n                deferral.resolve(new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Text, payload, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. ${e}`);\n        }\n        return deferral.promise;\n    }\n}\nexports.ConversationWebsocketMessageFormatter = ConversationWebsocketMessageFormatter;\n\n//# sourceMappingURL=ConversationWebsocketMessageFormatter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/Exports.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/Exports.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nvar ConversationManager_js_1 = __webpack_require__(/*! ./ConversationManager.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationManager.js\");\nObject.defineProperty(exports, \"ConversationManager\", ({ enumerable: true, get: function () { return ConversationManager_js_1.ConversationManager; } }));\nvar ConversationConnectionConfig_js_1 = __webpack_require__(/*! ./ConversationConnectionConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js\");\nObject.defineProperty(exports, \"ConversationConnectionConfig\", ({ enumerable: true, get: function () { return ConversationConnectionConfig_js_1.ConversationConnectionConfig; } }));\nvar ConversationTranslatorRecognizer_js_1 = __webpack_require__(/*! ./ConversationTranslatorRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorRecognizer.js\");\nObject.defineProperty(exports, \"ConversationRecognizerFactory\", ({ enumerable: true, get: function () { return ConversationTranslatorRecognizer_js_1.ConversationRecognizerFactory; } }));\nvar TranscriberRecognizer_js_1 = __webpack_require__(/*! ./TranscriberRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/TranscriberRecognizer.js\");\nObject.defineProperty(exports, \"TranscriberRecognizer\", ({ enumerable: true, get: function () { return TranscriberRecognizer_js_1.TranscriberRecognizer; } }));\nvar ConversationTranslatorEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranslatorEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js\");\nObject.defineProperty(exports, \"ConversationReceivedTranslationEventArgs\", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.ConversationReceivedTranslationEventArgs; } }));\nObject.defineProperty(exports, \"LockRoomEventArgs\", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.LockRoomEventArgs; } }));\nObject.defineProperty(exports, \"MuteAllEventArgs\", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.MuteAllEventArgs; } }));\nObject.defineProperty(exports, \"ParticipantAttributeEventArgs\", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs; } }));\nObject.defineProperty(exports, \"ParticipantEventArgs\", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.ParticipantEventArgs; } }));\nObject.defineProperty(exports, \"ParticipantsListEventArgs\", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.ParticipantsListEventArgs; } }));\nvar ConversationTranslatorInterfaces_js_1 = __webpack_require__(/*! ./ConversationTranslatorInterfaces.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\nObject.defineProperty(exports, \"ConversationTranslatorCommandTypes\", ({ enumerable: true, get: function () { return ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes; } }));\nObject.defineProperty(exports, \"ConversationTranslatorMessageTypes\", ({ enumerable: true, get: function () { return ConversationTranslatorInterfaces_js_1.ConversationTranslatorMessageTypes; } }));\nObject.defineProperty(exports, \"InternalParticipants\", ({ enumerable: true, get: function () { return ConversationTranslatorInterfaces_js_1.InternalParticipants; } }));\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js":
/*!***************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js ***!
  \***************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CommandResponsePayload = void 0;\nconst parseCommandResponse = (json) => JSON.parse(json);\nclass CommandResponsePayload {\n    constructor(json) {\n        this.privCommandResponse = parseCommandResponse(json);\n    }\n    get type() {\n        return this.privCommandResponse.type;\n    }\n    get command() {\n        return this.privCommandResponse.command;\n    }\n    get id() {\n        return this.privCommandResponse.id;\n    }\n    get nickname() {\n        return this.privCommandResponse.nickname;\n    }\n    get participantId() {\n        return this.privCommandResponse.participantId;\n    }\n    get roomid() {\n        return this.privCommandResponse.roomid;\n    }\n    get value() {\n        return this.privCommandResponse.value;\n    }\n    get token() {\n        return this.privCommandResponse.token;\n    }\n    static fromJSON(json) {\n        return new CommandResponsePayload(json);\n    }\n}\nexports.CommandResponsePayload = CommandResponsePayload;\n\n//# sourceMappingURL=CommandResponsePayload.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/Exports.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/Exports.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nvar CommandResponsePayload_js_1 = __webpack_require__(/*! ./CommandResponsePayload.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js\");\nObject.defineProperty(exports, \"CommandResponsePayload\", ({ enumerable: true, get: function () { return CommandResponsePayload_js_1.CommandResponsePayload; } }));\nvar ParticipantResponsePayload_js_1 = __webpack_require__(/*! ./ParticipantResponsePayload.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js\");\nObject.defineProperty(exports, \"ParticipantsListPayloadResponse\", ({ enumerable: true, get: function () { return ParticipantResponsePayload_js_1.ParticipantsListPayloadResponse; } }));\nObject.defineProperty(exports, \"ParticipantPayloadResponse\", ({ enumerable: true, get: function () { return ParticipantResponsePayload_js_1.ParticipantPayloadResponse; } }));\nvar TranslationResponsePayload_js_1 = __webpack_require__(/*! ./TranslationResponsePayload.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js\");\nObject.defineProperty(exports, \"SpeechResponsePayload\", ({ enumerable: true, get: function () { return TranslationResponsePayload_js_1.SpeechResponsePayload; } }));\nObject.defineProperty(exports, \"TextResponsePayload\", ({ enumerable: true, get: function () { return TranslationResponsePayload_js_1.TextResponsePayload; } }));\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js":
/*!*******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js ***!
  \*******************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ParticipantPayloadResponse = exports.ParticipantsListPayloadResponse = void 0;\nconst parseListResponse = (json) => JSON.parse(json);\nconst parseParticipantResponse = (json) => JSON.parse(json);\nclass ParticipantsListPayloadResponse {\n    constructor(json) {\n        this.privParticipantsPayloadResponse = parseListResponse(json);\n    }\n    get roomid() {\n        return this.privParticipantsPayloadResponse.roomid;\n    }\n    get id() {\n        return this.privParticipantsPayloadResponse.id;\n    }\n    get command() {\n        return this.privParticipantsPayloadResponse.command;\n    }\n    get participants() {\n        return this.privParticipantsPayloadResponse.participants;\n    }\n    get token() {\n        return this.privParticipantsPayloadResponse.token;\n    }\n    get translateTo() {\n        return this.privParticipantsPayloadResponse.translateTo;\n    }\n    get profanityFilter() {\n        return this.privParticipantsPayloadResponse.profanityFilter;\n    }\n    get roomProfanityFilter() {\n        return this.privParticipantsPayloadResponse.roomProfanityFilter;\n    }\n    get roomLocked() {\n        return this.privParticipantsPayloadResponse.roomLocked;\n    }\n    get muteAll() {\n        return this.privParticipantsPayloadResponse.muteAll;\n    }\n    get type() {\n        return this.privParticipantsPayloadResponse.type;\n    }\n    static fromJSON(json) {\n        return new ParticipantsListPayloadResponse(json);\n    }\n}\nexports.ParticipantsListPayloadResponse = ParticipantsListPayloadResponse;\nclass ParticipantPayloadResponse {\n    constructor(json) {\n        this.privParticipantPayloadResponse = parseParticipantResponse(json);\n    }\n    get nickname() {\n        return this.privParticipantPayloadResponse.nickname;\n    }\n    get locale() {\n        return this.privParticipantPayloadResponse.locale;\n    }\n    get usetts() {\n        return this.privParticipantPayloadResponse.usetts;\n    }\n    get ismuted() {\n        return this.privParticipantPayloadResponse.ismuted;\n    }\n    get ishost() {\n        return this.privParticipantPayloadResponse.ishost;\n    }\n    get participantId() {\n        return this.privParticipantPayloadResponse.participantId;\n    }\n    get avatar() {\n        return this.privParticipantPayloadResponse.avatar;\n    }\n    static fromJSON(json) {\n        return new ParticipantPayloadResponse(json);\n    }\n}\nexports.ParticipantPayloadResponse = ParticipantPayloadResponse;\n\n//# sourceMappingURL=ParticipantResponsePayload.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js":
/*!*******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js ***!
  \*******************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TextResponsePayload = exports.SpeechResponsePayload = void 0;\nconst parseSpeechResponse = (json) => JSON.parse(json);\nconst parseTextResponse = (json) => JSON.parse(json);\nclass SpeechResponsePayload {\n    constructor(json) {\n        this.privSpeechResponse = parseSpeechResponse(json);\n    }\n    get recognition() {\n        return this.privSpeechResponse.recognition;\n    }\n    get translations() {\n        return this.privSpeechResponse.translations;\n    }\n    get id() {\n        return this.privSpeechResponse.id;\n    }\n    get language() {\n        return this.privSpeechResponse.language;\n    }\n    get nickname() {\n        return this.privSpeechResponse.nickname;\n    }\n    get participantId() {\n        return this.privSpeechResponse.participantId;\n    }\n    get roomid() {\n        return this.privSpeechResponse.roomid;\n    }\n    get timestamp() {\n        return this.privSpeechResponse.timestamp;\n    }\n    get type() {\n        return this.privSpeechResponse.type;\n    }\n    get isFinal() {\n        return this.privSpeechResponse.type === \"final\";\n    }\n    static fromJSON(json) {\n        return new SpeechResponsePayload(json);\n    }\n}\nexports.SpeechResponsePayload = SpeechResponsePayload;\nclass TextResponsePayload {\n    constructor(json) {\n        this.privTextResponse = parseTextResponse(json);\n    }\n    get originalText() {\n        return this.privTextResponse.originalText;\n    }\n    get translations() {\n        return this.privTextResponse.translations;\n    }\n    get id() {\n        return this.privTextResponse.id;\n    }\n    get language() {\n        return this.privTextResponse.language;\n    }\n    get nickname() {\n        return this.privTextResponse.nickname;\n    }\n    get participantId() {\n        return this.privTextResponse.participantId;\n    }\n    get roomid() {\n        return this.privTextResponse.roomid;\n    }\n    get timestamp() {\n        return this.privTextResponse.timestamp;\n    }\n    get type() {\n        return this.privTextResponse.type;\n    }\n    static fromJSON(json) {\n        return new TextResponsePayload(json);\n    }\n}\nexports.TextResponsePayload = TextResponsePayload;\n\n//# sourceMappingURL=TranslationResponsePayload.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/TranscriberRecognizer.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/TranscriberRecognizer.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranscriberRecognizer = void 0;\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nclass TranscriberRecognizer extends Exports_js_2.Recognizer {\n    /**\n     * TranscriberRecognizer constructor.\n     * @constructor\n     * @param {SpeechTranslationConfig} speechTranslationConfig - Non-audio configuration associated with the recognizer\n     * @param {AudioConfig} audioConfig - An audio configuration associated with the recognizer\n     */\n    constructor(speechTranslationConfig, audioConfig) {\n        const speechTranslationConfigImpl = speechTranslationConfig;\n        Contracts_js_1.Contracts.throwIfNull(speechTranslationConfigImpl, \"speechTranslationConfig\");\n        const audioConfigImpl = audioConfig;\n        Contracts_js_1.Contracts.throwIfNull(audioConfigImpl, \"audioConfigImpl\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(speechTranslationConfigImpl.speechRecognitionLanguage, Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        super(audioConfig, speechTranslationConfigImpl.properties, new Exports_js_3.TranscriberConnectionFactory());\n        this.privDisposedRecognizer = false;\n        this.isMeetingRecognizer = false;\n    }\n    get speechRecognitionLanguage() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    set authorizationToken(token) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    set conversation(c) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(c, \"Conversation\");\n        this.isMeetingRecognizer = false;\n        this.privConversation = c;\n    }\n    getConversationInfo() {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation, \"Conversation\");\n        return this.privConversation.conversationInfo;\n    }\n    set meeting(m) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(m, \"Meeting\");\n        this.isMeetingRecognizer = true;\n        this.privMeeting = m;\n    }\n    getMeetingInfo() {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privMeeting, \"Meeting\");\n        return this.privMeeting.meetingInfo;\n    }\n    IsMeetingRecognizer() {\n        return this.isMeetingRecognizer;\n    }\n    startContinuousRecognitionAsync(cb, err) {\n        Exports_js_1.marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(Exports_js_3.RecognitionMode.Conversation), cb, err);\n    }\n    stopContinuousRecognitionAsync(cb, err) {\n        Exports_js_1.marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    async close() {\n        if (!this.privDisposedRecognizer) {\n            await this.dispose(true);\n        }\n    }\n    // Push async join/leave conversation message via serviceRecognizer\n    async pushConversationEvent(conversationInfo, command) {\n        const reco = (this.privReco);\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(reco, \"serviceRecognizer\");\n        await reco.sendSpeechEventAsync(conversationInfo, command);\n    }\n    // Push async join/leave meeting message via serviceRecognizer\n    async pushMeetingEvent(meetingInfo, command) {\n        const reco = (this.privReco);\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(reco, \"serviceRecognizer\");\n        await reco.sendMeetingSpeechEventAsync(meetingInfo, command);\n    }\n    async enforceAudioGating() {\n        const audioConfigImpl = this.audioConfig;\n        const format = await audioConfigImpl.format;\n        const channels = format.channels;\n        if (channels === 1) {\n            if (this.properties.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() !== \"true\") {\n                throw new Error(\"Single channel audio configuration for MeetingTranscriber is currently under private preview, please contact diarizationrequest@microsoft.com for more details\");\n            }\n        }\n        else if (channels !== 8) {\n            throw new Error(`Unsupported audio configuration: Detected ${channels}-channel audio`);\n        }\n        return;\n    }\n    connectMeetingCallbacks(transcriber) {\n        this.isMeetingRecognizer = true;\n        this.canceled = (s, e) => {\n            if (!!transcriber.canceled) {\n                transcriber.canceled(transcriber, e);\n            }\n        };\n        this.recognizing = (s, e) => {\n            if (!!transcriber.transcribing) {\n                transcriber.transcribing(transcriber, e);\n            }\n        };\n        this.recognized = (s, e) => {\n            if (!!transcriber.transcribed) {\n                transcriber.transcribed(transcriber, e);\n            }\n        };\n        this.sessionStarted = (s, e) => {\n            if (!!transcriber.sessionStarted) {\n                transcriber.sessionStarted(transcriber, e);\n            }\n        };\n        this.sessionStopped = (s, e) => {\n            if (!!transcriber.sessionStopped) {\n                transcriber.sessionStopped(transcriber, e);\n            }\n        };\n    }\n    disconnectCallbacks() {\n        this.canceled = undefined;\n        this.recognizing = undefined;\n        this.recognized = undefined;\n        this.sessionStarted = undefined;\n        this.sessionStopped = undefined;\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member ConversationTranscriber.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    async dispose(disposing) {\n        if (this.privDisposedRecognizer) {\n            return;\n        }\n        if (disposing) {\n            this.privDisposedRecognizer = true;\n            await this.implRecognizerStop();\n        }\n        await super.dispose(disposing);\n    }\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_3.RecognizerConfig(speechConfig, this.properties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        return new Exports_js_3.TranscriptionServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n}\nexports.TranscriberRecognizer = TranscriberRecognizer;\n\n//# sourceMappingURL=TranscriberRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/TranscriberRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriptionServiceRecognizer.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriptionServiceRecognizer.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranscriptionServiceRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// eslint-disable-next-line max-classes-per-file\nclass TranscriptionServiceRecognizer extends Exports_js_3.ConversationServiceRecognizer {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, transcriber) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, transcriber);\n        this.privTranscriberRecognizer = transcriber;\n        this.sendPrePayloadJSONOverride = (connection) => this.sendTranscriptionStartJSON(connection);\n        if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps) === \"true\") {\n            this.privSpeechContext.setWordLevelTimings();\n        }\n    }\n    async sendSpeechEventAsync(info, command) {\n        if (!!this.privRequestSession.isRecognizing) {\n            const connection = await this.fetchConnection();\n            await this.sendSpeechEvent(connection, this.createSpeechEventPayload(info, command));\n        }\n    }\n    async sendMeetingSpeechEventAsync(info, command) {\n        if (!!this.privRequestSession.isRecognizing) {\n            const connection = await this.fetchConnection();\n            await this.sendSpeechEvent(connection, this.createMeetingSpeechEventPayload(info, command));\n        }\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        return this.processSpeechMessages(connectionMessage);\n    }\n    handleRecognizedCallback(result, offset, sessionId) {\n        try {\n            const event = new Exports_js_2.SpeechRecognitionEventArgs(result, offset, sessionId);\n            this.privTranscriberRecognizer.recognized(this.privTranscriberRecognizer, event);\n            if (!!this.privSuccessCallback) {\n                try {\n                    this.privSuccessCallback(result);\n                }\n                catch (e) {\n                    if (!!this.privErrorCallback) {\n                        this.privErrorCallback(e);\n                    }\n                }\n                // Only invoke the call back once.\n                // and if it's successful don't invoke the\n                // error after that.\n                this.privSuccessCallback = undefined;\n                this.privErrorCallback = undefined;\n            }\n            /* eslint-disable no-empty */\n        }\n        catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n        }\n    }\n    handleRecognizingCallback(result, duration, sessionId) {\n        try {\n            const ev = new Exports_js_2.SpeechRecognitionEventArgs(result, duration, sessionId);\n            this.privTranscriberRecognizer.recognizing(this.privTranscriberRecognizer, ev);\n            /* eslint-disable no-empty */\n        }\n        catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n        }\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new Exports_js_2.PropertyCollection();\n        properties.setProperty(Exports_js_3.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[errorCode]);\n        if (this.privTranscriberRecognizer.IsMeetingRecognizer()) {\n            if (!!this.privTranscriberRecognizer.canceled) {\n                const cancelEvent = new Exports_js_2.MeetingTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n                try {\n                    this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);\n                    /* eslint-disable no-empty */\n                }\n                catch { }\n            }\n        }\n        else {\n            if (!!this.privTranscriberRecognizer.canceled) {\n                const cancelEvent = new Exports_js_2.ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n                try {\n                    this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);\n                    /* eslint-disable no-empty */\n                }\n                catch { }\n            }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new Exports_js_2.SpeechRecognitionResult(requestId, Exports_js_2.ResultReason.Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // Language Detection Confidence\n            undefined, // Speaker Id\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n    }\n    // Encapsulated for derived service recognizers that need to send additional JSON\n    async sendTranscriptionStartJSON(connection) {\n        await this.sendSpeechContext(connection, true);\n        if (this.privTranscriberRecognizer.IsMeetingRecognizer()) {\n            const info = this.privTranscriberRecognizer.getMeetingInfo();\n            const payload = this.createMeetingSpeechEventPayload(info, \"start\");\n            await this.sendSpeechEvent(connection, payload);\n        }\n        else {\n            const info = this.privTranscriberRecognizer.getConversationInfo();\n            const payload = this.createSpeechEventPayload(info, \"start\");\n            await this.sendSpeechEvent(connection, payload);\n        }\n        await this.sendWaveHeader(connection);\n        return;\n    }\n    sendSpeechEvent(connection, payload) {\n        const speechEventJson = JSON.stringify(payload);\n        if (speechEventJson) {\n            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, \"speech.event\", this.privRequestSession.requestId, \"application/json\", speechEventJson));\n        }\n        return;\n    }\n    createSpeechEventPayload(info, command) {\n        const eventDict = { id: \"meeting\", name: command, meeting: info.conversationProperties };\n        eventDict.meeting.id = info.id;\n        eventDict.meeting.attendees = info.participants;\n        return eventDict;\n    }\n    createMeetingSpeechEventPayload(info, command) {\n        const eventDict = { id: \"meeting\", name: command, meeting: info.meetingProperties };\n        eventDict.meeting.id = info.id;\n        eventDict.meeting.attendees = info.participants;\n        return eventDict;\n    }\n}\nexports.TranscriptionServiceRecognizer = TranscriptionServiceRecognizer;\n\n//# sourceMappingURL=TranscriptionServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriptionServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationConnectionFactory.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationConnectionFactory.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationConnectionFactory = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst StringUtils_js_1 = __webpack_require__(/*! ../common/StringUtils.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js\");\nclass TranslationConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {\n    create(config, authInfo, connectionId) {\n        const endpoint = this.getEndpointUrl(config);\n        const queryParams = {};\n        if (config.autoDetectSourceLanguages !== undefined) {\n            queryParams[QueryParameterNames_js_1.QueryParameterNames.EnableLanguageId] = \"true\";\n        }\n        this.setQueryParams(queryParams, config, endpoint);\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;\n        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n    getEndpointUrl(config, returnRegionPlaceholder) {\n        const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);\n        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);\n        let endpointUrl = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n        if (!endpointUrl) {\n            if (config.autoDetectSourceLanguages !== undefined) {\n                const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, \"wss://{region}.stt.speech\" + hostSuffix);\n                endpointUrl = host + \"/speech/universal/v2\";\n            }\n            else {\n                const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, \"wss://{region}.s2s.speech\" + hostSuffix);\n                endpointUrl = host + \"/speech/translation/cognitiveservices/v1\";\n            }\n        }\n        if (returnRegionPlaceholder === true) {\n            return endpointUrl;\n        }\n        return StringUtils_js_1.StringUtils.formatString(endpointUrl, { region });\n    }\n    setQueryParams(queryParams, config, endpointUrl) {\n        queryParams.from = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage);\n        queryParams.to = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationToLanguages);\n        queryParams.scenario = config.recognitionMode === Exports_js_3.RecognitionMode.Interactive ? \"interactive\" :\n            config.recognitionMode === Exports_js_3.RecognitionMode.Conversation ? \"conversation\" : \"\";\n        this.setCommonUrlParams(config, queryParams, endpointUrl);\n        this.setUrlParameter(Exports_js_2.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult, QueryParameterNames_js_1.QueryParameterNames.StableTranslation, config, queryParams, endpointUrl);\n        const translationVoice = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);\n        if (translationVoice !== undefined) {\n            queryParams.voice = translationVoice;\n            queryParams.features = \"texttospeech\";\n        }\n    }\n}\nexports.TranslationConnectionFactory = TranslationConnectionFactory;\n\n//# sourceMappingURL=TranslationConnectionFactory.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationServiceRecognizer.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationServiceRecognizer.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationServiceRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\n// eslint-disable-next-line max-classes-per-file\nclass TranslationServiceRecognizer extends Exports_js_3.ConversationServiceRecognizer {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer);\n        this.privTranslationRecognizer = translationRecognizer;\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionEstablishedEvent\") {\n                this.privTranslationRecognizer.onConnection();\n            }\n        });\n    }\n    async processTypeSpecificMessages(connectionMessage) {\n        const resultProps = new Exports_js_2.PropertyCollection();\n        let processed = await this.processSpeechMessages(connectionMessage);\n        if (processed) {\n            return true;\n        }\n        const handleTranslationPhrase = async (translatedPhrase) => {\n            resultProps.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_JsonResult, translatedPhrase.asJson());\n            this.privRequestSession.onPhraseRecognized(translatedPhrase.Offset + translatedPhrase.Duration);\n            if (translatedPhrase.RecognitionStatus === Exports_js_3.RecognitionStatus.Success) {\n                // OK, the recognition was successful. How'd the translation do?\n                const result = this.fireEventForResult(translatedPhrase, resultProps);\n                if (!!this.privTranslationRecognizer.recognized) {\n                    try {\n                        this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, result);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                // report result to promise.\n                if (!!this.privSuccessCallback) {\n                    try {\n                        this.privSuccessCallback(result.result);\n                    }\n                    catch (e) {\n                        if (!!this.privErrorCallback) {\n                            this.privErrorCallback(e);\n                        }\n                    }\n                    // Only invoke the call back once.\n                    // and if it's successful don't invoke the\n                    // error after that.\n                    this.privSuccessCallback = undefined;\n                    this.privErrorCallback = undefined;\n                }\n            }\n            else {\n                const reason = Exports_js_3.EnumTranslation.implTranslateRecognitionResult(translatedPhrase.RecognitionStatus);\n                const result = new Exports_js_2.TranslationRecognitionResult(undefined, this.privRequestSession.requestId, reason, translatedPhrase.Text, translatedPhrase.Duration, translatedPhrase.Offset, translatedPhrase.Language, translatedPhrase.Confidence, undefined, translatedPhrase.asJson(), resultProps);\n                if (reason === Exports_js_2.ResultReason.Canceled) {\n                    const cancelReason = Exports_js_3.EnumTranslation.implTranslateCancelResult(translatedPhrase.RecognitionStatus);\n                    const cancellationErrorCode = Exports_js_3.EnumTranslation.implTranslateCancelErrorCode(translatedPhrase.RecognitionStatus);\n                    await this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_3.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n                }\n                else {\n                    if (translatedPhrase.RecognitionStatus !== Exports_js_3.RecognitionStatus.EndOfDictation) {\n                        const ev = new Exports_js_2.TranslationRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n                        if (!!this.privTranslationRecognizer.recognized) {\n                            try {\n                                this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);\n                                /* eslint-disable no-empty */\n                            }\n                            catch (error) {\n                                // Not going to let errors in the event handler\n                                // trip things up.\n                            }\n                        }\n                        // report result to promise.\n                        if (!!this.privSuccessCallback) {\n                            try {\n                                this.privSuccessCallback(result);\n                            }\n                            catch (e) {\n                                if (!!this.privErrorCallback) {\n                                    this.privErrorCallback(e);\n                                }\n                            }\n                            // Only invoke the call back once.\n                            // and if it's successful don't invoke the\n                            // error after that.\n                            this.privSuccessCallback = undefined;\n                            this.privErrorCallback = undefined;\n                        }\n                    }\n                }\n                processed = true;\n            }\n        };\n        const handleTranslationHypothesis = (hypothesis) => {\n            resultProps.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_JsonResult, hypothesis.asJson());\n            const result = this.fireEventForResult(hypothesis, resultProps);\n            this.privRequestSession.onHypothesis(result.offset);\n            if (!!this.privTranslationRecognizer.recognizing) {\n                try {\n                    this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, result);\n                    /* eslint-disable no-empty */\n                }\n                catch (error) {\n                    // Not going to let errors in the event handler\n                    // trip things up.\n                }\n            }\n            processed = true;\n        };\n        if (connectionMessage.messageType === Exports_js_1.MessageType.Text) {\n            resultProps.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"translation.hypothesis\":\n                handleTranslationHypothesis(Exports_js_3.TranslationHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset));\n                break;\n            case \"translation.response\":\n                const phrase = JSON.parse(connectionMessage.textBody);\n                if (!!phrase.SpeechPhrase) {\n                    await handleTranslationPhrase(Exports_js_3.TranslationPhrase.fromTranslationResponse(phrase, this.privRequestSession.currentTurnAudioOffset));\n                }\n                else {\n                    const hypothesis = JSON.parse(connectionMessage.textBody);\n                    if (!!hypothesis.SpeechHypothesis) {\n                        handleTranslationHypothesis(Exports_js_3.TranslationHypothesis.fromTranslationResponse(hypothesis, this.privRequestSession.currentTurnAudioOffset));\n                    }\n                }\n                break;\n            case \"translation.phrase\":\n                await handleTranslationPhrase(Exports_js_3.TranslationPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset));\n                break;\n            case \"translation.synthesis\":\n                this.sendSynthesisAudio(connectionMessage.binaryBody, this.privRequestSession.sessionId);\n                processed = true;\n                break;\n            case \"audio.end\":\n            case \"translation.synthesis.end\":\n                const synthEnd = Exports_js_3.TranslationSynthesisEnd.fromJSON(connectionMessage.textBody);\n                switch (synthEnd.SynthesisStatus) {\n                    case Exports_js_3.SynthesisStatus.Error:\n                        if (!!this.privTranslationRecognizer.synthesizing) {\n                            const result = new Exports_js_2.TranslationSynthesisResult(Exports_js_2.ResultReason.Canceled, undefined);\n                            const retEvent = new Exports_js_2.TranslationSynthesisEventArgs(result, this.privRequestSession.sessionId);\n                            try {\n                                this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);\n                                /* eslint-disable no-empty */\n                            }\n                            catch (error) {\n                                // Not going to let errors in the event handler\n                                // trip things up.\n                            }\n                        }\n                        if (!!this.privTranslationRecognizer.canceled) {\n                            // And raise a canceled event to send the rich(er) error message back.\n                            const canceledResult = new Exports_js_2.TranslationRecognitionCanceledEventArgs(this.privRequestSession.sessionId, Exports_js_2.CancellationReason.Error, synthEnd.FailureReason, Exports_js_2.CancellationErrorCode.ServiceError, null);\n                            try {\n                                this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, canceledResult);\n                                /* eslint-disable no-empty */\n                            }\n                            catch (error) {\n                                // Not going to let errors in the event handler\n                                // trip things up.\n                            }\n                        }\n                        break;\n                    case Exports_js_3.SynthesisStatus.Success:\n                        this.sendSynthesisAudio(undefined, this.privRequestSession.sessionId);\n                        break;\n                    default:\n                        break;\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        return processed;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new Exports_js_2.PropertyCollection();\n        properties.setProperty(Exports_js_3.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[errorCode]);\n        if (!!this.privTranslationRecognizer.canceled) {\n            const cancelEvent = new Exports_js_2.TranslationRecognitionCanceledEventArgs(sessionId, cancellationReason, error, errorCode, undefined);\n            try {\n                this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new Exports_js_2.TranslationRecognitionResult(undefined, // Translations\n            requestId, Exports_js_2.ResultReason.Canceled, undefined, // Text\n            undefined, // Druation\n            undefined, // Offset\n            undefined, // Language\n            undefined, // LanguageDetectionConfidence\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                /* eslint-disable no-empty */\n                this.privSuccessCallback = undefined;\n            }\n            catch { }\n        }\n    }\n    handleRecognizingCallback(result, offset, sessionId) {\n        try {\n            const ev = new Exports_js_2.TranslationRecognitionEventArgs(Exports_js_2.TranslationRecognitionResult.fromSpeechRecognitionResult(result), offset, sessionId);\n            this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, ev);\n            /* eslint-disable no-empty */\n        }\n        catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n        }\n    }\n    handleRecognizedCallback(result, offset, sessionId) {\n        try {\n            const ev = new Exports_js_2.TranslationRecognitionEventArgs(Exports_js_2.TranslationRecognitionResult.fromSpeechRecognitionResult(result), offset, sessionId);\n            this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);\n        }\n        catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n        }\n    }\n    fireEventForResult(serviceResult, properties) {\n        let translations;\n        if (undefined !== serviceResult.Translation.Translations) {\n            translations = new Exports_js_2.Translations();\n            for (const translation of serviceResult.Translation.Translations) {\n                translations.set(translation.Language, translation.Text || translation.DisplayText);\n            }\n        }\n        let resultReason;\n        let confidence;\n        if (serviceResult instanceof Exports_js_3.TranslationPhrase) {\n            if (!!serviceResult.Translation && serviceResult.Translation.TranslationStatus === Exports_js_1.TranslationStatus.Success) {\n                resultReason = Exports_js_2.ResultReason.TranslatedSpeech;\n            }\n            else {\n                resultReason = Exports_js_2.ResultReason.RecognizedSpeech;\n            }\n            confidence = serviceResult.Confidence;\n        }\n        else {\n            resultReason = Exports_js_2.ResultReason.TranslatingSpeech;\n        }\n        const language = serviceResult.Language;\n        const result = new Exports_js_2.TranslationRecognitionResult(translations, this.privRequestSession.requestId, resultReason, serviceResult.Text, serviceResult.Duration, serviceResult.Offset, language, confidence, serviceResult.Translation.FailureReason, serviceResult.asJson(), properties);\n        const ev = new Exports_js_2.TranslationRecognitionEventArgs(result, serviceResult.Offset, this.privRequestSession.sessionId);\n        return ev;\n    }\n    sendSynthesisAudio(audio, sessionId) {\n        const reason = (undefined === audio) ? Exports_js_2.ResultReason.SynthesizingAudioCompleted : Exports_js_2.ResultReason.SynthesizingAudio;\n        const result = new Exports_js_2.TranslationSynthesisResult(reason, audio);\n        const retEvent = new Exports_js_2.TranslationSynthesisEventArgs(result, sessionId);\n        if (!!this.privTranslationRecognizer.synthesizing) {\n            try {\n                this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (error) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n}\nexports.TranslationServiceRecognizer = TranslationServiceRecognizer;\n\n//# sourceMappingURL=TranslationServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationStatus = void 0;\n/**\n * Defines translation status.\n * @class TranslationStatus\n */\nvar TranslationStatus;\n(function (TranslationStatus) {\n    /**\n     * @member TranslationStatus.Success\n     */\n    TranslationStatus[TranslationStatus[\"Success\"] = 0] = \"Success\";\n    /**\n     * @member TranslationStatus.Error\n     */\n    TranslationStatus[TranslationStatus[\"Error\"] = 1] = \"Error\";\n})(TranslationStatus = exports.TranslationStatus || (exports.TranslationStatus = {}));\n\n//# sourceMappingURL=TranslationStatus.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/VoiceServiceRecognizer.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/VoiceServiceRecognizer.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceServiceRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// eslint-disable-next-line max-classes-per-file\nclass VoiceServiceRecognizer extends Exports_js_4.ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.privDeferralMap = new Exports_js_2.DeferralMap();\n        this.privSpeakerAudioSource = audioSource;\n        this.sendPrePayloadJSONOverride = () => this.noOp();\n    }\n    set SpeakerAudioSource(audioSource) {\n        this.privSpeakerAudioSource = audioSource;\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        let processed = false;\n        const resultProps = new Exports_js_3.PropertyCollection();\n        if (connectionMessage.messageType === Exports_js_2.MessageType.Text) {\n            resultProps.setProperty(Exports_js_3.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        switch (connectionMessage.path.toLowerCase()) {\n            // Profile management response for create, fetch, delete, reset\n            case \"speaker.profiles\":\n                const response = JSON.parse(connectionMessage.textBody);\n                switch (response.operation.toLowerCase()) {\n                    case \"create\":\n                        this.handleCreateResponse(response, connectionMessage.requestId);\n                        break;\n                    case \"delete\":\n                    case \"reset\":\n                        this.handleResultResponse(response, connectionMessage.requestId);\n                        break;\n                    case \"fetch\":\n                        const enrollmentResponse = JSON.parse(connectionMessage.textBody);\n                        this.handleFetchResponse(enrollmentResponse, connectionMessage.requestId);\n                        break;\n                    default:\n                        break;\n                }\n                processed = true;\n                break;\n            // Activation and authorization phrase response\n            case \"speaker.phrases\":\n                const phraseResponse = JSON.parse(connectionMessage.textBody);\n                this.handlePhrasesResponse(phraseResponse, connectionMessage.requestId);\n                processed = true;\n                break;\n            // Enrollment response\n            case \"speaker.profile.enrollment\":\n                const enrollmentResponse = JSON.parse(connectionMessage.textBody);\n                const result = new Exports_js_3.VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(!!enrollmentResponse.enrollment ? enrollmentResponse.enrollment.enrollmentStatus : enrollmentResponse.status.statusCode), !!enrollmentResponse.enrollment ? JSON.stringify(enrollmentResponse.enrollment) : undefined, enrollmentResponse.status.reason);\n                if (!!this.privDeferralMap.getId(connectionMessage.requestId)) {\n                    this.privDeferralMap.complete(connectionMessage.requestId, result);\n                }\n                this.privRequestSession.onSpeechEnded();\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new Exports_js_2.Deferred();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new Exports_js_3.PropertyCollection();\n        // const enrollmentResponse: EnrollmentResponse = JSON.parse(connectionMessage.textBody) as EnrollmentResponse;\n        properties.setProperty(Exports_js_4.CancellationErrorCodePropertyName, Exports_js_3.CancellationErrorCode[errorCode]);\n        const result = new Exports_js_3.VoiceProfileEnrollmentResult(Exports_js_3.ResultReason.Canceled, error, error);\n        if (!!this.privDeferralMap.getId(requestId)) {\n            this.privDeferralMap.complete(requestId, result);\n        }\n    }\n    async createProfile(profileType, locale) {\n        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n        this.voiceProfileType = profileType.toString();\n        const conPromise = this.connectImpl();\n        try {\n            const createProfileDeferral = new Exports_js_2.Deferred();\n            await conPromise;\n            await this.sendCreateProfile(createProfileDeferral, profileType, locale);\n            void this.receiveMessage();\n            return createProfileDeferral.promise;\n        }\n        catch (err) {\n            throw err;\n        }\n    }\n    async resetProfile(profile) {\n        this.voiceProfileType = profile.profileType.toString();\n        return this.sendCommonRequest(\"reset\", profile.profileType, profile);\n    }\n    async deleteProfile(profile) {\n        this.voiceProfileType = profile.profileType.toString();\n        return this.sendCommonRequest(\"delete\", profile.profileType, profile);\n    }\n    async retrieveEnrollmentResult(profile) {\n        this.voiceProfileType = profile.profileType.toString();\n        this.privExpectedProfileId = profile.profileId;\n        return this.sendCommonRequest(\"fetch\", profile.profileType, profile);\n    }\n    async getAllProfiles(profileType) {\n        this.voiceProfileType = profileType.toString();\n        return this.sendCommonRequest(\"fetch\", profileType);\n    }\n    async getActivationPhrases(profileType, lang) {\n        this.voiceProfileType = profileType.toString();\n        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n        const conPromise = this.connectImpl();\n        try {\n            const getPhrasesDeferral = new Exports_js_2.Deferred();\n            await conPromise;\n            await this.sendPhrasesRequest(getPhrasesDeferral, profileType, lang);\n            void this.receiveMessage();\n            return getPhrasesDeferral.promise;\n        }\n        catch (err) {\n            throw err;\n        }\n    }\n    async enrollProfile(profile) {\n        this.voiceProfileType = profile.profileType.toString();\n        const enrollmentDeferral = new Exports_js_2.Deferred();\n        this.privRequestSession.startNewRecognition();\n        this.privRequestSession.listenForServiceTelemetry(this.privSpeakerAudioSource.events);\n        this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);\n        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n        const conPromise = this.connectImpl();\n        const preAudioPromise = this.sendPreAudioMessages(profile, enrollmentDeferral);\n        const node = await this.privSpeakerAudioSource.attach(this.privRequestSession.audioNodeId);\n        const format = await this.privSpeakerAudioSource.format;\n        const deviceInfo = await this.privSpeakerAudioSource.deviceInfo;\n        const audioNode = new Exports_js_1.ReplayableAudioNode(node, format.avgBytesPerSec);\n        await this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n        try {\n            await conPromise;\n            await preAudioPromise;\n        }\n        catch (err) {\n            this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.ConnectionFailure, err);\n        }\n        const sessionStartEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);\n        if (!!this.privRecognizer.sessionStarted) {\n            this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n        }\n        void this.receiveMessage();\n        const audioSendPromise = this.sendAudio(audioNode);\n        // /* eslint-disable no-empty */\n        audioSendPromise.then(() => { }, (error) => {\n            this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);\n        });\n        return enrollmentDeferral.promise;\n    }\n    async sendPreAudioMessages(profile, enrollmentDeferral) {\n        const connection = await this.fetchConnection();\n        this.privRequestSession.onSpeechContext();\n        this.privDeferralMap.add(this.privRequestSession.requestId, enrollmentDeferral);\n        await this.sendBaseRequest(connection, \"enroll\", this.scenarioFrom(profile.profileType), profile);\n    }\n    async sendPhrasesRequest(getPhrasesDeferral, profileType, locale) {\n        const connection = await this.fetchConnection();\n        this.privRequestSession.onSpeechContext();\n        this.privDeferralMap.add(this.privRequestSession.requestId, getPhrasesDeferral);\n        const scenario = this.scenarioFrom(profileType);\n        const profileCreateRequest = {\n            locale,\n            scenario,\n        };\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speaker.profile.phrases\", this.privRequestSession.requestId, \"application/json; charset=utf-8\", JSON.stringify(profileCreateRequest)));\n    }\n    async sendCreateProfile(createProfileDeferral, profileType, locale) {\n        const connection = await this.fetchConnection();\n        this.privRequestSession.onSpeechContext();\n        this.privDeferralMap.add(this.privRequestSession.requestId, createProfileDeferral);\n        const scenario = profileType === Exports_js_3.VoiceProfileType.TextIndependentIdentification ? \"TextIndependentIdentification\" :\n            profileType === Exports_js_3.VoiceProfileType.TextIndependentVerification ? \"TextIndependentVerification\" : \"TextDependentVerification\";\n        const profileCreateRequest = {\n            locale,\n            number: \"1\",\n            scenario,\n        };\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, \"speaker.profile.create\", this.privRequestSession.requestId, \"application/json; charset=utf-8\", JSON.stringify(profileCreateRequest)));\n    }\n    async sendCommonRequest(operation, profileType, profile = undefined) {\n        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n        const conPromise = this.connectImpl();\n        try {\n            const deferral = new Exports_js_2.Deferred();\n            this.privRequestSession.onSpeechContext();\n            await conPromise;\n            const connection = await this.fetchConnection();\n            this.privDeferralMap.add(this.privRequestSession.requestId, deferral);\n            await this.sendBaseRequest(connection, operation, this.scenarioFrom(profileType), profile);\n            void this.receiveMessage();\n            return deferral.promise;\n        }\n        catch (err) {\n            throw err;\n        }\n    }\n    async sendBaseRequest(connection, operation, scenario, profile) {\n        const profileRequest = {\n            scenario\n        };\n        if (!!profile) {\n            profileRequest.profileIds = [profile.profileId];\n        }\n        else {\n            profileRequest.maxPageSize = -1;\n        }\n        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, `speaker.profile.${operation}`, this.privRequestSession.requestId, \"application/json; charset=utf-8\", JSON.stringify(profileRequest)));\n    }\n    extractSpeakerContext(model) {\n        return {\n            features: {\n                interimResult: \"enabled\",\n                progressiveDetection: \"disabled\",\n            },\n            profileIds: model.profileIds,\n            scenario: model.scenario,\n        };\n    }\n    handlePhrasesResponse(response, requestId) {\n        if (!!this.privDeferralMap.getId(requestId)) {\n            if (response.status.statusCode.toLowerCase() !== \"success\") {\n                const reason = Exports_js_3.ResultReason.Canceled;\n                const result = new Exports_js_3.VoiceProfilePhraseResult(reason, response.status.statusCode, response.passPhraseType, []);\n                this.privDeferralMap.complete(requestId, result);\n            }\n            else if (!!response.phrases && response.phrases.length > 0) {\n                const reason = Exports_js_3.ResultReason.EnrollingVoiceProfile;\n                const result = new Exports_js_3.VoiceProfilePhraseResult(reason, response.status.statusCode, response.passPhraseType, response.phrases);\n                this.privDeferralMap.complete(requestId, result);\n            }\n            else {\n                throw new Error(\"Voice Profile get activation phrases failed, no phrases received\");\n            }\n        }\n        else {\n            throw new Error(`Voice Profile get activation phrases request for requestID ${requestId} not found`);\n        }\n    }\n    handleCreateResponse(response, requestId) {\n        if (!!response.profiles && response.profiles.length > 0) {\n            if (!!this.privDeferralMap.getId(requestId)) {\n                const profileIds = response.profiles.map((profile) => profile.profileId);\n                this.privDeferralMap.complete(requestId, profileIds);\n            }\n            else {\n                throw new Error(`Voice Profile create request for requestID ${requestId} not found`);\n            }\n        }\n        else {\n            throw new Error(\"Voice Profile create failed, no profile id received\");\n        }\n    }\n    handleResultResponse(response, requestId) {\n        if (!!this.privDeferralMap.getId(requestId)) {\n            const successReason = response.operation.toLowerCase() === \"delete\" ? Exports_js_3.ResultReason.DeletedVoiceProfile : Exports_js_3.ResultReason.ResetVoiceProfile;\n            const reason = response.status.statusCode.toLowerCase() === \"success\" ? successReason : Exports_js_3.ResultReason.Canceled;\n            const result = new Exports_js_3.VoiceProfileResult(reason, `statusCode: ${response.status.statusCode}, errorDetails: ${response.status.reason}`);\n            this.privDeferralMap.complete(requestId, result);\n        }\n        else {\n            throw new Error(`Voice Profile create request for requestID ${requestId} not found`);\n        }\n    }\n    handleFetchResponse(enrollmentResponse, requestId) {\n        if (!!this.privDeferralMap.getId(requestId) && !!enrollmentResponse.profiles[0]) {\n            if (!!this.privExpectedProfileId && enrollmentResponse.profiles.length === 1 && enrollmentResponse.profiles[0].profileId === this.privExpectedProfileId) {\n                this.privExpectedProfileId = undefined;\n                const profileInfo = enrollmentResponse.profiles[0];\n                const result = new Exports_js_3.VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(profileInfo.enrollmentStatus), JSON.stringify(profileInfo), enrollmentResponse.status.reason);\n                this.privDeferralMap.complete(requestId, result);\n            }\n            else if (enrollmentResponse.profiles.length > 0) {\n                const iProfiles = enrollmentResponse.profiles;\n                const profileResults = [];\n                for (const profile of iProfiles) {\n                    profileResults.push(new Exports_js_3.VoiceProfileEnrollmentResult(this.enrollmentReasonFrom(profile.enrollmentStatus), JSON.stringify(profile), enrollmentResponse.status.reason));\n                }\n                this.privDeferralMap.complete(requestId, profileResults);\n            }\n        }\n        else {\n            throw new Error(`Voice Profile fetch request for requestID ${requestId} not found`);\n        }\n    }\n    enrollmentReasonFrom(statusCode) {\n        switch (statusCode.toLowerCase()) {\n            case \"enrolled\":\n                return Exports_js_3.ResultReason.EnrolledVoiceProfile;\n            case \"invalidlocale\":\n            case \"invalidphrase\":\n            case \"invalidaudioformat\":\n            case \"invalidscenario\":\n            case \"invalidprofilecount\":\n            case \"invalidoperation\":\n            case \"audiotooshort\":\n            case \"audiotoolong\":\n            case \"toomanyenrollments\":\n            case \"storageconflict\":\n            case \"profilenotfound\":\n            case \"incompatibleprofiles\":\n            case \"incompleteenrollment\":\n                return Exports_js_3.ResultReason.Canceled;\n            default:\n                return Exports_js_3.ResultReason.EnrollingVoiceProfile;\n        }\n    }\n    scenarioFrom(profileType) {\n        return profileType === Exports_js_3.VoiceProfileType.TextIndependentIdentification ? \"TextIndependentIdentification\" :\n            profileType === Exports_js_3.VoiceProfileType.TextIndependentVerification ? \"TextIndependentVerification\" : \"TextDependentVerification\";\n    }\n}\nexports.VoiceServiceRecognizer = VoiceServiceRecognizer;\n\n//# sourceMappingURL=VoiceServiceRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/VoiceServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/WebsocketMessageFormatter.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/WebsocketMessageFormatter.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WebsocketMessageFormatter = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst CRLF = \"\\r\\n\";\nclass WebsocketMessageFormatter {\n    toConnectionMessage(message) {\n        const deferral = new Exports_js_1.Deferred();\n        try {\n            if (message.messageType === Exports_js_1.MessageType.Text) {\n                const textMessage = message.textContent;\n                let headers = {};\n                let body = null;\n                if (textMessage) {\n                    const headerBodySplit = textMessage.split(\"\\r\\n\\r\\n\");\n                    if (headerBodySplit && headerBodySplit.length > 0) {\n                        headers = this.parseHeaders(headerBodySplit[0]);\n                        if (headerBodySplit.length > 1) {\n                            body = headerBodySplit[1];\n                        }\n                    }\n                }\n                deferral.resolve(new Exports_js_1.ConnectionMessage(message.messageType, body, headers, message.id));\n            }\n            else if (message.messageType === Exports_js_1.MessageType.Binary) {\n                const binaryMessage = message.binaryContent;\n                let headers = {};\n                let body = null;\n                if (!binaryMessage || binaryMessage.byteLength < 2) {\n                    throw new Error(\"Invalid binary message format. Header length missing.\");\n                }\n                const dataView = new DataView(binaryMessage);\n                const headerLength = dataView.getInt16(0);\n                if (binaryMessage.byteLength < headerLength + 2) {\n                    throw new Error(\"Invalid binary message format. Header content missing.\");\n                }\n                let headersString = \"\";\n                for (let i = 0; i < headerLength; i++) {\n                    headersString += String.fromCharCode((dataView).getInt8(i + 2));\n                }\n                headers = this.parseHeaders(headersString);\n                if (binaryMessage.byteLength > headerLength + 2) {\n                    body = binaryMessage.slice(2 + headerLength);\n                }\n                deferral.resolve(new Exports_js_1.ConnectionMessage(message.messageType, body, headers, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. Error: ${e}`);\n        }\n        return deferral.promise;\n    }\n    fromConnectionMessage(message) {\n        const deferral = new Exports_js_1.Deferred();\n        try {\n            if (message.messageType === Exports_js_1.MessageType.Text) {\n                const payload = `${this.makeHeaders(message)}${CRLF}${message.textBody ? message.textBody : \"\"}`;\n                deferral.resolve(new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Text, payload, message.id));\n            }\n            else if (message.messageType === Exports_js_1.MessageType.Binary) {\n                const headersString = this.makeHeaders(message);\n                const content = message.binaryBody;\n                const headerBuffer = this.stringToArrayBuffer(headersString);\n                const headerInt8Array = new Int8Array(headerBuffer);\n                const headerLength = headerInt8Array.byteLength;\n                const payloadInt8Array = new Int8Array(2 + headerLength + (content ? content.byteLength : 0));\n                payloadInt8Array[0] = ((headerLength >> 8) & 0xff);\n                payloadInt8Array[1] = headerLength & 0xff;\n                payloadInt8Array.set(headerInt8Array, 2);\n                if (content) {\n                    const bodyInt8Array = new Int8Array(content);\n                    payloadInt8Array.set(bodyInt8Array, 2 + headerLength);\n                }\n                const payload = payloadInt8Array.buffer;\n                deferral.resolve(new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Binary, payload, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. ${e}`);\n        }\n        return deferral.promise;\n    }\n    makeHeaders(message) {\n        let headersString = \"\";\n        if (message.headers) {\n            for (const header in message.headers) {\n                if (header) {\n                    headersString += `${header}: ${message.headers[header]}${CRLF}`;\n                }\n            }\n        }\n        return headersString;\n    }\n    parseHeaders(headersString) {\n        const headers = {};\n        if (headersString) {\n            const headerMatches = headersString.match(/[^\\r\\n]+/g);\n            if (headers) {\n                for (const header of headerMatches) {\n                    if (header) {\n                        const separatorIndex = header.indexOf(\":\");\n                        const headerName = separatorIndex > 0 ? header.substr(0, separatorIndex).trim().toLowerCase() : header;\n                        const headerValue = separatorIndex > 0 && header.length > (separatorIndex + 1) ?\n                            header.substr(separatorIndex + 1).trim() :\n                            \"\";\n                        headers[headerName] = headerValue;\n                    }\n                }\n            }\n        }\n        return headers;\n    }\n    stringToArrayBuffer(str) {\n        const buffer = new ArrayBuffer(str.length);\n        const view = new DataView(buffer);\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(i, str.charCodeAt(i));\n        }\n        return buffer;\n    }\n}\nexports.WebsocketMessageFormatter = WebsocketMessageFormatter;\n\n//# sourceMappingURL=WebsocketMessageFormatter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/WebsocketMessageFormatter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/AudioSourceEvents.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/AudioSourceEvents.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AudioStreamNodeErrorEvent = exports.AudioStreamNodeDetachedEvent = exports.AudioStreamNodeAttachedEvent = exports.AudioStreamNodeAttachingEvent = exports.AudioStreamNodeEvent = exports.AudioSourceErrorEvent = exports.AudioSourceOffEvent = exports.AudioSourceReadyEvent = exports.AudioSourceInitializingEvent = exports.AudioSourceEvent = void 0;\n/* eslint-disable max-classes-per-file */\nconst PlatformEvent_js_1 = __webpack_require__(/*! ./PlatformEvent.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js\");\nclass AudioSourceEvent extends PlatformEvent_js_1.PlatformEvent {\n    constructor(eventName, audioSourceId, eventType = PlatformEvent_js_1.EventType.Info) {\n        super(eventName, eventType);\n        this.privAudioSourceId = audioSourceId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n}\nexports.AudioSourceEvent = AudioSourceEvent;\nclass AudioSourceInitializingEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceInitializingEvent\", audioSourceId);\n    }\n}\nexports.AudioSourceInitializingEvent = AudioSourceInitializingEvent;\nclass AudioSourceReadyEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceReadyEvent\", audioSourceId);\n    }\n}\nexports.AudioSourceReadyEvent = AudioSourceReadyEvent;\nclass AudioSourceOffEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceOffEvent\", audioSourceId);\n    }\n}\nexports.AudioSourceOffEvent = AudioSourceOffEvent;\nclass AudioSourceErrorEvent extends AudioSourceEvent {\n    constructor(audioSourceId, error) {\n        super(\"AudioSourceErrorEvent\", audioSourceId, PlatformEvent_js_1.EventType.Error);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\nexports.AudioSourceErrorEvent = AudioSourceErrorEvent;\nclass AudioStreamNodeEvent extends AudioSourceEvent {\n    constructor(eventName, audioSourceId, audioNodeId) {\n        super(eventName, audioSourceId);\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nexports.AudioStreamNodeEvent = AudioStreamNodeEvent;\nclass AudioStreamNodeAttachingEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeAttachingEvent\", audioSourceId, audioNodeId);\n    }\n}\nexports.AudioStreamNodeAttachingEvent = AudioStreamNodeAttachingEvent;\nclass AudioStreamNodeAttachedEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeAttachedEvent\", audioSourceId, audioNodeId);\n    }\n}\nexports.AudioStreamNodeAttachedEvent = AudioStreamNodeAttachedEvent;\nclass AudioStreamNodeDetachedEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeDetachedEvent\", audioSourceId, audioNodeId);\n    }\n}\nexports.AudioStreamNodeDetachedEvent = AudioStreamNodeDetachedEvent;\nclass AudioStreamNodeErrorEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId, error) {\n        super(\"AudioStreamNodeErrorEvent\", audioSourceId, audioNodeId);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\nexports.AudioStreamNodeErrorEvent = AudioStreamNodeErrorEvent;\n\n//# sourceMappingURL=AudioSourceEvents.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/AudioSourceEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/BackgroundError.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/BackgroundError.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BackgroundEvent = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nclass BackgroundEvent extends Exports_js_1.PlatformEvent {\n    constructor(error) {\n        super(\"BackgroundEvent\", Exports_js_1.EventType.Error);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\nexports.BackgroundEvent = BackgroundEvent;\n\n//# sourceMappingURL=BackgroundError.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/BackgroundError.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ChunkedArrayBufferStream.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ChunkedArrayBufferStream.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ChunkedArrayBufferStream = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nclass ChunkedArrayBufferStream extends Exports_js_1.Stream {\n    constructor(targetChunkSize, streamId) {\n        super(streamId);\n        this.privTargetChunkSize = Math.round(targetChunkSize);\n        this.privNextBufferReadyBytes = 0;\n    }\n    writeStreamChunk(chunk) {\n        // No pending write, and the buffer is the right size so write it.\n        if (chunk.isEnd ||\n            (0 === this.privNextBufferReadyBytes && chunk.buffer.byteLength === this.privTargetChunkSize)) {\n            super.writeStreamChunk(chunk);\n            return;\n        }\n        let bytesCopiedFromBuffer = 0;\n        while (bytesCopiedFromBuffer < chunk.buffer.byteLength) {\n            // Fill the next buffer.\n            if (undefined === this.privNextBufferToWrite) {\n                this.privNextBufferToWrite = new ArrayBuffer(this.privTargetChunkSize);\n                this.privNextBufferStartTime = chunk.timeReceived;\n            }\n            // Find out how many bytes we can copy into the read buffer.\n            const bytesToCopy = Math.min(chunk.buffer.byteLength - bytesCopiedFromBuffer, this.privTargetChunkSize - this.privNextBufferReadyBytes);\n            const targetView = new Uint8Array(this.privNextBufferToWrite);\n            const sourceView = new Uint8Array(chunk.buffer.slice(bytesCopiedFromBuffer, bytesToCopy + bytesCopiedFromBuffer));\n            targetView.set(sourceView, this.privNextBufferReadyBytes);\n            this.privNextBufferReadyBytes += bytesToCopy;\n            bytesCopiedFromBuffer += bytesToCopy;\n            // Are we ready to write?\n            if (this.privNextBufferReadyBytes === this.privTargetChunkSize) {\n                super.writeStreamChunk({\n                    buffer: this.privNextBufferToWrite,\n                    isEnd: false,\n                    timeReceived: this.privNextBufferStartTime,\n                });\n                this.privNextBufferReadyBytes = 0;\n                this.privNextBufferToWrite = undefined;\n            }\n        }\n    }\n    close() {\n        // Send whatever is pending, then close the base class.\n        if (0 !== this.privNextBufferReadyBytes && !this.isClosed) {\n            super.writeStreamChunk({\n                buffer: this.privNextBufferToWrite.slice(0, this.privNextBufferReadyBytes),\n                isEnd: false,\n                timeReceived: this.privNextBufferStartTime,\n            });\n        }\n        super.close();\n    }\n}\nexports.ChunkedArrayBufferStream = ChunkedArrayBufferStream;\n\n//# sourceMappingURL=ChunkedArrayBufferStream.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ChunkedArrayBufferStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionEvents.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionEvents.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionMessageSentEvent = exports.ConnectionMessageReceivedEvent = exports.ConnectionEstablishErrorEvent = exports.ConnectionErrorEvent = exports.ConnectionClosedEvent = exports.ConnectionEstablishedEvent = exports.ConnectionStartEvent = exports.ConnectionEvent = exports.ServiceEvent = void 0;\nconst PlatformEvent_js_1 = __webpack_require__(/*! ./PlatformEvent.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js\");\nclass ServiceEvent extends PlatformEvent_js_1.PlatformEvent {\n    constructor(eventName, jsonstring, eventType = PlatformEvent_js_1.EventType.Info) {\n        super(eventName, eventType);\n        this.privJsonResult = jsonstring;\n    }\n    get jsonString() {\n        return this.privJsonResult;\n    }\n}\nexports.ServiceEvent = ServiceEvent;\nclass ConnectionEvent extends PlatformEvent_js_1.PlatformEvent {\n    constructor(eventName, connectionId, eventType = PlatformEvent_js_1.EventType.Info) {\n        super(eventName, eventType);\n        this.privConnectionId = connectionId;\n    }\n    get connectionId() {\n        return this.privConnectionId;\n    }\n}\nexports.ConnectionEvent = ConnectionEvent;\nclass ConnectionStartEvent extends ConnectionEvent {\n    constructor(connectionId, uri, headers) {\n        super(\"ConnectionStartEvent\", connectionId);\n        this.privUri = uri;\n        this.privHeaders = headers;\n    }\n    get uri() {\n        return this.privUri;\n    }\n    get headers() {\n        return this.privHeaders;\n    }\n}\nexports.ConnectionStartEvent = ConnectionStartEvent;\nclass ConnectionEstablishedEvent extends ConnectionEvent {\n    constructor(connectionId) {\n        super(\"ConnectionEstablishedEvent\", connectionId);\n    }\n}\nexports.ConnectionEstablishedEvent = ConnectionEstablishedEvent;\nclass ConnectionClosedEvent extends ConnectionEvent {\n    constructor(connectionId, statusCode, reason) {\n        super(\"ConnectionClosedEvent\", connectionId, PlatformEvent_js_1.EventType.Debug);\n        this.privReason = reason;\n        this.privStatusCode = statusCode;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n}\nexports.ConnectionClosedEvent = ConnectionClosedEvent;\nclass ConnectionErrorEvent extends ConnectionEvent {\n    constructor(connectionId, message, type) {\n        super(\"ConnectionErrorEvent\", connectionId, PlatformEvent_js_1.EventType.Debug);\n        this.privMessage = message;\n        this.privType = type;\n    }\n    get message() {\n        return this.privMessage;\n    }\n    get type() {\n        return this.privType;\n    }\n}\nexports.ConnectionErrorEvent = ConnectionErrorEvent;\nclass ConnectionEstablishErrorEvent extends ConnectionEvent {\n    constructor(connectionId, statuscode, reason) {\n        super(\"ConnectionEstablishErrorEvent\", connectionId, PlatformEvent_js_1.EventType.Error);\n        this.privStatusCode = statuscode;\n        this.privReason = reason;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n}\nexports.ConnectionEstablishErrorEvent = ConnectionEstablishErrorEvent;\nclass ConnectionMessageReceivedEvent extends ConnectionEvent {\n    constructor(connectionId, networkReceivedTimeISO, message) {\n        super(\"ConnectionMessageReceivedEvent\", connectionId);\n        this.privNetworkReceivedTime = networkReceivedTimeISO;\n        this.privMessage = message;\n    }\n    get networkReceivedTime() {\n        return this.privNetworkReceivedTime;\n    }\n    get message() {\n        return this.privMessage;\n    }\n}\nexports.ConnectionMessageReceivedEvent = ConnectionMessageReceivedEvent;\nclass ConnectionMessageSentEvent extends ConnectionEvent {\n    constructor(connectionId, networkSentTimeISO, message) {\n        super(\"ConnectionMessageSentEvent\", connectionId);\n        this.privNetworkSentTime = networkSentTimeISO;\n        this.privMessage = message;\n    }\n    get networkSentTime() {\n        return this.privNetworkSentTime;\n    }\n    get message() {\n        return this.privMessage;\n    }\n}\nexports.ConnectionMessageSentEvent = ConnectionMessageSentEvent;\n\n//# sourceMappingURL=ConnectionEvents.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n/* eslint-disable @typescript-eslint/no-unsafe-return */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionMessage = exports.MessageType = void 0;\nconst Error_js_1 = __webpack_require__(/*! ./Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nconst Guid_js_1 = __webpack_require__(/*! ./Guid.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js\");\nvar MessageType;\n(function (MessageType) {\n    MessageType[MessageType[\"Text\"] = 0] = \"Text\";\n    MessageType[MessageType[\"Binary\"] = 1] = \"Binary\";\n})(MessageType = exports.MessageType || (exports.MessageType = {}));\nclass ConnectionMessage {\n    constructor(messageType, body, headers, id) {\n        this.privBody = null;\n        if (messageType === MessageType.Text && body && !(typeof (body) === \"string\")) {\n            throw new Error_js_1.InvalidOperationError(\"Payload must be a string\");\n        }\n        if (messageType === MessageType.Binary && body && !(body instanceof ArrayBuffer)) {\n            throw new Error_js_1.InvalidOperationError(\"Payload must be ArrayBuffer\");\n        }\n        this.privMessageType = messageType;\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n        this.privBody = body;\n        this.privHeaders = headers ? headers : {};\n        this.privId = id ? id : Guid_js_1.createNoDashGuid();\n        switch (this.messageType) {\n            case MessageType.Binary:\n                this.privSize = this.binaryBody !== null ? this.binaryBody.byteLength : 0;\n                break;\n            case MessageType.Text:\n                this.privSize = this.textBody.length;\n        }\n    }\n    get messageType() {\n        return this.privMessageType;\n    }\n    get headers() {\n        return this.privHeaders;\n    }\n    get body() {\n        return this.privBody;\n    }\n    get textBody() {\n        if (this.privMessageType === MessageType.Binary) {\n            throw new Error_js_1.InvalidOperationError(\"Not supported for binary message\");\n        }\n        return this.privBody;\n    }\n    get binaryBody() {\n        if (this.privMessageType === MessageType.Text) {\n            throw new Error_js_1.InvalidOperationError(\"Not supported for text message\");\n        }\n        return this.privBody;\n    }\n    get id() {\n        return this.privId;\n    }\n}\nexports.ConnectionMessage = ConnectionMessage;\n\n//# sourceMappingURL=ConnectionMessage.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionOpenResponse.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionOpenResponse.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionOpenResponse = void 0;\nclass ConnectionOpenResponse {\n    constructor(statusCode, reason) {\n        this.privStatusCode = statusCode;\n        this.privReason = reason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n    get reason() {\n        return this.privReason;\n    }\n}\nexports.ConnectionOpenResponse = ConnectionOpenResponse;\n\n//# sourceMappingURL=ConnectionOpenResponse.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionOpenResponse.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DeferralMap.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DeferralMap.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DeferralMap = void 0;\n/**\n * The error that is thrown when an argument passed in is null.\n *\n * @export\n * @class DefferalMap\n */\nclass DeferralMap {\n    constructor() {\n        this.privMap = {};\n    }\n    add(id, deferral) {\n        this.privMap[id] = deferral;\n    }\n    getId(id) {\n        return this.privMap[id];\n    }\n    complete(id, result) {\n        try {\n            this.privMap[id].resolve(result);\n        }\n        catch (error) {\n            this.privMap[id].reject(error);\n        }\n        finally {\n            this.privMap[id] = undefined;\n        }\n    }\n}\nexports.DeferralMap = DeferralMap;\n\n//# sourceMappingURL=DeferralMap.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DeferralMap.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SendingAgentContextMessageEvent = exports.DialogEvent = void 0;\nconst PlatformEvent_js_1 = __webpack_require__(/*! ./PlatformEvent.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js\");\nclass DialogEvent extends PlatformEvent_js_1.PlatformEvent {\n    constructor(eventName, eventType = PlatformEvent_js_1.EventType.Info) {\n        super(eventName, eventType);\n    }\n}\nexports.DialogEvent = DialogEvent;\nclass SendingAgentContextMessageEvent extends DialogEvent {\n    constructor(agentConfig) {\n        super(\"SendingAgentContextMessageEvent\");\n        this.privAgentConfig = agentConfig;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n}\nexports.SendingAgentContextMessageEvent = SendingAgentContextMessageEvent;\n\n//# sourceMappingURL=DialogEvents.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ObjectDisposedError = exports.InvalidOperationError = exports.ArgumentNullError = void 0;\n/* eslint-disable max-classes-per-file */\n/**\n * The error that is thrown when an argument passed in is null.\n *\n * @export\n * @class ArgumentNullError\n * @extends {Error}\n */\nclass ArgumentNullError extends Error {\n    /**\n     * Creates an instance of ArgumentNullError.\n     *\n     * @param {string} argumentName - Name of the argument that is null\n     *\n     * @memberOf ArgumentNullError\n     */\n    constructor(argumentName) {\n        super(argumentName);\n        this.name = \"ArgumentNull\";\n        this.message = argumentName;\n    }\n}\nexports.ArgumentNullError = ArgumentNullError;\n/**\n * The error that is thrown when an invalid operation is performed in the code.\n *\n * @export\n * @class InvalidOperationError\n * @extends {Error}\n */\nclass InvalidOperationError extends Error {\n    /**\n     * Creates an instance of InvalidOperationError.\n     *\n     * @param {string} error - The error\n     *\n     * @memberOf InvalidOperationError\n     */\n    constructor(error) {\n        super(error);\n        this.name = \"InvalidOperation\";\n        this.message = error;\n    }\n}\nexports.InvalidOperationError = InvalidOperationError;\n/**\n * The error that is thrown when an object is disposed.\n *\n * @export\n * @class ObjectDisposedError\n * @extends {Error}\n */\nclass ObjectDisposedError extends Error {\n    /**\n     * Creates an instance of ObjectDisposedError.\n     *\n     * @param {string} objectName - The object that is disposed\n     * @param {string} error - The error\n     *\n     * @memberOf ObjectDisposedError\n     */\n    constructor(objectName, error) {\n        super(error);\n        this.name = objectName + \"ObjectDisposed\";\n        this.message = error;\n    }\n}\nexports.ObjectDisposedError = ObjectDisposedError;\n\n//# sourceMappingURL=Error.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EventSource = void 0;\nconst Error_js_1 = __webpack_require__(/*! ./Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nconst Guid_js_1 = __webpack_require__(/*! ./Guid.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js\");\nclass EventSource {\n    constructor(metadata) {\n        this.privEventListeners = {};\n        this.privIsDisposed = false;\n        this.privConsoleListener = undefined;\n        this.privMetadata = metadata;\n    }\n    onEvent(event) {\n        if (this.isDisposed()) {\n            throw (new Error_js_1.ObjectDisposedError(\"EventSource\"));\n        }\n        if (this.metadata) {\n            for (const paramName in this.metadata) {\n                if (paramName) {\n                    if (event.metadata) {\n                        if (!event.metadata[paramName]) {\n                            event.metadata[paramName] = this.metadata[paramName];\n                        }\n                    }\n                }\n            }\n        }\n        for (const eventId in this.privEventListeners) {\n            if (eventId && this.privEventListeners[eventId]) {\n                this.privEventListeners[eventId](event);\n            }\n        }\n    }\n    attach(onEventCallback) {\n        const id = Guid_js_1.createNoDashGuid();\n        this.privEventListeners[id] = onEventCallback;\n        return {\n            detach: () => {\n                delete this.privEventListeners[id];\n                return Promise.resolve();\n            },\n        };\n    }\n    attachListener(listener) {\n        return this.attach((e) => listener.onEvent(e));\n    }\n    attachConsoleListener(listener) {\n        if (!!this.privConsoleListener) {\n            void this.privConsoleListener.detach(); // Detach implementation for eventListeners is synchronous\n        }\n        this.privConsoleListener = this.attach((e) => listener.onEvent(e));\n        return this.privConsoleListener;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose() {\n        this.privEventListeners = null;\n        this.privIsDisposed = true;\n    }\n    get metadata() {\n        return this.privMetadata;\n    }\n}\nexports.EventSource = EventSource;\n\n//# sourceMappingURL=EventSource.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Events.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Events.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Events = void 0;\nconst Error_js_1 = __webpack_require__(/*! ./Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nconst EventSource_js_1 = __webpack_require__(/*! ./EventSource.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js\");\nclass Events {\n    static setEventSource(eventSource) {\n        if (!eventSource) {\n            throw new Error_js_1.ArgumentNullError(\"eventSource\");\n        }\n        Events.privInstance = eventSource;\n    }\n    static get instance() {\n        return Events.privInstance;\n    }\n}\nexports.Events = Events;\nEvents.privInstance = new EventSource_js_1.EventSource();\n\n//# sourceMappingURL=Events.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Events.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js ***!
  \***********************************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !exports.hasOwnProperty(p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./AudioSourceEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/AudioSourceEvents.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ConnectionEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionEvents.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ConnectionMessage.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ConnectionOpenResponse.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionOpenResponse.js\"), exports);\n__exportStar(__webpack_require__(/*! ./DeferralMap.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DeferralMap.js\"), exports);\n__exportStar(__webpack_require__(/*! ./DialogEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Events.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Events.js\"), exports);\n__exportStar(__webpack_require__(/*! ./EventSource.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Guid.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IAudioSource.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioSource.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IConnection.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IConnection.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IDetachable.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDetachable.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IDictionary.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDictionary.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IDisposable.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDisposable.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IEventListener.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventListener.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IEventSource.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventSource.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IErrorMessages.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IErrorMessages.js\"), exports);\n__exportStar(__webpack_require__(/*! ./ITimer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ITimer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IWebsocketMessageFormatter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IWebsocketMessageFormatter.js\"), exports);\n__exportStar(__webpack_require__(/*! ./List.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js\"), exports);\n__exportStar(__webpack_require__(/*! ./PlatformEvent.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Promise.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Queue.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js\"), exports);\n__exportStar(__webpack_require__(/*! ./RawWebsocketMessage.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RawWebsocketMessage.js\"), exports);\n__exportStar(__webpack_require__(/*! ./RiffPcmEncoder.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RiffPcmEncoder.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Stream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Stream.js\"), exports);\nvar TranslationStatus_js_1 = __webpack_require__(/*! ../common.speech/TranslationStatus.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js\");\nObject.defineProperty(exports, \"TranslationStatus\", ({ enumerable: true, get: function () { return TranslationStatus_js_1.TranslationStatus; } }));\n__exportStar(__webpack_require__(/*! ./ChunkedArrayBufferStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ChunkedArrayBufferStream.js\"), exports);\n__exportStar(__webpack_require__(/*! ./IAudioDestination.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioDestination.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Timeout.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Timeout.js\"), exports);\n__exportStar(__webpack_require__(/*! ./OCSPEvents.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/OCSPEvents.js\"), exports);\n__exportStar(__webpack_require__(/*! ./BackgroundError.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/BackgroundError.js\"), exports);\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.createNoDashGuid = exports.createGuid = void 0;\nconst uuid_1 = __webpack_require__(/*! uuid */ \"./node_modules/uuid/dist/esm-browser/index.js\");\nconst createGuid = () => uuid_1.v4();\nexports.createGuid = createGuid;\nconst createNoDashGuid = () => createGuid().replace(new RegExp(\"-\", \"g\"), \"\").toUpperCase();\nexports.createNoDashGuid = createNoDashGuid;\n\n//# sourceMappingURL=Guid.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioDestination.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioDestination.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IAudioDestination.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioDestination.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioSource.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioSource.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IAudioSource.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IConnection.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IConnection.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionState = void 0;\nvar ConnectionState;\n(function (ConnectionState) {\n    ConnectionState[ConnectionState[\"None\"] = 0] = \"None\";\n    ConnectionState[ConnectionState[\"Connected\"] = 1] = \"Connected\";\n    ConnectionState[ConnectionState[\"Connecting\"] = 2] = \"Connecting\";\n    ConnectionState[ConnectionState[\"Disconnected\"] = 3] = \"Disconnected\";\n})(ConnectionState = exports.ConnectionState || (exports.ConnectionState = {}));\n\n//# sourceMappingURL=IConnection.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IConnection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDetachable.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDetachable.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IDetachable.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDetachable.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDictionary.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDictionary.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IDictionary.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDictionary.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDisposable.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDisposable.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IDisposable.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDisposable.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IErrorMessages.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IErrorMessages.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IErrorMessages.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IErrorMessages.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventListener.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventListener.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IEventListener.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventListener.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventSource.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventSource.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IEventSource.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ITimer.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ITimer.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=ITimer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ITimer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IWebsocketMessageFormatter.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IWebsocketMessageFormatter.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n//# sourceMappingURL=IWebsocketMessageFormatter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IWebsocketMessageFormatter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.List = void 0;\nconst Error_js_1 = __webpack_require__(/*! ./Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nclass List {\n    constructor(list) {\n        this.privSubscriptionIdCounter = 0;\n        this.privAddSubscriptions = {};\n        this.privRemoveSubscriptions = {};\n        this.privDisposedSubscriptions = {};\n        this.privDisposeReason = null;\n        this.privList = [];\n        // copy the list rather than taking as is.\n        if (list) {\n            for (const item of list) {\n                this.privList.push(item);\n            }\n        }\n    }\n    get(itemIndex) {\n        this.throwIfDisposed();\n        return this.privList[itemIndex];\n    }\n    first() {\n        return this.get(0);\n    }\n    last() {\n        return this.get(this.length() - 1);\n    }\n    add(item) {\n        this.throwIfDisposed();\n        this.insertAt(this.privList.length, item);\n    }\n    insertAt(index, item) {\n        this.throwIfDisposed();\n        if (index === 0) {\n            this.privList.unshift(item);\n        }\n        else if (index === this.privList.length) {\n            this.privList.push(item);\n        }\n        else {\n            this.privList.splice(index, 0, item);\n        }\n        this.triggerSubscriptions(this.privAddSubscriptions);\n    }\n    removeFirst() {\n        this.throwIfDisposed();\n        return this.removeAt(0);\n    }\n    removeLast() {\n        this.throwIfDisposed();\n        return this.removeAt(this.length() - 1);\n    }\n    removeAt(index) {\n        this.throwIfDisposed();\n        return this.remove(index, 1)[0];\n    }\n    remove(index, count) {\n        this.throwIfDisposed();\n        const removedElements = this.privList.splice(index, count);\n        this.triggerSubscriptions(this.privRemoveSubscriptions);\n        return removedElements;\n    }\n    clear() {\n        this.throwIfDisposed();\n        this.remove(0, this.length());\n    }\n    length() {\n        this.throwIfDisposed();\n        return this.privList.length;\n    }\n    onAdded(addedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privAddSubscriptions[subscriptionId] = addedCallback;\n        return {\n            detach: () => {\n                delete this.privAddSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    onRemoved(removedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privRemoveSubscriptions[subscriptionId] = removedCallback;\n        return {\n            detach: () => {\n                delete this.privRemoveSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    onDisposed(disposedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privDisposedSubscriptions[subscriptionId] = disposedCallback;\n        return {\n            detach: () => {\n                delete this.privDisposedSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    join(seperator) {\n        this.throwIfDisposed();\n        return this.privList.join(seperator);\n    }\n    toArray() {\n        const cloneCopy = Array();\n        this.privList.forEach((val) => {\n            cloneCopy.push(val);\n        });\n        return cloneCopy;\n    }\n    any(callback) {\n        this.throwIfDisposed();\n        if (callback) {\n            return this.where(callback).length() > 0;\n        }\n        else {\n            return this.length() > 0;\n        }\n    }\n    all(callback) {\n        this.throwIfDisposed();\n        return this.where(callback).length() === this.length();\n    }\n    forEach(callback) {\n        this.throwIfDisposed();\n        for (let i = 0; i < this.length(); i++) {\n            callback(this.privList[i], i);\n        }\n    }\n    select(callback) {\n        this.throwIfDisposed();\n        const selectList = [];\n        for (let i = 0; i < this.privList.length; i++) {\n            selectList.push(callback(this.privList[i], i));\n        }\n        return new List(selectList);\n    }\n    where(callback) {\n        this.throwIfDisposed();\n        const filteredList = new List();\n        for (let i = 0; i < this.privList.length; i++) {\n            if (callback(this.privList[i], i)) {\n                filteredList.add(this.privList[i]);\n            }\n        }\n        return filteredList;\n    }\n    orderBy(compareFn) {\n        this.throwIfDisposed();\n        const clonedArray = this.toArray();\n        const orderedArray = clonedArray.sort(compareFn);\n        return new List(orderedArray);\n    }\n    orderByDesc(compareFn) {\n        this.throwIfDisposed();\n        return this.orderBy((a, b) => compareFn(b, a));\n    }\n    clone() {\n        this.throwIfDisposed();\n        return new List(this.toArray());\n    }\n    concat(list) {\n        this.throwIfDisposed();\n        return new List(this.privList.concat(list.toArray()));\n    }\n    concatArray(array) {\n        this.throwIfDisposed();\n        return new List(this.privList.concat(array));\n    }\n    isDisposed() {\n        return this.privList == null;\n    }\n    dispose(reason) {\n        if (!this.isDisposed()) {\n            this.privDisposeReason = reason;\n            this.privList = null;\n            this.privAddSubscriptions = null;\n            this.privRemoveSubscriptions = null;\n            this.triggerSubscriptions(this.privDisposedSubscriptions);\n        }\n    }\n    throwIfDisposed() {\n        if (this.isDisposed()) {\n            throw new Error_js_1.ObjectDisposedError(\"List\", this.privDisposeReason);\n        }\n    }\n    triggerSubscriptions(subscriptions) {\n        if (subscriptions) {\n            for (const subscriptionId in subscriptions) {\n                if (subscriptionId) {\n                    subscriptions[subscriptionId]();\n                }\n            }\n        }\n    }\n}\nexports.List = List;\n\n//# sourceMappingURL=List.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/OCSPEvents.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/OCSPEvents.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OCSPCacheUpdateErrorEvent = exports.OCSPResponseRetrievedEvent = exports.OCSPCacheFetchErrorEvent = exports.OCSPVerificationFailedEvent = exports.OCSPCacheHitEvent = exports.OCSPCacheEntryNeedsRefreshEvent = exports.OCSPCacheEntryExpiredEvent = exports.OCSPWSUpgradeStartedEvent = exports.OCSPStapleReceivedEvent = exports.OCSPCacheUpdateCompleteEvent = exports.OCSPDiskCacheStoreEvent = exports.OCSPMemoryCacheStoreEvent = exports.OCSPCacheUpdateNeededEvent = exports.OCSPDiskCacheHitEvent = exports.OCSPCacheMissEvent = exports.OCSPMemoryCacheHitEvent = exports.OCSPEvent = void 0;\n/* eslint-disable max-classes-per-file */\nconst PlatformEvent_js_1 = __webpack_require__(/*! ./PlatformEvent.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js\");\nclass OCSPEvent extends PlatformEvent_js_1.PlatformEvent {\n    constructor(eventName, eventType, signature) {\n        super(eventName, eventType);\n        this.privSignature = signature;\n    }\n}\nexports.OCSPEvent = OCSPEvent;\nclass OCSPMemoryCacheHitEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPMemoryCacheHitEvent\", PlatformEvent_js_1.EventType.Debug, signature);\n    }\n}\nexports.OCSPMemoryCacheHitEvent = OCSPMemoryCacheHitEvent;\nclass OCSPCacheMissEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheMissEvent\", PlatformEvent_js_1.EventType.Debug, signature);\n    }\n}\nexports.OCSPCacheMissEvent = OCSPCacheMissEvent;\nclass OCSPDiskCacheHitEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPDiskCacheHitEvent\", PlatformEvent_js_1.EventType.Debug, signature);\n    }\n}\nexports.OCSPDiskCacheHitEvent = OCSPDiskCacheHitEvent;\nclass OCSPCacheUpdateNeededEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheUpdateNeededEvent\", PlatformEvent_js_1.EventType.Debug, signature);\n    }\n}\nexports.OCSPCacheUpdateNeededEvent = OCSPCacheUpdateNeededEvent;\nclass OCSPMemoryCacheStoreEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPMemoryCacheStoreEvent\", PlatformEvent_js_1.EventType.Debug, signature);\n    }\n}\nexports.OCSPMemoryCacheStoreEvent = OCSPMemoryCacheStoreEvent;\nclass OCSPDiskCacheStoreEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPDiskCacheStoreEvent\", PlatformEvent_js_1.EventType.Debug, signature);\n    }\n}\nexports.OCSPDiskCacheStoreEvent = OCSPDiskCacheStoreEvent;\nclass OCSPCacheUpdateCompleteEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheUpdateCompleteEvent\", PlatformEvent_js_1.EventType.Debug, signature);\n    }\n}\nexports.OCSPCacheUpdateCompleteEvent = OCSPCacheUpdateCompleteEvent;\nclass OCSPStapleReceivedEvent extends OCSPEvent {\n    constructor() {\n        super(\"OCSPStapleReceivedEvent\", PlatformEvent_js_1.EventType.Debug, \"\");\n    }\n}\nexports.OCSPStapleReceivedEvent = OCSPStapleReceivedEvent;\nclass OCSPWSUpgradeStartedEvent extends OCSPEvent {\n    constructor(serialNumber) {\n        super(\"OCSPWSUpgradeStartedEvent\", PlatformEvent_js_1.EventType.Debug, serialNumber);\n    }\n}\nexports.OCSPWSUpgradeStartedEvent = OCSPWSUpgradeStartedEvent;\nclass OCSPCacheEntryExpiredEvent extends OCSPEvent {\n    constructor(serialNumber, expireTime) {\n        super(\"OCSPCacheEntryExpiredEvent\", PlatformEvent_js_1.EventType.Debug, serialNumber);\n        this.privExpireTime = expireTime;\n    }\n}\nexports.OCSPCacheEntryExpiredEvent = OCSPCacheEntryExpiredEvent;\nclass OCSPCacheEntryNeedsRefreshEvent extends OCSPEvent {\n    constructor(serialNumber, startTime, expireTime) {\n        super(\"OCSPCacheEntryNeedsRefreshEvent\", PlatformEvent_js_1.EventType.Debug, serialNumber);\n        this.privExpireTime = expireTime;\n        this.privStartTime = startTime;\n    }\n}\nexports.OCSPCacheEntryNeedsRefreshEvent = OCSPCacheEntryNeedsRefreshEvent;\nclass OCSPCacheHitEvent extends OCSPEvent {\n    constructor(serialNumber, startTime, expireTime) {\n        super(\"OCSPCacheHitEvent\", PlatformEvent_js_1.EventType.Debug, serialNumber);\n        this.privExpireTime = expireTime;\n        this.privExpireTimeString = new Date(expireTime).toLocaleDateString();\n        this.privStartTime = startTime;\n        this.privStartTimeString = new Date(startTime).toLocaleTimeString();\n    }\n}\nexports.OCSPCacheHitEvent = OCSPCacheHitEvent;\nclass OCSPVerificationFailedEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPVerificationFailedEvent\", PlatformEvent_js_1.EventType.Debug, serialNumber);\n        this.privError = error;\n    }\n}\nexports.OCSPVerificationFailedEvent = OCSPVerificationFailedEvent;\nclass OCSPCacheFetchErrorEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPCacheFetchErrorEvent\", PlatformEvent_js_1.EventType.Debug, serialNumber);\n        this.privError = error;\n    }\n}\nexports.OCSPCacheFetchErrorEvent = OCSPCacheFetchErrorEvent;\nclass OCSPResponseRetrievedEvent extends OCSPEvent {\n    constructor(serialNumber) {\n        super(\"OCSPResponseRetrievedEvent\", PlatformEvent_js_1.EventType.Debug, serialNumber);\n    }\n}\nexports.OCSPResponseRetrievedEvent = OCSPResponseRetrievedEvent;\nclass OCSPCacheUpdateErrorEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPCacheUpdateErrorEvent\", PlatformEvent_js_1.EventType.Debug, serialNumber);\n        this.privError = error;\n    }\n}\nexports.OCSPCacheUpdateErrorEvent = OCSPCacheUpdateErrorEvent;\n\n//# sourceMappingURL=OCSPEvents.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/OCSPEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PlatformEvent = exports.EventType = void 0;\nconst Guid_js_1 = __webpack_require__(/*! ./Guid.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js\");\nvar EventType;\n(function (EventType) {\n    EventType[EventType[\"Debug\"] = 0] = \"Debug\";\n    EventType[EventType[\"Info\"] = 1] = \"Info\";\n    EventType[EventType[\"Warning\"] = 2] = \"Warning\";\n    EventType[EventType[\"Error\"] = 3] = \"Error\";\n    EventType[EventType[\"None\"] = 4] = \"None\";\n})(EventType = exports.EventType || (exports.EventType = {}));\nclass PlatformEvent {\n    constructor(eventName, eventType) {\n        this.privName = eventName;\n        this.privEventId = Guid_js_1.createNoDashGuid();\n        this.privEventTime = new Date().toISOString();\n        this.privEventType = eventType;\n        this.privMetadata = {};\n    }\n    get name() {\n        return this.privName;\n    }\n    get eventId() {\n        return this.privEventId;\n    }\n    get eventTime() {\n        return this.privEventTime;\n    }\n    get eventType() {\n        return this.privEventType;\n    }\n    get metadata() {\n        return this.privMetadata;\n    }\n}\nexports.PlatformEvent = PlatformEvent;\n\n//# sourceMappingURL=PlatformEvent.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.marshalPromiseToCallbacks = exports.Sink = exports.Deferred = exports.PromiseResultEventSource = exports.PromiseResult = exports.PromiseState = void 0;\n/* eslint-disable max-classes-per-file, @typescript-eslint/typedef */\nvar PromiseState;\n(function (PromiseState) {\n    PromiseState[PromiseState[\"None\"] = 0] = \"None\";\n    PromiseState[PromiseState[\"Resolved\"] = 1] = \"Resolved\";\n    PromiseState[PromiseState[\"Rejected\"] = 2] = \"Rejected\";\n})(PromiseState = exports.PromiseState || (exports.PromiseState = {}));\nclass PromiseResult {\n    constructor(promiseResultEventSource) {\n        this.throwIfError = () => {\n            if (this.isError) {\n                throw this.error;\n            }\n        };\n        promiseResultEventSource.on((result) => {\n            if (!this.privIsCompleted) {\n                this.privIsCompleted = true;\n                this.privIsError = false;\n                this.privResult = result;\n            }\n        }, (error) => {\n            if (!this.privIsCompleted) {\n                this.privIsCompleted = true;\n                this.privIsError = true;\n                this.privError = error;\n            }\n        });\n    }\n    get isCompleted() {\n        return this.privIsCompleted;\n    }\n    get isError() {\n        return this.privIsError;\n    }\n    get error() {\n        return this.privError;\n    }\n    get result() {\n        return this.privResult;\n    }\n}\nexports.PromiseResult = PromiseResult;\nclass PromiseResultEventSource {\n    constructor() {\n        this.setResult = (result) => {\n            this.privOnSetResult(result);\n        };\n        this.setError = (error) => {\n            this.privOnSetError(error);\n        };\n        this.on = (onSetResult, onSetError) => {\n            this.privOnSetResult = onSetResult;\n            this.privOnSetError = onSetError;\n        };\n    }\n}\nexports.PromiseResultEventSource = PromiseResultEventSource;\nclass Deferred {\n    constructor() {\n        this.resolve = (result) => {\n            this.privResolve(result);\n            return this;\n        };\n        this.reject = (error) => {\n            this.privReject(error);\n            return this;\n        };\n        // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n        this.privPromise = new Promise((resolve, reject) => {\n            this.privResolve = resolve;\n            this.privReject = reject;\n        });\n    }\n    get promise() {\n        return this.privPromise;\n    }\n}\nexports.Deferred = Deferred;\nclass Sink {\n    constructor() {\n        this.privState = PromiseState.None;\n        this.privPromiseResult = null;\n        this.privPromiseResultEvents = null;\n        this.privSuccessHandlers = [];\n        this.privErrorHandlers = [];\n        this.privPromiseResultEvents = new PromiseResultEventSource();\n        this.privPromiseResult = new PromiseResult(this.privPromiseResultEvents);\n    }\n    get state() {\n        return this.privState;\n    }\n    get result() {\n        return this.privPromiseResult;\n    }\n    resolve(result) {\n        if (this.privState !== PromiseState.None) {\n            throw new Error(\"'Cannot resolve a completed promise'\");\n        }\n        this.privState = PromiseState.Resolved;\n        this.privPromiseResultEvents.setResult(result);\n        for (let i = 0; i < this.privSuccessHandlers.length; i++) {\n            this.executeSuccessCallback(result, this.privSuccessHandlers[i], this.privErrorHandlers[i]);\n        }\n        this.detachHandlers();\n    }\n    reject(error) {\n        if (this.privState !== PromiseState.None) {\n            throw new Error(\"'Cannot reject a completed promise'\");\n        }\n        this.privState = PromiseState.Rejected;\n        this.privPromiseResultEvents.setError(error);\n        for (const errorHandler of this.privErrorHandlers) {\n            this.executeErrorCallback(error, errorHandler);\n        }\n        this.detachHandlers();\n    }\n    on(successCallback, errorCallback) {\n        if (successCallback == null) {\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            successCallback = () => { };\n        }\n        if (this.privState === PromiseState.None) {\n            this.privSuccessHandlers.push(successCallback);\n            this.privErrorHandlers.push(errorCallback);\n        }\n        else {\n            if (this.privState === PromiseState.Resolved) {\n                this.executeSuccessCallback(this.privPromiseResult.result, successCallback, errorCallback);\n            }\n            else if (this.privState === PromiseState.Rejected) {\n                this.executeErrorCallback(this.privPromiseResult.error, errorCallback);\n            }\n            this.detachHandlers();\n        }\n    }\n    executeSuccessCallback(result, successCallback, errorCallback) {\n        try {\n            successCallback(result);\n        }\n        catch (e) {\n            this.executeErrorCallback(`'Unhandled callback error: ${e}'`, errorCallback);\n        }\n    }\n    executeErrorCallback(error, errorCallback) {\n        if (errorCallback) {\n            try {\n                errorCallback(error);\n            }\n            catch (e) {\n                throw new Error(`'Unhandled callback error: ${e}. InnerError: ${error}'`);\n            }\n        }\n        else {\n            throw new Error(`'Unhandled error: ${error}'`);\n        }\n    }\n    detachHandlers() {\n        this.privErrorHandlers = [];\n        this.privSuccessHandlers = [];\n    }\n}\nexports.Sink = Sink;\n// eslint-disable-next-line prefer-arrow/prefer-arrow-functions\nfunction marshalPromiseToCallbacks(promise, cb, err) {\n    promise.then((val) => {\n        try {\n            if (!!cb) {\n                cb(val);\n            }\n        }\n        catch (error) {\n            if (!!err) {\n                try {\n                    if (error instanceof Error) {\n                        const typedError = error;\n                        err(typedError.name + \": \" + typedError.message);\n                    }\n                    else {\n                        err(error);\n                    }\n                    // eslint-disable-next-line no-empty\n                }\n                catch (error) { }\n            }\n        }\n    }, (error) => {\n        if (!!err) {\n            try {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n                // eslint-disable-next-line no-empty\n            }\n            catch (error) { }\n        }\n    });\n}\nexports.marshalPromiseToCallbacks = marshalPromiseToCallbacks;\n\n//# sourceMappingURL=Promise.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Queue = void 0;\nconst Error_js_1 = __webpack_require__(/*! ./Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nconst List_js_1 = __webpack_require__(/*! ./List.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js\");\nconst Promise_js_1 = __webpack_require__(/*! ./Promise.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js\");\nvar SubscriberType;\n(function (SubscriberType) {\n    SubscriberType[SubscriberType[\"Dequeue\"] = 0] = \"Dequeue\";\n    SubscriberType[SubscriberType[\"Peek\"] = 1] = \"Peek\";\n})(SubscriberType || (SubscriberType = {}));\nclass Queue {\n    constructor(list) {\n        this.privPromiseStore = new List_js_1.List();\n        this.privIsDrainInProgress = false;\n        this.privIsDisposing = false;\n        this.privDisposeReason = null;\n        this.privList = list ? list : new List_js_1.List();\n        this.privDetachables = [];\n        this.privSubscribers = new List_js_1.List();\n        this.privDetachables.push(this.privList.onAdded(() => this.drain()));\n    }\n    enqueue(item) {\n        this.throwIfDispose();\n        this.enqueueFromPromise(new Promise((resolve) => resolve(item)));\n    }\n    enqueueFromPromise(promise) {\n        this.throwIfDispose();\n        promise.then((val) => {\n            this.privList.add(val);\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n        }, () => { });\n    }\n    dequeue() {\n        this.throwIfDispose();\n        const deferredSubscriber = new Promise_js_1.Deferred();\n        if (this.privSubscribers) {\n            this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Dequeue });\n            this.drain();\n        }\n        return deferredSubscriber.promise;\n    }\n    peek() {\n        this.throwIfDispose();\n        const deferredSubscriber = new Promise_js_1.Deferred();\n        const subs = this.privSubscribers;\n        if (subs) {\n            this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Peek });\n            this.drain();\n        }\n        return deferredSubscriber.promise;\n    }\n    length() {\n        this.throwIfDispose();\n        return this.privList.length();\n    }\n    isDisposed() {\n        return this.privSubscribers == null;\n    }\n    async drainAndDispose(pendingItemProcessor, reason) {\n        if (!this.isDisposed() && !this.privIsDisposing) {\n            this.privDisposeReason = reason;\n            this.privIsDisposing = true;\n            const subs = this.privSubscribers;\n            if (subs) {\n                while (subs.length() > 0) {\n                    const subscriber = subs.removeFirst();\n                    // TODO: this needs work (Resolve(null) instead?).\n                    subscriber.deferral.resolve(undefined);\n                    // subscriber.deferral.reject(\"Disposed\");\n                }\n                // note: this block assumes cooperative multitasking, i.e.,\n                // between the if-statement and the assignment there are no\n                // thread switches.\n                // Reason is that between the initial const = this.; and this\n                // point there is the derral.resolve() operation that might have\n                // caused recursive calls to the Queue, especially, calling\n                // Dispose() on the queue alredy (which would reset the var\n                // here to null!).\n                // That should generally hold true for javascript...\n                if (this.privSubscribers === subs) {\n                    this.privSubscribers = subs;\n                }\n            }\n            for (const detachable of this.privDetachables) {\n                await detachable.detach();\n            }\n            if (this.privPromiseStore.length() > 0 && pendingItemProcessor) {\n                const promiseArray = [];\n                this.privPromiseStore.toArray().forEach((wrapper) => {\n                    promiseArray.push(wrapper);\n                });\n                return Promise.all(promiseArray).finally(() => {\n                    this.privSubscribers = null;\n                    this.privList.forEach((item) => {\n                        pendingItemProcessor(item);\n                    });\n                    this.privList = null;\n                    return;\n                }).then();\n            }\n            else {\n                this.privSubscribers = null;\n                this.privList = null;\n            }\n        }\n    }\n    async dispose(reason) {\n        await this.drainAndDispose(null, reason);\n    }\n    drain() {\n        if (!this.privIsDrainInProgress && !this.privIsDisposing) {\n            this.privIsDrainInProgress = true;\n            const subs = this.privSubscribers;\n            const lists = this.privList;\n            if (subs && lists) {\n                while (lists.length() > 0 && subs.length() > 0 && !this.privIsDisposing) {\n                    const subscriber = subs.removeFirst();\n                    if (subscriber.type === SubscriberType.Peek) {\n                        subscriber.deferral.resolve(lists.first());\n                    }\n                    else {\n                        const dequeuedItem = lists.removeFirst();\n                        subscriber.deferral.resolve(dequeuedItem);\n                    }\n                }\n                // note: this block assumes cooperative multitasking, i.e.,\n                // between the if-statement and the assignment there are no\n                // thread switches.\n                // Reason is that between the initial const = this.; and this\n                // point there is the derral.resolve() operation that might have\n                // caused recursive calls to the Queue, especially, calling\n                // Dispose() on the queue alredy (which would reset the var\n                // here to null!).\n                // That should generally hold true for javascript...\n                if (this.privSubscribers === subs) {\n                    this.privSubscribers = subs;\n                }\n                // note: this block assumes cooperative multitasking, i.e.,\n                // between the if-statement and the assignment there are no\n                // thread switches.\n                // Reason is that between the initial const = this.; and this\n                // point there is the derral.resolve() operation that might have\n                // caused recursive calls to the Queue, especially, calling\n                // Dispose() on the queue alredy (which would reset the var\n                // here to null!).\n                // That should generally hold true for javascript...\n                if (this.privList === lists) {\n                    this.privList = lists;\n                }\n            }\n            this.privIsDrainInProgress = false;\n        }\n    }\n    throwIfDispose() {\n        if (this.isDisposed()) {\n            if (this.privDisposeReason) {\n                throw new Error_js_1.InvalidOperationError(this.privDisposeReason);\n            }\n            throw new Error_js_1.ObjectDisposedError(\"Queue\");\n        }\n        else if (this.privIsDisposing) {\n            throw new Error_js_1.InvalidOperationError(\"Queue disposing\");\n        }\n    }\n}\nexports.Queue = Queue;\n\n//# sourceMappingURL=Queue.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RawWebsocketMessage.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RawWebsocketMessage.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n/* eslint-disable @typescript-eslint/no-unsafe-assignment */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RawWebsocketMessage = void 0;\nconst ConnectionMessage_js_1 = __webpack_require__(/*! ./ConnectionMessage.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js\");\nconst Error_js_1 = __webpack_require__(/*! ./Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nconst Guid_js_1 = __webpack_require__(/*! ./Guid.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js\");\nclass RawWebsocketMessage {\n    constructor(messageType, payload, id) {\n        this.privPayload = null;\n        if (!payload) {\n            throw new Error_js_1.ArgumentNullError(\"payload\");\n        }\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n        if (messageType === ConnectionMessage_js_1.MessageType.Binary && Object.getPrototypeOf(payload).constructor.name !== \"ArrayBuffer\") {\n            throw new Error_js_1.InvalidOperationError(\"Payload must be ArrayBuffer\");\n        }\n        if (messageType === ConnectionMessage_js_1.MessageType.Text && !(typeof (payload) === \"string\")) {\n            throw new Error_js_1.InvalidOperationError(\"Payload must be a string\");\n        }\n        this.privMessageType = messageType;\n        this.privPayload = payload;\n        this.privId = id ? id : Guid_js_1.createNoDashGuid();\n    }\n    get messageType() {\n        return this.privMessageType;\n    }\n    get payload() {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n        return this.privPayload;\n    }\n    get textContent() {\n        if (this.privMessageType === ConnectionMessage_js_1.MessageType.Binary) {\n            throw new Error_js_1.InvalidOperationError(\"Not supported for binary message\");\n        }\n        return this.privPayload;\n    }\n    get binaryContent() {\n        if (this.privMessageType === ConnectionMessage_js_1.MessageType.Text) {\n            throw new Error_js_1.InvalidOperationError(\"Not supported for text message\");\n        }\n        return this.privPayload;\n    }\n    get id() {\n        return this.privId;\n    }\n}\nexports.RawWebsocketMessage = RawWebsocketMessage;\n\n//# sourceMappingURL=RawWebsocketMessage.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RawWebsocketMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RiffPcmEncoder.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RiffPcmEncoder.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RiffPcmEncoder = void 0;\nclass RiffPcmEncoder {\n    constructor(actualSampleRate, desiredSampleRate) {\n        this.privActualSampleRate = actualSampleRate;\n        this.privDesiredSampleRate = desiredSampleRate;\n    }\n    encode(actualAudioFrame) {\n        const audioFrame = this.downSampleAudioFrame(actualAudioFrame, this.privActualSampleRate, this.privDesiredSampleRate);\n        if (!audioFrame) {\n            return null;\n        }\n        const audioLength = audioFrame.length * 2;\n        const buffer = new ArrayBuffer(audioLength);\n        const view = new DataView(buffer);\n        this.floatTo16BitPCM(view, 0, audioFrame);\n        return buffer;\n    }\n    setString(view, offset, str) {\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(offset + i, str.charCodeAt(i));\n        }\n    }\n    floatTo16BitPCM(view, offset, input) {\n        for (let i = 0; i < input.length; i++, offset += 2) {\n            const s = Math.max(-1, Math.min(1, input[i]));\n            view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);\n        }\n    }\n    downSampleAudioFrame(srcFrame, srcRate, dstRate) {\n        if (!srcFrame) {\n            return null;\n        }\n        if (dstRate === srcRate || dstRate > srcRate) {\n            return srcFrame;\n        }\n        const ratio = srcRate / dstRate;\n        const dstLength = Math.round(srcFrame.length / ratio);\n        const dstFrame = new Float32Array(dstLength);\n        let srcOffset = 0;\n        let dstOffset = 0;\n        while (dstOffset < dstLength) {\n            const nextSrcOffset = Math.round((dstOffset + 1) * ratio);\n            let accum = 0;\n            let count = 0;\n            while (srcOffset < nextSrcOffset && srcOffset < srcFrame.length) {\n                accum += srcFrame[srcOffset++];\n                count++;\n            }\n            dstFrame[dstOffset++] = accum / count;\n        }\n        return dstFrame;\n    }\n}\nexports.RiffPcmEncoder = RiffPcmEncoder;\n\n//# sourceMappingURL=RiffPcmEncoder.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RiffPcmEncoder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Stream.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Stream.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Stream = void 0;\nconst Error_js_1 = __webpack_require__(/*! ./Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nconst Guid_js_1 = __webpack_require__(/*! ./Guid.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js\");\nconst Queue_js_1 = __webpack_require__(/*! ./Queue.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js\");\nclass Stream {\n    constructor(streamId) {\n        this.privIsWriteEnded = false;\n        this.privIsReadEnded = false;\n        this.privId = streamId ? streamId : Guid_js_1.createNoDashGuid();\n        this.privReaderQueue = new Queue_js_1.Queue();\n    }\n    get isClosed() {\n        return this.privIsWriteEnded;\n    }\n    get isReadEnded() {\n        return this.privIsReadEnded;\n    }\n    get id() {\n        return this.privId;\n    }\n    close() {\n        if (!this.privIsWriteEnded) {\n            this.writeStreamChunk({\n                buffer: null,\n                isEnd: true,\n                timeReceived: Date.now(),\n            });\n            this.privIsWriteEnded = true;\n        }\n    }\n    writeStreamChunk(streamChunk) {\n        this.throwIfClosed();\n        if (!this.privReaderQueue.isDisposed()) {\n            try {\n                this.privReaderQueue.enqueue(streamChunk);\n            }\n            catch (e) {\n                // Do nothing\n            }\n        }\n    }\n    read() {\n        if (this.privIsReadEnded) {\n            throw new Error_js_1.InvalidOperationError(\"Stream read has already finished\");\n        }\n        return this.privReaderQueue\n            .dequeue()\n            .then(async (streamChunk) => {\n            if (streamChunk === undefined || streamChunk.isEnd) {\n                await this.privReaderQueue.dispose(\"End of stream reached\");\n            }\n            return streamChunk;\n        });\n    }\n    readEnded() {\n        if (!this.privIsReadEnded) {\n            this.privIsReadEnded = true;\n            this.privReaderQueue = new Queue_js_1.Queue();\n        }\n    }\n    throwIfClosed() {\n        if (this.privIsWriteEnded) {\n            throw new Error_js_1.InvalidOperationError(\"Stream closed\");\n        }\n    }\n}\nexports.Stream = Stream;\n\n//# sourceMappingURL=Stream.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Stream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.StringUtils = void 0;\n/**\n * String helper functions\n */\nclass StringUtils {\n    /**\n     * Formats a string by replacing the named {keys} in the string with the values contained in the replacement dictionary.\n     * @param format The format string that contains the parts to replace surrounded by {}. For example: \"wss://{region}.cts.speech.microsoft.com\".\n     * If your string needs to contain a { or } you can use the {{ and }} escape sequences respectively.\n     * @param replacements The dictionary of replacements. If a replacement is not found, it is replaced with an empty string\n     * @returns The formatted string. If you pass in a null or undefined format string, an empty string will be returned\n     */\n    static formatString(format, replacements) {\n        if (!format) {\n            return \"\";\n        }\n        if (!replacements) {\n            return format;\n        }\n        let formatted = \"\";\n        let key = \"\";\n        const appendToFormatted = (str) => {\n            formatted += str;\n        };\n        const appendToKey = (str) => {\n            key += str;\n        };\n        let appendFunc = appendToFormatted;\n        for (let i = 0; i < format.length; i++) {\n            const c = format[i];\n            const next = i + 1 < format.length ? format[i + 1] : \"\";\n            switch (c) {\n                case \"{\":\n                    if (next === \"{\") {\n                        appendFunc(\"{\");\n                        i++;\n                    }\n                    else {\n                        appendFunc = appendToKey;\n                    }\n                    break;\n                case \"}\":\n                    if (next === \"}\") {\n                        appendFunc(\"}\");\n                        i++;\n                    }\n                    else {\n                        if (replacements.hasOwnProperty(key)) {\n                            formatted += replacements[key];\n                        }\n                        appendFunc = appendToFormatted;\n                        key = \"\";\n                    }\n                    break;\n                default:\n                    appendFunc(c);\n                    break;\n            }\n        }\n        return formatted;\n    }\n}\nexports.StringUtils = StringUtils;\n\n//# sourceMappingURL=StringUtils.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Timeout.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Timeout.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Timeout = void 0;\nclass Timeout {\n    static load() {\n        // Prefilling the Maps with a function indexed by zero is necessary to be compliant with the specification.\n        const scheduledTimeoutFunctions = new Map([[0, () => { }]]); // eslint-disable-line @typescript-eslint/no-empty-function\n        const unhandledRequests = new Map();\n        // eslint-disable-next-line\n        const workerScript = `!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&\"object\"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,\"a\",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p=\"\",n(n.s=14)}([function(e,t,n){\"use strict\";n.d(t,\"a\",(function(){return i})),n.d(t,\"b\",(function(){return u})),n.d(t,\"c\",(function(){return a})),n.d(t,\"d\",(function(){return d}));const r=new Map,o=new Map,i=e=>{const t=r.get(e);if(void 0===t)throw new Error('There is no interval scheduled with the given id \"'.concat(e,'\".'));clearTimeout(t),r.delete(e)},u=e=>{const t=o.get(e);if(void 0===t)throw new Error('There is no timeout scheduled with the given id \"'.concat(e,'\".'));clearTimeout(t),o.delete(e)},f=(e,t)=>{let n,r;if(\"performance\"in self){const o=performance.now();n=o,r=e-Math.max(0,o-t)}else n=Date.now(),r=e;return{expected:n+r,remainingDelay:r}},c=(e,t,n,r)=>{const o=\"performance\"in self?performance.now():Date.now();o>n?postMessage({id:null,method:\"call\",params:{timerId:t}}):e.set(t,setTimeout(c,n-o,e,t,n))},a=(e,t,n)=>{const{expected:o,remainingDelay:i}=f(e,n);r.set(t,setTimeout(c,i,r,t,o))},d=(e,t,n)=>{const{expected:r,remainingDelay:i}=f(e,n);o.set(t,setTimeout(c,i,o,t,r))}},function(e,t,n){\"use strict\";n.r(t);var r=n(2);for(var o in r)\"default\"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(3);for(var o in i)\"default\"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(4);for(var o in u)\"default\"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o);var f=n(5);for(var o in f)\"default\"!==o&&function(e){n.d(t,e,(function(){return f[e]}))}(o);var c=n(6);for(var o in c)\"default\"!==o&&function(e){n.d(t,e,(function(){return c[e]}))}(o);var a=n(7);for(var o in a)\"default\"!==o&&function(e){n.d(t,e,(function(){return a[e]}))}(o);var d=n(8);for(var o in d)\"default\"!==o&&function(e){n.d(t,e,(function(){return d[e]}))}(o);var s=n(9);for(var o in s)\"default\"!==o&&function(e){n.d(t,e,(function(){return s[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){\"use strict\";n.r(t);var r=n(11);for(var o in r)\"default\"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(12);for(var o in i)\"default\"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(13);for(var o in u)\"default\"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){\"use strict\";n.r(t);var r=n(0),o=n(1);for(var i in o)\"default\"!==i&&function(e){n.d(t,e,(function(){return o[e]}))}(i);var u=n(10);for(var i in u)\"default\"!==i&&function(e){n.d(t,e,(function(){return u[e]}))}(i);addEventListener(\"message\",({data:e})=>{try{if(\"clear\"===e.method){const{id:t,params:{timerId:n}}=e;Object(r.b)(n),postMessage({error:null,id:t})}else{if(\"set\"!==e.method)throw new Error('The given method \"'.concat(e.method,'\" is not supported'));{const{params:{delay:t,now:n,timerId:o}}=e;Object(r.d)(t,o,n)}}}catch(t){postMessage({error:{message:t.message},id:e.id,result:null})}})}]);`;\n        const workerUrl = \"data:text/javascript;base64,\" + btoa(workerScript);\n        const worker = new Worker(workerUrl);\n        worker.addEventListener(\"message\", ({ data }) => {\n            if (Timeout.isCallNotification(data)) {\n                const { params: { timerId } } = data;\n                const idOrFunc = scheduledTimeoutFunctions.get(timerId);\n                if (typeof idOrFunc === \"number\") {\n                    const unhandledTimerId = unhandledRequests.get(idOrFunc);\n                    if (unhandledTimerId === undefined ||\n                        unhandledTimerId !== timerId) {\n                        throw new Error(\"The timer is in an undefined state.\");\n                    }\n                }\n                else if (typeof idOrFunc !== \"undefined\") {\n                    idOrFunc();\n                    // A timeout can be safely deleted because it is only called once.\n                    scheduledTimeoutFunctions.delete(timerId);\n                }\n                else {\n                    throw new Error(\"The timer is in an undefined state.\");\n                }\n            }\n            else if (Timeout.isClearResponse(data)) {\n                const { id } = data;\n                const unhandledTimerId = unhandledRequests.get(id);\n                if (unhandledTimerId === undefined) {\n                    throw new Error(\"The timer is in an undefined state.\");\n                }\n                unhandledRequests.delete(id);\n                scheduledTimeoutFunctions.delete(unhandledTimerId);\n            }\n            else {\n                const { error: { message } } = data;\n                throw new Error(message);\n            }\n        });\n        const clearTimeout = (timerId) => {\n            const id = Math.random();\n            unhandledRequests.set(id, timerId);\n            scheduledTimeoutFunctions.set(timerId, id);\n            worker.postMessage({\n                id,\n                method: \"clear\",\n                params: { timerId }\n            });\n        };\n        const setTimeout = (func, delay) => {\n            const timerId = Math.random();\n            scheduledTimeoutFunctions.set(timerId, func);\n            worker.postMessage({\n                id: null,\n                method: \"set\",\n                params: {\n                    delay,\n                    now: performance.now(),\n                    timerId\n                }\n            });\n            return timerId;\n        };\n        return {\n            clearTimeout,\n            setTimeout\n        };\n    }\n    static loadWorkerTimers() {\n        return () => {\n            if (Timeout.workerTimers !== null) {\n                return Timeout.workerTimers;\n            }\n            Timeout.workerTimers = Timeout.load();\n            return Timeout.workerTimers;\n        };\n    }\n    static isCallNotification(message) {\n        return message.method !== undefined && message.method === \"call\";\n    }\n    static isClearResponse(message) {\n        return message.error === null && typeof message.id === \"number\";\n    }\n}\nexports.Timeout = Timeout;\nTimeout.workerTimers = null;\nTimeout.clearTimeout = (timerId) => Timeout.timers().clearTimeout(timerId);\nTimeout.setTimeout = (func, delay) => Timeout.timers().setTimeout(func, delay);\nTimeout.timers = Timeout.loadWorkerTimers();\n\n//# sourceMappingURL=Timeout.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Timeout.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ActivityReceivedEventArgs.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ActivityReceivedEventArgs.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ActivityReceivedEventArgs = void 0;\n/**\n * Defines contents of received message/events.\n * @class ActivityReceivedEventArgs\n */\nclass ActivityReceivedEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {any} activity - The activity..\n     */\n    constructor(activity, audioStream) {\n        this.privActivity = activity;\n        this.privAudioStream = audioStream;\n    }\n    /**\n     * Gets the received activity\n     * @member ActivityReceivedEventArgs.prototype.activity\n     * @function\n     * @public\n     * @returns {any} the received activity.\n     */\n    get activity() {\n        return this.privActivity;\n    }\n    get audioStream() {\n        return this.privAudioStream;\n    }\n}\nexports.ActivityReceivedEventArgs = ActivityReceivedEventArgs;\n\n//# sourceMappingURL=ActivityReceivedEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ActivityReceivedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AudioOutputConfigImpl = exports.AudioConfigImpl = exports.AudioConfig = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst AudioFileWriter_js_1 = __webpack_require__(/*! ./AudioFileWriter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js\");\nconst AudioInputStream_js_1 = __webpack_require__(/*! ./AudioInputStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js\");\nconst AudioOutputStream_js_1 = __webpack_require__(/*! ./AudioOutputStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js\");\n/**\n * Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).\n * @class AudioConfig\n * Updated in version 1.11.0\n */\nclass AudioConfig {\n    /**\n     * Creates an AudioConfig object representing the default microphone on the system.\n     * @member AudioConfig.fromDefaultMicrophoneInput\n     * @function\n     * @public\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromDefaultMicrophoneInput() {\n        const pcmRecorder = new Exports_js_1.PcmRecorder(true);\n        return new AudioConfigImpl(new Exports_js_1.MicAudioSource(pcmRecorder));\n    }\n    /**\n     * Creates an AudioConfig object representing a microphone with the specified device ID.\n     * @member AudioConfig.fromMicrophoneInput\n     * @function\n     * @public\n     * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.\n     * Default microphone is used the value is omitted.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromMicrophoneInput(deviceId) {\n        const pcmRecorder = new Exports_js_1.PcmRecorder(true);\n        return new AudioConfigImpl(new Exports_js_1.MicAudioSource(pcmRecorder, deviceId));\n    }\n    /**\n     * Creates an AudioConfig object representing the specified file.\n     * @member AudioConfig.fromWavFileInput\n     * @function\n     * @public\n     * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM is supported.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromWavFileInput(file, name = \"unnamedBuffer.wav\") {\n        return new AudioConfigImpl(new Exports_js_1.FileAudioSource(file, name));\n    }\n    /**\n     * Creates an AudioConfig object representing the specified stream.\n     * @member AudioConfig.fromStreamInput\n     * @function\n     * @public\n     * @param {AudioInputStream | PullAudioInputStreamCallback | MediaStream} audioStream - Specifies the custom audio input\n     * stream. Currently, only WAV / PCM is supported.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromStreamInput(audioStream) {\n        if (audioStream instanceof Exports_js_2.PullAudioInputStreamCallback) {\n            return new AudioConfigImpl(new AudioInputStream_js_1.PullAudioInputStreamImpl(audioStream));\n        }\n        if (audioStream instanceof Exports_js_2.AudioInputStream) {\n            return new AudioConfigImpl(audioStream);\n        }\n        if (typeof MediaStream !== \"undefined\" && audioStream instanceof MediaStream) {\n            const pcmRecorder = new Exports_js_1.PcmRecorder(false);\n            return new AudioConfigImpl(new Exports_js_1.MicAudioSource(pcmRecorder, null, null, audioStream));\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n    /**\n     * Creates an AudioConfig object representing the default speaker.\n     * @member AudioConfig.fromDefaultSpeakerOutput\n     * @function\n     * @public\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromDefaultSpeakerOutput() {\n        return new AudioOutputConfigImpl(new Exports_js_2.SpeakerAudioDestination());\n    }\n    /**\n     * Creates an AudioConfig object representing the custom IPlayer object.\n     * You can use the IPlayer object to control pause, resume, etc.\n     * @member AudioConfig.fromSpeakerOutput\n     * @function\n     * @public\n     * @param {IPlayer} player - the IPlayer object for playback.\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.12.0\n     */\n    static fromSpeakerOutput(player) {\n        if (player === undefined) {\n            return AudioConfig.fromDefaultSpeakerOutput();\n        }\n        if (player instanceof Exports_js_2.SpeakerAudioDestination) {\n            return new AudioOutputConfigImpl(player);\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n    /**\n     * Creates an AudioConfig object representing a specified output audio file\n     * @member AudioConfig.fromAudioFileOutput\n     * @function\n     * @public\n     * @param {PathLike} filename - the filename of the output audio file\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromAudioFileOutput(filename) {\n        return new AudioOutputConfigImpl(new AudioFileWriter_js_1.AudioFileWriter(filename));\n    }\n    /**\n     * Creates an AudioConfig object representing a specified audio output stream\n     * @member AudioConfig.fromStreamOutput\n     * @function\n     * @public\n     * @param {AudioOutputStream | PushAudioOutputStreamCallback} audioStream - Specifies the custom audio output\n     * stream.\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromStreamOutput(audioStream) {\n        if (audioStream instanceof Exports_js_2.PushAudioOutputStreamCallback) {\n            return new AudioOutputConfigImpl(new AudioOutputStream_js_1.PushAudioOutputStreamImpl(audioStream));\n        }\n        if (audioStream instanceof Exports_js_2.PushAudioOutputStream) {\n            return new AudioOutputConfigImpl(audioStream);\n        }\n        if (audioStream instanceof Exports_js_2.PullAudioOutputStream) {\n            return new AudioOutputConfigImpl(audioStream);\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n}\nexports.AudioConfig = AudioConfig;\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @private\n * @class AudioConfigImpl\n */\nclass AudioConfigImpl extends AudioConfig {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {IAudioSource} source - An audio source.\n     */\n    constructor(source) {\n        super();\n        this.privSource = source;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return this.privSource.format;\n    }\n    /**\n     * @member AudioConfigImpl.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, err) {\n        this.privSource.turnOff().then(() => {\n            if (!!cb) {\n                cb();\n            }\n        }, (error) => {\n            if (!!err) {\n                err(error);\n            }\n        });\n    }\n    /**\n     * @member AudioConfigImpl.prototype.id\n     * @function\n     * @public\n     */\n    id() {\n        return this.privSource.id();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.turnOn\n     * @function\n     * @public\n     * @returns {Promise<void>} A promise.\n     */\n    turnOn() {\n        return this.privSource.turnOn();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.attach\n     * @function\n     * @public\n     * @param {string} audioNodeId - The audio node id.\n     * @returns {Promise<IAudioStreamNode>} A promise.\n     */\n    attach(audioNodeId) {\n        return this.privSource.attach(audioNodeId);\n    }\n    /**\n     * @member AudioConfigImpl.prototype.detach\n     * @function\n     * @public\n     * @param {string} audioNodeId - The audio node id.\n     */\n    detach(audioNodeId) {\n        return this.privSource.detach(audioNodeId);\n    }\n    /**\n     * @member AudioConfigImpl.prototype.turnOff\n     * @function\n     * @public\n     * @returns {Promise<void>} A promise.\n     */\n    turnOff() {\n        return this.privSource.turnOff();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.events\n     * @function\n     * @public\n     * @returns {EventSource<AudioSourceEvent>} An event source for audio events.\n     */\n    get events() {\n        return this.privSource.events;\n    }\n    setProperty(name, value) {\n        Contracts_js_1.Contracts.throwIfNull(value, \"value\");\n        if (undefined !== this.privSource.setProperty) {\n            this.privSource.setProperty(name, value);\n        }\n        else {\n            throw new Error(\"This AudioConfig instance does not support setting properties.\");\n        }\n    }\n    getProperty(name, def) {\n        if (undefined !== this.privSource.getProperty) {\n            return this.privSource.getProperty(name, def);\n        }\n        else {\n            throw new Error(\"This AudioConfig instance does not support getting properties.\");\n        }\n        return def;\n    }\n    get deviceInfo() {\n        return this.privSource.deviceInfo;\n    }\n}\nexports.AudioConfigImpl = AudioConfigImpl;\nclass AudioOutputConfigImpl extends AudioConfig {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {IAudioDestination} destination - An audio destination.\n     */\n    constructor(destination) {\n        super();\n        this.privDestination = destination;\n    }\n    set format(format) {\n        this.privDestination.format = format;\n    }\n    write(buffer) {\n        this.privDestination.write(buffer);\n    }\n    close() {\n        this.privDestination.close();\n    }\n    id() {\n        return this.privDestination.id();\n    }\n    setProperty() {\n        throw new Error(\"This AudioConfig instance does not support setting properties.\");\n    }\n    getProperty() {\n        throw new Error(\"This AudioConfig instance does not support getting properties.\");\n    }\n}\nexports.AudioOutputConfigImpl = AudioOutputConfigImpl;\n\n//# sourceMappingURL=AudioConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js ***!
  \**********************************************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AudioFileWriter = void 0;\nconst fs = __importStar(__webpack_require__(/*! fs */ \"fs\"));\nconst Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nclass AudioFileWriter {\n    constructor(filename) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(fs.openSync, \"\\nFile System access not available, please use Push or PullAudioOutputStream\");\n        this.privFd = fs.openSync(filename, \"w\");\n    }\n    set format(format) {\n        Contracts_js_1.Contracts.throwIfNotUndefined(this.privAudioFormat, \"format is already set\");\n        this.privAudioFormat = format;\n        let headerOffset = 0;\n        if (this.privAudioFormat.hasHeader) {\n            headerOffset = this.privAudioFormat.header.byteLength;\n        }\n        if (this.privFd !== undefined) {\n            this.privWriteStream = fs.createWriteStream(\"\", { fd: this.privFd, start: headerOffset, autoClose: false });\n        }\n    }\n    write(buffer) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privAudioFormat, \"must set format before writing.\");\n        if (this.privWriteStream !== undefined) {\n            this.privWriteStream.write(new Uint8Array(buffer.slice(0)));\n        }\n    }\n    close() {\n        if (this.privFd !== undefined) {\n            this.privWriteStream.on(\"finish\", () => {\n                if (this.privAudioFormat.hasHeader) {\n                    this.privAudioFormat.updateHeader(this.privWriteStream.bytesWritten);\n                    fs.writeSync(this.privFd, new Int8Array(this.privAudioFormat.header), 0, this.privAudioFormat.header.byteLength, 0);\n                }\n                fs.closeSync(this.privFd);\n                this.privFd = undefined;\n            });\n            this.privWriteStream.end();\n        }\n    }\n    id() {\n        return this.privId;\n    }\n}\nexports.AudioFileWriter = AudioFileWriter;\n\n//# sourceMappingURL=AudioFileWriter.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PullAudioInputStreamImpl = exports.PullAudioInputStream = exports.PushAudioInputStreamImpl = exports.PushAudioInputStream = exports.AudioInputStream = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Guid_js_1 = __webpack_require__(/*! ../../common/Guid.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst AudioStreamFormat_js_1 = __webpack_require__(/*! ./AudioStreamFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js\");\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @class AudioInputStream\n */\nclass AudioInputStream {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Creates a memory backed PushAudioInputStream with the specified audio format.\n     * @member AudioInputStream.createPushStream\n     * @function\n     * @public\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * written to the push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PushAudioInputStream} The audio input stream being created.\n     */\n    static createPushStream(format) {\n        return PushAudioInputStream.create(format);\n    }\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for read()\n     * and close() methods.\n     * @member AudioInputStream.createPullStream\n     * @function\n     * @public\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from\n     * PullAudioInputStreamCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from\n     * the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PullAudioInputStream} The audio input stream being created.\n     */\n    static createPullStream(callback, format) {\n        return PullAudioInputStream.create(callback, format);\n        // throw new Error(\"Oops\");\n    }\n}\nexports.AudioInputStream = AudioInputStream;\n/**\n * Represents memory backed push audio input stream used for custom audio input configurations.\n * @class PushAudioInputStream\n */\nclass PushAudioInputStream extends AudioInputStream {\n    /**\n     * Creates a memory backed PushAudioInputStream with the specified audio format.\n     * @member PushAudioInputStream.create\n     * @function\n     * @public\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the\n     * push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PushAudioInputStream} The push audio input stream being created.\n     */\n    static create(format) {\n        return new PushAudioInputStreamImpl(format);\n    }\n}\nexports.PushAudioInputStream = PushAudioInputStream;\n/**\n * Represents memory backed push audio input stream used for custom audio input configurations.\n * @private\n * @class PushAudioInputStreamImpl\n */\nclass PushAudioInputStreamImpl extends PushAudioInputStream {\n    /**\n     * Creates and initalizes an instance with the given values.\n     * @constructor\n     * @param {AudioStreamFormat} format - The audio stream format.\n     */\n    constructor(format) {\n        super();\n        if (format === undefined) {\n            this.privFormat = AudioStreamFormat_js_1.AudioStreamFormatImpl.getDefaultInputFormat();\n        }\n        else {\n            this.privFormat = format;\n        }\n        this.privEvents = new Exports_js_2.EventSource();\n        this.privId = Guid_js_1.createNoDashGuid();\n        this.privStream = new Exports_js_2.ChunkedArrayBufferStream(this.privFormat.avgBytesPerSec / 10);\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return Promise.resolve(this.privFormat);\n    }\n    /**\n     * Writes the audio data specified by making an internal copy of the data.\n     * @member PushAudioInputStreamImpl.prototype.write\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.\n     */\n    write(dataBuffer) {\n        this.privStream.writeStreamChunk({\n            buffer: dataBuffer,\n            isEnd: false,\n            timeReceived: Date.now()\n        });\n    }\n    /**\n     * Closes the stream.\n     * @member PushAudioInputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privStream.close();\n    }\n    id() {\n        return this.privId;\n    }\n    turnOn() {\n        this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id\n        this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));\n        return;\n    }\n    async attach(audioNodeId) {\n        this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n        await this.turnOn();\n        const stream = this.privStream;\n        this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n        return {\n            detach: async () => {\n                this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n                return this.turnOff();\n            },\n            id: () => audioNodeId,\n            read: () => stream.read(),\n        };\n    }\n    detach(audioNodeId) {\n        this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n    }\n    turnOff() {\n        return;\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return Promise.resolve({\n            bitspersample: this.privFormat.bitsPerSample,\n            channelcount: this.privFormat.channels,\n            connectivity: Exports_js_1.connectivity.Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"PushStream\",\n            samplerate: this.privFormat.samplesPerSec,\n            type: Exports_js_1.type.Stream,\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        Exports_js_2.Events.instance.onEvent(event);\n    }\n    toBuffer(arrayBuffer) {\n        const buf = Buffer.alloc(arrayBuffer.byteLength);\n        const view = new Uint8Array(arrayBuffer);\n        for (let i = 0; i < buf.length; ++i) {\n            buf[i] = view[i];\n        }\n        return buf;\n    }\n}\nexports.PushAudioInputStreamImpl = PushAudioInputStreamImpl;\n/*\n * Represents audio input stream used for custom audio input configurations.\n * @class PullAudioInputStream\n */\nclass PullAudioInputStream extends AudioInputStream {\n    /**\n     * Creates and initializes and instance.\n     * @constructor\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for\n     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).\n     * @member PullAudioInputStream.create\n     * @function\n     * @public\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,\n     * derived from PullAudioInputStreamCustomCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PullAudioInputStream} The push audio input stream being created.\n     */\n    static create(callback, format) {\n        return new PullAudioInputStreamImpl(callback, format);\n    }\n}\nexports.PullAudioInputStream = PullAudioInputStream;\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @private\n * @class PullAudioInputStreamImpl\n */\nclass PullAudioInputStreamImpl extends PullAudioInputStream {\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for\n     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).\n     * @constructor\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,\n     * derived from PullAudioInputStreamCustomCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     */\n    constructor(callback, format) {\n        super();\n        if (undefined === format) {\n            this.privFormat = Exports_js_3.AudioStreamFormat.getDefaultInputFormat();\n        }\n        else {\n            this.privFormat = format;\n        }\n        this.privEvents = new Exports_js_2.EventSource();\n        this.privId = Guid_js_1.createNoDashGuid();\n        this.privCallback = callback;\n        this.privIsClosed = false;\n        this.privBufferSize = this.privFormat.avgBytesPerSec / 10;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return Promise.resolve(this.privFormat);\n    }\n    /**\n     * Closes the stream.\n     * @member PullAudioInputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privIsClosed = true;\n        this.privCallback.close();\n    }\n    id() {\n        return this.privId;\n    }\n    turnOn() {\n        this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id\n        this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));\n        return;\n    }\n    async attach(audioNodeId) {\n        this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n        await this.turnOn();\n        this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n        return {\n            detach: () => {\n                this.privCallback.close();\n                this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n                return this.turnOff();\n            },\n            id: () => audioNodeId,\n            read: () => {\n                let totalBytes = 0;\n                let transmitBuff;\n                // Until we have the minimum number of bytes to send in a transmission, keep asking for more.\n                while (totalBytes < this.privBufferSize) {\n                    // Sizing the read buffer to the delta between the perfect size and what's left means we won't ever get too much\n                    // data back.\n                    const readBuff = new ArrayBuffer(this.privBufferSize - totalBytes);\n                    const pulledBytes = this.privCallback.read(readBuff);\n                    // If there is no return buffer yet defined, set the return buffer to the that was just populated.\n                    // This was, if we have enough data there's no copy penalty, but if we don't we have a buffer that's the\n                    // preferred size allocated.\n                    if (undefined === transmitBuff) {\n                        transmitBuff = readBuff;\n                    }\n                    else {\n                        // Not the first bite at the apple, so fill the return buffer with the data we got back.\n                        const intView = new Int8Array(transmitBuff);\n                        intView.set(new Int8Array(readBuff), totalBytes);\n                    }\n                    // If there are no bytes to read, just break out and be done.\n                    if (0 === pulledBytes) {\n                        break;\n                    }\n                    totalBytes += pulledBytes;\n                }\n                return Promise.resolve({\n                    buffer: transmitBuff.slice(0, totalBytes),\n                    isEnd: this.privIsClosed || totalBytes === 0,\n                    timeReceived: Date.now(),\n                });\n            },\n        };\n    }\n    detach(audioNodeId) {\n        this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n    }\n    turnOff() {\n        return;\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return Promise.resolve({\n            bitspersample: this.privFormat.bitsPerSample,\n            channelcount: this.privFormat.channels,\n            connectivity: Exports_js_1.connectivity.Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"PullStream\",\n            samplerate: this.privFormat.samplesPerSec,\n            type: Exports_js_1.type.Stream,\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        Exports_js_2.Events.instance.onEvent(event);\n    }\n}\nexports.PullAudioInputStreamImpl = PullAudioInputStreamImpl;\n\n//# sourceMappingURL=AudioInputStream.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AudioOutputFormatImpl = void 0;\nconst SpeechSynthesisOutputFormat_js_1 = __webpack_require__(/*! ../SpeechSynthesisOutputFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js\");\nconst AudioStreamFormat_js_1 = __webpack_require__(/*! ./AudioStreamFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js\");\n/**\n * @private\n * @class AudioOutputFormatImpl\n * Updated in version 1.17.0\n */\n// eslint-disable-next-line max-classes-per-file\nclass AudioOutputFormatImpl extends AudioStreamFormat_js_1.AudioStreamFormatImpl {\n    /**\n     * Creates an instance with the given values.\n     * @constructor\n     * @param formatTag\n     * @param {number} channels - Number of channels.\n     * @param {number} samplesPerSec - Samples per second.\n     * @param {number} avgBytesPerSec - Average bytes per second.\n     * @param {number} blockAlign - Block alignment.\n     * @param {number} bitsPerSample - Bits per sample.\n     * @param {string} audioFormatString - Audio format string\n     * @param {string} requestAudioFormatString - Audio format string sent to service.\n     * @param {boolean} hasHeader - If the format has header or not.\n     */\n    constructor(formatTag, channels, samplesPerSec, avgBytesPerSec, blockAlign, bitsPerSample, audioFormatString, requestAudioFormatString, hasHeader) {\n        super(samplesPerSec, bitsPerSample, channels, formatTag);\n        this.formatTag = formatTag;\n        this.avgBytesPerSec = avgBytesPerSec;\n        this.blockAlign = blockAlign;\n        this.priAudioFormatString = audioFormatString;\n        this.priRequestAudioFormatString = requestAudioFormatString;\n        this.priHasHeader = hasHeader;\n    }\n    static fromSpeechSynthesisOutputFormat(speechSynthesisOutputFormat) {\n        if (speechSynthesisOutputFormat === undefined) {\n            return AudioOutputFormatImpl.getDefaultOutputFormat();\n        }\n        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString[speechSynthesisOutputFormat]);\n    }\n    static fromSpeechSynthesisOutputFormatString(speechSynthesisOutputFormatString) {\n        switch (speechSynthesisOutputFormatString) {\n            case \"raw-8khz-8bit-mono-mulaw\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-16khz-16kbps-mono-siren\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, \"audio-16khz-16kbps-mono-siren\", true);\n            case \"audio-16khz-16kbps-mono-siren\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-32kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 16000, 32 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-128kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 16000, 128 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-64kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 16000, 64 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-48kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 24000, 48 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-96kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 24000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-160kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 24000, 160 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-16khz-16bit-mono-truesilk\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.SILKSkype, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-8khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, \"raw-8khz-16bit-mono-pcm\", true);\n            case \"riff-24khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, \"raw-24khz-16bit-mono-pcm\", true);\n            case \"riff-8khz-8bit-mono-mulaw\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, \"raw-8khz-8bit-mono-mulaw\", true);\n            case \"raw-16khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, \"raw-16khz-16bit-mono-pcm\", false);\n            case \"raw-24khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, \"raw-24khz-16bit-mono-pcm\", false);\n            case \"raw-8khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, \"raw-8khz-16bit-mono-pcm\", false);\n            case \"ogg-16khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OGG_OPUS, 1, 16000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"ogg-24khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OGG_OPUS, 1, 24000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-48khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, \"raw-48khz-16bit-mono-pcm\", false);\n            case \"riff-48khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, \"raw-48khz-16bit-mono-pcm\", true);\n            case \"audio-48khz-96kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 48000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-48khz-192kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 48000, 192 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"ogg-48khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OGG_OPUS, 1, 48000, 12000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-16khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.WEBM_OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-24khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.WEBM_OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-24khz-16bit-24kbps-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.WEBM_OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-16bit-32kbps-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-48kbps-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-24kbps-mono-opus\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-mono-flac\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.FLAC, 1, 24000, 24000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-48khz-16bit-mono-flac\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.FLAC, 1, 48000, 30000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-24khz-16bit-mono-truesilk\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.SILKSkype, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-8khz-8bit-mono-alaw\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-8khz-8bit-mono-alaw\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, \"raw-8khz-8bit-mono-alaw\", true);\n            case \"raw-22050hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-22050hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, \"raw-22050hz-16bit-mono-pcm\", true);\n            case \"raw-44100hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-44100hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, \"raw-44100hz-16bit-mono-pcm\", true);\n            case \"amr-wb-16000h\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.AMR_WB, 1, 16000, 3052, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"g722-16khz-64kbps\":\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.G722, 1, 16000, 8000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-16khz-16bit-mono-pcm\":\n            default:\n                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, \"riff-16khz-16bit-mono-pcm\", \"raw-16khz-16bit-mono-pcm\", true);\n        }\n    }\n    static getDefaultOutputFormat() {\n        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString((typeof window !== \"undefined\") ? \"audio-24khz-48kbitrate-mono-mp3\" : \"riff-16khz-16bit-mono-pcm\");\n    }\n    /**\n     * Specifies if this audio output format has a header\n     * @boolean AudioOutputFormatImpl.prototype.hasHeader\n     * @function\n     * @public\n     */\n    get hasHeader() {\n        return this.priHasHeader;\n    }\n    /**\n     * Specifies the header of this format\n     * @ArrayBuffer AudioOutputFormatImpl.prototype.header\n     * @function\n     * @public\n     */\n    get header() {\n        if (this.hasHeader) {\n            return this.privHeader;\n        }\n        return undefined;\n    }\n    /**\n     * Updates the header based on the audio length\n     * @member AudioOutputFormatImpl.updateHeader\n     * @function\n     * @public\n     * @param {number} audioLength - the audio length\n     */\n    updateHeader(audioLength) {\n        if (this.priHasHeader) {\n            const view = new DataView(this.privHeader);\n            view.setUint32(4, audioLength + this.privHeader.byteLength - 8, true);\n            view.setUint32(40, audioLength, true);\n        }\n    }\n    /**\n     * Specifies the audio format string to be sent to the service\n     * @string AudioOutputFormatImpl.prototype.requestAudioFormatString\n     * @function\n     * @public\n     */\n    get requestAudioFormatString() {\n        return this.priRequestAudioFormatString;\n    }\n    /**\n     * Adds audio header\n     * @param audio the raw audio without header\n     * @returns the audio with header if applicable\n     */\n    addHeader(audio) {\n        if (!this.hasHeader) {\n            return audio;\n        }\n        this.updateHeader(audio.byteLength);\n        const tmp = new Uint8Array(audio.byteLength + this.header.byteLength);\n        tmp.set(new Uint8Array(this.header), 0);\n        tmp.set(new Uint8Array(audio), this.header.byteLength);\n        return tmp.buffer;\n    }\n}\nexports.AudioOutputFormatImpl = AudioOutputFormatImpl;\nAudioOutputFormatImpl.SpeechSynthesisOutputFormatToString = {\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw]: \"raw-8khz-8bit-mono-mulaw\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren]: \"riff-16khz-16kbps-mono-siren\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren]: \"audio-16khz-16kbps-mono-siren\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3]: \"audio-16khz-32kbitrate-mono-mp3\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3]: \"audio-16khz-128kbitrate-mono-mp3\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3]: \"audio-16khz-64kbitrate-mono-mp3\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3]: \"audio-24khz-48kbitrate-mono-mp3\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3]: \"audio-24khz-96kbitrate-mono-mp3\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3]: \"audio-24khz-160kbitrate-mono-mp3\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk]: \"raw-16khz-16bit-mono-truesilk\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm]: \"riff-16khz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm]: \"riff-8khz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm]: \"riff-24khz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw]: \"riff-8khz-8bit-mono-mulaw\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm]: \"raw-16khz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm]: \"raw-24khz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm]: \"raw-8khz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus]: \"ogg-16khz-16bit-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus]: \"ogg-24khz-16bit-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm]: \"raw-48khz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm]: \"riff-48khz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3]: \"audio-48khz-96kbitrate-mono-mp3\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3]: \"audio-48khz-192kbitrate-mono-mp3\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus]: \"ogg-48khz-16bit-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus]: \"webm-16khz-16bit-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus]: \"webm-24khz-16bit-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus]: \"webm-24khz-16bit-24kbps-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk]: \"raw-24khz-16bit-mono-truesilk\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw]: \"raw-8khz-8bit-mono-alaw\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw]: \"riff-8khz-8bit-mono-alaw\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus]: \"audio-16khz-16bit-32kbps-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus]: \"audio-24khz-16bit-48kbps-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus]: \"audio-24khz-16bit-24kbps-mono-opus\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm]: \"raw-22050hz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm]: \"riff-22050hz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm]: \"raw-44100hz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm]: \"riff-44100hz-16bit-mono-pcm\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.AmrWb16000Hz]: \"amr-wb-16000hz\",\n    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.G72216Khz64Kbps]: \"g722-16khz-64kbps\",\n};\n\n//# sourceMappingURL=AudioOutputFormat.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PushAudioOutputStreamImpl = exports.PushAudioOutputStream = exports.PullAudioOutputStreamImpl = exports.PullAudioOutputStream = exports.AudioOutputStream = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst AudioOutputFormat_js_1 = __webpack_require__(/*! ./AudioOutputFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js\");\n/**\n * Represents audio output stream used for custom audio output configurations.\n * @class AudioOutputStream\n */\nclass AudioOutputStream {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Creates a memory backed PullAudioOutputStream with the specified audio format.\n     * @member AudioOutputStream.createPullStream\n     * @function\n     * @public\n     * @returns {PullAudioOutputStream} The audio output stream being created.\n     */\n    static createPullStream() {\n        return PullAudioOutputStream.create();\n    }\n}\nexports.AudioOutputStream = AudioOutputStream;\n/**\n * Represents memory backed push audio output stream used for custom audio output configurations.\n * @class PullAudioOutputStream\n */\nclass PullAudioOutputStream extends AudioOutputStream {\n    /**\n     * Creates a memory backed PullAudioOutputStream with the specified audio format.\n     * @member PullAudioOutputStream.create\n     * @function\n     * @public\n     * @returns {PullAudioOutputStream} The push audio output stream being created.\n     */\n    static create() {\n        return new PullAudioOutputStreamImpl();\n    }\n}\nexports.PullAudioOutputStream = PullAudioOutputStream;\n/**\n * Represents memory backed push audio output stream used for custom audio output configurations.\n * @private\n * @class PullAudioOutputStreamImpl\n */\nclass PullAudioOutputStreamImpl extends PullAudioOutputStream {\n    /**\n     * Creates and initializes an instance with the given values.\n     * @constructor\n     */\n    constructor() {\n        super();\n        this.privId = Exports_js_1.createNoDashGuid();\n        this.privStream = new Exports_js_1.Stream();\n    }\n    /**\n     * Sets the format information to the stream. For internal use only.\n     * @param {AudioStreamFormat} format - the format to be set.\n     */\n    set format(format) {\n        if (format === undefined || format === null) {\n            this.privFormat = AudioOutputFormat_js_1.AudioOutputFormatImpl.getDefaultOutputFormat();\n        }\n        this.privFormat = format;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return this.privFormat;\n    }\n    /**\n     * Checks if the stream is closed\n     * @member PullAudioOutputStreamImpl.prototype.isClosed\n     * @property\n     * @public\n     */\n    get isClosed() {\n        return this.privStream.isClosed;\n    }\n    /**\n     * Gets the id of the stream\n     * @member PullAudioOutputStreamImpl.prototype.id\n     * @property\n     * @public\n     */\n    id() {\n        return this.privId;\n    }\n    /**\n     * Reads audio data from the internal buffer.\n     * @member PullAudioOutputStreamImpl.prototype.read\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - An ArrayBuffer to store the read data.\n     * @returns {Promise<number>} - Audio buffer length has been read.\n     */\n    async read(dataBuffer) {\n        const intView = new Int8Array(dataBuffer);\n        let totalBytes = 0;\n        if (this.privLastChunkView !== undefined) {\n            if (this.privLastChunkView.length > dataBuffer.byteLength) {\n                intView.set(this.privLastChunkView.slice(0, dataBuffer.byteLength));\n                this.privLastChunkView = this.privLastChunkView.slice(dataBuffer.byteLength);\n                return Promise.resolve(dataBuffer.byteLength);\n            }\n            intView.set(this.privLastChunkView);\n            totalBytes = this.privLastChunkView.length;\n            this.privLastChunkView = undefined;\n        }\n        // Until we have the minimum number of bytes to send in a transmission, keep asking for more.\n        while (totalBytes < dataBuffer.byteLength && !this.privStream.isReadEnded) {\n            const chunk = await this.privStream.read();\n            if (chunk !== undefined && !chunk.isEnd) {\n                let tmpBuffer;\n                if (chunk.buffer.byteLength > dataBuffer.byteLength - totalBytes) {\n                    tmpBuffer = chunk.buffer.slice(0, dataBuffer.byteLength - totalBytes);\n                    this.privLastChunkView = new Int8Array(chunk.buffer.slice(dataBuffer.byteLength - totalBytes));\n                }\n                else {\n                    tmpBuffer = chunk.buffer;\n                }\n                intView.set(new Int8Array(tmpBuffer), totalBytes);\n                totalBytes += tmpBuffer.byteLength;\n            }\n            else {\n                this.privStream.readEnded();\n            }\n        }\n        return totalBytes;\n    }\n    /**\n     * Writes the audio data specified by making an internal copy of the data.\n     * @member PullAudioOutputStreamImpl.prototype.write\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.\n     */\n    write(dataBuffer) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privStream, \"must set format before writing\");\n        this.privStream.writeStreamChunk({\n            buffer: dataBuffer,\n            isEnd: false,\n            timeReceived: Date.now()\n        });\n    }\n    /**\n     * Closes the stream.\n     * @member PullAudioOutputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privStream.close();\n    }\n}\nexports.PullAudioOutputStreamImpl = PullAudioOutputStreamImpl;\n/*\n * Represents audio output stream used for custom audio output configurations.\n * @class PushAudioOutputStream\n */\nclass PushAudioOutputStream extends AudioOutputStream {\n    /**\n     * Creates and initializes and instance.\n     * @constructor\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates a PushAudioOutputStream that delegates to the specified callback interface for\n     * write() and close() methods.\n     * @member PushAudioOutputStream.create\n     * @function\n     * @public\n     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,\n     * derived from PushAudioOutputStreamCallback\n     * @returns {PushAudioOutputStream} The push audio output stream being created.\n     */\n    static create(callback) {\n        return new PushAudioOutputStreamImpl(callback);\n    }\n}\nexports.PushAudioOutputStream = PushAudioOutputStream;\n/**\n * Represents audio output stream used for custom audio output configurations.\n * @private\n * @class PushAudioOutputStreamImpl\n */\nclass PushAudioOutputStreamImpl extends PushAudioOutputStream {\n    /**\n     * Creates a PushAudioOutputStream that delegates to the specified callback interface for\n     * read() and close() methods.\n     * @constructor\n     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,\n     * derived from PushAudioOutputStreamCallback\n     */\n    constructor(callback) {\n        super();\n        this.privId = Exports_js_1.createNoDashGuid();\n        this.privCallback = callback;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    set format(format) { }\n    write(buffer) {\n        if (!!this.privCallback.write) {\n            this.privCallback.write(buffer);\n        }\n    }\n    close() {\n        if (!!this.privCallback.close) {\n            this.privCallback.close();\n        }\n    }\n    id() {\n        return this.privId;\n    }\n}\nexports.PushAudioOutputStreamImpl = PushAudioOutputStreamImpl;\n\n//# sourceMappingURL=AudioOutputStream.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AudioStreamFormatImpl = exports.AudioStreamFormat = exports.AudioFormatTag = void 0;\n// eslint-disable-next-line max-classes-per-file\nvar AudioFormatTag;\n(function (AudioFormatTag) {\n    AudioFormatTag[AudioFormatTag[\"PCM\"] = 1] = \"PCM\";\n    AudioFormatTag[AudioFormatTag[\"MuLaw\"] = 2] = \"MuLaw\";\n    AudioFormatTag[AudioFormatTag[\"Siren\"] = 3] = \"Siren\";\n    AudioFormatTag[AudioFormatTag[\"MP3\"] = 4] = \"MP3\";\n    AudioFormatTag[AudioFormatTag[\"SILKSkype\"] = 5] = \"SILKSkype\";\n    AudioFormatTag[AudioFormatTag[\"OGG_OPUS\"] = 6] = \"OGG_OPUS\";\n    AudioFormatTag[AudioFormatTag[\"WEBM_OPUS\"] = 7] = \"WEBM_OPUS\";\n    AudioFormatTag[AudioFormatTag[\"ALaw\"] = 8] = \"ALaw\";\n    AudioFormatTag[AudioFormatTag[\"FLAC\"] = 9] = \"FLAC\";\n    AudioFormatTag[AudioFormatTag[\"OPUS\"] = 10] = \"OPUS\";\n    AudioFormatTag[AudioFormatTag[\"AMR_WB\"] = 11] = \"AMR_WB\";\n    AudioFormatTag[AudioFormatTag[\"G722\"] = 12] = \"G722\";\n})(AudioFormatTag = exports.AudioFormatTag || (exports.AudioFormatTag = {}));\n/**\n * Represents audio stream format used for custom audio input configurations.\n * @class AudioStreamFormat\n */\nclass AudioStreamFormat {\n    /**\n     * Creates an audio stream format object representing the default audio stream\n     * format (16KHz 16bit mono PCM).\n     * @member AudioStreamFormat.getDefaultInputFormat\n     * @function\n     * @public\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getDefaultInputFormat() {\n        return AudioStreamFormatImpl.getDefaultInputFormat();\n    }\n    /**\n     * Creates an audio stream format object with the specified format characteristics.\n     * @member AudioStreamFormat.getWaveFormat\n     * @function\n     * @public\n     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n     * @param {number} bitsPerSample - Bits per sample, typically 16.\n     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n     * uses one channel and stereo data uses two channels.\n     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getWaveFormat(samplesPerSecond, bitsPerSample, channels, format) {\n        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels, format);\n    }\n    /**\n     * Creates an audio stream format object with the specified pcm waveformat characteristics.\n     * @member AudioStreamFormat.getWaveFormatPCM\n     * @function\n     * @public\n     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n     * @param {number} bitsPerSample - Bits per sample, typically 16.\n     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n     * uses one channel and stereo data uses two channels.\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {\n        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);\n    }\n}\nexports.AudioStreamFormat = AudioStreamFormat;\n/**\n * @private\n * @class AudioStreamFormatImpl\n */\nclass AudioStreamFormatImpl extends AudioStreamFormat {\n    /**\n     * Creates an instance with the given values.\n     * @constructor\n     * @param {number} samplesPerSec - Samples per second.\n     * @param {number} bitsPerSample - Bits per sample.\n     * @param {number} channels - Number of channels.\n     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n     */\n    constructor(samplesPerSec = 16000, bitsPerSample = 16, channels = 1, format = AudioFormatTag.PCM) {\n        super();\n        let isWavFormat = true;\n        /* 1 for PCM; 6 for alaw; 7 for mulaw */\n        switch (format) {\n            case AudioFormatTag.PCM:\n                this.formatTag = 1;\n                break;\n            case AudioFormatTag.ALaw:\n                this.formatTag = 6;\n                break;\n            case AudioFormatTag.MuLaw:\n                this.formatTag = 7;\n                break;\n            default:\n                isWavFormat = false;\n        }\n        this.bitsPerSample = bitsPerSample;\n        this.samplesPerSec = samplesPerSec;\n        this.channels = channels;\n        this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);\n        this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);\n        if (isWavFormat) {\n            this.privHeader = new ArrayBuffer(44);\n            // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView\n            const view = new DataView(this.privHeader);\n            /* RIFF identifier */\n            this.setString(view, 0, \"RIFF\");\n            /* file length */\n            view.setUint32(4, 0, true);\n            /* RIFF type & Format */\n            this.setString(view, 8, \"WAVEfmt \");\n            /* format chunk length */\n            view.setUint32(16, 16, true);\n            /* audio format */\n            view.setUint16(20, this.formatTag, true);\n            /* channel count */\n            view.setUint16(22, this.channels, true);\n            /* sample rate */\n            view.setUint32(24, this.samplesPerSec, true);\n            /* byte rate (sample rate * block align) */\n            view.setUint32(28, this.avgBytesPerSec, true);\n            /* block align (channel count * bytes per sample) */\n            view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);\n            /* bits per sample */\n            view.setUint16(34, this.bitsPerSample, true);\n            /* data chunk identifier */\n            this.setString(view, 36, \"data\");\n            /* data chunk length */\n            view.setUint32(40, 0, true);\n        }\n    }\n    /**\n     * Retrieves the default input format.\n     * @member AudioStreamFormatImpl.getDefaultInputFormat\n     * @function\n     * @public\n     * @returns {AudioStreamFormatImpl} The default input format.\n     */\n    static getDefaultInputFormat() {\n        return new AudioStreamFormatImpl();\n    }\n    /**\n     * Creates an audio context appropriate to current browser\n     * @member AudioStreamFormatImpl.getAudioContext\n     * @function\n     * @public\n     * @returns {AudioContext} An audio context instance\n     */\n    /* eslint-disable */\n    static getAudioContext(sampleRate) {\n        // Workaround for Speech SDK bug in Safari.\n        const AudioContext = window.AudioContext // our preferred impl\n            || window.webkitAudioContext // fallback, mostly when on Safari\n            || false; // could not find.\n        // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext\n        if (!!AudioContext) {\n            if (sampleRate !== undefined && navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n                return new AudioContext({ sampleRate });\n            }\n            else {\n                return new AudioContext();\n            }\n        }\n        else {\n            throw new Error(\"Browser does not support Web Audio API (AudioContext is not available).\");\n        }\n    }\n    /* eslint-enable */\n    /**\n     * Closes the configuration object.\n     * @member AudioStreamFormatImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n    get header() {\n        return this.privHeader;\n    }\n    setString(view, offset, str) {\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(offset + i, str.charCodeAt(i));\n        }\n    }\n}\nexports.AudioStreamFormatImpl = AudioStreamFormatImpl;\n\n//# sourceMappingURL=AudioStreamFormat.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/BaseAudioPlayer.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/BaseAudioPlayer.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BaseAudioPlayer = void 0;\nconst Error_js_1 = __webpack_require__(/*! ../../common/Error.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js\");\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst AudioStreamFormat_js_1 = __webpack_require__(/*! ./AudioStreamFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js\");\n/**\n * Base audio player class\n * TODO: Plays only PCM for now.\n * @class\n */\nclass BaseAudioPlayer {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {AudioStreamFormat} audioFormat audio stream format recognized by the player.\n     */\n    constructor(audioFormat) {\n        this.audioContext = null;\n        this.gainNode = null;\n        this.autoUpdateBufferTimer = 0;\n        if (audioFormat === undefined) {\n            audioFormat = Exports_js_1.AudioStreamFormat.getDefaultInputFormat();\n        }\n        this.init(audioFormat);\n    }\n    /**\n     * play Audio sample\n     * @param newAudioData audio data to be played.\n     */\n    playAudioSample(newAudioData, cb, err) {\n        try {\n            this.ensureInitializedContext();\n            const audioData = this.formatAudioData(newAudioData);\n            const newSamplesData = new Float32Array(this.samples.length + audioData.length);\n            newSamplesData.set(this.samples, 0);\n            newSamplesData.set(audioData, this.samples.length);\n            this.samples = newSamplesData;\n            if (!!cb) {\n                cb();\n            }\n        }\n        catch (e) {\n            if (!!err) {\n                err(e);\n            }\n        }\n    }\n    /**\n     * stops audio and clears the buffers\n     */\n    stopAudio(cb, err) {\n        if (this.audioContext !== null) {\n            this.samples = new Float32Array();\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            clearInterval(this.autoUpdateBufferTimer);\n            this.audioContext.close().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n            this.audioContext = null;\n        }\n    }\n    init(audioFormat) {\n        this.audioFormat = audioFormat;\n        this.samples = new Float32Array();\n    }\n    ensureInitializedContext() {\n        if (this.audioContext === null) {\n            this.createAudioContext();\n            const timerPeriod = 200;\n            this.autoUpdateBufferTimer = setInterval(() => {\n                this.updateAudioBuffer();\n            }, timerPeriod);\n        }\n    }\n    createAudioContext() {\n        // new ((window as any).AudioContext || (window as any).webkitAudioContext)();\n        this.audioContext = AudioStreamFormat_js_1.AudioStreamFormatImpl.getAudioContext();\n        // TODO: Various examples shows this gain node, it does not seem to be needed unless we plan\n        // to control the volume, not likely\n        this.gainNode = this.audioContext.createGain();\n        this.gainNode.gain.value = 1;\n        this.gainNode.connect(this.audioContext.destination);\n        this.startTime = this.audioContext.currentTime;\n    }\n    formatAudioData(audioData) {\n        switch (this.audioFormat.bitsPerSample) {\n            case 8:\n                return this.formatArrayBuffer(new Int8Array(audioData), 128);\n            case 16:\n                return this.formatArrayBuffer(new Int16Array(audioData), 32768);\n            case 32:\n                return this.formatArrayBuffer(new Int32Array(audioData), 2147483648);\n            default:\n                throw new Error_js_1.InvalidOperationError(\"Only WAVE_FORMAT_PCM (8/16/32 bps) format supported at this time\");\n        }\n    }\n    formatArrayBuffer(audioData, maxValue) {\n        const float32Data = new Float32Array(audioData.length);\n        for (let i = 0; i < audioData.length; i++) {\n            float32Data[i] = audioData[i] / maxValue;\n        }\n        return float32Data;\n    }\n    updateAudioBuffer() {\n        if (this.samples.length === 0) {\n            return;\n        }\n        const channelCount = this.audioFormat.channels;\n        const bufferSource = this.audioContext.createBufferSource();\n        const frameCount = this.samples.length / channelCount;\n        const audioBuffer = this.audioContext.createBuffer(channelCount, frameCount, this.audioFormat.samplesPerSec);\n        // TODO: Should we do the conversion in the pushAudioSample instead?\n        for (let channel = 0; channel < channelCount; channel++) {\n            // Fill in individual channel data\n            let channelOffset = channel;\n            const audioData = audioBuffer.getChannelData(channel);\n            for (let i = 0; i < this.samples.length; i++, channelOffset += channelCount) {\n                audioData[i] = this.samples[channelOffset];\n            }\n        }\n        if (this.startTime < this.audioContext.currentTime) {\n            this.startTime = this.audioContext.currentTime;\n        }\n        bufferSource.buffer = audioBuffer;\n        bufferSource.connect(this.gainNode);\n        bufferSource.start(this.startTime);\n        // Make sure we play the next sample after the current one.\n        this.startTime += audioBuffer.duration;\n        // Clear the samples for the next pushed data.\n        this.samples = new Float32Array();\n    }\n    async playAudio(audioData) {\n        if (this.audioContext === null) {\n            this.createAudioContext();\n        }\n        const source = this.audioContext.createBufferSource();\n        const destination = this.audioContext.destination;\n        await this.audioContext.decodeAudioData(audioData, (newBuffer) => {\n            source.buffer = newBuffer;\n            source.connect(destination);\n            source.start(0);\n        });\n    }\n}\nexports.BaseAudioPlayer = BaseAudioPlayer;\n\n//# sourceMappingURL=BaseAudioPlayer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/BaseAudioPlayer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PullAudioInputStreamCallback.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PullAudioInputStreamCallback.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PullAudioInputStreamCallback = void 0;\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * An abstract base class that defines callback methods (read() and close()) for\n * custom audio input streams).\n * @class PullAudioInputStreamCallback\n */\nclass PullAudioInputStreamCallback {\n}\nexports.PullAudioInputStreamCallback = PullAudioInputStreamCallback;\n\n//# sourceMappingURL=PullAudioInputStreamCallback.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PullAudioInputStreamCallback.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PushAudioOutputStreamCallback.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PushAudioOutputStreamCallback.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PushAudioOutputStreamCallback = void 0;\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * An abstract base class that defines callback methods (write() and close()) for\n * custom audio output streams).\n * @class PushAudioOutputStreamCallback\n */\nclass PushAudioOutputStreamCallback {\n}\nexports.PushAudioOutputStreamCallback = PushAudioOutputStreamCallback;\n\n//# sourceMappingURL=PushAudioOutputStreamCallback.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PushAudioOutputStreamCallback.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/SpeakerAudioDestination.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/SpeakerAudioDestination.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeakerAudioDestination = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst AudioOutputStream_js_1 = __webpack_require__(/*! ./AudioOutputStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js\");\nconst AudioStreamFormat_js_1 = __webpack_require__(/*! ./AudioStreamFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js\");\nconst MediaDurationPlaceholderSeconds = 60 * 30;\nconst AudioFormatToMimeType = {\n    [AudioStreamFormat_js_1.AudioFormatTag.PCM]: \"audio/wav\",\n    [AudioStreamFormat_js_1.AudioFormatTag.MuLaw]: \"audio/x-wav\",\n    [AudioStreamFormat_js_1.AudioFormatTag.MP3]: \"audio/mpeg\",\n    [AudioStreamFormat_js_1.AudioFormatTag.OGG_OPUS]: \"audio/ogg\",\n    [AudioStreamFormat_js_1.AudioFormatTag.WEBM_OPUS]: \"audio/webm; codecs=opus\",\n    [AudioStreamFormat_js_1.AudioFormatTag.ALaw]: \"audio/x-wav\",\n    [AudioStreamFormat_js_1.AudioFormatTag.FLAC]: \"audio/flac\",\n    [AudioStreamFormat_js_1.AudioFormatTag.AMR_WB]: \"audio/amr-wb\",\n    [AudioStreamFormat_js_1.AudioFormatTag.G722]: \"audio/G722\",\n};\n/**\n * Represents the speaker playback audio destination, which only works in browser.\n * Note: the SDK will try to use <a href=\"https://www.w3.org/TR/media-source/\">Media Source Extensions</a> to play audio.\n * Mp3 format has better supports on Microsoft Edge, Chrome and Safari (desktop), so, it's better to specify mp3 format for playback.\n * @class SpeakerAudioDestination\n * Updated in version 1.17.0\n */\nclass SpeakerAudioDestination {\n    constructor(audioDestinationId) {\n        this.privPlaybackStarted = false;\n        this.privAppendingToBuffer = false;\n        this.privMediaSourceOpened = false;\n        this.privBytesReceived = 0;\n        this.privId = audioDestinationId ? audioDestinationId : Exports_js_1.createNoDashGuid();\n        this.privIsPaused = false;\n        this.privIsClosed = false;\n    }\n    id() {\n        return this.privId;\n    }\n    write(buffer, cb, err) {\n        if (this.privAudioBuffer !== undefined) {\n            this.privAudioBuffer.push(buffer);\n            this.updateSourceBuffer().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        else if (this.privAudioOutputStream !== undefined) {\n            this.privAudioOutputStream.write(buffer);\n            this.privBytesReceived += buffer.byteLength;\n        }\n    }\n    close(cb, err) {\n        this.privIsClosed = true;\n        if (this.privSourceBuffer !== undefined) {\n            this.handleSourceBufferUpdateEnd().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        else if (this.privAudioOutputStream !== undefined && typeof window !== \"undefined\") {\n            if ((this.privFormat.formatTag === AudioStreamFormat_js_1.AudioFormatTag.PCM || this.privFormat.formatTag === AudioStreamFormat_js_1.AudioFormatTag.MuLaw\n                || this.privFormat.formatTag === AudioStreamFormat_js_1.AudioFormatTag.ALaw) && this.privFormat.hasHeader === false) {\n                // eslint-disable-next-line no-console\n                console.warn(\"Play back is not supported for raw PCM, mulaw or alaw format without header.\");\n                if (!!this.onAudioEnd) {\n                    this.onAudioEnd(this);\n                }\n            }\n            else {\n                let receivedAudio = new ArrayBuffer(this.privBytesReceived);\n                this.privAudioOutputStream.read(receivedAudio).then(() => {\n                    receivedAudio = this.privFormat.addHeader(receivedAudio);\n                    const audioBlob = new Blob([receivedAudio], { type: AudioFormatToMimeType[this.privFormat.formatTag] });\n                    this.privAudio.src = window.URL.createObjectURL(audioBlob);\n                    this.notifyPlayback().then(() => {\n                        if (!!cb) {\n                            cb();\n                        }\n                    }, (error) => {\n                        if (!!err) {\n                            err(error);\n                        }\n                    });\n                }, (error) => {\n                    if (!!err) {\n                        err(error);\n                    }\n                });\n            }\n        }\n        else {\n            // unsupported format, call onAudioEnd directly.\n            if (!!this.onAudioEnd) {\n                this.onAudioEnd(this);\n            }\n        }\n    }\n    set format(format) {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n        if (typeof (AudioContext) !== \"undefined\" || (typeof (window) !== \"undefined\" && typeof (window.webkitAudioContext) !== \"undefined\")) {\n            this.privFormat = format;\n            const mimeType = AudioFormatToMimeType[this.privFormat.formatTag];\n            if (mimeType === undefined) {\n                // eslint-disable-next-line no-console\n                console.warn(`Unknown mimeType for format ${AudioStreamFormat_js_1.AudioFormatTag[this.privFormat.formatTag]}; playback is not supported.`);\n            }\n            else if (typeof (MediaSource) !== \"undefined\" && MediaSource.isTypeSupported(mimeType)) {\n                this.privAudio = new Audio();\n                this.privAudioBuffer = [];\n                this.privMediaSource = new MediaSource();\n                this.privAudio.src = URL.createObjectURL(this.privMediaSource);\n                this.privAudio.load();\n                this.privMediaSource.onsourceopen = () => {\n                    this.privMediaSourceOpened = true;\n                    this.privMediaSource.duration = MediaDurationPlaceholderSeconds;\n                    this.privSourceBuffer = this.privMediaSource.addSourceBuffer(mimeType);\n                    this.privSourceBuffer.onupdate = () => {\n                        this.updateSourceBuffer().catch((reason) => {\n                            Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));\n                        });\n                    };\n                    this.privSourceBuffer.onupdateend = () => {\n                        this.handleSourceBufferUpdateEnd().catch((reason) => {\n                            Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));\n                        });\n                    };\n                    this.privSourceBuffer.onupdatestart = () => {\n                        this.privAppendingToBuffer = false;\n                    };\n                };\n                this.updateSourceBuffer().catch((reason) => {\n                    Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));\n                });\n            }\n            else {\n                // eslint-disable-next-line no-console\n                console.warn(`Format ${AudioStreamFormat_js_1.AudioFormatTag[this.privFormat.formatTag]} could not be played by MSE, streaming playback is not enabled.`);\n                this.privAudioOutputStream = new AudioOutputStream_js_1.PullAudioOutputStreamImpl();\n                this.privAudioOutputStream.format = this.privFormat;\n                this.privAudio = new Audio();\n            }\n        }\n    }\n    get volume() {\n        return this.privAudio?.volume ?? -1;\n    }\n    set volume(volume) {\n        if (!!this.privAudio) {\n            this.privAudio.volume = volume;\n        }\n    }\n    mute() {\n        if (!!this.privAudio) {\n            this.privAudio.muted = true;\n        }\n    }\n    unmute() {\n        if (!!this.privAudio) {\n            this.privAudio.muted = false;\n        }\n    }\n    get isClosed() {\n        return this.privIsClosed;\n    }\n    get currentTime() {\n        if (this.privAudio !== undefined) {\n            return this.privAudio.currentTime;\n        }\n        return -1;\n    }\n    pause() {\n        if (!this.privIsPaused && this.privAudio !== undefined) {\n            this.privAudio.pause();\n            this.privIsPaused = true;\n        }\n    }\n    resume(cb, err) {\n        if (this.privIsPaused && this.privAudio !== undefined) {\n            this.privAudio.play().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n            this.privIsPaused = false;\n        }\n    }\n    get internalAudio() {\n        return this.privAudio;\n    }\n    async updateSourceBuffer() {\n        if (this.privAudioBuffer !== undefined && (this.privAudioBuffer.length > 0) && this.sourceBufferAvailable()) {\n            this.privAppendingToBuffer = true;\n            const binary = this.privAudioBuffer.shift();\n            try {\n                this.privSourceBuffer.appendBuffer(binary);\n            }\n            catch (error) {\n                this.privAudioBuffer.unshift(binary);\n                // eslint-disable-next-line no-console\n                console.log(\"buffer filled, pausing addition of binaries until space is made\");\n                return;\n            }\n            await this.notifyPlayback();\n        }\n        else if (this.canEndStream()) {\n            await this.handleSourceBufferUpdateEnd();\n        }\n    }\n    async handleSourceBufferUpdateEnd() {\n        if (this.canEndStream() && this.sourceBufferAvailable()) {\n            this.privMediaSource.endOfStream();\n            await this.notifyPlayback();\n        }\n    }\n    async notifyPlayback() {\n        if (!this.privPlaybackStarted && this.privAudio !== undefined) {\n            this.privPlaybackStarted = true;\n            if (!!this.onAudioStart) {\n                this.onAudioStart(this);\n            }\n            this.privAudio.onended = () => {\n                if (!!this.onAudioEnd) {\n                    this.onAudioEnd(this);\n                }\n            };\n            if (!this.privIsPaused) {\n                await this.privAudio.play();\n            }\n        }\n    }\n    canEndStream() {\n        return (this.isClosed && this.privSourceBuffer !== undefined && (this.privAudioBuffer.length === 0)\n            && this.privMediaSourceOpened && !this.privAppendingToBuffer && this.privMediaSource.readyState === \"open\");\n    }\n    sourceBufferAvailable() {\n        return (this.privSourceBuffer !== undefined && !this.privSourceBuffer.updating);\n    }\n}\nexports.SpeakerAudioDestination = SpeakerAudioDestination;\n\n//# sourceMappingURL=SpeakerAudioDestination.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/SpeakerAudioDestination.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageConfig.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageConfig.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AutoDetectSourceLanguageConfig = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst LanguageIdMode_js_1 = __webpack_require__(/*! ./LanguageIdMode.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js\");\n/**\n * Language auto detect configuration.\n * @class AutoDetectSourceLanguageConfig\n * Added in version 1.13.0.\n */\nclass AutoDetectSourceLanguageConfig {\n    constructor() {\n        this.privProperties = new Exports_js_2.PropertyCollection();\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_LanguageIdMode, \"AtStart\");\n        this.privLanguageIdMode = LanguageIdMode_js_1.LanguageIdMode.AtStart;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.fromOpenRange\n     * @function\n     * @public\n     * Only [[SpeechSynthesizer]] supports source language auto detection from open range,\n     * for [[Recognizer]], please use AutoDetectSourceLanguageConfig with specific source languages.\n     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with open range.\n     */\n    static fromOpenRange() {\n        const config = new AutoDetectSourceLanguageConfig();\n        config.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, Exports_js_1.AutoDetectSourceLanguagesOpenRangeOptionName);\n        return config;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.fromLanguages\n     * @function\n     * @public\n     * @param {string[]} languages Comma-separated string of languages (eg. \"en-US,fr-FR\") to populate properties of config.\n     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given languages.\n     */\n    static fromLanguages(languages) {\n        Contracts_js_1.Contracts.throwIfArrayEmptyOrWhitespace(languages, \"languages\");\n        const config = new AutoDetectSourceLanguageConfig();\n        config.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, languages.join());\n        return config;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.fromSourceLanguageConfigs\n     * @function\n     * @public\n     * @param {SourceLanguageConfig[]} configs SourceLanguageConfigs to populate properties of config.\n     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given SourceLanguageConfigs.\n     */\n    static fromSourceLanguageConfigs(configs) {\n        if (configs.length < 1) {\n            throw new Error(\"Expected non-empty SourceLanguageConfig array.\");\n        }\n        const autoConfig = new AutoDetectSourceLanguageConfig();\n        const langs = [];\n        configs.forEach((config) => {\n            langs.push(config.language);\n            if (config.endpointId !== undefined && config.endpointId !== \"\") {\n                const customProperty = config.language + Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId.toString();\n                autoConfig.properties.setProperty(customProperty, config.endpointId);\n            }\n        });\n        autoConfig.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, langs.join());\n        return autoConfig;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.prototype.properties\n     * @function\n     * @public\n     * @return {PropertyCollection} Properties of the config.\n     * @summary Gets an auto detected language config properties\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.prototype.mode\n     * @function\n     * @public\n     * @param {LanguageIdMode} mode LID mode desired.\n     * @summary Sets LID operation to desired mode\n     */\n    set mode(mode) {\n        if (mode === LanguageIdMode_js_1.LanguageIdMode.Continuous) {\n            this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, \"2\");\n            this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_LanguageIdMode, \"Continuous\");\n        }\n        else { // LanguageIdMode.AtStart\n            this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, \"1\");\n            this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_LanguageIdMode, \"AtStart\");\n        }\n        this.privLanguageIdMode = mode;\n    }\n}\nexports.AutoDetectSourceLanguageConfig = AutoDetectSourceLanguageConfig;\n\n//# sourceMappingURL=AutoDetectSourceLanguageConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageResult.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageResult.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AutoDetectSourceLanguageResult = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\n/**\n * Output format\n * @class AutoDetectSourceLanguageResult\n */\nclass AutoDetectSourceLanguageResult {\n    constructor(language, languageDetectionConfidence) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(language, \"language\");\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(languageDetectionConfidence, \"languageDetectionConfidence\");\n        this.privLanguage = language;\n        this.privLanguageDetectionConfidence = languageDetectionConfidence;\n    }\n    /**\n     * Creates an instance of AutoDetectSourceLanguageResult object from a SpeechRecognitionResult instance.\n     * @member AutoDetectSourceLanguageResult.fromResult\n     * @function\n     * @public\n     * @param {SpeechRecognitionResult} result - The recognition result.\n     * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.\n     */\n    static fromResult(result) {\n        return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);\n    }\n    /**\n     * Creates an instance of AutoDetectSourceLanguageResult object from a ConversationTranscriptionResult instance.\n     * @member AutoDetectSourceLanguageResult.fromConversationTranscriptionResult\n     * @function\n     * @public\n     * @param {ConversationTranscriptionResult} result - The transcription result.\n     * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.\n     */\n    static fromConversationTranscriptionResult(result) {\n        return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);\n    }\n    get language() {\n        return this.privLanguage;\n    }\n    get languageDetectionConfidence() {\n        return this.privLanguageDetectionConfidence;\n    }\n}\nexports.AutoDetectSourceLanguageResult = AutoDetectSourceLanguageResult;\n\n//# sourceMappingURL=AutoDetectSourceLanguageResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarConfig.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarConfig.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AvatarConfig = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines the talking avatar configuration.\n * @class AvatarConfig\n * Added in version 1.33.0\n *\n * @experimental This feature is experimental and might change or have limited support.\n */\nclass AvatarConfig {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} character - The avatar character.\n     * @param {string} style - The avatar style.\n     * @param {AvatarVideoFormat} videoFormat - The talking avatar output video format.\n     */\n    constructor(character, style, videoFormat) {\n        this.privCustomized = false;\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(character, \"character\");\n        this.character = character;\n        this.style = style;\n        if (videoFormat === undefined) {\n            videoFormat = new Exports_js_1.AvatarVideoFormat();\n        }\n        this.videoFormat = videoFormat;\n    }\n    /**\n     * Indicates if the talking avatar is customized.\n     */\n    get customized() {\n        return this.privCustomized;\n    }\n    /**\n     * Sets if the talking avatar is customized.\n     */\n    set customized(value) {\n        this.privCustomized = value;\n    }\n    /**\n     * Gets the background color.\n     */\n    get backgroundColor() {\n        return this.privBackgroundColor;\n    }\n    /**\n     * Sets the background color.\n     */\n    set backgroundColor(value) {\n        this.privBackgroundColor = value;\n    }\n    /**\n     * Gets the background image.\n     */\n    get backgroundImage() {\n        return this.privBackgroundImage;\n    }\n    /**\n     * Sets the background image.\n     * @param {URL} value - The background image.\n     */\n    set backgroundImage(value) {\n        this.privBackgroundImage = value;\n    }\n    /**\n     * Gets the remote ICE servers.\n     * @remarks This method is designed to be used internally in the SDK.\n     * @returns {RTCIceServer[]} The remote ICE servers.\n     */\n    get remoteIceServers() {\n        return this.privRemoteIceServers;\n    }\n    /**\n     * Sets the remote ICE servers.\n     * @remarks Normally, the ICE servers are gathered from the PeerConnection,\n     * set this property to override the ICE servers. E.g., the ICE servers are\n     * different in client and server side.\n     * @param {RTCIceServer[]} value - The remote ICE servers.\n     */\n    set remoteIceServers(value) {\n        this.privRemoteIceServers = value;\n    }\n}\nexports.AvatarConfig = AvatarConfig;\n\n//# sourceMappingURL=AvatarConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarEventArgs.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarEventArgs.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AvatarEventArgs = exports.AvatarEventTypes = void 0;\nvar AvatarEventTypes;\n(function (AvatarEventTypes) {\n    AvatarEventTypes[\"SwitchedToSpeaking\"] = \"SwitchedToSpeaking\";\n    AvatarEventTypes[\"SwitchedToIdle\"] = \"SwitchedToIdle\";\n    AvatarEventTypes[\"SessionClosed\"] = \"SessionClosed\";\n})(AvatarEventTypes = exports.AvatarEventTypes || (exports.AvatarEventTypes = {}));\n/**\n * Defines content for talking avatar events.\n * @class AvatarEventArgs\n * Added in version 1.33.0\n *\n * @experimental This feature is experimental and might change or have limited support.\n */\nclass AvatarEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {string} description - The description of the event.\n     */\n    constructor(audioOffset, description) {\n        this.privOffset = audioOffset;\n        this.privDescription = description;\n    }\n    /**\n     * The type of the event.\n     * @public\n     * @returns {AvatarEventTypes} The type of the event.\n     */\n    get type() {\n        return this.privType;\n    }\n    /**\n     * The time offset associated with this event.\n     * @public\n     * @returns {number} The time offset associated with this event.\n     */\n    get offset() {\n        return this.privOffset;\n    }\n    /**\n     * The description of the event.\n     * @public\n     * @returns {string} The description of the event.\n     */\n    get description() {\n        return this.privDescription;\n    }\n}\nexports.AvatarEventArgs = AvatarEventArgs;\n\n//# sourceMappingURL=AvatarEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarSynthesizer.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarSynthesizer.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AvatarSynthesizer = void 0;\nconst SpeechSynthesisConnectionFactory_js_1 = __webpack_require__(/*! ../common.speech/SpeechSynthesisConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js\");\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst AudioOutputFormat_js_1 = __webpack_require__(/*! ./Audio/AudioOutputFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Synthesizer_js_1 = __webpack_require__(/*! ./Synthesizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js\");\n/**\n * Defines the avatar synthesizer.\n * @class AvatarSynthesizer\n * Added in version 1.33.0\n *\n * @experimental This feature is experimental and might change or have limited support.\n */\nclass AvatarSynthesizer extends Exports_js_3.Synthesizer {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - The speech config.\n     * @param {AvatarConfig} avatarConfig - The talking avatar config.\n     */\n    constructor(speechConfig, avatarConfig) {\n        super(speechConfig);\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(avatarConfig, \"avatarConfig\");\n        this.privConnectionFactory = new SpeechSynthesisConnectionFactory_js_1.SpeechSynthesisConnectionFactory();\n        this.privAvatarConfig = avatarConfig;\n        this.implCommonSynthesizeSetup();\n    }\n    implCommonSynthesizeSetup() {\n        super.implCommonSynthesizeSetup();\n        // The service checks the audio format setting while it ignores it in avatar synthesis.\n        this.privAdapter.audioOutputFormat = AudioOutputFormat_js_1.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(Exports_js_3.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm);\n    }\n    /**\n     * Starts the talking avatar session and establishes the WebRTC connection.\n     * @member AvatarSynthesizer.prototype.startAvatarAsync\n     * @function\n     * @public\n     * @param {AvatarWebRTCConnectionInfo} peerConnection - The peer connection.\n     * @returns {Promise<SynthesisResult>} The promise of the connection result.\n     */\n    async startAvatarAsync(peerConnection) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(peerConnection, \"peerConnection\");\n        this.privIceServers = peerConnection.getConfiguration().iceServers;\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privIceServers, \"Ice servers must be set.\");\n        const iceGatheringDone = new Exports_js_2.Deferred();\n        // https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/icegatheringstatechange_event\n        peerConnection.onicegatheringstatechange = () => {\n            Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: ice gathering state: \" + peerConnection.iceGatheringState, Exports_js_2.EventType.Debug));\n            if (peerConnection.iceGatheringState === \"complete\") {\n                Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: ice gathering complete.\", Exports_js_2.EventType.Info));\n                iceGatheringDone.resolve();\n            }\n        };\n        peerConnection.onicecandidate = (event) => {\n            if (event.candidate) {\n                Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: ice candidate: \" + event.candidate.candidate, Exports_js_2.EventType.Debug));\n            }\n            else {\n                Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: ice candidate: complete\", Exports_js_2.EventType.Debug));\n                iceGatheringDone.resolve();\n            }\n        };\n        // Set a timeout for ice gathering, currently 2 seconds.\n        setTimeout(() => {\n            if (peerConnection.iceGatheringState !== \"complete\") {\n                Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: ice gathering timeout.\", Exports_js_2.EventType.Warning));\n                iceGatheringDone.resolve();\n            }\n        }, 2000);\n        const sdp = await peerConnection.createOffer();\n        await peerConnection.setLocalDescription(sdp);\n        await iceGatheringDone.promise;\n        Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent(\"peer connection: got local SDP.\", Exports_js_2.EventType.Info));\n        this.privProperties.setProperty(Exports_js_3.PropertyId.TalkingAvatarService_WebRTC_SDP, JSON.stringify(peerConnection.localDescription));\n        const result = await this.speak(\"\", false);\n        if (result.reason !== Exports_js_3.ResultReason.SynthesizingAudioCompleted) {\n            return new Exports_js_3.SynthesisResult(result.resultId, result.reason, result.errorDetails, result.properties);\n        }\n        const sdpAnswerString = atob(result.properties.getProperty(Exports_js_3.PropertyId.TalkingAvatarService_WebRTC_SDP));\n        const sdpAnswer = new RTCSessionDescription(JSON.parse(sdpAnswerString));\n        await peerConnection.setRemoteDescription(sdpAnswer);\n        return new Exports_js_3.SynthesisResult(result.resultId, result.reason, undefined, result.properties);\n    }\n    /**\n     * Speaks plain text asynchronously. The rendered audio and video will be sent via the WebRTC connection.\n     * @member AvatarSynthesizer.prototype.speakTextAsync\n     * @function\n     * @public\n     * @param {string} text - The plain text to speak.\n     * @returns {Promise<SynthesisResult>} The promise of the synthesis result.\n     */\n    async speakTextAsync(text) {\n        const r = await this.speak(text, false);\n        return new Exports_js_3.SynthesisResult(r.resultId, r.reason, r.errorDetails, r.properties);\n    }\n    /**\n     * Speaks SSML asynchronously. The rendered audio and video will be sent via the WebRTC connection.\n     * @member AvatarSynthesizer.prototype.speakSsmlAsync\n     * @function\n     * @public\n     * @param {string} ssml - The SSML text to speak.\n     * @returns {Promise<SynthesisResult>} The promise of the synthesis result.\n     */\n    async speakSsmlAsync(ssml) {\n        const r = await this.speak(ssml, true);\n        return new Exports_js_3.SynthesisResult(r.resultId, r.reason, r.errorDetails, r.properties);\n    }\n    /**\n     * Speaks text asynchronously. The avatar will switch to idle state.\n     * @member AvatarSynthesizer.prototype.stopSpeakingAsync\n     * @function\n     * @public\n     * @returns {Promise<void>} The promise of the void result.\n     */\n    async stopSpeakingAsync() {\n        while (this.synthesisRequestQueue.length() > 0) {\n            const request = await this.synthesisRequestQueue.dequeue();\n            request.err(\"Synthesis is canceled by user.\");\n        }\n        return this.privAdapter.stopSpeaking();\n    }\n    /**\n     * Stops the talking avatar session and closes the WebRTC connection.\n     * For now, this is the same as close().\n     * You need to create a new AvatarSynthesizer instance to start a new session.\n     * @member AvatarSynthesizer.prototype.stopAvatarAsync\n     * @function\n     * @public\n     * @returns {Promise<void>} The promise of the void result.\n     */\n    async stopAvatarAsync() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);\n        return this.dispose(true);\n    }\n    /**\n     * Dispose of associated resources.\n     * @member AvatarSynthesizer.prototype.close\n     * @function\n     * @public\n     */\n    async close() {\n        if (this.privDisposed) {\n            return;\n        }\n        return this.dispose(true);\n    }\n    /**\n     * Gets the ICE servers. Internal use only.\n     */\n    get iceServers() {\n        return this.privIceServers;\n    }\n    // Creates the synthesis adapter\n    createSynthesisAdapter(authentication, connectionFactory, synthesizerConfig) {\n        return new Exports_js_1.AvatarSynthesisAdapter(authentication, connectionFactory, synthesizerConfig, this, this.privAvatarConfig);\n    }\n    createRestSynthesisAdapter(_authentication, _synthesizerConfig) {\n        return undefined;\n    }\n    createSynthesizerConfig(speechConfig) {\n        const config = super.createSynthesizerConfig(speechConfig);\n        config.avatarEnabled = true;\n        return config;\n    }\n    async speak(text, isSSML) {\n        const requestId = Exports_js_2.createNoDashGuid();\n        const deferredResult = new Exports_js_2.Deferred();\n        this.synthesisRequestQueue.enqueue(new Synthesizer_js_1.SynthesisRequest(requestId, text, isSSML, (e) => {\n            deferredResult.resolve(e);\n            this.privSynthesizing = false;\n            void this.adapterSpeak();\n        }, (e) => {\n            deferredResult.reject(e);\n            this.privSynthesizing = false;\n        }));\n        void this.adapterSpeak();\n        return deferredResult.promise;\n    }\n}\nexports.AvatarSynthesizer = AvatarSynthesizer;\n\n//# sourceMappingURL=AvatarSynthesizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarSynthesizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarVideoFormat.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarVideoFormat.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AvatarVideoFormat = exports.Coordinate = void 0;\n/* eslint-disable max-classes-per-file */\n/**\n * Defines a coordinate in 2D space.\n * @class Coordinate\n * Added in version 1.33.0\n */\nclass Coordinate {\n    constructor(x, y) {\n        this.x = x;\n        this.y = y;\n    }\n}\nexports.Coordinate = Coordinate;\n/**\n * Defines the avatar output video format.\n * @class AvatarVideoFormat\n * Added in version 1.33.0\n *\n * @experimental This feature is experimental and might change in the future.\n */\nclass AvatarVideoFormat {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} codec - The video codec.\n     * @param {number} bitrate - The video bitrate.\n     * @param {number} width - The video width.\n     * @param {number} height - The video height.\n     */\n    constructor(codec = \"H264\", bitrate = 2000000, width = 1920, height = 1080) {\n        this.codec = codec;\n        this.bitrate = bitrate;\n        this.width = width;\n        this.height = height;\n    }\n    /**\n     * Sets the video crop range.\n     */\n    setCropRange(topLeft, bottomRight) {\n        this.cropRange = {\n            bottomRight,\n            topLeft,\n        };\n    }\n}\nexports.AvatarVideoFormat = AvatarVideoFormat;\n\n//# sourceMappingURL=AvatarVideoFormat.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarVideoFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarWebRTCConnectionResult.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarWebRTCConnectionResult.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AvatarWebRTCConnectionResult = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines the avatar WebRTC connection result.\n * @class AvatarWebRTCConnectionResult\n * Added in version 1.33.0\n *\n * @experimental This feature is experimental and might change in the future.\n */\nclass AvatarWebRTCConnectionResult extends Exports_js_1.SynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {RTCSessionDescriptionInit} SDPAnswer - The SDP answer of WebRTC connection.\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(SDPAnswer, resultId, reason, errorDetails, properties) {\n        super(resultId, reason, errorDetails, properties);\n        this.privSDPAnswer = SDPAnswer;\n    }\n    /**\n     * Specifies SDP (Session Description Protocol) answer of WebRTC connection.\n     * @member AvatarWebRTCConnectionResult.prototype.SDPAnswer\n     * @function\n     * @public\n     * @returns {RTCSessionDescriptionInit} Specifies the SDP answer of WebRTC connection.\n     */\n    get SDPAnswer() {\n        return this.privSDPAnswer;\n    }\n}\nexports.AvatarWebRTCConnectionResult = AvatarWebRTCConnectionResult;\n\n//# sourceMappingURL=AvatarWebRTCConnectionResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarWebRTCConnectionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/BotFrameworkConfig.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/BotFrameworkConfig.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BotFrameworkConfig = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst DialogServiceConfig_js_1 = __webpack_require__(/*! ./DialogServiceConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Class that defines configurations for the dialog service connector object for using a Bot Framework backend.\n * @class BotFrameworkConfig\n */\nclass BotFrameworkConfig extends DialogServiceConfig_js_1.DialogServiceConfigImpl {\n    /**\n     * Creates an instance of BotFrameworkConfig.\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates a bot framework configuration instance with the provided subscription information.\n     * @member BotFrameworkConfig.fromSubscription\n     * @function\n     * @public\n     * @param subscription Subscription key associated with the bot\n     * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n     * resource name.\n     * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n     */\n    static fromSubscription(subscription, region, botId) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscription, \"subscription\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const botFrameworkConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.BotFramework);\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Key, subscription);\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Region, region);\n        if (botId) {\n            botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, botId);\n        }\n        return botFrameworkConfig;\n    }\n    /**\n     * Creates a bot framework configuration instance for the specified authorization token and region.\n     * Note: The caller must ensure that an authorization token is valid. Before an authorization token expires, the\n     * caller must refresh it by setting the authorizationToken property on the corresponding\n     * DialogServiceConnector instance created with this config. The contents of configuration objects are copied\n     * when connectors are created, so setting authorizationToken on a DialogServiceConnector will not update the\n     * original configuration's authorization token. Create a new configuration instance or set the\n     * SpeechServiceAuthorization_Token property to update an existing instance if it will be used to create\n     * further DialogServiceConnectors.\n     * @member BotFrameworkConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param authorizationToken The authorization token associated with the bot\n     * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n     * resource name.\n     * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n     */\n    static fromAuthorizationToken(authorizationToken, region, botId) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const botFrameworkConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.BotFramework);\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Region, region);\n        if (botId) {\n            botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, botId);\n        }\n        return botFrameworkConfig;\n    }\n    /**\n     * Creates an instance of a BotFrameworkConfig.\n     * This method is intended only for users who use a non-default service host. The standard resource path will be\n     * assumed. For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n     * Note: To use an authorization token with fromHost, use fromHost(URL) and then set the AuthorizationToken\n     * property on the created BotFrameworkConfig instance.\n     * Note: Added in version 1.15.0.\n     * @member BotFrameworkConfig.fromHost\n     * @function\n     * @public\n     * @param {URL | string} host - If a URL is provided, the fully-qualified host with protocol (e.g.\n     * wss://your.host.com:1234) will be used. If a string is provided, it will be embedded in\n     * wss://{host}.convai.speech.azure.us.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization\n     * token must be set.\n     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n     * resource name.\n     * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n     */\n    static fromHost(host, subscriptionKey, botId) {\n        void botId;\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(host, \"host\");\n        const resolvedHost = host instanceof URL ? host : new URL(`wss://${host}.convai.speech.azure.us`);\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(resolvedHost, \"resolvedHost\");\n        const botFrameworkConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.BotFramework);\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Host, resolvedHost.toString());\n        if (undefined !== subscriptionKey) {\n            botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return botFrameworkConfig;\n    }\n    /**\n     * Creates an instance of a BotFrameworkConfig.\n     * This method is intended only for users who use a non-standard service endpoint or parameters.\n     * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.\n     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n     * fromEndpoint method, and then set authorizationToken=\"token\" on the created BotFrameworkConfig instance to\n     * use the authorization token.\n     * Note: Added in version 1.15.0.\n     * @member BotFrameworkConfig.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} endpoint - The service endpoint to connect to.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization\n     * token must be set.\n     * @returns {BotFrameworkConfig} - A new bot framework configuration instance using the provided endpoint.\n     */\n    static fromEndpoint(endpoint, subscriptionKey) {\n        Contracts_js_1.Contracts.throwIfNull(endpoint, \"endpoint\");\n        const botFrameworkConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.BotFramework);\n        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Endpoint, endpoint.toString());\n        if (undefined !== subscriptionKey) {\n            botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return botFrameworkConfig;\n    }\n}\nexports.BotFrameworkConfig = BotFrameworkConfig;\n\n//# sourceMappingURL=BotFrameworkConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/BotFrameworkConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetails.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetails.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationDetails = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst CancellationDetailsBase_js_1 = __webpack_require__(/*! ./CancellationDetailsBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Contains detailed information about why a result was canceled.\n * @class CancellationDetails\n */\nclass CancellationDetails extends CancellationDetailsBase_js_1.CancellationDetailsBase {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of CancellationDetails object for the canceled RecognitionResult.\n     * @member CancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {RecognitionResult | SpeechSynthesisResult} result - The result that was canceled.\n     * @returns {CancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        let reason = Exports_js_2.CancellationReason.Error;\n        let errorCode = Exports_js_2.CancellationErrorCode.NoError;\n        if (result instanceof Exports_js_2.RecognitionResult && !!result.json) {\n            const simpleSpeech = Exports_js_1.SimpleSpeechPhrase.fromJSON(result.json, 0); // Offset fixups are already done.\n            reason = Exports_js_1.EnumTranslation.implTranslateCancelResult(simpleSpeech.RecognitionStatus);\n        }\n        if (!!result.properties) {\n            errorCode = Exports_js_2.CancellationErrorCode[result.properties.getProperty(Exports_js_1.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[Exports_js_2.CancellationErrorCode.NoError])];\n        }\n        return new CancellationDetails(reason, result.errorDetails || Exports_js_1.EnumTranslation.implTranslateErrorDetails(errorCode), errorCode);\n    }\n}\nexports.CancellationDetails = CancellationDetails;\n\n//# sourceMappingURL=CancellationDetails.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetails.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationDetailsBase = void 0;\n/**\n * Contains detailed information about why a result was canceled.\n * @class CancellationDetailsBase\n */\nclass CancellationDetailsBase {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} reason - The cancellation reason.\n     * @param {string} errorDetails - The error details, if provided.\n     */\n    constructor(reason, errorDetails, errorCode) {\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member CancellationDetailsBase.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member CancellationDetailsBase.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get ErrorCode() {\n        return this.privErrorCode;\n    }\n}\nexports.CancellationDetailsBase = CancellationDetailsBase;\n\n//# sourceMappingURL=CancellationDetailsBase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationErrorCodes.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationErrorCodes.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationErrorCode = void 0;\n/**\n * Defines error code in case that CancellationReason is Error.\n * Added in version 1.1.0.\n */\nvar CancellationErrorCode;\n(function (CancellationErrorCode) {\n    /**\n     * Indicates that no error occurred during speech recognition.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"NoError\"] = 0] = \"NoError\";\n    /**\n     * Indicates an authentication error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"AuthenticationFailure\"] = 1] = \"AuthenticationFailure\";\n    /**\n     * Indicates that one or more recognition parameters are invalid.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"BadRequestParameters\"] = 2] = \"BadRequestParameters\";\n    /**\n     * Indicates that the number of parallel requests exceeded the number of allowed\n     * concurrent transcriptions for the subscription.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"TooManyRequests\"] = 3] = \"TooManyRequests\";\n    /**\n     * Indicates a connection error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ConnectionFailure\"] = 4] = \"ConnectionFailure\";\n    /**\n     * Indicates a time-out error when waiting for response from service.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ServiceTimeout\"] = 5] = \"ServiceTimeout\";\n    /**\n     * Indicates that an error is returned by the service.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ServiceError\"] = 6] = \"ServiceError\";\n    /**\n     * Indicates an unexpected runtime error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"RuntimeError\"] = 7] = \"RuntimeError\";\n    /**\n     * Indicates an quota overrun on existing key.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"Forbidden\"] = 8] = \"Forbidden\";\n})(CancellationErrorCode = exports.CancellationErrorCode || (exports.CancellationErrorCode = {}));\n\n//# sourceMappingURL=CancellationErrorCodes.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationErrorCodes.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationEventArgsBase = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines content of a CancellationEvent.\n * @class CancellationEventArgsBase\n */\nclass CancellationEventArgsBase extends Exports_js_1.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} reason - The cancellation reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(reason, errorDetails, errorCode, offset, sessionId) {\n        super(offset, sessionId);\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member CancellationEventArgsBase.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * The error code in case of an unsuccessful operation.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful operation, provides details of the occurred error.\n     * @member CancellationEventArgsBase.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\nexports.CancellationEventArgsBase = CancellationEventArgsBase;\n\n//# sourceMappingURL=CancellationEventArgsBase.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationReason.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationReason.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationReason = void 0;\n/**\n * Defines the possible reasons a recognition result might be canceled.\n * @class CancellationReason\n */\nvar CancellationReason;\n(function (CancellationReason) {\n    /**\n     * Indicates that an error occurred during speech recognition.\n     * @member CancellationReason.Error\n     */\n    CancellationReason[CancellationReason[\"Error\"] = 0] = \"Error\";\n    /**\n     * Indicates that the end of the audio stream was reached.\n     * @member CancellationReason.EndOfStream\n     */\n    CancellationReason[CancellationReason[\"EndOfStream\"] = 1] = \"EndOfStream\";\n})(CancellationReason = exports.CancellationReason || (exports.CancellationReason = {}));\n\n//# sourceMappingURL=CancellationReason.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Connection = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst ConnectionMessage_js_1 = __webpack_require__(/*! ./ConnectionMessage.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Connection is a proxy class for managing connection to the speech service of the specified Recognizer.\n * By default, a Recognizer autonomously manages connection to service when needed.\n * The Connection class provides additional methods for users to explicitly open or close a connection and\n * to subscribe to connection status changes.\n * The use of Connection is optional, and mainly for scenarios where fine tuning of application\n * behavior based on connection status is needed. Users can optionally call Open() to manually set up a connection\n * in advance before starting recognition on the Recognizer associated with this Connection.\n * If the Recognizer needs to connect or disconnect to service, it will\n * setup or shutdown the connection independently. In this case the Connection will be notified by change of connection\n * status via Connected/Disconnected events.\n * Added in version 1.2.1.\n */\nclass Connection {\n    /**\n     * Gets the Connection instance from the specified recognizer.\n     * @param recognizer The recognizer associated with the connection.\n     * @return The Connection instance of the recognizer.\n     */\n    static fromRecognizer(recognizer) {\n        const recoBase = recognizer.internalData;\n        const ret = new Connection();\n        ret.privInternalData = recoBase;\n        ret.setupEvents();\n        return ret;\n    }\n    /**\n     * Gets the Connection instance from the specified synthesizer.\n     * @param synthesizer The synthesizer associated with the connection.\n     * @return The Connection instance of the synthesizer.\n     */\n    static fromSynthesizer(synthesizer) {\n        const synthBase = synthesizer.internalData;\n        const ret = new Connection();\n        ret.privInternalData = synthBase;\n        ret.setupEvents();\n        return ret;\n    }\n    /**\n     * Starts to set up connection to the service.\n     * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the\n     * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect\n     *\n     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to\n     * be notified when the connection is established.\n     */\n    openConnection(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.privInternalData.connect(), cb, err);\n    }\n    /**\n     * Closes the connection the service.\n     * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.\n     *\n     * If closeConnection() is called during recognition, recognition will fail and cancel with an error.\n     */\n    closeConnection(cb, err) {\n        if (this.privInternalData instanceof Exports_js_1.SynthesisAdapterBase) {\n            throw new Error(\"Disconnecting a synthesizer's connection is currently not supported\");\n        }\n        else {\n            Exports_js_2.marshalPromiseToCallbacks(this.privInternalData.disconnect(), cb, err);\n        }\n    }\n    /**\n     * Appends a parameter in a message to service.\n     * Added in version 1.12.1.\n     * @param path The path of the network message.\n     * @param propertyName Name of the property\n     * @param propertyValue Value of the property. This is a json string.\n     */\n    setMessageProperty(path, propertyName, propertyValue) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(propertyName, \"propertyName\");\n        if (this.privInternalData instanceof Exports_js_1.ServiceRecognizerBase) {\n            if (path.toLowerCase() !== \"speech.context\") {\n                throw new Error(\"Only speech.context message property sets are currently supported for recognizer\");\n            }\n            else {\n                this.privInternalData.speechContext.setSection(propertyName, propertyValue);\n            }\n        }\n        else if (this.privInternalData instanceof Exports_js_1.SynthesisAdapterBase) {\n            if (path.toLowerCase() !== \"synthesis.context\") {\n                throw new Error(\"Only synthesis.context message property sets are currently supported for synthesizer\");\n            }\n            else {\n                this.privInternalData.synthesisContext.setSection(propertyName, propertyValue);\n            }\n        }\n    }\n    /**\n     * Sends a message to the speech service.\n     * Added in version 1.13.0.\n     * @param path The WebSocket path of the message\n     * @param payload The payload of the message. This is a json string or a ArrayBuffer.\n     * @param success A callback to indicate success.\n     * @param error A callback to indicate an error.\n     */\n    sendMessageAsync(path, payload, success, error) {\n        Exports_js_2.marshalPromiseToCallbacks(this.privInternalData.sendNetworkMessage(path, payload), success, error);\n    }\n    /**\n     * Dispose of associated resources.\n     */\n    close() {\n        /* eslint-disable no-empty */\n    }\n    setupEvents() {\n        this.privEventListener = this.privInternalData.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionEstablishedEvent\") {\n                if (!!this.connected) {\n                    this.connected(new Exports_js_3.ConnectionEventArgs(connectionEvent.connectionId));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                if (!!this.disconnected) {\n                    this.disconnected(new Exports_js_3.ConnectionEventArgs(connectionEvent.connectionId));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionMessageSentEvent\") {\n                if (!!this.messageSent) {\n                    this.messageSent(new Exports_js_3.ConnectionMessageEventArgs(new ConnectionMessage_js_1.ConnectionMessageImpl(connectionEvent.message)));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionMessageReceivedEvent\") {\n                if (!!this.messageReceived) {\n                    this.messageReceived(new Exports_js_3.ConnectionMessageEventArgs(new ConnectionMessage_js_1.ConnectionMessageImpl(connectionEvent.message)));\n                }\n            }\n        });\n        this.privServiceEventListener = this.privInternalData.serviceEvents.attach((e) => {\n            if (!!this.receivedServiceMessage) {\n                this.receivedServiceMessage(new Exports_js_3.ServiceEventArgs(e.jsonString, e.name));\n            }\n        });\n    }\n}\nexports.Connection = Connection;\n\n//# sourceMappingURL=Connection.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionEventArgs.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines payload for connection events like Connected/Disconnected.\n * Added in version 1.2.0\n */\nclass ConnectionEventArgs extends Exports_js_1.SessionEventArgs {\n}\nexports.ConnectionEventArgs = ConnectionEventArgs;\n\n//# sourceMappingURL=ConnectionEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionMessageImpl = exports.ConnectionMessage = void 0;\n// eslint-disable-next-line max-classes-per-file\nconst HeaderNames_js_1 = __webpack_require__(/*! ../common.speech/HeaderNames.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js\");\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst PropertyCollection_js_1 = __webpack_require__(/*! ./PropertyCollection.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js\");\nconst PropertyId_js_1 = __webpack_require__(/*! ./PropertyId.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js\");\n/**\n * ConnectionMessage represents implementation specific messages sent to and received from\n * the speech service. These messages are provided for debugging purposes and should not\n * be used for production use cases with the Azure Cognitive Services Speech Service.\n * Messages sent to and received from the Speech Service are subject to change without\n * notice. This includes message contents, headers, payloads, ordering, etc.\n * Added in version 1.11.0.\n */\nclass ConnectionMessage {\n}\nexports.ConnectionMessage = ConnectionMessage;\nclass ConnectionMessageImpl {\n    constructor(message) {\n        this.privConnectionMessage = message;\n        this.privProperties = new PropertyCollection_js_1.PropertyCollection();\n        if (!!this.privConnectionMessage.headers[HeaderNames_js_1.HeaderNames.ConnectionId]) {\n            this.privProperties.setProperty(PropertyId_js_1.PropertyId.Speech_SessionId, this.privConnectionMessage.headers[HeaderNames_js_1.HeaderNames.ConnectionId]);\n        }\n        Object.keys(this.privConnectionMessage.headers).forEach((header) => {\n            this.privProperties.setProperty(header, this.privConnectionMessage.headers[header]);\n        });\n    }\n    /**\n     * The message path.\n     */\n    get path() {\n        return this.privConnectionMessage.headers[Object.keys(this.privConnectionMessage.headers).find((key) => key.toLowerCase() === \"path\".toLowerCase())];\n    }\n    /**\n     * Checks to see if the ConnectionMessage is a text message.\n     * See also IsBinaryMessage().\n     */\n    get isTextMessage() {\n        return this.privConnectionMessage.messageType === Exports_js_1.MessageType.Text;\n    }\n    /**\n     * Checks to see if the ConnectionMessage is a binary message.\n     * See also GetBinaryMessage().\n     */\n    get isBinaryMessage() {\n        return this.privConnectionMessage.messageType === Exports_js_1.MessageType.Binary;\n    }\n    /**\n     * Gets the text message payload. Typically the text message content-type is\n     * application/json. To determine other content-types use\n     * Properties.GetProperty(\"Content-Type\").\n     */\n    get TextMessage() {\n        return this.privConnectionMessage.textBody;\n    }\n    /**\n     * Gets the binary message payload.\n     */\n    get binaryMessage() {\n        return this.privConnectionMessage.binaryBody;\n    }\n    /**\n     * A collection of properties and their values defined for this <see cref=\"ConnectionMessage\"/>.\n     * Message headers can be accessed via this collection (e.g. \"Content-Type\").\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Returns a string that represents the connection message.\n     */\n    toString() {\n        return \"\";\n    }\n}\nexports.ConnectionMessageImpl = ConnectionMessageImpl;\n\n//# sourceMappingURL=ConnectionMessage.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessageEventArgs.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessageEventArgs.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionMessageEventArgs = void 0;\nclass ConnectionMessageEventArgs {\n    constructor(message) {\n        this.privConnectionMessage = message;\n    }\n    /**\n     * Gets the <see cref=\"ConnectionMessage\"/> associated with this <see cref=\"ConnectionMessageEventArgs\"/>.\n     */\n    get message() {\n        return this.privConnectionMessage;\n    }\n    /**\n     * Returns a string that represents the connection message event.\n     */\n    toString() {\n        return \"Message: \" + this.privConnectionMessage.toString();\n    }\n}\nexports.ConnectionMessageEventArgs = ConnectionMessageEventArgs;\n\n//# sourceMappingURL=ConnectionMessageEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessageEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Contracts = void 0;\n/**\n * @class Contracts\n * @private\n */\nclass Contracts {\n    static throwIfNullOrUndefined(param, name) {\n        if (param === undefined || param === null) {\n            throw new Error(\"throwIfNullOrUndefined:\" + name);\n        }\n    }\n    static throwIfNull(param, name) {\n        if (param === null) {\n            throw new Error(\"throwIfNull:\" + name);\n        }\n    }\n    static throwIfNullOrWhitespace(param, name) {\n        Contracts.throwIfNullOrUndefined(param, name);\n        if ((\"\" + param).trim().length < 1) {\n            throw new Error(\"throwIfNullOrWhitespace:\" + name);\n        }\n    }\n    static throwIfNullOrTooLong(param, name, maxLength) {\n        Contracts.throwIfNullOrUndefined(param, name);\n        if ((\"\" + param).length > maxLength) {\n            throw new Error(\"throwIfNullOrTooLong:\" + name + \" (more than \" + maxLength.toString() + \" characters)\");\n        }\n    }\n    static throwIfNullOrTooShort(param, name, minLength) {\n        Contracts.throwIfNullOrUndefined(param, name);\n        if ((\"\" + param).length < minLength) {\n            throw new Error(\"throwIfNullOrTooShort:\" + name + \" (less than \" + minLength.toString() + \" characters)\");\n        }\n    }\n    static throwIfDisposed(isDisposed) {\n        if (isDisposed) {\n            throw new Error(\"the object is already disposed\");\n        }\n    }\n    static throwIfArrayEmptyOrWhitespace(array, name) {\n        Contracts.throwIfNullOrUndefined(array, name);\n        if (array.length === 0) {\n            throw new Error(\"throwIfArrayEmptyOrWhitespace:\" + name);\n        }\n        for (const item of array) {\n            Contracts.throwIfNullOrWhitespace(item, name);\n        }\n    }\n    static throwIfFileDoesNotExist(param, name) {\n        Contracts.throwIfNullOrWhitespace(param, name);\n        // TODO check for file existence.\n    }\n    static throwIfNotUndefined(param, name) {\n        if (param !== undefined) {\n            throw new Error(\"throwIfNotUndefined:\" + name);\n        }\n    }\n}\nexports.Contracts = Contracts;\n\n//# sourceMappingURL=Contracts.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConversationTranscriptionCanceledEventArgs.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConversationTranscriptionCanceledEventArgs.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranscriptionCanceledEventArgs = void 0;\nconst CancellationEventArgsBase_js_1 = __webpack_require__(/*! ./CancellationEventArgsBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js\");\n/**\n * Defines content of a RecognitionErrorEvent.\n * @class ConversationTranscriptionCanceledEventArgs\n */\nclass ConversationTranscriptionCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {\n}\nexports.ConversationTranscriptionCanceledEventArgs = ConversationTranscriptionCanceledEventArgs;\n\n//# sourceMappingURL=ConversationTranscriptionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConversationTranscriptionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CustomCommandsConfig.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CustomCommandsConfig.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CustomCommandsConfig = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst DialogServiceConfig_js_1 = __webpack_require__(/*! ./DialogServiceConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Class that defines configurations for the dialog service connector object for using a CustomCommands backend.\n * @class CustomCommandsConfig\n */\nclass CustomCommandsConfig extends DialogServiceConfig_js_1.DialogServiceConfigImpl {\n    /**\n     * Creates an instance of CustomCommandsConfig.\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates an instance of the bot framework config with the specified subscription and region.\n     * @member CustomCommandsConfig.fromSubscription\n     * @function\n     * @public\n     * @param applicationId Speech Commands application id.\n     * @param subscription Subscription key associated with the bot\n     * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {CustomCommandsConfig} A new bot framework config.\n     */\n    static fromSubscription(applicationId, subscription, region) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(applicationId, \"applicationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscription, \"subscription\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const customCommandsConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();\n        customCommandsConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.CustomCommands);\n        customCommandsConfig.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, applicationId);\n        customCommandsConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Key, subscription);\n        customCommandsConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Region, region);\n        return customCommandsConfig;\n    }\n    /**\n     * Creates an instance of the bot framework config with the specified Speech Commands application id, authorization token and region.\n     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n     * expires, the caller needs to refresh it by calling this setter with a new valid token.\n     * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.\n     * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer\n     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n     * @member CustomCommandsConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param applicationId Speech Commands application id.\n     * @param authorizationToken The authorization token associated with the application.\n     * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {CustomCommandsConfig} A new speech commands config.\n     */\n    static fromAuthorizationToken(applicationId, authorizationToken, region) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(applicationId, \"applicationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const customCommandsConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();\n        customCommandsConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.CustomCommands);\n        customCommandsConfig.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, applicationId);\n        customCommandsConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);\n        customCommandsConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Region, region);\n        return customCommandsConfig;\n    }\n    /**\n     * Sets the corresponding backend application identifier.\n     * @member CustomCommandsConfig.prototype.Conversation_ApplicationId\n     * @function\n     * @public\n     * @param {string} value - The application identifier to set.\n     */\n    set applicationId(value) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, \"value\");\n        this.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, value);\n    }\n    /**\n     * Gets the corresponding backend application identifier.\n     * @member CustomCommandsConfig.prototype.Conversation_ApplicationId\n     * @function\n     * @public\n     * @param {string} value - The application identifier to get.\n     */\n    get applicationId() {\n        return this.getProperty(Exports_js_1.PropertyId.Conversation_ApplicationId);\n    }\n}\nexports.CustomCommandsConfig = CustomCommandsConfig;\n\n//# sourceMappingURL=CustomCommandsConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CustomCommandsConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Diagnostics.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Diagnostics.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Diagnostics = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\n/**\n * Defines diagnostics API for managing console output\n * Added in version 1.21.0\n */\nclass Diagnostics {\n    static SetLoggingLevel(logLevel) {\n        this.privListener = new Exports_js_1.ConsoleLoggingListener(logLevel);\n        Exports_js_2.Events.instance.attachConsoleListener(this.privListener);\n    }\n    static StartConsoleOutput() {\n        if (!!this.privListener) {\n            this.privListener.enableConsoleOutput = true;\n        }\n    }\n    static StopConsoleOutput() {\n        if (!!this.privListener) {\n            this.privListener.enableConsoleOutput = false;\n        }\n    }\n    static SetLogOutputPath(path) {\n        if (typeof window === \"undefined\") {\n            if (!!this.privListener) {\n                this.privListener.logPath = path;\n            }\n        }\n        else {\n            throw new Error(\"File system logging not available in browser.\");\n        }\n    }\n    static set onLogOutput(callback) {\n        if (!!this.privListener) {\n            this.privListener.logCallback = callback;\n        }\n    }\n}\nexports.Diagnostics = Diagnostics;\nDiagnostics.privListener = undefined;\n\n//# sourceMappingURL=Diagnostics.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Diagnostics.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DialogServiceConfigImpl = exports.DialogServiceConfig = void 0;\n/* eslint-disable max-classes-per-file */\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Class that defines base configurations for dialog service connector\n * @class DialogServiceConfig\n */\nclass DialogServiceConfig {\n    /**\n     * Creates an instance of DialogService config.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Sets the corresponding backend application identifier.\n     * @member DialogServiceConfig.prototype.Conversation_ApplicationId\n     * @function\n     * @public\n     * @param {string} value - The application identifier to set.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    set applicationId(value) { }\n    static get DialogTypes() {\n        return {\n            BotFramework: \"bot_framework\",\n            CustomCommands: \"custom_commands\"\n        };\n    }\n}\nexports.DialogServiceConfig = DialogServiceConfig;\n/**\n * Dialog Service configuration.\n * @class DialogServiceConfigImpl\n */\nclass DialogServiceConfigImpl extends DialogServiceConfig {\n    /**\n     * Creates an instance of dialogService config.\n     */\n    constructor() {\n        super();\n        this.privSpeechConfig = new Exports_js_1.SpeechConfigImpl();\n    }\n    /**\n     * Provides access to custom properties.\n     * @member DialogServiceConfigImpl.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The properties.\n     */\n    get properties() {\n        return this.privSpeechConfig.properties;\n    }\n    /**\n     * Gets the speech recognition language.\n     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     */\n    get speechRecognitionLanguage() {\n        return this.privSpeechConfig.speechRecognitionLanguage;\n    }\n    /**\n     * Sets the speech recognition language.\n     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @param {string} value - The language to set.\n     */\n    set speechRecognitionLanguage(value) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechConfig.speechRecognitionLanguage = value;\n    }\n    get outputFormat() {\n        return this.privSpeechConfig.outputFormat;\n    }\n    set outputFormat(value) {\n        this.privSpeechConfig.outputFormat = value;\n    }\n    /**\n     * Sets a named property as value\n     * @member DialogServiceConfigImpl.prototype.setProperty\n     * @function\n     * @public\n     * @param {PropertyId | string} name - The property to set.\n     * @param {string} value - The value.\n     */\n    setProperty(name, value) {\n        this.privSpeechConfig.setProperty(name, value);\n    }\n    /**\n     * Sets a named property as value\n     * @member DialogServiceConfigImpl.prototype.getProperty\n     * @function\n     * @public\n     * @param {PropertyId | string} name - The property to get.\n     * @param {string} def - The default value to return in case the property is not known.\n     * @returns {string} The current value, or provided default, of the given property.\n     */\n    getProperty(name, def) {\n        void def;\n        return this.privSpeechConfig.getProperty(name);\n    }\n    /**\n     * Sets the proxy configuration.\n     * Only relevant in Node.js environments.\n     * Added in version 1.4.0.\n     * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)\n     * @param proxyPort The port number of the proxy server.\n     * @param proxyUserName The user name of the proxy server.\n     * @param proxyPassword The password of the proxy server.\n     */\n    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyHostName, proxyHostName);\n        this.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyPort, `${proxyPort}`);\n        if (proxyUserName) {\n            this.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyUserName, proxyUserName);\n        }\n        if (proxyPassword) {\n            this.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyPassword, proxyPassword);\n        }\n    }\n    setServiceProperty(name, value, channel) {\n        void channel;\n        this.privSpeechConfig.setServiceProperty(name, value);\n    }\n    /**\n     * Dispose of associated resources.\n     * @member DialogServiceConfigImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n}\nexports.DialogServiceConfigImpl = DialogServiceConfigImpl;\n\n//# sourceMappingURL=DialogServiceConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConnector.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConnector.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DialogServiceConnector = void 0;\nconst DialogConnectorFactory_js_1 = __webpack_require__(/*! ../common.speech/DialogConnectorFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogConnectorFactory.js\");\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst PropertyId_js_1 = __webpack_require__(/*! ./PropertyId.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js\");\n/**\n * Dialog Service Connector\n * @class DialogServiceConnector\n */\nclass DialogServiceConnector extends Exports_js_3.Recognizer {\n    /**\n     * Initializes an instance of the DialogServiceConnector.\n     * @constructor\n     * @param {DialogServiceConfig} dialogConfig - Set of properties to configure this recognizer.\n     * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer\n     */\n    constructor(dialogConfig, audioConfig) {\n        const dialogServiceConfigImpl = dialogConfig;\n        Contracts_js_1.Contracts.throwIfNull(dialogConfig, \"dialogConfig\");\n        super(audioConfig, dialogServiceConfigImpl.properties, new DialogConnectorFactory_js_1.DialogConnectionFactory());\n        this.isTurnComplete = true;\n        this.privIsDisposed = false;\n        this.privProperties = dialogServiceConfigImpl.properties.clone();\n        const agentConfig = this.buildAgentConfig();\n        this.privReco.agentConfig.set(agentConfig);\n    }\n    /**\n     * Starts a connection to the service.\n     * Users can optionally call connect() to manually set up a connection in advance, before starting interactions.\n     *\n     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to\n     * be notified when the connection is established.\n     * @member DialogServiceConnector.prototype.connect\n     * @function\n     * @public\n     */\n    connect(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.privReco.connect(), cb, err);\n    }\n    /**\n     * Closes the connection the service.\n     * Users can optionally call disconnect() to manually shutdown the connection of the associated DialogServiceConnector.\n     *\n     * If disconnect() is called during a recognition, recognition will fail and cancel with an error.\n     */\n    disconnect(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.privReco.disconnect(), cb, err);\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member DialogServiceConnector.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(PropertyId_js_1.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Sets the authorization token used to communicate with the service.\n     * @member DialogServiceConnector.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(PropertyId_js_1.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * The collection of properties and their values defined for this DialogServiceConnector.\n     * @member DialogServiceConnector.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this DialogServiceConnector.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /** Gets the template for the activity generated by service from speech.\n     * Properties from the template will be stamped on the generated activity.\n     * It can be empty\n     */\n    get speechActivityTemplate() {\n        return this.properties.getProperty(PropertyId_js_1.PropertyId.Conversation_Speech_Activity_Template);\n    }\n    /** Sets the template for the activity generated by service from speech.\n     * Properties from the template will be stamped on the generated activity.\n     * It can be null or empty.\n     * Note: it has to be a valid Json object.\n     */\n    set speechActivityTemplate(speechActivityTemplate) {\n        this.properties.setProperty(PropertyId_js_1.PropertyId.Conversation_Speech_Activity_Template, speechActivityTemplate);\n    }\n    /**\n     * Starts recognition and stops after the first utterance is recognized.\n     * @member DialogServiceConnector.prototype.listenOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the result when the reco has completed.\n     * @param err - Callback invoked in case of an error.\n     */\n    listenOnceAsync(cb, err) {\n        if (this.isTurnComplete) {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            const callbackHolder = async () => {\n                await this.privReco.connect();\n                await this.implRecognizerStop();\n                this.isTurnComplete = false;\n                const ret = new Exports_js_2.Deferred();\n                await this.privReco.recognize(Exports_js_1.RecognitionMode.Conversation, ret.resolve, ret.reject);\n                const e = await ret.promise;\n                await this.implRecognizerStop();\n                return e;\n            };\n            const retPromise = callbackHolder();\n            retPromise.catch(() => {\n                // Destroy the recognizer.\n                // We've done all we can here.\n                // eslint-disable-next-line @typescript-eslint/no-empty-function\n                this.dispose(true).catch(() => { });\n            });\n            Exports_js_2.marshalPromiseToCallbacks(retPromise.finally(() => {\n                this.isTurnComplete = true;\n            }), cb, err);\n        }\n    }\n    sendActivityAsync(activity, cb, errCb) {\n        Exports_js_2.marshalPromiseToCallbacks(this.privReco.sendMessage(activity), cb, errCb);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member DialogServiceConnector.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, err) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n        Exports_js_2.marshalPromiseToCallbacks(this.dispose(true), cb, err);\n    }\n    async dispose(disposing) {\n        if (this.privIsDisposed) {\n            return;\n        }\n        if (disposing) {\n            this.privIsDisposed = true;\n            await this.implRecognizerStop();\n            await super.dispose(disposing);\n        }\n    }\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioSource = audioConfig;\n        return new Exports_js_1.DialogServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);\n    }\n    buildAgentConfig() {\n        const communicationType = this.properties.getProperty(\"Conversation_Communication_Type\", \"Default\");\n        return {\n            botInfo: {\n                commType: communicationType,\n                commandsCulture: undefined,\n                connectionId: this.properties.getProperty(PropertyId_js_1.PropertyId.Conversation_Agent_Connection_Id),\n                conversationId: this.properties.getProperty(PropertyId_js_1.PropertyId.Conversation_Conversation_Id, undefined),\n                fromId: this.properties.getProperty(PropertyId_js_1.PropertyId.Conversation_From_Id, undefined),\n                ttsAudioFormat: this.properties.getProperty(PropertyId_js_1.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)\n            },\n            version: 0.2\n        };\n    }\n}\nexports.DialogServiceConnector = DialogServiceConnector;\n\n//# sourceMappingURL=DialogServiceConnector.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConnector.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nvar AudioConfig_js_1 = __webpack_require__(/*! ./Audio/AudioConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig.js\");\nObject.defineProperty(exports, \"AudioConfig\", ({ enumerable: true, get: function () { return AudioConfig_js_1.AudioConfig; } }));\nvar AudioStreamFormat_js_1 = __webpack_require__(/*! ./Audio/AudioStreamFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js\");\nObject.defineProperty(exports, \"AudioStreamFormat\", ({ enumerable: true, get: function () { return AudioStreamFormat_js_1.AudioStreamFormat; } }));\nObject.defineProperty(exports, \"AudioFormatTag\", ({ enumerable: true, get: function () { return AudioStreamFormat_js_1.AudioFormatTag; } }));\nvar AudioInputStream_js_1 = __webpack_require__(/*! ./Audio/AudioInputStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js\");\nObject.defineProperty(exports, \"AudioInputStream\", ({ enumerable: true, get: function () { return AudioInputStream_js_1.AudioInputStream; } }));\nObject.defineProperty(exports, \"PullAudioInputStream\", ({ enumerable: true, get: function () { return AudioInputStream_js_1.PullAudioInputStream; } }));\nObject.defineProperty(exports, \"PushAudioInputStream\", ({ enumerable: true, get: function () { return AudioInputStream_js_1.PushAudioInputStream; } }));\nvar AudioOutputStream_js_1 = __webpack_require__(/*! ./Audio/AudioOutputStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js\");\nObject.defineProperty(exports, \"AudioOutputStream\", ({ enumerable: true, get: function () { return AudioOutputStream_js_1.AudioOutputStream; } }));\nObject.defineProperty(exports, \"PullAudioOutputStream\", ({ enumerable: true, get: function () { return AudioOutputStream_js_1.PullAudioOutputStream; } }));\nObject.defineProperty(exports, \"PushAudioOutputStream\", ({ enumerable: true, get: function () { return AudioOutputStream_js_1.PushAudioOutputStream; } }));\nvar CancellationReason_js_1 = __webpack_require__(/*! ./CancellationReason.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationReason.js\");\nObject.defineProperty(exports, \"CancellationReason\", ({ enumerable: true, get: function () { return CancellationReason_js_1.CancellationReason; } }));\nvar PullAudioInputStreamCallback_js_1 = __webpack_require__(/*! ./Audio/PullAudioInputStreamCallback.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PullAudioInputStreamCallback.js\");\nObject.defineProperty(exports, \"PullAudioInputStreamCallback\", ({ enumerable: true, get: function () { return PullAudioInputStreamCallback_js_1.PullAudioInputStreamCallback; } }));\nvar PushAudioOutputStreamCallback_js_1 = __webpack_require__(/*! ./Audio/PushAudioOutputStreamCallback.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PushAudioOutputStreamCallback.js\");\nObject.defineProperty(exports, \"PushAudioOutputStreamCallback\", ({ enumerable: true, get: function () { return PushAudioOutputStreamCallback_js_1.PushAudioOutputStreamCallback; } }));\nvar KeywordRecognitionModel_js_1 = __webpack_require__(/*! ./KeywordRecognitionModel.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/KeywordRecognitionModel.js\");\nObject.defineProperty(exports, \"KeywordRecognitionModel\", ({ enumerable: true, get: function () { return KeywordRecognitionModel_js_1.KeywordRecognitionModel; } }));\nvar SessionEventArgs_js_1 = __webpack_require__(/*! ./SessionEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SessionEventArgs.js\");\nObject.defineProperty(exports, \"SessionEventArgs\", ({ enumerable: true, get: function () { return SessionEventArgs_js_1.SessionEventArgs; } }));\nvar RecognitionEventArgs_js_1 = __webpack_require__(/*! ./RecognitionEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionEventArgs.js\");\nObject.defineProperty(exports, \"RecognitionEventArgs\", ({ enumerable: true, get: function () { return RecognitionEventArgs_js_1.RecognitionEventArgs; } }));\nvar OutputFormat_js_1 = __webpack_require__(/*! ./OutputFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/OutputFormat.js\");\nObject.defineProperty(exports, \"OutputFormat\", ({ enumerable: true, get: function () { return OutputFormat_js_1.OutputFormat; } }));\nvar IntentRecognitionEventArgs_js_1 = __webpack_require__(/*! ./IntentRecognitionEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionEventArgs.js\");\nObject.defineProperty(exports, \"IntentRecognitionEventArgs\", ({ enumerable: true, get: function () { return IntentRecognitionEventArgs_js_1.IntentRecognitionEventArgs; } }));\nvar RecognitionResult_js_1 = __webpack_require__(/*! ./RecognitionResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionResult.js\");\nObject.defineProperty(exports, \"RecognitionResult\", ({ enumerable: true, get: function () { return RecognitionResult_js_1.RecognitionResult; } }));\nvar SpeechRecognitionResult_js_1 = __webpack_require__(/*! ./SpeechRecognitionResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionResult.js\");\nObject.defineProperty(exports, \"SpeechRecognitionResult\", ({ enumerable: true, get: function () { return SpeechRecognitionResult_js_1.SpeechRecognitionResult; } }));\nvar IntentRecognitionResult_js_1 = __webpack_require__(/*! ./IntentRecognitionResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionResult.js\");\nObject.defineProperty(exports, \"IntentRecognitionResult\", ({ enumerable: true, get: function () { return IntentRecognitionResult_js_1.IntentRecognitionResult; } }));\nvar LanguageUnderstandingModel_js_1 = __webpack_require__(/*! ./LanguageUnderstandingModel.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageUnderstandingModel.js\");\nObject.defineProperty(exports, \"LanguageUnderstandingModel\", ({ enumerable: true, get: function () { return LanguageUnderstandingModel_js_1.LanguageUnderstandingModel; } }));\nvar SpeechRecognitionEventArgs_js_1 = __webpack_require__(/*! ./SpeechRecognitionEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionEventArgs.js\");\nObject.defineProperty(exports, \"SpeechRecognitionEventArgs\", ({ enumerable: true, get: function () { return SpeechRecognitionEventArgs_js_1.SpeechRecognitionEventArgs; } }));\nObject.defineProperty(exports, \"ConversationTranscriptionEventArgs\", ({ enumerable: true, get: function () { return SpeechRecognitionEventArgs_js_1.ConversationTranscriptionEventArgs; } }));\nObject.defineProperty(exports, \"MeetingTranscriptionEventArgs\", ({ enumerable: true, get: function () { return SpeechRecognitionEventArgs_js_1.MeetingTranscriptionEventArgs; } }));\nvar SpeechRecognitionCanceledEventArgs_js_1 = __webpack_require__(/*! ./SpeechRecognitionCanceledEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionCanceledEventArgs.js\");\nObject.defineProperty(exports, \"SpeechRecognitionCanceledEventArgs\", ({ enumerable: true, get: function () { return SpeechRecognitionCanceledEventArgs_js_1.SpeechRecognitionCanceledEventArgs; } }));\nvar TranslationRecognitionEventArgs_js_1 = __webpack_require__(/*! ./TranslationRecognitionEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionEventArgs.js\");\nObject.defineProperty(exports, \"TranslationRecognitionEventArgs\", ({ enumerable: true, get: function () { return TranslationRecognitionEventArgs_js_1.TranslationRecognitionEventArgs; } }));\nvar TranslationSynthesisEventArgs_js_1 = __webpack_require__(/*! ./TranslationSynthesisEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisEventArgs.js\");\nObject.defineProperty(exports, \"TranslationSynthesisEventArgs\", ({ enumerable: true, get: function () { return TranslationSynthesisEventArgs_js_1.TranslationSynthesisEventArgs; } }));\nvar TranslationRecognitionResult_js_1 = __webpack_require__(/*! ./TranslationRecognitionResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js\");\nObject.defineProperty(exports, \"TranslationRecognitionResult\", ({ enumerable: true, get: function () { return TranslationRecognitionResult_js_1.TranslationRecognitionResult; } }));\nvar TranslationSynthesisResult_js_1 = __webpack_require__(/*! ./TranslationSynthesisResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisResult.js\");\nObject.defineProperty(exports, \"TranslationSynthesisResult\", ({ enumerable: true, get: function () { return TranslationSynthesisResult_js_1.TranslationSynthesisResult; } }));\nvar ResultReason_js_1 = __webpack_require__(/*! ./ResultReason.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ResultReason.js\");\nObject.defineProperty(exports, \"ResultReason\", ({ enumerable: true, get: function () { return ResultReason_js_1.ResultReason; } }));\nvar SpeechConfig_js_1 = __webpack_require__(/*! ./SpeechConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechConfig.js\");\nObject.defineProperty(exports, \"SpeechConfig\", ({ enumerable: true, get: function () { return SpeechConfig_js_1.SpeechConfig; } }));\nObject.defineProperty(exports, \"SpeechConfigImpl\", ({ enumerable: true, get: function () { return SpeechConfig_js_1.SpeechConfigImpl; } }));\nvar SpeechTranslationConfig_js_1 = __webpack_require__(/*! ./SpeechTranslationConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechTranslationConfig.js\");\nObject.defineProperty(exports, \"SpeechTranslationConfig\", ({ enumerable: true, get: function () { return SpeechTranslationConfig_js_1.SpeechTranslationConfig; } }));\nObject.defineProperty(exports, \"SpeechTranslationConfigImpl\", ({ enumerable: true, get: function () { return SpeechTranslationConfig_js_1.SpeechTranslationConfigImpl; } }));\nvar PropertyCollection_js_1 = __webpack_require__(/*! ./PropertyCollection.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js\");\nObject.defineProperty(exports, \"PropertyCollection\", ({ enumerable: true, get: function () { return PropertyCollection_js_1.PropertyCollection; } }));\nvar PropertyId_js_1 = __webpack_require__(/*! ./PropertyId.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js\");\nObject.defineProperty(exports, \"PropertyId\", ({ enumerable: true, get: function () { return PropertyId_js_1.PropertyId; } }));\nvar Recognizer_js_1 = __webpack_require__(/*! ./Recognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Recognizer.js\");\nObject.defineProperty(exports, \"Recognizer\", ({ enumerable: true, get: function () { return Recognizer_js_1.Recognizer; } }));\nvar SpeechRecognizer_js_1 = __webpack_require__(/*! ./SpeechRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognizer.js\");\nObject.defineProperty(exports, \"SpeechRecognizer\", ({ enumerable: true, get: function () { return SpeechRecognizer_js_1.SpeechRecognizer; } }));\nvar IntentRecognizer_js_1 = __webpack_require__(/*! ./IntentRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognizer.js\");\nObject.defineProperty(exports, \"IntentRecognizer\", ({ enumerable: true, get: function () { return IntentRecognizer_js_1.IntentRecognizer; } }));\nvar VoiceProfileType_js_1 = __webpack_require__(/*! ./VoiceProfileType.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileType.js\");\nObject.defineProperty(exports, \"VoiceProfileType\", ({ enumerable: true, get: function () { return VoiceProfileType_js_1.VoiceProfileType; } }));\nvar TranslationRecognizer_js_1 = __webpack_require__(/*! ./TranslationRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognizer.js\");\nObject.defineProperty(exports, \"TranslationRecognizer\", ({ enumerable: true, get: function () { return TranslationRecognizer_js_1.TranslationRecognizer; } }));\nvar Translations_js_1 = __webpack_require__(/*! ./Translations.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Translations.js\");\nObject.defineProperty(exports, \"Translations\", ({ enumerable: true, get: function () { return Translations_js_1.Translations; } }));\nvar NoMatchReason_js_1 = __webpack_require__(/*! ./NoMatchReason.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchReason.js\");\nObject.defineProperty(exports, \"NoMatchReason\", ({ enumerable: true, get: function () { return NoMatchReason_js_1.NoMatchReason; } }));\nvar NoMatchDetails_js_1 = __webpack_require__(/*! ./NoMatchDetails.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchDetails.js\");\nObject.defineProperty(exports, \"NoMatchDetails\", ({ enumerable: true, get: function () { return NoMatchDetails_js_1.NoMatchDetails; } }));\nvar TranslationRecognitionCanceledEventArgs_js_1 = __webpack_require__(/*! ./TranslationRecognitionCanceledEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionCanceledEventArgs.js\");\nObject.defineProperty(exports, \"TranslationRecognitionCanceledEventArgs\", ({ enumerable: true, get: function () { return TranslationRecognitionCanceledEventArgs_js_1.TranslationRecognitionCanceledEventArgs; } }));\nvar IntentRecognitionCanceledEventArgs_js_1 = __webpack_require__(/*! ./IntentRecognitionCanceledEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionCanceledEventArgs.js\");\nObject.defineProperty(exports, \"IntentRecognitionCanceledEventArgs\", ({ enumerable: true, get: function () { return IntentRecognitionCanceledEventArgs_js_1.IntentRecognitionCanceledEventArgs; } }));\nvar CancellationDetailsBase_js_1 = __webpack_require__(/*! ./CancellationDetailsBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js\");\nObject.defineProperty(exports, \"CancellationDetailsBase\", ({ enumerable: true, get: function () { return CancellationDetailsBase_js_1.CancellationDetailsBase; } }));\nvar CancellationDetails_js_1 = __webpack_require__(/*! ./CancellationDetails.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetails.js\");\nObject.defineProperty(exports, \"CancellationDetails\", ({ enumerable: true, get: function () { return CancellationDetails_js_1.CancellationDetails; } }));\nvar CancellationErrorCodes_js_1 = __webpack_require__(/*! ./CancellationErrorCodes.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationErrorCodes.js\");\nObject.defineProperty(exports, \"CancellationErrorCode\", ({ enumerable: true, get: function () { return CancellationErrorCodes_js_1.CancellationErrorCode; } }));\nvar ConnectionEventArgs_js_1 = __webpack_require__(/*! ./ConnectionEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionEventArgs.js\");\nObject.defineProperty(exports, \"ConnectionEventArgs\", ({ enumerable: true, get: function () { return ConnectionEventArgs_js_1.ConnectionEventArgs; } }));\nvar ServiceEventArgs_js_1 = __webpack_require__(/*! ./ServiceEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServiceEventArgs.js\");\nObject.defineProperty(exports, \"ServiceEventArgs\", ({ enumerable: true, get: function () { return ServiceEventArgs_js_1.ServiceEventArgs; } }));\nvar Connection_js_1 = __webpack_require__(/*! ./Connection.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js\");\nObject.defineProperty(exports, \"Connection\", ({ enumerable: true, get: function () { return Connection_js_1.Connection; } }));\nvar PhraseListGrammar_js_1 = __webpack_require__(/*! ./PhraseListGrammar.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PhraseListGrammar.js\");\nObject.defineProperty(exports, \"PhraseListGrammar\", ({ enumerable: true, get: function () { return PhraseListGrammar_js_1.PhraseListGrammar; } }));\nvar DialogServiceConfig_js_1 = __webpack_require__(/*! ./DialogServiceConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js\");\nObject.defineProperty(exports, \"DialogServiceConfig\", ({ enumerable: true, get: function () { return DialogServiceConfig_js_1.DialogServiceConfig; } }));\nvar BotFrameworkConfig_js_1 = __webpack_require__(/*! ./BotFrameworkConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/BotFrameworkConfig.js\");\nObject.defineProperty(exports, \"BotFrameworkConfig\", ({ enumerable: true, get: function () { return BotFrameworkConfig_js_1.BotFrameworkConfig; } }));\nvar CustomCommandsConfig_js_1 = __webpack_require__(/*! ./CustomCommandsConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CustomCommandsConfig.js\");\nObject.defineProperty(exports, \"CustomCommandsConfig\", ({ enumerable: true, get: function () { return CustomCommandsConfig_js_1.CustomCommandsConfig; } }));\nvar DialogServiceConnector_js_1 = __webpack_require__(/*! ./DialogServiceConnector.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConnector.js\");\nObject.defineProperty(exports, \"DialogServiceConnector\", ({ enumerable: true, get: function () { return DialogServiceConnector_js_1.DialogServiceConnector; } }));\nvar ActivityReceivedEventArgs_js_1 = __webpack_require__(/*! ./ActivityReceivedEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ActivityReceivedEventArgs.js\");\nObject.defineProperty(exports, \"ActivityReceivedEventArgs\", ({ enumerable: true, get: function () { return ActivityReceivedEventArgs_js_1.ActivityReceivedEventArgs; } }));\nvar TurnStatusReceivedEventArgs_js_1 = __webpack_require__(/*! ./TurnStatusReceivedEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TurnStatusReceivedEventArgs.js\");\nObject.defineProperty(exports, \"TurnStatusReceivedEventArgs\", ({ enumerable: true, get: function () { return TurnStatusReceivedEventArgs_js_1.TurnStatusReceivedEventArgs; } }));\nvar ServicePropertyChannel_js_1 = __webpack_require__(/*! ./ServicePropertyChannel.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServicePropertyChannel.js\");\nObject.defineProperty(exports, \"ServicePropertyChannel\", ({ enumerable: true, get: function () { return ServicePropertyChannel_js_1.ServicePropertyChannel; } }));\nvar ProfanityOption_js_1 = __webpack_require__(/*! ./ProfanityOption.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ProfanityOption.js\");\nObject.defineProperty(exports, \"ProfanityOption\", ({ enumerable: true, get: function () { return ProfanityOption_js_1.ProfanityOption; } }));\nvar BaseAudioPlayer_js_1 = __webpack_require__(/*! ./Audio/BaseAudioPlayer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/BaseAudioPlayer.js\");\nObject.defineProperty(exports, \"BaseAudioPlayer\", ({ enumerable: true, get: function () { return BaseAudioPlayer_js_1.BaseAudioPlayer; } }));\nvar ConnectionMessageEventArgs_js_1 = __webpack_require__(/*! ./ConnectionMessageEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessageEventArgs.js\");\nObject.defineProperty(exports, \"ConnectionMessageEventArgs\", ({ enumerable: true, get: function () { return ConnectionMessageEventArgs_js_1.ConnectionMessageEventArgs; } }));\nvar ConnectionMessage_js_1 = __webpack_require__(/*! ./ConnectionMessage.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js\");\nObject.defineProperty(exports, \"ConnectionMessage\", ({ enumerable: true, get: function () { return ConnectionMessage_js_1.ConnectionMessage; } }));\nvar VoiceProfile_js_1 = __webpack_require__(/*! ./VoiceProfile.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfile.js\");\nObject.defineProperty(exports, \"VoiceProfile\", ({ enumerable: true, get: function () { return VoiceProfile_js_1.VoiceProfile; } }));\nvar VoiceProfileEnrollmentResult_js_1 = __webpack_require__(/*! ./VoiceProfileEnrollmentResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileEnrollmentResult.js\");\nObject.defineProperty(exports, \"VoiceProfileEnrollmentResult\", ({ enumerable: true, get: function () { return VoiceProfileEnrollmentResult_js_1.VoiceProfileEnrollmentResult; } }));\nObject.defineProperty(exports, \"VoiceProfileEnrollmentCancellationDetails\", ({ enumerable: true, get: function () { return VoiceProfileEnrollmentResult_js_1.VoiceProfileEnrollmentCancellationDetails; } }));\nvar VoiceProfileResult_js_1 = __webpack_require__(/*! ./VoiceProfileResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileResult.js\");\nObject.defineProperty(exports, \"VoiceProfileResult\", ({ enumerable: true, get: function () { return VoiceProfileResult_js_1.VoiceProfileResult; } }));\nObject.defineProperty(exports, \"VoiceProfileCancellationDetails\", ({ enumerable: true, get: function () { return VoiceProfileResult_js_1.VoiceProfileCancellationDetails; } }));\nvar VoiceProfilePhraseResult_js_1 = __webpack_require__(/*! ./VoiceProfilePhraseResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfilePhraseResult.js\");\nObject.defineProperty(exports, \"VoiceProfilePhraseResult\", ({ enumerable: true, get: function () { return VoiceProfilePhraseResult_js_1.VoiceProfilePhraseResult; } }));\nvar VoiceProfileClient_js_1 = __webpack_require__(/*! ./VoiceProfileClient.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileClient.js\");\nObject.defineProperty(exports, \"VoiceProfileClient\", ({ enumerable: true, get: function () { return VoiceProfileClient_js_1.VoiceProfileClient; } }));\nvar SpeakerRecognizer_js_1 = __webpack_require__(/*! ./SpeakerRecognizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerRecognizer.js\");\nObject.defineProperty(exports, \"SpeakerRecognizer\", ({ enumerable: true, get: function () { return SpeakerRecognizer_js_1.SpeakerRecognizer; } }));\nvar SpeakerIdentificationModel_js_1 = __webpack_require__(/*! ./SpeakerIdentificationModel.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerIdentificationModel.js\");\nObject.defineProperty(exports, \"SpeakerIdentificationModel\", ({ enumerable: true, get: function () { return SpeakerIdentificationModel_js_1.SpeakerIdentificationModel; } }));\nvar SpeakerVerificationModel_js_1 = __webpack_require__(/*! ./SpeakerVerificationModel.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerVerificationModel.js\");\nObject.defineProperty(exports, \"SpeakerVerificationModel\", ({ enumerable: true, get: function () { return SpeakerVerificationModel_js_1.SpeakerVerificationModel; } }));\nvar AutoDetectSourceLanguageConfig_js_1 = __webpack_require__(/*! ./AutoDetectSourceLanguageConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageConfig.js\");\nObject.defineProperty(exports, \"AutoDetectSourceLanguageConfig\", ({ enumerable: true, get: function () { return AutoDetectSourceLanguageConfig_js_1.AutoDetectSourceLanguageConfig; } }));\nvar AutoDetectSourceLanguageResult_js_1 = __webpack_require__(/*! ./AutoDetectSourceLanguageResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageResult.js\");\nObject.defineProperty(exports, \"AutoDetectSourceLanguageResult\", ({ enumerable: true, get: function () { return AutoDetectSourceLanguageResult_js_1.AutoDetectSourceLanguageResult; } }));\nvar SourceLanguageConfig_js_1 = __webpack_require__(/*! ./SourceLanguageConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SourceLanguageConfig.js\");\nObject.defineProperty(exports, \"SourceLanguageConfig\", ({ enumerable: true, get: function () { return SourceLanguageConfig_js_1.SourceLanguageConfig; } }));\nvar SpeakerRecognitionResult_js_1 = __webpack_require__(/*! ./SpeakerRecognitionResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerRecognitionResult.js\");\nObject.defineProperty(exports, \"SpeakerRecognitionResult\", ({ enumerable: true, get: function () { return SpeakerRecognitionResult_js_1.SpeakerRecognitionResult; } }));\nObject.defineProperty(exports, \"SpeakerRecognitionResultType\", ({ enumerable: true, get: function () { return SpeakerRecognitionResult_js_1.SpeakerRecognitionResultType; } }));\nObject.defineProperty(exports, \"SpeakerRecognitionCancellationDetails\", ({ enumerable: true, get: function () { return SpeakerRecognitionResult_js_1.SpeakerRecognitionCancellationDetails; } }));\nvar Exports_js_1 = __webpack_require__(/*! ./Transcription/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js\");\nObject.defineProperty(exports, \"Conversation\", ({ enumerable: true, get: function () { return Exports_js_1.Conversation; } }));\nObject.defineProperty(exports, \"ConversationExpirationEventArgs\", ({ enumerable: true, get: function () { return Exports_js_1.ConversationExpirationEventArgs; } }));\nObject.defineProperty(exports, \"ConversationParticipantsChangedEventArgs\", ({ enumerable: true, get: function () { return Exports_js_1.ConversationParticipantsChangedEventArgs; } }));\nObject.defineProperty(exports, \"ConversationTranslationCanceledEventArgs\", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranslationCanceledEventArgs; } }));\nObject.defineProperty(exports, \"ConversationTranslationEventArgs\", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranslationEventArgs; } }));\nObject.defineProperty(exports, \"ConversationTranslationResult\", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranslationResult; } }));\nObject.defineProperty(exports, \"ConversationTranslator\", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranslator; } }));\nObject.defineProperty(exports, \"ConversationTranscriber\", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranscriber; } }));\nObject.defineProperty(exports, \"ConversationTranscriptionResult\", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranscriptionResult; } }));\nObject.defineProperty(exports, \"Meeting\", ({ enumerable: true, get: function () { return Exports_js_1.Meeting; } }));\nObject.defineProperty(exports, \"MeetingTranscriber\", ({ enumerable: true, get: function () { return Exports_js_1.MeetingTranscriber; } }));\nObject.defineProperty(exports, \"Participant\", ({ enumerable: true, get: function () { return Exports_js_1.Participant; } }));\nObject.defineProperty(exports, \"ParticipantChangedReason\", ({ enumerable: true, get: function () { return Exports_js_1.ParticipantChangedReason; } }));\nObject.defineProperty(exports, \"User\", ({ enumerable: true, get: function () { return Exports_js_1.User; } }));\nvar Synthesizer_js_1 = __webpack_require__(/*! ./Synthesizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js\");\nObject.defineProperty(exports, \"Synthesizer\", ({ enumerable: true, get: function () { return Synthesizer_js_1.Synthesizer; } }));\nvar SpeechSynthesisOutputFormat_js_1 = __webpack_require__(/*! ./SpeechSynthesisOutputFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js\");\nObject.defineProperty(exports, \"SpeechSynthesisOutputFormat\", ({ enumerable: true, get: function () { return SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat; } }));\nvar SpeechSynthesizer_js_1 = __webpack_require__(/*! ./SpeechSynthesizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesizer.js\");\nObject.defineProperty(exports, \"SpeechSynthesizer\", ({ enumerable: true, get: function () { return SpeechSynthesizer_js_1.SpeechSynthesizer; } }));\nvar SynthesisResult_js_1 = __webpack_require__(/*! ./SynthesisResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisResult.js\");\nObject.defineProperty(exports, \"SynthesisResult\", ({ enumerable: true, get: function () { return SynthesisResult_js_1.SynthesisResult; } }));\nvar SpeechSynthesisResult_js_1 = __webpack_require__(/*! ./SpeechSynthesisResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisResult.js\");\nObject.defineProperty(exports, \"SpeechSynthesisResult\", ({ enumerable: true, get: function () { return SpeechSynthesisResult_js_1.SpeechSynthesisResult; } }));\nvar SpeechSynthesisEventArgs_js_1 = __webpack_require__(/*! ./SpeechSynthesisEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisEventArgs.js\");\nObject.defineProperty(exports, \"SpeechSynthesisEventArgs\", ({ enumerable: true, get: function () { return SpeechSynthesisEventArgs_js_1.SpeechSynthesisEventArgs; } }));\nvar SpeechSynthesisWordBoundaryEventArgs_js_1 = __webpack_require__(/*! ./SpeechSynthesisWordBoundaryEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js\");\nObject.defineProperty(exports, \"SpeechSynthesisWordBoundaryEventArgs\", ({ enumerable: true, get: function () { return SpeechSynthesisWordBoundaryEventArgs_js_1.SpeechSynthesisWordBoundaryEventArgs; } }));\nvar SpeechSynthesisBookmarkEventArgs_js_1 = __webpack_require__(/*! ./SpeechSynthesisBookmarkEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBookmarkEventArgs.js\");\nObject.defineProperty(exports, \"SpeechSynthesisBookmarkEventArgs\", ({ enumerable: true, get: function () { return SpeechSynthesisBookmarkEventArgs_js_1.SpeechSynthesisBookmarkEventArgs; } }));\nvar SpeechSynthesisVisemeEventArgs_js_1 = __webpack_require__(/*! ./SpeechSynthesisVisemeEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisVisemeEventArgs.js\");\nObject.defineProperty(exports, \"SpeechSynthesisVisemeEventArgs\", ({ enumerable: true, get: function () { return SpeechSynthesisVisemeEventArgs_js_1.SpeechSynthesisVisemeEventArgs; } }));\nvar SpeechSynthesisBoundaryType_js_1 = __webpack_require__(/*! ./SpeechSynthesisBoundaryType.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBoundaryType.js\");\nObject.defineProperty(exports, \"SpeechSynthesisBoundaryType\", ({ enumerable: true, get: function () { return SpeechSynthesisBoundaryType_js_1.SpeechSynthesisBoundaryType; } }));\nvar SynthesisVoicesResult_js_1 = __webpack_require__(/*! ./SynthesisVoicesResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisVoicesResult.js\");\nObject.defineProperty(exports, \"SynthesisVoicesResult\", ({ enumerable: true, get: function () { return SynthesisVoicesResult_js_1.SynthesisVoicesResult; } }));\nvar VoiceInfo_js_1 = __webpack_require__(/*! ./VoiceInfo.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceInfo.js\");\nObject.defineProperty(exports, \"VoiceInfo\", ({ enumerable: true, get: function () { return VoiceInfo_js_1.VoiceInfo; } }));\nvar SpeakerAudioDestination_js_1 = __webpack_require__(/*! ./Audio/SpeakerAudioDestination.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/SpeakerAudioDestination.js\");\nObject.defineProperty(exports, \"SpeakerAudioDestination\", ({ enumerable: true, get: function () { return SpeakerAudioDestination_js_1.SpeakerAudioDestination; } }));\nvar ConversationTranscriptionCanceledEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranscriptionCanceledEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConversationTranscriptionCanceledEventArgs.js\");\nObject.defineProperty(exports, \"ConversationTranscriptionCanceledEventArgs\", ({ enumerable: true, get: function () { return ConversationTranscriptionCanceledEventArgs_js_1.ConversationTranscriptionCanceledEventArgs; } }));\nvar MeetingTranscriptionCanceledEventArgs_js_1 = __webpack_require__(/*! ./MeetingTranscriptionCanceledEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/MeetingTranscriptionCanceledEventArgs.js\");\nObject.defineProperty(exports, \"MeetingTranscriptionCanceledEventArgs\", ({ enumerable: true, get: function () { return MeetingTranscriptionCanceledEventArgs_js_1.MeetingTranscriptionCanceledEventArgs; } }));\nvar PronunciationAssessmentGradingSystem_js_1 = __webpack_require__(/*! ./PronunciationAssessmentGradingSystem.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGradingSystem.js\");\nObject.defineProperty(exports, \"PronunciationAssessmentGradingSystem\", ({ enumerable: true, get: function () { return PronunciationAssessmentGradingSystem_js_1.PronunciationAssessmentGradingSystem; } }));\nvar PronunciationAssessmentGranularity_js_1 = __webpack_require__(/*! ./PronunciationAssessmentGranularity.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGranularity.js\");\nObject.defineProperty(exports, \"PronunciationAssessmentGranularity\", ({ enumerable: true, get: function () { return PronunciationAssessmentGranularity_js_1.PronunciationAssessmentGranularity; } }));\nvar PronunciationAssessmentConfig_js_1 = __webpack_require__(/*! ./PronunciationAssessmentConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentConfig.js\");\nObject.defineProperty(exports, \"PronunciationAssessmentConfig\", ({ enumerable: true, get: function () { return PronunciationAssessmentConfig_js_1.PronunciationAssessmentConfig; } }));\nvar PronunciationAssessmentResult_js_1 = __webpack_require__(/*! ./PronunciationAssessmentResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentResult.js\");\nObject.defineProperty(exports, \"PronunciationAssessmentResult\", ({ enumerable: true, get: function () { return PronunciationAssessmentResult_js_1.PronunciationAssessmentResult; } }));\nvar LanguageIdMode_js_1 = __webpack_require__(/*! ./LanguageIdMode.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js\");\nObject.defineProperty(exports, \"LanguageIdMode\", ({ enumerable: true, get: function () { return LanguageIdMode_js_1.LanguageIdMode; } }));\nvar AvatarConfig_js_1 = __webpack_require__(/*! ./AvatarConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarConfig.js\");\nObject.defineProperty(exports, \"AvatarConfig\", ({ enumerable: true, get: function () { return AvatarConfig_js_1.AvatarConfig; } }));\nvar AvatarEventArgs_js_1 = __webpack_require__(/*! ./AvatarEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarEventArgs.js\");\nObject.defineProperty(exports, \"AvatarEventArgs\", ({ enumerable: true, get: function () { return AvatarEventArgs_js_1.AvatarEventArgs; } }));\nvar AvatarSynthesizer_js_1 = __webpack_require__(/*! ./AvatarSynthesizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarSynthesizer.js\");\nObject.defineProperty(exports, \"AvatarSynthesizer\", ({ enumerable: true, get: function () { return AvatarSynthesizer_js_1.AvatarSynthesizer; } }));\nvar AvatarVideoFormat_js_1 = __webpack_require__(/*! ./AvatarVideoFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarVideoFormat.js\");\nObject.defineProperty(exports, \"AvatarVideoFormat\", ({ enumerable: true, get: function () { return AvatarVideoFormat_js_1.AvatarVideoFormat; } }));\nObject.defineProperty(exports, \"Coordinate\", ({ enumerable: true, get: function () { return AvatarVideoFormat_js_1.Coordinate; } }));\nvar AvatarWebRTCConnectionResult_js_1 = __webpack_require__(/*! ./AvatarWebRTCConnectionResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarWebRTCConnectionResult.js\");\nObject.defineProperty(exports, \"AvatarWebRTCConnectionResult\", ({ enumerable: true, get: function () { return AvatarWebRTCConnectionResult_js_1.AvatarWebRTCConnectionResult; } }));\nvar Diagnostics_js_1 = __webpack_require__(/*! ./Diagnostics.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Diagnostics.js\");\nObject.defineProperty(exports, \"Diagnostics\", ({ enumerable: true, get: function () { return Diagnostics_js_1.Diagnostics; } }));\nvar LogLevel_js_1 = __webpack_require__(/*! ./LogLevel.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js\");\nObject.defineProperty(exports, \"LogLevel\", ({ enumerable: true, get: function () { return LogLevel_js_1.LogLevel; } }));\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionCanceledEventArgs.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionCanceledEventArgs.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IntentRecognitionCanceledEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Define payload of intent recognition canceled result events.\n * @class IntentRecognitionCanceledEventArgs\n */\nclass IntentRecognitionCanceledEventArgs extends Exports_js_1.IntentRecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} result - The result of the intent recognition.\n     * @param {string} offset - The offset.\n     * @param {IntentRecognitionResult} sessionId - The session id.\n     */\n    constructor(reason, errorDetails, errorCode, result, offset, sessionId) {\n        super(result, offset, sessionId);\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member IntentRecognitionCanceledEventArgs.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member IntentRecognitionCanceledEventArgs.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\nexports.IntentRecognitionCanceledEventArgs = IntentRecognitionCanceledEventArgs;\n\n//# sourceMappingURL=IntentRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionEventArgs.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionEventArgs.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IntentRecognitionEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Intent recognition result event arguments.\n * @class\n */\nclass IntentRecognitionEventArgs extends Exports_js_1.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param result - The result of the intent recognition.\n     * @param offset - The offset.\n     * @param sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Represents the intent recognition result.\n     * @member IntentRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {IntentRecognitionResult} Represents the intent recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\nexports.IntentRecognitionEventArgs = IntentRecognitionEventArgs;\n\n//# sourceMappingURL=IntentRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionResult.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionResult.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IntentRecognitionResult = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Intent recognition result.\n * @class\n */\nclass IntentRecognitionResult extends Exports_js_1.SpeechRecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param intentId - The intent id.\n     * @param resultId - The result id.\n     * @param reason - The reason.\n     * @param text - The recognized text.\n     * @param duration - The duration.\n     * @param offset - The offset into the stream.\n     * @param language - Primary Language detected, if provided.\n     * @param languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param errorDetails - Error details, if provided.\n     * @param json - Additional Json, if provided.\n     * @param properties - Additional properties, if provided.\n     */\n    constructor(intentId, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);\n        this.privIntentId = intentId;\n    }\n    /**\n     * A String that represents the intent identifier being recognized.\n     * @member IntentRecognitionResult.prototype.intentId\n     * @function\n     * @public\n     * @returns {string} A String that represents the intent identifier being recognized.\n     */\n    get intentId() {\n        return this.privIntentId;\n    }\n}\nexports.IntentRecognitionResult = IntentRecognitionResult;\n\n//# sourceMappingURL=IntentRecognitionResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognizer.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognizer.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IntentRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Intent recognizer.\n * @class\n */\nclass IntentRecognizer extends Exports_js_3.Recognizer {\n    /**\n     * Initializes an instance of the IntentRecognizer.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - The set of configuration properties.\n     * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer\n     */\n    constructor(speechConfig, audioConfig) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig, \"speechConfig\");\n        const configImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(configImpl, \"speechConfig\");\n        super(audioConfig, configImpl.properties, new Exports_js_1.IntentConnectionFactory());\n        this.privAddedIntents = [];\n        this.privAddedLmIntents = {};\n        this.privDisposedIntentRecognizer = false;\n        this.privProperties = configImpl.properties;\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);\n    }\n    /**\n     * Gets the spoken language of recognition.\n     * @member IntentRecognizer.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} the spoken language of recognition.\n     */\n    get speechRecognitionLanguage() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member IntentRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * Note: Please use a token derived from your LanguageUnderstanding subscription key for the Intent recognizer.\n     * @member IntentRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} value - Authorization token.\n     */\n    set authorizationToken(value) {\n        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, value);\n    }\n    /**\n     * The collection of properties and their values defined for this IntentRecognizer.\n     * @member IntentRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their\n     * values defined for this IntentRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Starts intent recognition, and stops after the first utterance is recognized.\n     * The task returns the recognition text and intent as result.\n     * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,\n     * so it is suitable only for single shot recognition like command or query.\n     * For long-running recognition, use StartContinuousRecognitionAsync() instead.\n     * @member IntentRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the recognition has finished with an IntentRecognitionResult.\n     * @param err - Callback invoked in case of an error.\n     */\n    recognizeOnceAsync(cb, err) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n        if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {\n            const context = this.buildSpeechContext();\n            this.privReco.speechContext.setSection(\"intent\", context.Intent);\n            this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);\n            const intentReco = this.privReco;\n            intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);\n        }\n        Exports_js_2.marshalPromiseToCallbacks(this.recognizeOnceAsyncImpl(Exports_js_1.RecognitionMode.Interactive), cb, err);\n    }\n    /**\n     * Starts speech recognition, until stopContinuousRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * @member IntentRecognizer.prototype.startContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startContinuousRecognitionAsync(cb, err) {\n        if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {\n            const context = this.buildSpeechContext();\n            this.privReco.speechContext.setSection(\"intent\", context.Intent);\n            this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);\n            const intentReco = this.privReco;\n            intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);\n        }\n        Exports_js_2.marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(Exports_js_1.RecognitionMode.Conversation), cb, err);\n    }\n    /**\n     * Stops continuous intent recognition.\n     * @member IntentRecognizer.prototype.stopContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopContinuousRecognitionAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    /**\n     * Starts speech recognition with keyword spotting, until stopKeywordRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * Note: Key word spotting functionality is only available on the Speech Devices SDK.\n     * This functionality is currently not included in the SDK itself.\n     * @member IntentRecognizer.prototype.startKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param {KeywordRecognitionModel} model - The keyword recognition model that specifies the keyword to be recognized.\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startKeywordRecognitionAsync(model, cb, err) {\n        Contracts_js_1.Contracts.throwIfNull(model, \"model\");\n        if (!!err) {\n            err(\"Not yet implemented.\");\n        }\n    }\n    /**\n     * Stops continuous speech recognition.\n     * Note: Key word spotting functionality is only available on the Speech Devices SDK.\n     * This functionality is currently not included in the SDK itself.\n     * @member IntentRecognizer.prototype.stopKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopKeywordRecognitionAsync(cb, err) {\n        if (!!cb) {\n            try {\n                cb();\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n        }\n    }\n    /**\n     * Adds a phrase that should be recognized as intent.\n     * @member IntentRecognizer.prototype.addIntent\n     * @function\n     * @public\n     * @param {string} intentId - A String that represents the identifier of the intent to be recognized.\n     * @param {string} phrase - A String that specifies the phrase representing the intent.\n     */\n    addIntent(simplePhrase, intentId) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(intentId, \"intentId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(simplePhrase, \"simplePhrase\");\n        this.privAddedIntents.push([intentId, simplePhrase]);\n    }\n    /**\n     * Adds an intent from Language Understanding service for recognition.\n     * @member IntentRecognizer.prototype.addIntentWithLanguageModel\n     * @function\n     * @public\n     * @param {string} intentId - A String that represents the identifier of the intent\n     * to be recognized. Ignored if intentName is empty.\n     * @param {string} model - The intent model from Language Understanding service.\n     * @param {string} intentName - The intent name defined in the intent model. If it\n     * is empty, all intent names defined in the model will be added.\n     */\n    addIntentWithLanguageModel(intentId, model, intentName) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(intentId, \"intentId\");\n        Contracts_js_1.Contracts.throwIfNull(model, \"model\");\n        const modelImpl = model;\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(modelImpl.appId, \"model.appId\");\n        this.privAddedLmIntents[intentId] = new Exports_js_1.AddedLmIntent(modelImpl, intentName);\n    }\n    /**\n     * @summary Adds all intents from the specified Language Understanding Model.\n     * @member IntentRecognizer.prototype.addAllIntents\n     * @function\n     * @public\n     * @function\n     * @public\n     * @param {LanguageUnderstandingModel} model - The language understanding model containing the intents.\n     * @param {string} intentId - A custom id String to be returned in the IntentRecognitionResult's getIntentId() method.\n     */\n    addAllIntents(model, intentId) {\n        Contracts_js_1.Contracts.throwIfNull(model, \"model\");\n        const modelImpl = model;\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(modelImpl.appId, \"model.appId\");\n        this.privUmbrellaIntent = new Exports_js_1.AddedLmIntent(modelImpl, intentId);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member IntentRecognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n        Exports_js_2.marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);\n    }\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioImpl = audioConfig;\n        return new Exports_js_1.IntentServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);\n    }\n    async dispose(disposing) {\n        if (this.privDisposedIntentRecognizer) {\n            return;\n        }\n        if (disposing) {\n            this.privDisposedIntentRecognizer = true;\n            await super.dispose(disposing);\n        }\n    }\n    buildSpeechContext() {\n        let appId;\n        let region;\n        let subscriptionKey;\n        const refGrammers = [];\n        if (undefined !== this.privUmbrellaIntent) {\n            appId = this.privUmbrellaIntent.modelImpl.appId;\n            region = this.privUmbrellaIntent.modelImpl.region;\n            subscriptionKey = this.privUmbrellaIntent.modelImpl.subscriptionKey;\n        }\n        // Build the reference grammer array.\n        for (const intentId of Object.keys(this.privAddedLmIntents)) {\n            const addedLmIntent = this.privAddedLmIntents[intentId];\n            // validate all the same model, region, and key...\n            if (appId === undefined) {\n                appId = addedLmIntent.modelImpl.appId;\n            }\n            else {\n                if (appId !== addedLmIntent.modelImpl.appId) {\n                    throw new Error(\"Intents must all be from the same LUIS model\");\n                }\n            }\n            if (region === undefined) {\n                region = addedLmIntent.modelImpl.region;\n            }\n            else {\n                if (region !== addedLmIntent.modelImpl.region) {\n                    throw new Error(\"Intents must all be from the same LUIS model in a single region\");\n                }\n            }\n            if (subscriptionKey === undefined) {\n                subscriptionKey = addedLmIntent.modelImpl.subscriptionKey;\n            }\n            else {\n                if (subscriptionKey !== addedLmIntent.modelImpl.subscriptionKey) {\n                    throw new Error(\"Intents must all use the same subscription key\");\n                }\n            }\n            const grammer = \"luis/\" + appId + \"-PRODUCTION#\" + intentId;\n            refGrammers.push(grammer);\n        }\n        return {\n            Intent: {\n                id: appId,\n                key: (subscriptionKey === undefined) ? this.privProperties.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_Key]) : subscriptionKey,\n                provider: \"LUIS\",\n            },\n            ReferenceGrammars: (undefined === this.privUmbrellaIntent) ? refGrammers : [\"luis/\" + appId + \"-PRODUCTION\"],\n        };\n    }\n}\nexports.IntentRecognizer = IntentRecognizer;\n\n//# sourceMappingURL=IntentRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/IntentRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/KeywordRecognitionModel.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/KeywordRecognitionModel.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.KeywordRecognitionModel = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\n/**\n * Represents a keyword recognition model for recognizing when\n * the user says a keyword to initiate further speech recognition.\n * @class KeywordRecognitionModel\n */\nclass KeywordRecognitionModel {\n    /**\n     * Create and initializes a new instance.\n     * @constructor\n     */\n    constructor() {\n        this.privDisposed = false;\n        return;\n    }\n    /**\n     * Creates a keyword recognition model using the specified filename.\n     * @member KeywordRecognitionModel.fromFile\n     * @function\n     * @public\n     * @param {string} fileName - A string that represents file name for the keyword recognition model.\n     * Note, the file can point to a zip file in which case the model\n     * will be extracted from the zip.\n     * @returns {KeywordRecognitionModel} The keyword recognition model being created.\n     */\n    static fromFile(fileName) {\n        Contracts_js_1.Contracts.throwIfFileDoesNotExist(fileName, \"fileName\");\n        throw new Error(\"Not yet implemented.\");\n    }\n    /**\n     * Creates a keyword recognition model using the specified filename.\n     * @member KeywordRecognitionModel.fromStream\n     * @function\n     * @public\n     * @param {string} file - A File that represents file for the keyword recognition model.\n     * Note, the file can point to a zip file in which case the model will be extracted from the zip.\n     * @returns {KeywordRecognitionModel} The keyword recognition model being created.\n     */\n    static fromStream(file) {\n        Contracts_js_1.Contracts.throwIfNull(file, \"file\");\n        throw new Error(\"Not yet implemented.\");\n    }\n    /**\n     * Dispose of associated resources.\n     * @member KeywordRecognitionModel.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        if (this.privDisposed) {\n            return;\n        }\n        this.privDisposed = true;\n    }\n}\nexports.KeywordRecognitionModel = KeywordRecognitionModel;\n\n//# sourceMappingURL=KeywordRecognitionModel.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/KeywordRecognitionModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.LanguageIdMode = void 0;\n/**\n * Language Identification mode\n * @class LanguageIdMode\n */\nvar LanguageIdMode;\n(function (LanguageIdMode) {\n    /**\n     * Detect language at audio start\n     * @member LanguageIdMode.AtStart\n     */\n    LanguageIdMode[LanguageIdMode[\"AtStart\"] = 0] = \"AtStart\";\n    /**\n     * Continuously detect language\n     * @member LanguageIdMode.Continuous\n     */\n    LanguageIdMode[LanguageIdMode[\"Continuous\"] = 1] = \"Continuous\";\n})(LanguageIdMode = exports.LanguageIdMode || (exports.LanguageIdMode = {}));\n\n//# sourceMappingURL=LanguageIdMode.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageUnderstandingModel.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageUnderstandingModel.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.LanguageUnderstandingModelImpl = exports.LanguageUnderstandingModel = void 0;\n// eslint-disable-next-line max-classes-per-file\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\n/**\n * Language understanding model\n * @class LanguageUnderstandingModel\n */\nclass LanguageUnderstandingModel {\n    /**\n     * Creates and initializes a new instance\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Creates an language understanding model using the specified endpoint.\n     * @member LanguageUnderstandingModel.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} uri - A String that represents the endpoint of the language understanding model.\n     * @returns {LanguageUnderstandingModel} The language understanding model being created.\n     */\n    static fromEndpoint(uri) {\n        Contracts_js_1.Contracts.throwIfNull(uri, \"uri\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(uri.hostname, \"uri\");\n        const langModelImp = new LanguageUnderstandingModelImpl();\n        // Need to extract the app ID from the URL.\n        // URL is in the format: https://<region>.api.cognitive.microsoft.com/luis/v2.0/apps/<Guid>?subscription-key=<key>&timezoneOffset=-360\n        // Start tearing the string apart.\n        // region can be extracted from the host name.\n        const firstDot = uri.host.indexOf(\".\");\n        if (-1 === firstDot) {\n            throw new Error(\"Could not determine region from endpoint\");\n        }\n        langModelImp.region = uri.host.substr(0, firstDot);\n        // Now the app ID.\n        const lastSegment = uri.pathname.lastIndexOf(\"/\") + 1;\n        if (-1 === lastSegment) {\n            throw new Error(\"Could not determine appId from endpoint\");\n        }\n        langModelImp.appId = uri.pathname.substr(lastSegment);\n        // And finally the key.\n        langModelImp.subscriptionKey = uri.searchParams.get(\"subscription-key\");\n        if (undefined === langModelImp.subscriptionKey) {\n            throw new Error(\"Could not determine subscription key from endpoint\");\n        }\n        return langModelImp;\n    }\n    /**\n     * Creates an language understanding model using the application id of Language Understanding service.\n     * @member LanguageUnderstandingModel.fromAppId\n     * @function\n     * @public\n     * @param {string} appId - A String that represents the application id of Language Understanding service.\n     * @returns {LanguageUnderstandingModel} The language understanding model being created.\n     */\n    static fromAppId(appId) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(appId, \"appId\");\n        const langModelImp = new LanguageUnderstandingModelImpl();\n        langModelImp.appId = appId;\n        return langModelImp;\n    }\n    /**\n     * Creates a language understanding model using hostname, subscription key and application\n     * id of Language Understanding service.\n     * @member LanguageUnderstandingModel.fromSubscription\n     * @function\n     * @public\n     * @param {string} subscriptionKey - A String that represents the subscription key of\n     * Language Understanding service.\n     * @param {string} appId - A String that represents the application id of Language\n     * Understanding service.\n     * @param {LanguageUnderstandingModel} region - A String that represents the region\n     * of the Language Understanding service (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {LanguageUnderstandingModel} The language understanding model being created.\n     */\n    static fromSubscription(subscriptionKey, appId, region) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(appId, \"appId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const langModelImp = new LanguageUnderstandingModelImpl();\n        langModelImp.appId = appId;\n        langModelImp.region = region;\n        langModelImp.subscriptionKey = subscriptionKey;\n        return langModelImp;\n    }\n}\nexports.LanguageUnderstandingModel = LanguageUnderstandingModel;\n/**\n * @private\n * @class LanguageUnderstandingModelImpl\n */\nclass LanguageUnderstandingModelImpl extends LanguageUnderstandingModel {\n}\nexports.LanguageUnderstandingModelImpl = LanguageUnderstandingModelImpl;\n\n//# sourceMappingURL=LanguageUnderstandingModel.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageUnderstandingModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.LogLevel = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nObject.defineProperty(exports, \"LogLevel\", ({ enumerable: true, get: function () { return Exports_js_1.EventType; } }));\n\n//# sourceMappingURL=LogLevel.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/MeetingTranscriptionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/MeetingTranscriptionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MeetingTranscriptionCanceledEventArgs = void 0;\nconst CancellationEventArgsBase_js_1 = __webpack_require__(/*! ./CancellationEventArgsBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js\");\n/**\n * Defines content of a MeetingTranscriptionCanceledEvent.\n * @class MeetingTranscriptionCanceledEventArgs\n */\nclass MeetingTranscriptionCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {\n}\nexports.MeetingTranscriptionCanceledEventArgs = MeetingTranscriptionCanceledEventArgs;\n\n//# sourceMappingURL=MeetingTranscriptionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/MeetingTranscriptionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchDetails.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchDetails.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.NoMatchDetails = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../src/common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Contains detailed information for NoMatch recognition results.\n * @class NoMatchDetails\n */\nclass NoMatchDetails {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {NoMatchReason} reason - The no-match reason.\n     */\n    constructor(reason) {\n        this.privReason = reason;\n    }\n    /**\n     * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.\n     * @member NoMatchDetails.fromResult\n     * @function\n     * @public\n     * @param {SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult}\n     * result - The recognition result that was not recognized.\n     * @returns {NoMatchDetails} The no match details object being created.\n     */\n    static fromResult(result) {\n        const simpleSpeech = Exports_js_1.SimpleSpeechPhrase.fromJSON(result.json, 0); // Offset fixups are already done.\n        let reason = Exports_js_2.NoMatchReason.NotRecognized;\n        switch (simpleSpeech.RecognitionStatus) {\n            case Exports_js_1.RecognitionStatus.BabbleTimeout:\n                reason = Exports_js_2.NoMatchReason.InitialBabbleTimeout;\n                break;\n            case Exports_js_1.RecognitionStatus.InitialSilenceTimeout:\n                reason = Exports_js_2.NoMatchReason.InitialSilenceTimeout;\n                break;\n            default:\n                reason = Exports_js_2.NoMatchReason.NotRecognized;\n                break;\n        }\n        return new NoMatchDetails(reason);\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member NoMatchDetails.prototype.reason\n     * @function\n     * @public\n     * @returns {NoMatchReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n}\nexports.NoMatchDetails = NoMatchDetails;\n\n//# sourceMappingURL=NoMatchDetails.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchDetails.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchReason.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchReason.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.NoMatchReason = void 0;\n/**\n * Defines the possible reasons a recognition result might not be recognized.\n * @class NoMatchReason\n */\nvar NoMatchReason;\n(function (NoMatchReason) {\n    /**\n     * Indicates that speech was detected, but not recognized.\n     * @member NoMatchReason.NotRecognized\n     */\n    NoMatchReason[NoMatchReason[\"NotRecognized\"] = 0] = \"NotRecognized\";\n    /**\n     * Indicates that the start of the audio stream contained only silence,\n     * and the service timed out waiting for speech.\n     * @member NoMatchReason.InitialSilenceTimeout\n     */\n    NoMatchReason[NoMatchReason[\"InitialSilenceTimeout\"] = 1] = \"InitialSilenceTimeout\";\n    /**\n     * Indicates that the start of the audio stream contained only noise,\n     * and the service timed out waiting for speech.\n     * @member NoMatchReason.InitialBabbleTimeout\n     */\n    NoMatchReason[NoMatchReason[\"InitialBabbleTimeout\"] = 2] = \"InitialBabbleTimeout\";\n})(NoMatchReason = exports.NoMatchReason || (exports.NoMatchReason = {}));\n\n//# sourceMappingURL=NoMatchReason.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/OutputFormat.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/OutputFormat.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OutputFormat = void 0;\n/**\n * Define Speech Recognizer output formats.\n * @class OutputFormat\n */\nvar OutputFormat;\n(function (OutputFormat) {\n    /**\n     * @member OutputFormat.Simple\n     */\n    OutputFormat[OutputFormat[\"Simple\"] = 0] = \"Simple\";\n    /**\n     * @member OutputFormat.Detailed\n     */\n    OutputFormat[OutputFormat[\"Detailed\"] = 1] = \"Detailed\";\n})(OutputFormat = exports.OutputFormat || (exports.OutputFormat = {}));\n\n//# sourceMappingURL=OutputFormat.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/OutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PhraseListGrammar.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PhraseListGrammar.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PhraseListGrammar = void 0;\n/**\n * Allows additions of new phrases to improve speech recognition.\n *\n * Phrases added to the recognizer are effective at the start of the next recognition, or the next time the SpeechSDK must reconnect\n * to the speech service.\n */\nclass PhraseListGrammar {\n    constructor(recogBase) {\n        this.privGrammerBuilder = recogBase.dynamicGrammar;\n    }\n    /**\n     * Creates a PhraseListGrammar from a given speech recognizer. Will accept any recognizer that derives from @class Recognizer.\n     * @param recognizer The recognizer to add phrase lists to.\n     */\n    static fromRecognizer(recognizer) {\n        const recoBase = recognizer.internalData;\n        return new PhraseListGrammar(recoBase);\n    }\n    /**\n     * Adds a single phrase to the current recognizer.\n     * @param phrase Phrase to add.\n     */\n    addPhrase(phrase) {\n        this.privGrammerBuilder.addPhrase(phrase);\n    }\n    /**\n     * Adds multiple phrases to the current recognizer.\n     * @param phrases Array of phrases to add.\n     */\n    addPhrases(phrases) {\n        this.privGrammerBuilder.addPhrase(phrases);\n    }\n    /**\n     * Clears all phrases added to the current recognizer.\n     */\n    clear() {\n        this.privGrammerBuilder.clearPhrases();\n    }\n}\nexports.PhraseListGrammar = PhraseListGrammar;\n\n//# sourceMappingURL=PhraseListGrammar.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PhraseListGrammar.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ProfanityOption.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ProfanityOption.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ProfanityOption = void 0;\n/**\n * Profanity option.\n * Added in version 1.7.0.\n */\nvar ProfanityOption;\n(function (ProfanityOption) {\n    ProfanityOption[ProfanityOption[\"Masked\"] = 0] = \"Masked\";\n    ProfanityOption[ProfanityOption[\"Removed\"] = 1] = \"Removed\";\n    ProfanityOption[ProfanityOption[\"Raw\"] = 2] = \"Raw\";\n})(ProfanityOption = exports.ProfanityOption || (exports.ProfanityOption = {}));\n\n//# sourceMappingURL=ProfanityOption.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ProfanityOption.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentConfig.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentConfig.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PronunciationAssessmentConfig = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Pronunciation assessment configuration.\n * @class PronunciationAssessmentConfig\n * Added in version 1.15.0.\n */\nclass PronunciationAssessmentConfig {\n    /**\n     * PronunciationAssessmentConfig constructor.\n     * @constructor\n     * @param {string} referenceText\n     * @param gradingSystem\n     * @param granularity\n     * @param enableMiscue\n     */\n    constructor(referenceText, gradingSystem = Exports_js_1.PronunciationAssessmentGradingSystem.FivePoint, granularity = Exports_js_1.PronunciationAssessmentGranularity.Phoneme, enableMiscue = false) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(referenceText, \"referenceText\");\n        this.privProperties = new Exports_js_1.PropertyCollection();\n        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_ReferenceText, referenceText);\n        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_GradingSystem, Exports_js_1.PronunciationAssessmentGradingSystem[gradingSystem]);\n        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_Granularity, Exports_js_1.PronunciationAssessmentGranularity[granularity]);\n        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_EnableMiscue, String(enableMiscue));\n    }\n    /**\n     * @member PronunciationAssessmentConfig.fromJSON\n     * @function\n     * @public\n     * @param {string} json The json string containing the pronunciation assessment parameters.\n     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig\n     * @summary Creates an instance of the PronunciationAssessmentConfig from json.\n     * This method is designed to support the pronunciation assessment parameters still in preview.\n     * Under normal circumstances, use the constructor instead.\n     */\n    static fromJSON(json) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(json, \"json\");\n        const config = new PronunciationAssessmentConfig(\"\");\n        config.privProperties = new Exports_js_1.PropertyCollection();\n        config.properties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_Json, json);\n        return config;\n    }\n    toJSON() {\n        this.updateJson();\n        return this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_Params);\n    }\n    applyTo(recognizer) {\n        this.updateJson();\n        const recoBase = recognizer.internalData;\n        recoBase.expectContentAssessmentResponse = !!this.privContentAssessmentTopic;\n        recoBase.speechContext.setPronunciationAssessmentParams(this.properties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_Params), this.privContentAssessmentTopic, recoBase.isSpeakerDiarizationEnabled);\n    }\n    /**\n     * Gets the reference text.\n     * @member PronunciationAssessmentConfig.prototype.referenceText\n     * @function\n     * @public\n     * @returns {string} Reference text.\n     */\n    get referenceText() {\n        return this.properties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_ReferenceText);\n    }\n    /**\n     * Gets/Sets the reference text.\n     * @member PronunciationAssessmentConfig.prototype.referenceText\n     * @function\n     * @public\n     * @param {string} referenceText - Reference text.\n     */\n    set referenceText(referenceText) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(referenceText, \"referenceText\");\n        this.properties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_ReferenceText, referenceText);\n    }\n    /**\n     * Sets the phoneme alphabet.\n     * The valid values are \"SAPI\" (default) and \"IPA\".\n     * Added in version 1.20.0\n     * @member PronunciationAssessmentConfig.prototype.phonemeAlphabet\n     * @function\n     * @public\n     * @param {string} phonemeAlphabet - Phoneme alphabet.\n     */\n    set phonemeAlphabet(phonemeAlphabet) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(phonemeAlphabet, \"phonemeAlphabet\");\n        this.privPhonemeAlphabet = phonemeAlphabet;\n    }\n    /**\n     * Sets the boolean enableMiscue property.\n     * Added in version 1.26.0\n     * @member PronunciationAssessmentConfig.prototype.enableMiscue\n     * @function\n     * @public\n     * @param {boolean} enableMiscue - enable miscue.\n     */\n    set enableMiscue(enableMiscue) {\n        const enableMiscueString = enableMiscue ? \"true\" : \"false\";\n        this.properties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_EnableMiscue, enableMiscueString);\n    }\n    /**\n     * Gets the boolean enableMiscue property.\n     * Added in version 1.26.0\n     * @member PronunciationAssessmentConfig.prototype.enableMiscue\n     * @function\n     * @public\n     * @return {boolean} enableMiscue - enable miscue.\n     */\n    get enableMiscue() {\n        const enableMiscueString = this.properties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_EnableMiscue, \"false\");\n        return (enableMiscueString.toLowerCase() === \"true\");\n    }\n    /**\n     * Sets the nbest phoneme count\n     * Added in version 1.20.0\n     * @member PronunciationAssessmentConfig.prototype.nbestPhonemeCount\n     * @function\n     * @public\n     * @param {number} nbestPhonemeCount - NBest phoneme count.\n     */\n    set nbestPhonemeCount(nbestPhonemeCount) {\n        this.privNBestPhonemeCount = nbestPhonemeCount;\n    }\n    /**\n     * Enables the prosody assessment.\n     * Added in version 1.34.0\n     * @member PronunciationAssessmentConfig.prototype.enableProsodyAssessment\n     * @function\n     * @public\n     * @param {boolean} enableProsodyAssessment - enable prosody assessment.\n     */\n    set enableProsodyAssessment(enableProsodyAssessment) {\n        this.privEnableProsodyAssessment = enableProsodyAssessment;\n    }\n    /**\n     * Enables content assessment and sets the topic.\n     * Added in version 1.34.0\n     * @member PronunciationAssessmentConfig.prototype.enableContentAssessmentWithTopic\n     * @function\n     * @public\n     * @param {string} topic - Topic for content assessment.\n     */\n    enableContentAssessmentWithTopic(topic) {\n        this.privContentAssessmentTopic = topic;\n    }\n    /**\n     * @member PronunciationAssessmentConfig.prototype.properties\n     * @function\n     * @public\n     * @return {PropertyCollection} Properties of the config.\n     * @summary Gets a pronunciation assessment config properties\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    updateJson() {\n        const jsonString = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_Json, \"{}\");\n        const paramsJson = JSON.parse(jsonString);\n        const referenceText = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_ReferenceText);\n        if (referenceText) {\n            paramsJson.referenceText = referenceText;\n        }\n        const gradingSystem = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_GradingSystem);\n        if (gradingSystem) {\n            paramsJson.gradingSystem = gradingSystem;\n        }\n        const granularity = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_Granularity);\n        if (granularity) {\n            paramsJson.granularity = granularity;\n        }\n        if (this.privPhonemeAlphabet) {\n            paramsJson.phonemeAlphabet = this.privPhonemeAlphabet;\n        }\n        if (this.privNBestPhonemeCount) {\n            paramsJson.nbestPhonemeCount = this.privNBestPhonemeCount;\n        }\n        paramsJson.enableProsodyAssessment = this.privEnableProsodyAssessment;\n        // always set dimension to Comprehensive\n        paramsJson.dimension = \"Comprehensive\";\n        const enableMiscueString = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_EnableMiscue);\n        if (enableMiscueString) {\n            paramsJson.enableMiscue = this.enableMiscue;\n        }\n        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_Params, JSON.stringify(paramsJson));\n    }\n}\nexports.PronunciationAssessmentConfig = PronunciationAssessmentConfig;\n\n//# sourceMappingURL=PronunciationAssessmentConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGradingSystem.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGradingSystem.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PronunciationAssessmentGradingSystem = void 0;\n/**\n * Defines the point system for pronunciation score calibration; default value is FivePoint.\n * Added in version 1.15.0\n * @class PronunciationAssessmentGradingSystem\n */\nvar PronunciationAssessmentGradingSystem;\n(function (PronunciationAssessmentGradingSystem) {\n    /**\n     * Five point calibration\n     * @member PronunciationAssessmentGradingSystem.FivePoint\n     */\n    PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem[\"FivePoint\"] = 1] = \"FivePoint\";\n    /**\n     * Hundred mark\n     * @member PronunciationAssessmentGradingSystem.HundredMark\n     */\n    PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem[\"HundredMark\"] = 2] = \"HundredMark\";\n})(PronunciationAssessmentGradingSystem = exports.PronunciationAssessmentGradingSystem || (exports.PronunciationAssessmentGradingSystem = {}));\n\n//# sourceMappingURL=PronunciationAssessmentGradingSystem.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGradingSystem.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGranularity.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGranularity.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PronunciationAssessmentGranularity = void 0;\n/**\n * Defines the pronunciation evaluation granularity; default value is Phoneme.\n * Added in version 1.15.0\n * @class PronunciationAssessmentGranularity\n */\nvar PronunciationAssessmentGranularity;\n(function (PronunciationAssessmentGranularity) {\n    /**\n     * Shows the score on the full text, word and phoneme level\n     * @member PronunciationAssessmentGranularity.Phoneme\n     */\n    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"Phoneme\"] = 1] = \"Phoneme\";\n    /**\n     * Shows the score on the full text and word level\n     * @member PronunciationAssessmentGranularity.Word\n     */\n    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"Word\"] = 2] = \"Word\";\n    /**\n     * Shows the score on the full text level only\n     * @member PronunciationAssessmentGranularity.FullText\n     */\n    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"FullText\"] = 3] = \"FullText\";\n})(PronunciationAssessmentGranularity = exports.PronunciationAssessmentGranularity || (exports.PronunciationAssessmentGranularity = {}));\n\n//# sourceMappingURL=PronunciationAssessmentGranularity.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGranularity.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentResult.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentResult.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PronunciationAssessmentResult = exports.ContentAssessmentResult = void 0;\n/* eslint-disable max-classes-per-file */\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass ContentAssessmentResult {\n    /**\n     * @Internal\n     * Do not use externally.\n     */\n    constructor(detailResult) {\n        this.privPronJson = detailResult;\n    }\n    /**\n     * Correctness in using grammar and variety of sentence patterns.\n     * Grammatical errors are jointly evaluated by lexical accuracy,\n     * grammatical accuracy and diversity of sentence structures.\n     * @member ContentAssessmentResult.prototype.grammarScore\n     * @function\n     * @public\n     * @returns {number} Grammar score.\n     */\n    get grammarScore() {\n        return this.privPronJson.ContentAssessment.GrammarScore;\n    }\n    /**\n     * Proficiency in lexical usage. It evaluates the speaker's effective usage\n     * of words and their appropriateness within the given context to express\n     * ideas accurately, as well as level of lexical complexity.\n     * @member ContentAssessmentResult.prototype.vocabularyScore\n     * @function\n     * @public\n     * @returns {number} Vocabulary score.\n     */\n    get vocabularyScore() {\n        return this.privPronJson.ContentAssessment.VocabularyScore;\n    }\n    /**\n     * Level of understanding and engagement with the topic, which provides\n     * insights into the speakerâ€™s ability to express their thoughts and ideas\n     * effectively and the ability to engage with the topic.\n     * @member ContentAssessmentResult.prototype.topicScore\n     * @function\n     * @public\n     * @returns {number} Topic score.\n     */\n    get topicScore() {\n        return this.privPronJson.ContentAssessment.TopicScore;\n    }\n}\nexports.ContentAssessmentResult = ContentAssessmentResult;\n/**\n * Pronunciation assessment results.\n * @class PronunciationAssessmentResult\n * Added in version 1.15.0.\n */\nclass PronunciationAssessmentResult {\n    constructor(jsonString) {\n        const j = JSON.parse(jsonString);\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(j.NBest[0], \"NBest\");\n        this.privPronJson = j.NBest[0];\n    }\n    /**\n     * @member PronunciationAssessmentResult.fromResult\n     * @function\n     * @public\n     * @param {RecognitionResult} result The recognition result.\n     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig\n     * @summary Creates an instance of the PronunciationAssessmentResult from recognition result.\n     */\n    static fromResult(result) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(result, \"result\");\n        const json = result.properties.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult);\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(json, \"json\");\n        return new PronunciationAssessmentResult(json);\n    }\n    /**\n     * Gets the detail result of pronunciation assessment.\n     * @member PronunciationAssessmentConfig.prototype.detailResult\n     * @function\n     * @public\n     * @returns {DetailResult} detail result.\n     */\n    get detailResult() {\n        return this.privPronJson;\n    }\n    /**\n     * The score indicating the pronunciation accuracy of the given speech, which indicates\n     * how closely the phonemes match a native speaker's pronunciation.\n     * @member PronunciationAssessmentResult.prototype.accuracyScore\n     * @function\n     * @public\n     * @returns {number} Accuracy score.\n     */\n    get accuracyScore() {\n        return this.detailResult.PronunciationAssessment?.AccuracyScore;\n    }\n    /**\n     * The overall score indicating the pronunciation quality of the given speech.\n     * This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.\n     * @member PronunciationAssessmentResult.prototype.pronunciationScore\n     * @function\n     * @public\n     * @returns {number} Pronunciation score.\n     */\n    get pronunciationScore() {\n        return this.detailResult.PronunciationAssessment?.PronScore;\n    }\n    /**\n     * The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.\n     * @member PronunciationAssessmentResult.prototype.completenessScore\n     * @function\n     * @public\n     * @returns {number} Completeness score.\n     */\n    get completenessScore() {\n        return this.detailResult.PronunciationAssessment?.CompletenessScore;\n    }\n    /**\n     * The score indicating the fluency of the given speech.\n     * @member PronunciationAssessmentResult.prototype.fluencyScore\n     * @function\n     * @public\n     * @returns {number} Fluency score.\n     */\n    get fluencyScore() {\n        return this.detailResult.PronunciationAssessment?.FluencyScore;\n    }\n    /**\n     * The prosody score, which indicates how nature of the given speech, including stress, intonation, speaking speed and rhythm.\n     * @member PronunciationAssessmentResult.prototype.prosodyScore\n     * @function\n     * @public\n     * @returns {number} Prosody score.\n     */\n    get prosodyScore() {\n        return this.detailResult.PronunciationAssessment?.ProsodyScore;\n    }\n    /**\n     * The concent assessment result.\n     * Only available when content assessment is enabled.\n     * @member PronunciationAssessmentResult.prototype.contentAssessmentResult\n     * @function\n     * @public\n     * @returns {ContentAssessmentResult} Content assessment result.\n     */\n    get contentAssessmentResult() {\n        if (this.detailResult.ContentAssessment === undefined) {\n            return undefined;\n        }\n        return new ContentAssessmentResult(this.detailResult);\n    }\n}\nexports.PronunciationAssessmentResult = PronunciationAssessmentResult;\n\n//# sourceMappingURL=PronunciationAssessmentResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PropertyCollection = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Represents collection of properties and their values.\n * @class PropertyCollection\n */\nclass PropertyCollection {\n    constructor() {\n        this.privKeys = [];\n        this.privValues = [];\n    }\n    /**\n     * Returns the property value in type String.\n     * Currently only String, int and bool are allowed.\n     * If the name is not available, the specified defaultValue is returned.\n     * @member PropertyCollection.prototype.getProperty\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string | number | boolean} def - The default value which is returned if the parameter\n     * is not available in the collection.\n     * @returns {string} value of the parameter.\n     */\n    getProperty(key, def) {\n        let keyToUse;\n        if (typeof key === \"string\") {\n            keyToUse = key;\n        }\n        else {\n            keyToUse = Exports_js_1.PropertyId[key];\n        }\n        for (let n = 0; n < this.privKeys.length; n++) {\n            if (this.privKeys[n] === keyToUse) {\n                return this.privValues[n];\n            }\n        }\n        if (def === undefined) {\n            return undefined;\n        }\n        return String(def);\n    }\n    /**\n     * Sets the String value of the parameter specified by name.\n     * @member PropertyCollection.prototype.setProperty\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} value - The value of the parameter.\n     */\n    setProperty(key, value) {\n        let keyToUse;\n        if (typeof key === \"string\") {\n            keyToUse = key;\n        }\n        else {\n            keyToUse = Exports_js_1.PropertyId[key];\n        }\n        for (let n = 0; n < this.privKeys.length; n++) {\n            if (this.privKeys[n] === keyToUse) {\n                this.privValues[n] = value;\n                return;\n            }\n        }\n        this.privKeys.push(keyToUse);\n        this.privValues.push(value);\n    }\n    /**\n     * Clones the collection.\n     * @member PropertyCollection.prototype.clone\n     * @function\n     * @public\n     * @returns {PropertyCollection} A copy of the collection.\n     */\n    clone() {\n        const clonedMap = new PropertyCollection();\n        for (let n = 0; n < this.privKeys.length; n++) {\n            clonedMap.privKeys.push(this.privKeys[n]);\n            clonedMap.privValues.push(this.privValues[n]);\n        }\n        return clonedMap;\n    }\n    /**\n     * Merges this set of properties into another, no overwrites.\n     * @member PropertyCollection.prototype.mergeTo\n     * @function\n     * @public\n     * @param {PropertyCollection}  destinationCollection - The collection to merge into.\n     */\n    mergeTo(destinationCollection) {\n        this.privKeys.forEach((key) => {\n            if (destinationCollection.getProperty(key, undefined) === undefined) {\n                const value = this.getProperty(key);\n                destinationCollection.setProperty(key, value);\n            }\n        });\n    }\n    /**\n     * Get the keys in Property Collection.\n     * @member PropertyCollection.prototype.keys\n     * @function\n     * @public\n     * @returns {string []} Keys in the collection.\n     */\n    get keys() {\n        return this.privKeys;\n    }\n}\nexports.PropertyCollection = PropertyCollection;\n\n//# sourceMappingURL=PropertyCollection.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PropertyId = void 0;\n/**\n * Defines speech property ids.\n * @class PropertyId\n */\nvar PropertyId;\n(function (PropertyId) {\n    /**\n     * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\n     * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.fromSubscription]].\n     * @member PropertyId.SpeechServiceConnection_Key\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Key\"] = 0] = \"SpeechServiceConnection_Key\";\n    /**\n     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.fromEndpoint]].\n     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\n     * @member PropertyId.SpeechServiceConnection_Endpoint\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Endpoint\"] = 1] = \"SpeechServiceConnection_Endpoint\";\n    /**\n     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\n     * use this property directly.\n     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\n     * @member PropertyId.SpeechServiceConnection_Region\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Region\"] = 2] = \"SpeechServiceConnection_Region\";\n    /**\n     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\n     * you shouldn't have to use this property directly.\n     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\n     * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\n     * @member PropertyId.SpeechServiceAuthorization_Token\n     */\n    PropertyId[PropertyId[\"SpeechServiceAuthorization_Token\"] = 3] = \"SpeechServiceAuthorization_Token\";\n    /**\n     * The Cognitive Services Speech Service authorization type. Currently unused.\n     * @member PropertyId.SpeechServiceAuthorization_Type\n     */\n    PropertyId[PropertyId[\"SpeechServiceAuthorization_Type\"] = 4] = \"SpeechServiceAuthorization_Type\";\n    /**\n     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.endpointId]].\n     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\n     * @member PropertyId.SpeechServiceConnection_EndpointId\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EndpointId\"] = 5] = \"SpeechServiceConnection_EndpointId\";\n    /**\n     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\n     * you shouldn't have to use this property directly.\n     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\n     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\n     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationToLanguages\"] = 6] = \"SpeechServiceConnection_TranslationToLanguages\";\n    /**\n     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\n     * property directly.\n     * Instead, use [[SpeechTranslationConfig.voiceName]].\n     * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\n     * @member PropertyId.SpeechServiceConnection_TranslationVoice\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationVoice\"] = 7] = \"SpeechServiceConnection_TranslationVoice\";\n    /**\n     * Translation features.\n     * @member PropertyId.SpeechServiceConnection_TranslationFeatures\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationFeatures\"] = 8] = \"SpeechServiceConnection_TranslationFeatures\";\n    /**\n     * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\n     * Instead, use [[LanguageUnderstandingModel]].\n     * @member PropertyId.SpeechServiceConnection_IntentRegion\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_IntentRegion\"] = 9] = \"SpeechServiceConnection_IntentRegion\";\n    /**\n     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyHostName\"] = 10] = \"SpeechServiceConnection_ProxyHostName\";\n    /**\n     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPort\"] = 11] = \"SpeechServiceConnection_ProxyPort\";\n    /**\n     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyUserName\"] = 12] = \"SpeechServiceConnection_ProxyUserName\";\n    /**\n     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPassword\"] = 13] = \"SpeechServiceConnection_ProxyPassword\";\n    /**\n     * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\n     * This property is intended to be read-only. The SDK is using it internally.\n     * @member PropertyId.SpeechServiceConnection_RecoMode\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecoMode\"] = 14] = \"SpeechServiceConnection_RecoMode\";\n    /**\n     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\n     * directly.\n     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\n     * @member PropertyId.SpeechServiceConnection_RecoLanguage\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecoLanguage\"] = 15] = \"SpeechServiceConnection_RecoLanguage\";\n    /**\n     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\n     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\n     * property directly.\n     * Instead use [[SessionEventArgs.sessionId]].\n     * @member PropertyId.Speech_SessionId\n     */\n    PropertyId[PropertyId[\"Speech_SessionId\"] = 16] = \"Speech_SessionId\";\n    /**\n     * The spoken language to be synthesized (e.g. en-US)\n     * @member PropertyId.SpeechServiceConnection_SynthLanguage\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthLanguage\"] = 17] = \"SpeechServiceConnection_SynthLanguage\";\n    /**\n     * The name of the TTS voice to be used for speech synthesis\n     * @member PropertyId.SpeechServiceConnection_SynthVoice\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthVoice\"] = 18] = \"SpeechServiceConnection_SynthVoice\";\n    /**\n     * The string to specify TTS output audio format\n     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthOutputFormat\"] = 19] = \"SpeechServiceConnection_SynthOutputFormat\";\n    /**\n     * The list of comma separated languages used as possible source languages\n     * Added in version 1.13.0\n     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_AutoDetectSourceLanguages\"] = 20] = \"SpeechServiceConnection_AutoDetectSourceLanguages\";\n    /**\n     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\n     * to use this property directly.\n     * Instead use [[SpeechConfig.outputFormat]].\n     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestDetailedResultTrueFalse\"] = 21] = \"SpeechServiceResponse_RequestDetailedResultTrueFalse\";\n    /**\n     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\n     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestProfanityFilterTrueFalse\"] = 22] = \"SpeechServiceResponse_RequestProfanityFilterTrueFalse\";\n    /**\n     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\n     * @member PropertyId.SpeechServiceResponse_JsonResult\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_JsonResult\"] = 23] = \"SpeechServiceResponse_JsonResult\";\n    /**\n     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\n     * use this property directly. Instead use [[CancellationDetails.errorDetails]].\n     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_JsonErrorDetails\"] = 24] = \"SpeechServiceResponse_JsonErrorDetails\";\n    /**\n     * The cancellation reason. Currently unused.\n     * @member PropertyId.CancellationDetails_Reason\n     */\n    PropertyId[PropertyId[\"CancellationDetails_Reason\"] = 25] = \"CancellationDetails_Reason\";\n    /**\n     * The cancellation text. Currently unused.\n     * @member PropertyId.CancellationDetails_ReasonText\n     */\n    PropertyId[PropertyId[\"CancellationDetails_ReasonText\"] = 26] = \"CancellationDetails_ReasonText\";\n    /**\n     * The Cancellation detailed text. Currently unused.\n     * @member PropertyId.CancellationDetails_ReasonDetailedText\n     */\n    PropertyId[PropertyId[\"CancellationDetails_ReasonDetailedText\"] = 27] = \"CancellationDetails_ReasonDetailedText\";\n    /**\n     * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\n     * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n     */\n    PropertyId[PropertyId[\"LanguageUnderstandingServiceResponse_JsonResult\"] = 28] = \"LanguageUnderstandingServiceResponse_JsonResult\";\n    /**\n     * The URL string built from speech configuration.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * NOTE: Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Url\"] = 29] = \"SpeechServiceConnection_Url\";\n    /**\n     * The initial silence timeout value (in milliseconds) used by the service.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_InitialSilenceTimeoutMs\"] = 30] = \"SpeechServiceConnection_InitialSilenceTimeoutMs\";\n    /**\n     * The end silence timeout value (in milliseconds) used by the service.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EndSilenceTimeoutMs\"] = 31] = \"SpeechServiceConnection_EndSilenceTimeoutMs\";\n    /**\n     * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\n     * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\n     * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\n     * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\n     * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\n     * behavior should be thoroughly validated as intended.\n     *\n     * For more information about timeout configuration that includes discussion of default behaviors, please visit\n     * https://aka.ms/csspeech/timeouts.\n     *\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"Speech_SegmentationSilenceTimeoutMs\"] = 32] = \"Speech_SegmentationSilenceTimeoutMs\";\n    /**\n     * SegmentationMaximumTimeMs represents the maximum length of a spoken phrase when using the Time segmentation strategy.\n     * As the length of a spoken phrase approaches this value, the @member Speech_SegmentationSilenceTimeoutMs will be reduced until either\n     * the phrase silence timeout is reached or the phrase reaches the maximum length.\n     *\n     * Added in version 1.42.0.\n     */\n    PropertyId[PropertyId[\"Speech_SegmentationMaximumTimeMs\"] = 33] = \"Speech_SegmentationMaximumTimeMs\";\n    /**\n     * SegmentationStrategy defines the strategy used to determine when a spoken phrase has ended and a final Recognized result should be generated.\n     * Allowed values are \"Default\", \"Time\", and \"Semantic\".\n     *\n     * Valid values:\n     * - \"Default\": Uses the default strategy and settings as determined by the Speech Service. Suitable for most situations.\n     * - \"Time\": Uses a time-based strategy where the amount of silence between speech determines when to generate a final result.\n     * - \"Semantic\": Uses an AI model to determine the end of a spoken phrase based on the phrase's content.\n     *\n     * Additional Notes:\n     * - When using the Time strategy, @member Speech_SegmentationSilenceTimeoutMs can be adjusted to modify the required silence duration for ending a phrase,\n     * and @member Speech_SegmentationMaximumTimeMs can be adjusted to set the maximum length of a spoken phrase.\n     * - The Semantic strategy does not have any adjustable properties.\n     *\n     * Added in version 1.42.0.\n     */\n    PropertyId[PropertyId[\"Speech_SegmentationStrategy\"] = 34] = \"Speech_SegmentationStrategy\";\n    /**\n     * A boolean value specifying whether audio logging is enabled in the service or not.\n     * Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked\n     * to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).\n     * The logs will be removed after 30 days.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EnableAudioLogging\"] = 35] = \"SpeechServiceConnection_EnableAudioLogging\";\n    /**\n     * The speech service connection language identifier mode.\n     * Can be \"AtStart\" (the default), or \"Continuous\". See Language\n     * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript\n     * for more details.\n     * Added in 1.25.0\n     **/\n    PropertyId[PropertyId[\"SpeechServiceConnection_LanguageIdMode\"] = 36] = \"SpeechServiceConnection_LanguageIdMode\";\n    /**\n     * A string value representing the desired endpoint version to target for Speech Recognition.\n     * Added in version 1.21.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecognitionEndpointVersion\"] = 37] = \"SpeechServiceConnection_RecognitionEndpointVersion\";\n    /**\n    /**\n     * A string value the current speaker recognition scenario/mode (TextIndependentIdentification, etc.).\n     * Added in version 1.23.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SpeakerIdMode\"] = 38] = \"SpeechServiceConnection_SpeakerIdMode\";\n    /**\n     * The requested Cognitive Services Speech Service response output profanity setting.\n     * Allowed values are \"masked\", \"removed\", and \"raw\".\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_ProfanityOption\"] = 39] = \"SpeechServiceResponse_ProfanityOption\";\n    /**\n     * A string value specifying which post processing option should be used by service.\n     * Allowed values are \"TrueText\".\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_PostProcessingOption\"] = 40] = \"SpeechServiceResponse_PostProcessingOption\";\n    /**\n     * A boolean value specifying whether to include word-level timestamps in the response result.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordLevelTimestamps\"] = 41] = \"SpeechServiceResponse_RequestWordLevelTimestamps\";\n    /**\n     * The number of times a word has to be in partial results to be returned.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_StablePartialResultThreshold\"] = 42] = \"SpeechServiceResponse_StablePartialResultThreshold\";\n    /**\n     * A string value specifying the output format option in the response result. Internal use only.\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_OutputFormatOption\"] = 43] = \"SpeechServiceResponse_OutputFormatOption\";\n    /**\n     * A boolean value to request for stabilizing translation partial results by omitting words in the end.\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_TranslationRequestStablePartialResult\"] = 44] = \"SpeechServiceResponse_TranslationRequestStablePartialResult\";\n    /**\n     * A boolean value specifying whether to request WordBoundary events.\n     * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordBoundary\"] = 45] = \"SpeechServiceResponse_RequestWordBoundary\";\n    /**\n     * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\n     * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestPunctuationBoundary\"] = 46] = \"SpeechServiceResponse_RequestPunctuationBoundary\";\n    /**\n     * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\n     * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestSentenceBoundary\"] = 47] = \"SpeechServiceResponse_RequestSentenceBoundary\";\n    /**\n     * Determines if intermediate results contain speaker identification.\n     * Allowed values are \"true\" or \"false\". If set to \"true\", the intermediate results will contain speaker identification.\n     * The default value if unset or set to an invalid value is \"false\".\n     * This is currently only supported for scenarios using the ConversationTranscriber\".\n     * @member PropertyId.SpeechServiceResponse_DiarizeIntermediateResults\n     * Adding in version 1.41.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_DiarizeIntermediateResults\"] = 48] = \"SpeechServiceResponse_DiarizeIntermediateResults\";\n    /**\n     * Identifier used to connect to the backend service.\n     * @member PropertyId.Conversation_ApplicationId\n     */\n    PropertyId[PropertyId[\"Conversation_ApplicationId\"] = 49] = \"Conversation_ApplicationId\";\n    /**\n     * Type of dialog backend to connect to.\n     * @member PropertyId.Conversation_DialogType\n     */\n    PropertyId[PropertyId[\"Conversation_DialogType\"] = 50] = \"Conversation_DialogType\";\n    /**\n     * Silence timeout for listening\n     * @member PropertyId.Conversation_Initial_Silence_Timeout\n     */\n    PropertyId[PropertyId[\"Conversation_Initial_Silence_Timeout\"] = 51] = \"Conversation_Initial_Silence_Timeout\";\n    /**\n     * From Id to add to speech recognition activities.\n     * @member PropertyId.Conversation_From_Id\n     */\n    PropertyId[PropertyId[\"Conversation_From_Id\"] = 52] = \"Conversation_From_Id\";\n    /**\n     * ConversationId for the session.\n     * @member PropertyId.Conversation_Conversation_Id\n     */\n    PropertyId[PropertyId[\"Conversation_Conversation_Id\"] = 53] = \"Conversation_Conversation_Id\";\n    /**\n     * Comma separated list of custom voice deployment ids.\n     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\n     */\n    PropertyId[PropertyId[\"Conversation_Custom_Voice_Deployment_Ids\"] = 54] = \"Conversation_Custom_Voice_Deployment_Ids\";\n    /**\n     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\n     * @member PropertyId.Conversation_Speech_Activity_Template\n     * Added in version 1.10.0.\n     */\n    PropertyId[PropertyId[\"Conversation_Speech_Activity_Template\"] = 55] = \"Conversation_Speech_Activity_Template\";\n    /**\n     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\n     * @member PropertyId.Conversation_Request_Bot_Status_Messages\n     * Added in version 1.15.0.\n     */\n    PropertyId[PropertyId[\"Conversation_Request_Bot_Status_Messages\"] = 56] = \"Conversation_Request_Bot_Status_Messages\";\n    /**\n     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\n     * channel authentication.\n     * Added in version 1.15.1.\n     */\n    PropertyId[PropertyId[\"Conversation_Agent_Connection_Id\"] = 57] = \"Conversation_Agent_Connection_Id\";\n    /**\n     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n     * Instead, use [[SpeechConfig.fromHost]].\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Host\"] = 58] = \"SpeechServiceConnection_Host\";\n    /**\n     * Set the host for service calls to the Conversation Translator REST management and websocket calls.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Host\"] = 59] = \"ConversationTranslator_Host\";\n    /**\n     * Optionally set the the host's display name.\n     * Used when joining a conversation.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Name\"] = 60] = \"ConversationTranslator_Name\";\n    /**\n     * Optionally set a value for the X-CorrelationId request header.\n     * Used for troubleshooting errors in the server logs. It should be a valid guid.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_CorrelationId\"] = 61] = \"ConversationTranslator_CorrelationId\";\n    /**\n     * Set the conversation token to be sent to the speech service. This enables the\n     * service to service call from the speech service to the Conversation Translator service for relaying\n     * recognitions. For internal use.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Token\"] = 62] = \"ConversationTranslator_Token\";\n    /**\n     * The reference text of the audio for pronunciation evaluation.\n     * For this and the following pronunciation assessment parameters, see\n     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_ReferenceText\"] = 63] = \"PronunciationAssessment_ReferenceText\";\n    /**\n     * The point system for pronunciation score calibration (FivePoint or HundredMark).\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_GradingSystem\"] = 64] = \"PronunciationAssessment_GradingSystem\";\n    /**\n     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Granularity\"] = 65] = \"PronunciationAssessment_Granularity\";\n    /**\n     * Defines if enable miscue calculation.\n     * With this enabled, the pronounced words will be compared to the reference text,\n     * and will be marked with omission/insertion based on the comparison. The default setting is False.\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_EnableMiscue\"] = 66] = \"PronunciationAssessment_EnableMiscue\";\n    /**\n     * The json string of pronunciation assessment parameters\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Json\"] = 67] = \"PronunciationAssessment_Json\";\n    /**\n     * Pronunciation assessment parameters.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Params\"] = 68] = \"PronunciationAssessment_Params\";\n    /**\n     * Version of Speaker Recognition API to use.\n     * Added in version 1.18.0\n     */\n    PropertyId[PropertyId[\"SpeakerRecognition_Api_Version\"] = 69] = \"SpeakerRecognition_Api_Version\";\n    /**\n     * Specifies whether to allow load of data URL for web worker\n     * Allowed values are \"off\" and \"on\". Default is \"on\".\n     * Added in version 1.32.0\n     */\n    PropertyId[PropertyId[\"WebWorkerLoadType\"] = 70] = \"WebWorkerLoadType\";\n    /**\n     * Talking avatar service WebRTC session description protocol.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * Added in version 1.33.0\n     */\n    PropertyId[PropertyId[\"TalkingAvatarService_WebRTC_SDP\"] = 71] = \"TalkingAvatarService_WebRTC_SDP\";\n})(PropertyId = exports.PropertyId || (exports.PropertyId = {}));\n\n//# sourceMappingURL=PropertyId.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionEventArgs.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionEventArgs.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RecognitionEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines payload for session events like Speech Start/End Detected\n * @class\n */\nclass RecognitionEventArgs extends Exports_js_1.SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(offset, sessionId) {\n        super(sessionId);\n        this.privOffset = offset;\n    }\n    /**\n     * Represents the message offset\n     * @member RecognitionEventArgs.prototype.offset\n     * @function\n     * @public\n     */\n    get offset() {\n        return this.privOffset;\n    }\n}\nexports.RecognitionEventArgs = RecognitionEventArgs;\n\n//# sourceMappingURL=RecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionResult.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionResult.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RecognitionResult = void 0;\n/**\n * Defines result of speech recognition.\n * @class RecognitionResult\n */\nclass RecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} language - Primary Language detected, if provided.\n     * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n        this.privResultId = resultId;\n        this.privReason = reason;\n        this.privText = text;\n        this.privDuration = duration;\n        this.privOffset = offset;\n        this.privLanguage = language;\n        this.privLanguageDetectionConfidence = languageDetectionConfidence;\n        this.privErrorDetails = errorDetails;\n        this.privJson = json;\n        this.privProperties = properties;\n    }\n    /**\n     * Specifies the result identifier.\n     * @member RecognitionResult.prototype.resultId\n     * @function\n     * @public\n     * @returns {string} Specifies the result identifier.\n     */\n    get resultId() {\n        return this.privResultId;\n    }\n    /**\n     * Specifies status of the result.\n     * @member RecognitionResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} Specifies status of the result.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * Presents the recognized text in the result.\n     * @member RecognitionResult.prototype.text\n     * @function\n     * @public\n     * @returns {string} Presents the recognized text in the result.\n     */\n    get text() {\n        return this.privText;\n    }\n    /**\n     * Duration of recognized speech in 100 nano second increments.\n     * @member RecognitionResult.prototype.duration\n     * @function\n     * @public\n     * @returns {number} Duration of recognized speech in 100 nano second increments.\n     */\n    get duration() {\n        return this.privDuration;\n    }\n    /**\n     * Offset of recognized speech in 100 nano second increments.\n     * @member RecognitionResult.prototype.offset\n     * @function\n     * @public\n     * @returns {number} Offset of recognized speech in 100 nano second increments.\n     */\n    get offset() {\n        return this.privOffset;\n    }\n    /**\n     * Primary Language detected.\n     * @member RecognitionResult.prototype.language\n     * @function\n     * @public\n     * @returns {string} language detected.\n     */\n    get language() {\n        return this.privLanguage;\n    }\n    /**\n     * Primary Language detection confidence (Unknown, Low, Medium, High).\n     * @member RecognitionResult.prototype.languageDetectionConfidence\n     * @function\n     * @public\n     * @returns {string} detection confidence strength.\n     */\n    get languageDetectionConfidence() {\n        return this.privLanguageDetectionConfidence;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member RecognitionResult.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} a brief description of an error.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * A string containing Json serialized recognition result as it was received from the service.\n     * @member RecognitionResult.prototype.json\n     * @function\n     * @private\n     * @returns {string} Json serialized representation of the result.\n     */\n    get json() {\n        return this.privJson;\n    }\n    /**\n     * The set of properties exposed in the result.\n     * @member RecognitionResult.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The set of properties exposed in the result.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n}\nexports.RecognitionResult = RecognitionResult;\n\n//# sourceMappingURL=RecognitionResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Recognizer.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Recognizer.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Recognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines the base class Recognizer which mainly contains common event handlers.\n * @class Recognizer\n */\nclass Recognizer {\n    /**\n     * Creates and initializes an instance of a Recognizer\n     * @constructor\n     * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer\n     * @param {PropertyCollection} properties - A set of properties to set on the recognizer\n     * @param {IConnectionFactory} connectionFactory - The factory class used to create a custom IConnection for the recognizer\n     */\n    constructor(audioConfig, properties, connectionFactory) {\n        this.audioConfig = (audioConfig !== undefined) ? audioConfig : Exports_js_3.AudioConfig.fromDefaultMicrophoneInput();\n        this.privDisposed = false;\n        this.privProperties = properties.clone();\n        this.privConnectionFactory = connectionFactory;\n        this.implCommonRecognizerSetup();\n    }\n    /**\n     * Dispose of associated resources.\n     * @member Recognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);\n        Exports_js_2.marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * @Internal\n     * Internal data member to support fromRecognizer* pattern methods on other classes.\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    get internalData() {\n        return this.privReco;\n    }\n    /**\n     * This method performs cleanup of resources.\n     * The Boolean parameter disposing indicates whether the method is called\n     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).\n     * Derived classes should override this method to dispose resource if needed.\n     * @member Recognizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - Flag to request disposal.\n     */\n    async dispose(disposing) {\n        if (this.privDisposed) {\n            return;\n        }\n        this.privDisposed = true;\n        if (disposing) {\n            if (this.privReco) {\n                await this.privReco.audioSource.turnOff();\n                await this.privReco.dispose();\n            }\n        }\n    }\n    /**\n     * This method returns the current state of the telemetry setting.\n     * @member Recognizer.prototype.telemetryEnabled\n     * @function\n     * @public\n     * @returns true if the telemetry is enabled, false otherwise.\n     */\n    static get telemetryEnabled() {\n        return Exports_js_1.ServiceRecognizerBase.telemetryDataEnabled;\n    }\n    /**\n     * This method globally enables or disables telemetry.\n     * @member Recognizer.prototype.enableTelemetry\n     * @function\n     * @public\n     * @param enabled - Global setting for telemetry collection.\n     * If set to true, telemetry information like microphone errors,\n     * recognition errors are collected and sent to Microsoft.\n     * If set to false, no telemetry is sent to Microsoft.\n     */\n    static enableTelemetry(enabled) {\n        Exports_js_1.ServiceRecognizerBase.telemetryDataEnabled = enabled;\n    }\n    // Does the generic recognizer setup that is common across all recognizer types.\n    implCommonRecognizerSetup() {\n        let osPlatform = (typeof window !== \"undefined\") ? \"Browser\" : \"Node\";\n        let osName = \"unknown\";\n        let osVersion = \"unknown\";\n        if (typeof navigator !== \"undefined\") {\n            osPlatform = osPlatform + \"/\" + navigator.platform;\n            osName = navigator.userAgent;\n            osVersion = navigator.appVersion;\n        }\n        const recognizerConfig = this.createRecognizerConfig(new Exports_js_1.SpeechServiceConfig(new Exports_js_1.Context(new Exports_js_1.OS(osPlatform, osName, osVersion))));\n        this.privReco = this.createServiceRecognizer(Recognizer.getAuthFromProperties(this.privProperties), this.privConnectionFactory, this.audioConfig, recognizerConfig);\n    }\n    async recognizeOnceAsyncImpl(recognitionMode) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);\n        const ret = new Exports_js_2.Deferred();\n        await this.implRecognizerStop();\n        await this.privReco.recognize(recognitionMode, ret.resolve, ret.reject);\n        const result = await ret.promise;\n        await this.implRecognizerStop();\n        return result;\n    }\n    async startContinuousRecognitionAsyncImpl(recognitionMode) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);\n        await this.implRecognizerStop();\n        await this.privReco.recognize(recognitionMode, undefined, undefined);\n    }\n    async stopContinuousRecognitionAsyncImpl() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);\n        await this.implRecognizerStop();\n    }\n    async implRecognizerStop() {\n        if (this.privReco) {\n            await this.privReco.stopRecognizing();\n        }\n        return;\n    }\n    static getAuthFromProperties(properties) {\n        const subscriptionKey = properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Key, undefined);\n        const authentication = (subscriptionKey && subscriptionKey !== \"\") ?\n            new Exports_js_1.CognitiveSubscriptionKeyAuthentication(subscriptionKey) :\n            new Exports_js_1.CognitiveTokenAuthentication(() => {\n                const authorizationToken = properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            }, () => {\n                const authorizationToken = properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            });\n        return authentication;\n    }\n}\nexports.Recognizer = Recognizer;\n\n//# sourceMappingURL=Recognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Recognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ResultReason.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ResultReason.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ResultReason = void 0;\n/**\n * Defines the possible reasons a recognition result might be generated.\n * @class ResultReason\n */\nvar ResultReason;\n(function (ResultReason) {\n    /**\n     * Indicates speech could not be recognized. More details\n     * can be found in the NoMatchDetails object.\n     * @member ResultReason.NoMatch\n     */\n    ResultReason[ResultReason[\"NoMatch\"] = 0] = \"NoMatch\";\n    /**\n     * Indicates that the recognition was canceled. More details\n     * can be found using the CancellationDetails object.\n     * @member ResultReason.Canceled\n     */\n    ResultReason[ResultReason[\"Canceled\"] = 1] = \"Canceled\";\n    /**\n     * Indicates the speech result contains hypothesis text.\n     * @member ResultReason.RecognizedSpeech\n     */\n    ResultReason[ResultReason[\"RecognizingSpeech\"] = 2] = \"RecognizingSpeech\";\n    /**\n     * Indicates the speech result contains final text that has been recognized.\n     * Speech Recognition is now complete for this phrase.\n     * @member ResultReason.RecognizedSpeech\n     */\n    ResultReason[ResultReason[\"RecognizedSpeech\"] = 3] = \"RecognizedSpeech\";\n    /**\n     * Indicates the speech result contains a finalized acceptance of a provided keyword.\n     * Speech recognition will continue unless otherwise configured.\n     * @member ResultReason.RecognizedKeyword\n     */\n    ResultReason[ResultReason[\"RecognizedKeyword\"] = 4] = \"RecognizedKeyword\";\n    /**\n     * Indicates the intent result contains hypothesis text and intent.\n     * @member ResultReason.RecognizingIntent\n     */\n    ResultReason[ResultReason[\"RecognizingIntent\"] = 5] = \"RecognizingIntent\";\n    /**\n     * Indicates the intent result contains final text and intent.\n     * Speech Recognition and Intent determination are now complete for this phrase.\n     * @member ResultReason.RecognizedIntent\n     */\n    ResultReason[ResultReason[\"RecognizedIntent\"] = 6] = \"RecognizedIntent\";\n    /**\n     * Indicates the translation result contains hypothesis text and its translation(s).\n     * @member ResultReason.TranslatingSpeech\n     */\n    ResultReason[ResultReason[\"TranslatingSpeech\"] = 7] = \"TranslatingSpeech\";\n    /**\n     * Indicates the translation result contains final text and corresponding translation(s).\n     * Speech Recognition and Translation are now complete for this phrase.\n     * @member ResultReason.TranslatedSpeech\n     */\n    ResultReason[ResultReason[\"TranslatedSpeech\"] = 8] = \"TranslatedSpeech\";\n    /**\n     * Indicates the synthesized audio result contains a non-zero amount of audio data\n     * @member ResultReason.SynthesizingAudio\n     */\n    ResultReason[ResultReason[\"SynthesizingAudio\"] = 9] = \"SynthesizingAudio\";\n    /**\n     * Indicates the synthesized audio is now complete for this phrase.\n     * @member ResultReason.SynthesizingAudioCompleted\n     */\n    ResultReason[ResultReason[\"SynthesizingAudioCompleted\"] = 10] = \"SynthesizingAudioCompleted\";\n    /**\n     * Indicates the speech synthesis is now started\n     * @member ResultReason.SynthesizingAudioStarted\n     */\n    ResultReason[ResultReason[\"SynthesizingAudioStarted\"] = 11] = \"SynthesizingAudioStarted\";\n    /**\n     * Indicates the voice profile is being enrolled and customers need to send more audio to create a voice profile.\n     * @member ResultReason.EnrollingVoiceProfile\n     */\n    ResultReason[ResultReason[\"EnrollingVoiceProfile\"] = 12] = \"EnrollingVoiceProfile\";\n    /**\n     * Indicates the voice profile has been enrolled.\n     * @member ResultReason.EnrolledVoiceProfile\n     */\n    ResultReason[ResultReason[\"EnrolledVoiceProfile\"] = 13] = \"EnrolledVoiceProfile\";\n    /**\n     * Indicates successful identification of some speakers.\n     * @member ResultReason.RecognizedSpeakers\n     */\n    ResultReason[ResultReason[\"RecognizedSpeakers\"] = 14] = \"RecognizedSpeakers\";\n    /**\n     * Indicates successfully verified one speaker.\n     * @member ResultReason.RecognizedSpeaker\n     */\n    ResultReason[ResultReason[\"RecognizedSpeaker\"] = 15] = \"RecognizedSpeaker\";\n    /**\n     * Indicates a voice profile has been reset successfully.\n     * @member ResultReason.ResetVoiceProfile\n     */\n    ResultReason[ResultReason[\"ResetVoiceProfile\"] = 16] = \"ResetVoiceProfile\";\n    /**\n     * Indicates a voice profile has been deleted successfully.\n     * @member ResultReason.DeletedVoiceProfile\n     */\n    ResultReason[ResultReason[\"DeletedVoiceProfile\"] = 17] = \"DeletedVoiceProfile\";\n    /**\n     * Indicates synthesis voices list has been successfully retrieved.\n     * @member ResultReason.VoicesListRetrieved\n     */\n    ResultReason[ResultReason[\"VoicesListRetrieved\"] = 18] = \"VoicesListRetrieved\";\n    /**\n     * Indicates the transcription result contains hypothesis text and its translation(s) for\n     * other participants in the conversation.\n     * @member ResultReason.TranslatingParticipantSpeech\n     */\n    ResultReason[ResultReason[\"TranslatingParticipantSpeech\"] = 19] = \"TranslatingParticipantSpeech\";\n    /**\n     * Indicates the transcription result contains final text and corresponding translation(s)\n     * for other participants in the conversation. Speech Recognition and Translation are now\n     * complete for this phrase.\n     * @member ResultReason.TranslatedParticipantSpeech\n     */\n    ResultReason[ResultReason[\"TranslatedParticipantSpeech\"] = 20] = \"TranslatedParticipantSpeech\";\n    /**\n     * <summary>\n     * Indicates the transcription result contains the instant message and corresponding\n     * translation(s).\n     * @member ResultReason.TranslatedInstantMessage\n     */\n    ResultReason[ResultReason[\"TranslatedInstantMessage\"] = 21] = \"TranslatedInstantMessage\";\n    /**\n     * Indicates the transcription result contains the instant message for other participants\n     * in the conversation and corresponding translation(s).\n     * @member ResultReason.TranslatedParticipantInstantMessage\n     */\n    ResultReason[ResultReason[\"TranslatedParticipantInstantMessage\"] = 22] = \"TranslatedParticipantInstantMessage\";\n})(ResultReason = exports.ResultReason || (exports.ResultReason = {}));\n\n//# sourceMappingURL=ResultReason.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ResultReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServiceEventArgs.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServiceEventArgs.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServiceEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines payload for any Service message event\n * Added in version 1.9.0\n */\nclass ServiceEventArgs extends Exports_js_1.SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} json - json payload of the USP message.\n     */\n    constructor(json, name, sessionId) {\n        super(sessionId);\n        this.privJsonResult = json;\n        this.privEventName = name;\n    }\n    get jsonString() {\n        return this.privJsonResult;\n    }\n    get eventName() {\n        return this.privEventName;\n    }\n}\nexports.ServiceEventArgs = ServiceEventArgs;\n\n//# sourceMappingURL=ServiceEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServiceEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServicePropertyChannel.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServicePropertyChannel.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServicePropertyChannel = void 0;\n/**\n * Defines channels used to pass property settings to service.\n * Added in version 1.7.0.\n */\nvar ServicePropertyChannel;\n(function (ServicePropertyChannel) {\n    /**\n     * Uses URI query parameter to pass property settings to service.\n     */\n    ServicePropertyChannel[ServicePropertyChannel[\"UriQueryParameter\"] = 0] = \"UriQueryParameter\";\n})(ServicePropertyChannel = exports.ServicePropertyChannel || (exports.ServicePropertyChannel = {}));\n\n//# sourceMappingURL=ServicePropertyChannel.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServicePropertyChannel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SessionEventArgs.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SessionEventArgs.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SessionEventArgs = void 0;\n/**\n * Defines content for session events like SessionStarted/Stopped, SoundStarted/Stopped.\n * @class SessionEventArgs\n */\nclass SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} sessionId - The session id.\n     */\n    constructor(sessionId) {\n        this.privSessionId = sessionId;\n    }\n    /**\n     * Represents the session identifier.\n     * @member SessionEventArgs.prototype.sessionId\n     * @function\n     * @public\n     * @returns {string} Represents the session identifier.\n     */\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\nexports.SessionEventArgs = SessionEventArgs;\n\n//# sourceMappingURL=SessionEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SessionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SourceLanguageConfig.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SourceLanguageConfig.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SourceLanguageConfig = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\n/**\n * Source Language configuration.\n * @class SourceLanguageConfig\n */\nclass SourceLanguageConfig {\n    constructor(language, endpointId) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(language, \"language\");\n        this.privLanguage = language;\n        this.privEndpointId = endpointId;\n    }\n    /**\n     * @member SourceLanguageConfig.fromLanguage\n     * @function\n     * @public\n     * @param {string} language language (eg. \"en-US\") value of config.\n     * @param {string?} endpointId endpointId of model bound to given language of config.\n     * @return {SourceLanguageConfig} Instance of SourceLanguageConfig\n     * @summary Creates an instance of the SourceLanguageConfig with the given language and optional endpointId.\n     * Added in version 1.13.0.\n     */\n    static fromLanguage(language, endpointId) {\n        return new SourceLanguageConfig(language, endpointId);\n    }\n    get language() {\n        return this.privLanguage;\n    }\n    get endpointId() {\n        return this.privEndpointId;\n    }\n}\nexports.SourceLanguageConfig = SourceLanguageConfig;\n\n//# sourceMappingURL=SourceLanguageConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SourceLanguageConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerIdentificationModel.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerIdentificationModel.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeakerIdentificationModel = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines SpeakerIdentificationModel class for Speaker Recognition\n * Model contains a set of profiles against which to identify speaker(s)\n * @class SpeakerIdentificationModel\n */\nclass SpeakerIdentificationModel {\n    constructor(profiles) {\n        this.privVoiceProfiles = [];\n        this.privProfileIds = [];\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(profiles, \"VoiceProfiles\");\n        if (profiles.length === 0) {\n            throw new Error(\"Empty Voice Profiles array\");\n        }\n        for (const profile of profiles) {\n            if (profile.profileType !== Exports_js_1.VoiceProfileType.TextIndependentIdentification) {\n                throw new Error(\"Identification model can only be created from Identification profile: \" + profile.profileId);\n            }\n            this.privVoiceProfiles.push(profile);\n            this.privProfileIds.push(profile.profileId);\n        }\n    }\n    static fromProfiles(profiles) {\n        return new SpeakerIdentificationModel(profiles);\n    }\n    get voiceProfileIds() {\n        return this.privProfileIds.join(\",\");\n    }\n    get profileIds() {\n        return this.privProfileIds;\n    }\n    get scenario() {\n        return \"TextIndependentIdentification\";\n    }\n}\nexports.SpeakerIdentificationModel = SpeakerIdentificationModel;\n\n//# sourceMappingURL=SpeakerIdentificationModel.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerIdentificationModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerRecognitionResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerRecognitionResult.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeakerRecognitionCancellationDetails = exports.SpeakerRecognitionResult = exports.SpeakerRecognitionResultType = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nvar SpeakerRecognitionResultType;\n(function (SpeakerRecognitionResultType) {\n    SpeakerRecognitionResultType[SpeakerRecognitionResultType[\"Verify\"] = 0] = \"Verify\";\n    SpeakerRecognitionResultType[SpeakerRecognitionResultType[\"Identify\"] = 1] = \"Identify\";\n})(SpeakerRecognitionResultType = exports.SpeakerRecognitionResultType || (exports.SpeakerRecognitionResultType = {}));\n/**\n * Output format\n * @class SpeakerRecognitionResult\n */\nclass SpeakerRecognitionResult {\n    constructor(response, resultReason = Exports_js_2.ResultReason.RecognizedSpeaker, cancellationErrorCode = Exports_js_2.CancellationErrorCode.NoError, errorDetails = \"\") {\n        this.privProperties = new Exports_js_2.PropertyCollection();\n        const resultType = response.scenario === \"TextIndependentIdentification\" ? SpeakerRecognitionResultType.Identify : SpeakerRecognitionResultType.Verify;\n        this.privReason = resultReason;\n        if (this.privReason !== Exports_js_2.ResultReason.Canceled) {\n            if (resultType === SpeakerRecognitionResultType.Identify) {\n                this.privProfileId = response.identificationResult.identifiedProfile.profileId;\n                this.privScore = response.identificationResult.identifiedProfile.score;\n                this.privReason = Exports_js_2.ResultReason.RecognizedSpeakers;\n            }\n            else {\n                this.privScore = response.verificationResult.score;\n                if (response.verificationResult.recognitionResult.toLowerCase() !== \"accept\") {\n                    this.privReason = Exports_js_2.ResultReason.NoMatch;\n                }\n                if (response.verificationResult.profileId !== undefined && response.verificationResult.profileId !== \"\") {\n                    this.privProfileId = response.verificationResult.profileId;\n                }\n            }\n        }\n        else {\n            this.privErrorDetails = errorDetails;\n            this.privProperties.setProperty(Exports_js_1.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[cancellationErrorCode]);\n        }\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_JsonResult, JSON.stringify(response));\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get profileId() {\n        return this.privProfileId;\n    }\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    get score() {\n        return this.privScore;\n    }\n}\nexports.SpeakerRecognitionResult = SpeakerRecognitionResult;\n/**\n * @class SpeakerRecognitionCancellationDetails\n */\nclass SpeakerRecognitionCancellationDetails extends Exports_js_2.CancellationDetailsBase {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of SpeakerRecognitionCancellationDetails object for the canceled SpeakerRecognitionResult\n     * @member SpeakerRecognitionCancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {SpeakerRecognitionResult} result - The result that was canceled.\n     * @returns {SpeakerRecognitionCancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        const reason = Exports_js_2.CancellationReason.Error;\n        let errorCode = Exports_js_2.CancellationErrorCode.NoError;\n        if (!!result.properties) {\n            errorCode = Exports_js_2.CancellationErrorCode[result.properties.getProperty(Exports_js_1.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[Exports_js_2.CancellationErrorCode.NoError])];\n        }\n        return new SpeakerRecognitionCancellationDetails(reason, result.errorDetails, errorCode);\n    }\n}\nexports.SpeakerRecognitionCancellationDetails = SpeakerRecognitionCancellationDetails;\n\n//# sourceMappingURL=SpeakerRecognitionResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerRecognizer.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerRecognizer.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeakerRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines SpeakerRecognizer class for Speaker Recognition\n * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)\n * @class SpeakerRecognizer\n */\nclass SpeakerRecognizer extends Exports_js_2.Recognizer {\n    /**\n     * Initializes an instance of the SpeakerRecognizer.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - The set of configuration properties.\n     * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer\n     */\n    constructor(speechConfig, audioConfig) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig, \"speechConfig\");\n        const configImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(configImpl, \"speechConfig\");\n        super(audioConfig, configImpl.properties, new Exports_js_1.SpeakerRecognitionConnectionFactory());\n        this.privAudioConfigImpl = audioConfig;\n        Contracts_js_1.Contracts.throwIfNull(this.privAudioConfigImpl, \"audioConfig\");\n        this.privDisposedSpeakerRecognizer = false;\n        this.privProperties = configImpl.properties;\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member SpeakerRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member SpeakerRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * The collection of properties and their values defined for this SpeakerRecognizer.\n     * @member SpeakerRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeakerRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Get recognition result for model using given audio\n     * @member SpeakerRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @async\n     * @param {SpeakerIdentificationModel | SpeakerVerificationModel} model Model containing Voice Profiles to be identified\n     * @param cb - Callback invoked once result is returned.\n     * @param err - Callback invoked in case of an error.\n     */\n    async recognizeOnceAsync(model) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);\n        return this.recognizeSpeakerOnceAsyncImpl(model);\n    }\n    /**\n     * Included for compatibility\n     * @member SpeakerRecognizer.prototype.close\n     * @function\n     * @public\n     * @async\n     */\n    async close() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);\n        await this.dispose(true);\n    }\n    async recognizeSpeakerOnceAsyncImpl(model) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedSpeakerRecognizer);\n        await this.implRecognizerStop();\n        const result = await this.privReco.recognizeSpeaker(model);\n        await this.implRecognizerStop();\n        return result;\n    }\n    async implRecognizerStop() {\n        if (this.privReco) {\n            await this.privReco.stopRecognizing();\n        }\n        return;\n    }\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioImpl = audioConfig;\n        return new Exports_js_1.SpeakerServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);\n    }\n    async dispose(disposing) {\n        if (this.privDisposedSpeakerRecognizer) {\n            return;\n        }\n        if (disposing) {\n            this.privDisposedSpeakerRecognizer = true;\n            await super.dispose(disposing);\n        }\n    }\n}\nexports.SpeakerRecognizer = SpeakerRecognizer;\n\n//# sourceMappingURL=SpeakerRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerVerificationModel.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerVerificationModel.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeakerVerificationModel = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines SpeakerVerificationModel class for Speaker Recognition\n * Model contains a profile against which to verify a speaker\n * @class SpeakerVerificationModel\n */\nclass SpeakerVerificationModel {\n    constructor(profile) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(profile, \"VoiceProfile\");\n        if (profile.profileType === Exports_js_1.VoiceProfileType.TextIndependentIdentification) {\n            throw new Error(\"Verification model cannot be created from Identification profile\");\n        }\n        this.privVoiceProfile = profile;\n    }\n    static fromProfile(profile) {\n        return new SpeakerVerificationModel(profile);\n    }\n    get voiceProfile() {\n        return this.privVoiceProfile;\n    }\n    get profileIds() {\n        return [this.voiceProfile.profileId];\n    }\n    get scenario() {\n        if (this.voiceProfile.profileType === Exports_js_1.VoiceProfileType.TextDependentVerification) {\n            return \"TextDependentVerification\";\n        }\n        else {\n            return \"TextIndependentVerification\";\n        }\n    }\n}\nexports.SpeakerVerificationModel = SpeakerVerificationModel;\n\n//# sourceMappingURL=SpeakerVerificationModel.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeakerVerificationModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechConfig.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechConfig.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechConfigImpl = exports.SpeechConfig = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Speech configuration.\n * @class SpeechConfig\n */\nclass SpeechConfig {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Static instance of SpeechConfig returned by passing subscriptionKey and service region.\n     * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.\n     * @member SpeechConfig.fromSubscription\n     * @function\n     * @public\n     * @param {string} subscriptionKey - The subscription key.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechConfig} The speech factory\n     */\n    static fromSubscription(subscriptionKey, region) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, region);\n        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_IntentRegion, region);\n        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech config with specified endpoint and subscription key.\n     * This method is intended only for users who use a non-standard service endpoint or parameters.\n     * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.\n     * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.\n     * For example, if language is defined in the uri as query parameter \"language=de-DE\", and also set by\n     * SpeechConfig.speechRecognitionLanguage = \"en-US\", the language setting in uri takes precedence,\n     * and the effective language is \"de-DE\". Only the parameters that are not specified in the\n     * endpoint URL can be set by other APIs.\n     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n     * fromEndpoint method, and then set authorizationToken=\"token\" on the created SpeechConfig instance to\n     * use the authorization token.\n     * @member SpeechConfig.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} endpoint - The service endpoint to connect to.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromEndpoint(endpoint, subscriptionKey) {\n        Contracts_js_1.Contracts.throwIfNull(endpoint, \"endpoint\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);\n        if (undefined !== subscriptionKey) {\n            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech config with specified host and subscription key.\n     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.\n     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n     * Note: To use an authorization token with fromHost, use fromHost(URL),\n     * and then set the AuthorizationToken property on the created SpeechConfig instance.\n     * Note: Added in version 1.9.0.\n     * @member SpeechConfig.fromHost\n     * @function\n     * @public\n     * @param {URL} host - The service endpoint to connect to. Format is \"protocol://host:port\" where \":port\" is optional.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromHost(hostName, subscriptionKey) {\n        Contracts_js_1.Contracts.throwIfNull(hostName, \"hostName\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, hostName.protocol + \"//\" + hostName.hostname + (hostName.port === \"\" ? \"\" : \":\" + hostName.port));\n        if (undefined !== subscriptionKey) {\n            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech factory with specified initial authorization token and region.\n     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n     * expires, the caller needs to refresh it by calling this setter with a new valid token.\n     * Note: Please use a token derived from your LanguageUnderstanding subscription key in case you want\n     * to use the Intent recognizer. As configuration values are copied when creating a new recognizer,\n     * the new token value will not apply to recognizers that have already been created. For recognizers\n     * that have been created before, you need to set authorization token of the corresponding recognizer\n     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n     * @member SpeechConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param {string} authorizationToken - The initial authorization token.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromAuthorizationToken(authorizationToken, region) {\n        Contracts_js_1.Contracts.throwIfNull(authorizationToken, \"authorizationToken\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, region);\n        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_IntentRegion, region);\n        speechImpl.authorizationToken = authorizationToken;\n        return speechImpl;\n    }\n    /**\n     * Closes the configuration.\n     * @member SpeechConfig.prototype.close\n     * @function\n     * @public\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    close() { }\n}\nexports.SpeechConfig = SpeechConfig;\n/**\n * @public\n * @class SpeechConfigImpl\n */\nclass SpeechConfigImpl extends SpeechConfig {\n    constructor() {\n        super();\n        this.privProperties = new Exports_js_2.PropertyCollection();\n        this.speechRecognitionLanguage = \"en-US\"; // Should we have a default?\n        this.outputFormat = Exports_js_2.OutputFormat.Simple;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get endPoint() {\n        return new URL(this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint));\n    }\n    get subscriptionKey() {\n        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key);\n    }\n    get region() {\n        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);\n    }\n    get authorizationToken() {\n        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    set authorizationToken(value) {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, value);\n    }\n    get speechRecognitionLanguage() {\n        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    set speechRecognitionLanguage(value) {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, value);\n    }\n    get autoDetectSourceLanguages() {\n        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages);\n    }\n    set autoDetectSourceLanguages(value) {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, value);\n    }\n    get outputFormat() {\n        return Exports_js_2.OutputFormat[this.privProperties.getProperty(Exports_js_1.OutputFormatPropertyName, undefined)];\n    }\n    set outputFormat(value) {\n        this.privProperties.setProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_2.OutputFormat[value]);\n    }\n    get endpointId() {\n        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId);\n    }\n    set endpointId(value) {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, value);\n    }\n    setProperty(name, value) {\n        Contracts_js_1.Contracts.throwIfNull(value, \"value\");\n        this.privProperties.setProperty(name, value);\n    }\n    getProperty(name, def) {\n        return this.privProperties.getProperty(name, def);\n    }\n    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);\n        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);\n        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);\n        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);\n    }\n    setServiceProperty(name, value) {\n        const currentProperties = JSON.parse(this.privProperties.getProperty(Exports_js_1.ServicePropertiesPropertyName, \"{}\"));\n        currentProperties[name] = value;\n        this.privProperties.setProperty(Exports_js_1.ServicePropertiesPropertyName, JSON.stringify(currentProperties));\n    }\n    setProfanity(profanity) {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_ProfanityOption, Exports_js_2.ProfanityOption[profanity]);\n    }\n    enableAudioLogging() {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EnableAudioLogging, \"true\");\n    }\n    requestWordLevelTimestamps() {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"true\");\n        this.privProperties.setProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_2.OutputFormat[Exports_js_2.OutputFormat.Detailed]);\n    }\n    enableDictation() {\n        this.privProperties.setProperty(Exports_js_1.ForceDictationPropertyName, \"true\");\n    }\n    clone() {\n        const ret = new SpeechConfigImpl();\n        ret.privProperties = this.privProperties.clone();\n        return ret;\n    }\n    get speechSynthesisLanguage() {\n        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthLanguage);\n    }\n    set speechSynthesisLanguage(language) {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthLanguage, language);\n    }\n    get speechSynthesisVoiceName() {\n        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthVoice);\n    }\n    set speechSynthesisVoiceName(voice) {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthVoice, voice);\n    }\n    get speechSynthesisOutputFormat() {\n        return Exports_js_2.SpeechSynthesisOutputFormat[this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];\n    }\n    set speechSynthesisOutputFormat(format) {\n        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthOutputFormat, Exports_js_2.SpeechSynthesisOutputFormat[format]);\n    }\n}\nexports.SpeechConfigImpl = SpeechConfigImpl;\n\n//# sourceMappingURL=SpeechConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionCanceledEventArgs.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionCanceledEventArgs.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechRecognitionCanceledEventArgs = void 0;\nconst CancellationEventArgsBase_js_1 = __webpack_require__(/*! ./CancellationEventArgsBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js\");\nclass SpeechRecognitionCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {\n}\nexports.SpeechRecognitionCanceledEventArgs = SpeechRecognitionCanceledEventArgs;\n\n//# sourceMappingURL=SpeechRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionEventArgs.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionEventArgs.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MeetingTranscriptionEventArgs = exports.ConversationTranscriptionEventArgs = exports.SpeechRecognitionEventArgs = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines contents of speech recognizing/recognized event.\n * @class SpeechRecognitionEventArgs\n */\nclass SpeechRecognitionEventArgs extends Exports_js_1.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {SpeechRecognitionResult} result - The speech recognition result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member SpeechRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {SpeechRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\nexports.SpeechRecognitionEventArgs = SpeechRecognitionEventArgs;\n/**\n * Defines contents of conversation transcribed/transcribing event.\n * @class ConversationTranscriptionEventArgs\n */\nclass ConversationTranscriptionEventArgs extends Exports_js_1.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {ConversationTranscriptionResult} result - The conversation transcription result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the transcription result.\n     * @member ConversationTranscription1EventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {ConversationTranscriptionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\nexports.ConversationTranscriptionEventArgs = ConversationTranscriptionEventArgs;\n/**\n * Defines contents of meeting transcribed/transcribing event.\n * @class MeetingTranscriptionEventArgs\n */\nclass MeetingTranscriptionEventArgs extends SpeechRecognitionEventArgs {\n}\nexports.MeetingTranscriptionEventArgs = MeetingTranscriptionEventArgs;\n\n//# sourceMappingURL=SpeechRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionResult.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionResult.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechRecognitionResult = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines result of speech recognition.\n * @class SpeechRecognitionResult\n */\nclass SpeechRecognitionResult extends Exports_js_1.RecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @public\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} language - Primary Language detected, if provided.\n     * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param {string} speakerId - speaker id for conversation transcription, if provided.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);\n        this.privSpeakerId = speakerId;\n    }\n    /**\n     * speaker id from conversation transcription/id scenarios\n     * @member SpeechRecognitionResult.prototype.speakerId\n     * @function\n     * @public\n     * @returns {string} id of speaker in given result\n     */\n    get speakerId() {\n        return this.privSpeakerId;\n    }\n}\nexports.SpeechRecognitionResult = SpeechRecognitionResult;\n\n//# sourceMappingURL=SpeechRecognitionResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognizer.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognizer.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.\n * @class SpeechRecognizer\n */\nclass SpeechRecognizer extends Exports_js_3.Recognizer {\n    /**\n     * SpeechRecognizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    constructor(speechConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        super(audioConfig, speechConfigImpl.properties, new Exports_js_1.SpeechConnectionFactory());\n        this.privDisposedRecognizer = false;\n    }\n    /**\n     * SpeechRecognizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n        const recognizer = new SpeechRecognizer(speechConfig, audioConfig);\n        return recognizer;\n    }\n    /**\n     * Gets the endpoint id of a customized speech model that is used for speech recognition.\n     * @member SpeechRecognizer.prototype.endpointId\n     * @function\n     * @public\n     * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.\n     */\n    get endpointId() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_EndpointId, \"00000000-0000-0000-0000-000000000000\");\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member SpeechRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member SpeechRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * Gets the spoken language of recognition.\n     * @member SpeechRecognizer.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} The spoken language of recognition.\n     */\n    get speechRecognitionLanguage() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * Gets the output format of recognition.\n     * @member SpeechRecognizer.prototype.outputFormat\n     * @function\n     * @public\n     * @returns {OutputFormat} The output format of recognition.\n     */\n    get outputFormat() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        if (this.properties.getProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]) === Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]) {\n            return Exports_js_3.OutputFormat.Simple;\n        }\n        else {\n            return Exports_js_3.OutputFormat.Detailed;\n        }\n    }\n    /**\n     * The collection of properties and their values defined for this SpeechRecognizer.\n     * @member SpeechRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Starts speech recognition, and stops after the first utterance is recognized.\n     * The task returns the recognition text as result.\n     * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,\n     * so it is suitable only for single shot recognition\n     * like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.\n     * @member SpeechRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the SpeechRecognitionResult.\n     * @param err - Callback invoked in case of an error.\n     */\n    recognizeOnceAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.recognizeOnceAsyncImpl(Exports_js_1.RecognitionMode.Interactive), cb, err);\n    }\n    /**\n     * Starts speech recognition, until stopContinuousRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startContinuousRecognitionAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(Exports_js_1.RecognitionMode.Conversation), cb, err);\n    }\n    /**\n     * Stops continuous speech recognition.\n     * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopContinuousRecognitionAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    /**\n     * Starts speech recognition with keyword spotting, until\n     * stopKeywordRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * Note: Key word spotting functionality is only available on the\n     * Speech Devices SDK. This functionality is currently not included in the SDK itself.\n     * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param {KeywordRecognitionModel} model The keyword recognition model that\n     * specifies the keyword to be recognized.\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startKeywordRecognitionAsync(model, cb, err) {\n        Contracts_js_1.Contracts.throwIfNull(model, \"model\");\n        if (!!err) {\n            err(\"Not yet implemented.\");\n        }\n    }\n    /**\n     * Stops continuous speech recognition.\n     * Note: Key word spotting functionality is only available on the\n     * Speech Devices SDK. This functionality is currently not included in the SDK itself.\n     * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopKeywordRecognitionAsync(cb) {\n        if (!!cb) {\n            cb();\n        }\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member SpeechRecognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        Exports_js_2.marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member SpeechRecognizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    async dispose(disposing) {\n        if (this.privDisposedRecognizer) {\n            return;\n        }\n        if (disposing) {\n            this.privDisposedRecognizer = true;\n            await this.implRecognizerStop();\n        }\n        await super.dispose(disposing);\n    }\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        return new Exports_js_1.SpeechServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n}\nexports.SpeechRecognizer = SpeechRecognizer;\n\n//# sourceMappingURL=SpeechRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBookmarkEventArgs.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBookmarkEventArgs.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisBookmarkEventArgs = void 0;\n/**\n * Defines contents of speech synthesis bookmark event.\n * @class SpeechSynthesisBookmarkEventArgs\n * Added in version 1.16.0\n */\nclass SpeechSynthesisBookmarkEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {string} text - The bookmark text.\n     */\n    constructor(audioOffset, text) {\n        this.privAudioOffset = audioOffset;\n        this.privText = text;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisBookmarkEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the bookmark.\n     * @member SpeechSynthesisBookmarkEventArgs.prototype.text\n     * @function\n     * @public\n     * @returns {string} the bookmark text.\n     */\n    get text() {\n        return this.privText;\n    }\n}\nexports.SpeechSynthesisBookmarkEventArgs = SpeechSynthesisBookmarkEventArgs;\n\n//# sourceMappingURL=SpeechSynthesisBookmarkEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBookmarkEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBoundaryType.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBoundaryType.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisBoundaryType = void 0;\n/**\n * Defines the boundary type of speech synthesis boundary event.\n * @class SpeechSynthesisBoundaryType\n * Added in version 1.21.0\n */\nvar SpeechSynthesisBoundaryType;\n(function (SpeechSynthesisBoundaryType) {\n    /**\n     * Indicates the boundary text is a word.\n     * @member SpeechSynthesisBoundaryType.Word\n     */\n    SpeechSynthesisBoundaryType[\"Word\"] = \"WordBoundary\";\n    /**\n     * Indicates the boundary text is a punctuation.\n     * @member SpeechSynthesisBoundaryType.Punctuation\n     */\n    SpeechSynthesisBoundaryType[\"Punctuation\"] = \"PunctuationBoundary\";\n    /**\n     * Indicates the boundary text is a sentence.\n     * @member SpeechSynthesisBoundaryType.Sentence\n     */\n    SpeechSynthesisBoundaryType[\"Sentence\"] = \"SentenceBoundary\";\n})(SpeechSynthesisBoundaryType = exports.SpeechSynthesisBoundaryType || (exports.SpeechSynthesisBoundaryType = {}));\n\n//# sourceMappingURL=SpeechSynthesisBoundaryType.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBoundaryType.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisEventArgs.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisEventArgs.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisEventArgs = void 0;\n/**\n * Defines contents of speech synthesis events.\n * @class SpeechSynthesisEventArgs\n * Added in version 1.11.0\n */\nclass SpeechSynthesisEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {SpeechSynthesisResult} result - The speech synthesis result.\n     */\n    constructor(result) {\n        this.privResult = result;\n    }\n    /**\n     * Specifies the synthesis result.\n     * @member SpeechSynthesisEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {SpeechSynthesisResult} the synthesis result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\nexports.SpeechSynthesisEventArgs = SpeechSynthesisEventArgs;\n\n//# sourceMappingURL=SpeechSynthesisEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisOutputFormat = void 0;\n/**\n * Define speech synthesis audio output formats.\n * @enum SpeechSynthesisOutputFormat\n * Updated in version 1.17.0\n */\nvar SpeechSynthesisOutputFormat;\n(function (SpeechSynthesisOutputFormat) {\n    /**\n     * raw-8khz-8bit-mono-mulaw\n     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw,\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz8BitMonoMULaw\"] = 0] = \"Raw8Khz8BitMonoMULaw\";\n    /**\n     * riff-16khz-16kbps-mono-siren\n     * @note Unsupported by the service. Do not use this value.\n     * @member SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff16Khz16KbpsMonoSiren\"] = 1] = \"Riff16Khz16KbpsMonoSiren\";\n    /**\n     * audio-16khz-16kbps-mono-siren\n     * @note Unsupported by the service. Do not use this value.\n     * @member SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz16KbpsMonoSiren\"] = 2] = \"Audio16Khz16KbpsMonoSiren\";\n    /**\n     * audio-16khz-32kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz32KBitRateMonoMp3\"] = 3] = \"Audio16Khz32KBitRateMonoMp3\";\n    /**\n     * audio-16khz-128kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz128KBitRateMonoMp3\"] = 4] = \"Audio16Khz128KBitRateMonoMp3\";\n    /**\n     * audio-16khz-64kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz64KBitRateMonoMp3\"] = 5] = \"Audio16Khz64KBitRateMonoMp3\";\n    /**\n     * audio-24khz-48kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz48KBitRateMonoMp3\"] = 6] = \"Audio24Khz48KBitRateMonoMp3\";\n    /**\n     * audio-24khz-96kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz96KBitRateMonoMp3\"] = 7] = \"Audio24Khz96KBitRateMonoMp3\";\n    /**\n     * audio-24khz-160kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz160KBitRateMonoMp3\"] = 8] = \"Audio24Khz160KBitRateMonoMp3\";\n    /**\n     * raw-16khz-16bit-mono-truesilk\n     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw16Khz16BitMonoTrueSilk\"] = 9] = \"Raw16Khz16BitMonoTrueSilk\";\n    /**\n     * riff-16khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff16Khz16BitMonoPcm\"] = 10] = \"Riff16Khz16BitMonoPcm\";\n    /**\n     * riff-8khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz16BitMonoPcm\"] = 11] = \"Riff8Khz16BitMonoPcm\";\n    /**\n     * riff-24khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff24Khz16BitMonoPcm\"] = 12] = \"Riff24Khz16BitMonoPcm\";\n    /**\n     * riff-8khz-8bit-mono-mulaw\n     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz8BitMonoMULaw\"] = 13] = \"Riff8Khz8BitMonoMULaw\";\n    /**\n     * raw-16khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw16Khz16BitMonoPcm\"] = 14] = \"Raw16Khz16BitMonoPcm\";\n    /**\n     * raw-24khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw24Khz16BitMonoPcm\"] = 15] = \"Raw24Khz16BitMonoPcm\";\n    /**\n     * raw-8khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz16BitMonoPcm\"] = 16] = \"Raw8Khz16BitMonoPcm\";\n    /**\n     * ogg-16khz-16bit-mono-opus\n     * @member SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg16Khz16BitMonoOpus\"] = 17] = \"Ogg16Khz16BitMonoOpus\";\n    /**\n     * ogg-24khz-16bit-mono-opus\n     * @member SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg24Khz16BitMonoOpus\"] = 18] = \"Ogg24Khz16BitMonoOpus\";\n    /**\n     * raw-48khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw48Khz16BitMonoPcm\"] = 19] = \"Raw48Khz16BitMonoPcm\";\n    /**\n     * riff-48khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff48Khz16BitMonoPcm\"] = 20] = \"Riff48Khz16BitMonoPcm\";\n    /**\n     * audio-48khz-96kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio48Khz96KBitRateMonoMp3\"] = 21] = \"Audio48Khz96KBitRateMonoMp3\";\n    /**\n     * audio-48khz-192kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio48Khz192KBitRateMonoMp3\"] = 22] = \"Audio48Khz192KBitRateMonoMp3\";\n    /**\n     * ogg-48khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg48Khz16BitMonoOpus\"] = 23] = \"Ogg48Khz16BitMonoOpus\";\n    /**\n     * webm-16khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm16Khz16BitMonoOpus\"] = 24] = \"Webm16Khz16BitMonoOpus\";\n    /**\n     * webm-24khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm24Khz16BitMonoOpus\"] = 25] = \"Webm24Khz16BitMonoOpus\";\n    /**\n     * raw-24khz-16bit-mono-truesilk\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw24Khz16BitMonoTrueSilk\"] = 26] = \"Raw24Khz16BitMonoTrueSilk\";\n    /**\n     * raw-8khz-8bit-mono-alaw\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz8BitMonoALaw\"] = 27] = \"Raw8Khz8BitMonoALaw\";\n    /**\n     * riff-8khz-8bit-mono-alaw\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz8BitMonoALaw\"] = 28] = \"Riff8Khz8BitMonoALaw\";\n    /**\n     * webm-24khz-16bit-24kbps-mono-opus\n     * Audio compressed by OPUS codec in a webm container, with bitrate of 24kbps, optimized for IoT scenario.\n     * Added in version 1.19.0\n     * @member SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm24Khz16Bit24KbpsMonoOpus\"] = 29] = \"Webm24Khz16Bit24KbpsMonoOpus\";\n    /**\n     * audio-16khz-16bit-32kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 32kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz16Bit32KbpsMonoOpus\"] = 30] = \"Audio16Khz16Bit32KbpsMonoOpus\";\n    /**\n     * audio-24khz-16bit-48kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 48kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz16Bit48KbpsMonoOpus\"] = 31] = \"Audio24Khz16Bit48KbpsMonoOpus\";\n    /**\n     * audio-24khz-16bit-24kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 24kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz16Bit24KbpsMonoOpus\"] = 32] = \"Audio24Khz16Bit24KbpsMonoOpus\";\n    /**\n     * raw-22050hz-16bit-mono-pcm\n     * Raw PCM audio at 22050Hz sampling rate and 16-bit depth.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw22050Hz16BitMonoPcm\"] = 33] = \"Raw22050Hz16BitMonoPcm\";\n    /**\n     * riff-22050hz-16bit-mono-pcm\n     * PCM audio at 22050Hz sampling rate and 16-bit depth, with RIFF header.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff22050Hz16BitMonoPcm\"] = 34] = \"Riff22050Hz16BitMonoPcm\";\n    /**\n     * raw-44100hz-16bit-mono-pcm\n     * Raw PCM audio at 44100Hz sampling rate and 16-bit depth.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw44100Hz16BitMonoPcm\"] = 35] = \"Raw44100Hz16BitMonoPcm\";\n    /**\n     * riff-44100hz-16bit-mono-pcm\n     * PCM audio at 44100Hz sampling rate and 16-bit depth, with RIFF header.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff44100Hz16BitMonoPcm\"] = 36] = \"Riff44100Hz16BitMonoPcm\";\n    /**\n     * amr-wb-16000hz\n     * AMR-WB audio at 16kHz sampling rate.\n     * Added in version 1.38.0\n     * @member SpeechSynthesisOutputFormat.AmrWb16000Hz\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"AmrWb16000Hz\"] = 37] = \"AmrWb16000Hz\";\n    /**\n     * g722-16khz-64kbps\n     * G.722 audio at 16kHz sampling rate and 64kbps bitrate.\n     * Added in version 1.38.0\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"G72216Khz64Kbps\"] = 38] = \"G72216Khz64Kbps\";\n})(SpeechSynthesisOutputFormat = exports.SpeechSynthesisOutputFormat || (exports.SpeechSynthesisOutputFormat = {}));\n\n//# sourceMappingURL=SpeechSynthesisOutputFormat.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisResult.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisResult.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisResult = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines result of speech synthesis.\n * @class SpeechSynthesisResult\n * Added in version 1.11.0\n */\nclass SpeechSynthesisResult extends Exports_js_1.SynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {ArrayBuffer} audioData - The synthesized audio binary.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     * @param {number} audioDuration - The audio duration.\n     */\n    constructor(resultId, reason, audioData, errorDetails, properties, audioDuration) {\n        super(resultId, reason, errorDetails, properties);\n        this.privAudioData = audioData;\n        this.privAudioDuration = audioDuration;\n    }\n    /**\n     * The synthesized audio data\n     * @member SpeechSynthesisResult.prototype.audioData\n     * @function\n     * @public\n     * @returns {ArrayBuffer} The synthesized audio data.\n     */\n    get audioData() {\n        return this.privAudioData;\n    }\n    /**\n     * The time duration of synthesized audio, in ticks (100 nanoseconds).\n     * @member SpeechSynthesisResult.prototype.audioDuration\n     * @function\n     * @public\n     * @returns {number} The time duration of synthesized audio.\n     */\n    get audioDuration() {\n        return this.privAudioDuration;\n    }\n}\nexports.SpeechSynthesisResult = SpeechSynthesisResult;\n\n//# sourceMappingURL=SpeechSynthesisResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisVisemeEventArgs.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisVisemeEventArgs.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisVisemeEventArgs = void 0;\n/**\n * Defines contents of speech synthesis viseme event.\n * @class SpeechSynthesisVisemeEventArgs\n * Added in version 1.16.0\n */\nclass SpeechSynthesisVisemeEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {number} visemeId - The viseme ID.\n     * @param {string} animation - The animation, could be in svg or other format.\n     */\n    constructor(audioOffset, visemeId, animation) {\n        this.privAudioOffset = audioOffset;\n        this.privVisemeId = visemeId;\n        this.privAnimation = animation;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the viseme ID.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.visemeId\n     * @function\n     * @public\n     * @returns {number} the viseme ID.\n     */\n    get visemeId() {\n        return this.privVisemeId;\n    }\n    /**\n     * Specifies the animation.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.animation\n     * @function\n     * @public\n     * @returns {string} the animation, could be in svg or other format.\n     */\n    get animation() {\n        return this.privAnimation;\n    }\n}\nexports.SpeechSynthesisVisemeEventArgs = SpeechSynthesisVisemeEventArgs;\n\n//# sourceMappingURL=SpeechSynthesisVisemeEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisVisemeEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesisWordBoundaryEventArgs = void 0;\n/**\n * Defines contents of speech synthesis word boundary event.\n * @class SpeechSynthesisWordBoundaryEventArgs\n * Added in version 1.11.0\n */\nclass SpeechSynthesisWordBoundaryEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {number} duration - The audio duration.\n     * @param {string} text - The text.\n     * @param {number} wordLength - The length of the word.\n     * @param {number} textOffset - The text offset.\n     * @param {SpeechSynthesisBoundaryType} boundaryType - The boundary type\n     */\n    constructor(audioOffset, duration, text, wordLength, textOffset, boundaryType) {\n        this.privAudioOffset = audioOffset;\n        this.privDuration = duration;\n        this.privText = text;\n        this.privWordLength = wordLength;\n        this.privTextOffset = textOffset;\n        this.privBoundaryType = boundaryType;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the duration, in ticks (100 nanoseconds).\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.duration\n     * @function\n     * @public\n     * @returns {number} Duration in 100 nanosecond increments.\n     */\n    get duration() {\n        return this.privDuration;\n    }\n    /**\n     * Specifies the text of the word boundary event.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.text\n     * @function\n     * @public\n     * @returns {string} the text.\n     */\n    get text() {\n        return this.privText;\n    }\n    /**\n     * Specifies the word length\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.wordLength\n     * @function\n     * @public\n     * @returns {number} the word length\n     */\n    get wordLength() {\n        return this.privWordLength;\n    }\n    /**\n     * Specifies the text offset.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.textOffset\n     * @function\n     * @public\n     * @returns {number} the text offset.\n     */\n    get textOffset() {\n        return this.privTextOffset;\n    }\n    /**\n     * Specifies the boundary type.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.boundaryType\n     * @function\n     * @public\n     * @returns {SpeechSynthesisBoundaryType} the boundary type.\n     */\n    get boundaryType() {\n        return this.privBoundaryType;\n    }\n}\nexports.SpeechSynthesisWordBoundaryEventArgs = SpeechSynthesisWordBoundaryEventArgs;\n\n//# sourceMappingURL=SpeechSynthesisWordBoundaryEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesizer.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesizer.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechSynthesizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst AudioFileWriter_js_1 = __webpack_require__(/*! ./Audio/AudioFileWriter.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js\");\nconst AudioOutputFormat_js_1 = __webpack_require__(/*! ./Audio/AudioOutputFormat.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js\");\nconst AudioOutputStream_js_1 = __webpack_require__(/*! ./Audio/AudioOutputStream.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Synthesizer_js_1 = __webpack_require__(/*! ./Synthesizer.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js\");\n/**\n * Defines the class SpeechSynthesizer for text to speech.\n * Updated in version 1.16.0\n * @class SpeechSynthesizer\n */\nclass SpeechSynthesizer extends Exports_js_3.Synthesizer {\n    /**\n     * SpeechSynthesizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer.\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer.\n     */\n    constructor(speechConfig, audioConfig) {\n        super(speechConfig);\n        if (audioConfig !== null) {\n            if (audioConfig === undefined) {\n                this.audioConfig = (typeof window === \"undefined\") ? undefined : Exports_js_3.AudioConfig.fromDefaultSpeakerOutput();\n            }\n            else {\n                this.audioConfig = audioConfig;\n            }\n        }\n        this.privConnectionFactory = new Exports_js_1.SpeechSynthesisConnectionFactory();\n        this.implCommonSynthesizeSetup();\n    }\n    /**\n     * SpeechSynthesizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this synthesizer\n     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the synthesizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer\n     */\n    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n        return new SpeechSynthesizer(speechConfig, audioConfig);\n    }\n    /**\n     * Executes speech synthesis on plain text.\n     * The task returns the synthesis result.\n     * @member SpeechSynthesizer.prototype.speakTextAsync\n     * @function\n     * @public\n     * @param text - Text to be synthesized.\n     * @param cb - Callback that received the SpeechSynthesisResult.\n     * @param err - Callback invoked in case of an error.\n     * @param stream - AudioOutputStream to receive the synthesized audio.\n     */\n    speakTextAsync(text, cb, err, stream) {\n        this.speakImpl(text, false, cb, err, stream);\n    }\n    /**\n     * Executes speech synthesis on SSML.\n     * The task returns the synthesis result.\n     * @member SpeechSynthesizer.prototype.speakSsmlAsync\n     * @function\n     * @public\n     * @param ssml - SSML to be synthesized.\n     * @param cb - Callback that received the SpeechSynthesisResult.\n     * @param err - Callback invoked in case of an error.\n     * @param stream - AudioOutputStream to receive the synthesized audio.\n     */\n    speakSsmlAsync(ssml, cb, err, stream) {\n        this.speakImpl(ssml, true, cb, err, stream);\n    }\n    /**\n     * Get list of synthesis voices available.\n     * The task returns the synthesis voice result.\n     * @member SpeechSynthesizer.prototype.getVoicesAsync\n     * @function\n     * @async\n     * @public\n     * @param locale - Locale of voices in BCP-47 format; if left empty, get all available voices.\n     * @return {Promise<SynthesisVoicesResult>} - Promise of a SynthesisVoicesResult.\n     */\n    async getVoicesAsync(locale = \"\") {\n        return this.getVoices(locale);\n    }\n    /**\n     * Dispose of associated resources.\n     * @member SpeechSynthesizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, err) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);\n        Exports_js_2.marshalPromiseToCallbacks(this.dispose(true), cb, err);\n    }\n    /**\n     * @Internal\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    get internalData() {\n        return this.privAdapter;\n    }\n    //\n    // ################################################################################################################\n    // IMPLEMENTATION.\n    // ################################################################################################################\n    //\n    // Creates the synthesis adapter\n    createSynthesisAdapter(authentication, connectionFactory, synthesizerConfig) {\n        return new Exports_js_1.SpeechSynthesisAdapter(authentication, connectionFactory, synthesizerConfig, this, this.audioConfig);\n    }\n    createRestSynthesisAdapter(authentication, synthesizerConfig) {\n        return new Exports_js_1.SynthesisRestAdapter(synthesizerConfig, authentication);\n    }\n    implCommonSynthesizeSetup() {\n        super.implCommonSynthesizeSetup();\n        this.privAdapter.audioOutputFormat = AudioOutputFormat_js_1.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(Exports_js_3.SpeechSynthesisOutputFormat[this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)]);\n    }\n    speakImpl(text, IsSsml, cb, err, dataStream) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);\n            const requestId = Exports_js_2.createNoDashGuid();\n            let audioDestination;\n            if (dataStream instanceof Exports_js_3.PushAudioOutputStreamCallback) {\n                audioDestination = new AudioOutputStream_js_1.PushAudioOutputStreamImpl(dataStream);\n            }\n            else if (dataStream instanceof Exports_js_3.PullAudioOutputStream) {\n                audioDestination = dataStream;\n            }\n            else if (dataStream !== undefined) {\n                audioDestination = new AudioFileWriter_js_1.AudioFileWriter(dataStream);\n            }\n            else {\n                audioDestination = undefined;\n            }\n            this.synthesisRequestQueue.enqueue(new Synthesizer_js_1.SynthesisRequest(requestId, text, IsSsml, (e) => {\n                this.privSynthesizing = false;\n                if (!!cb) {\n                    try {\n                        cb(e);\n                    }\n                    catch (e) {\n                        if (!!err) {\n                            err(e);\n                        }\n                    }\n                }\n                cb = undefined;\n                /* eslint-disable no-empty */\n                this.adapterSpeak().catch(() => { });\n            }, (e) => {\n                if (!!err) {\n                    err(e);\n                }\n            }, audioDestination));\n            /* eslint-disable no-empty-function */\n            this.adapterSpeak().catch(() => { });\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n            // Destroy the synthesizer.\n            /* eslint-disable no-empty */\n            this.dispose(true).catch(() => { });\n        }\n    }\n    async getVoices(locale) {\n        const requestId = Exports_js_2.createNoDashGuid();\n        const response = await this.privRestAdapter.getVoicesList(requestId);\n        if (response.ok && Array.isArray(response.json)) {\n            let json = response.json;\n            if (!!locale && locale.length > 0) {\n                json = json.filter((item) => !!item.Locale && item.Locale.toLowerCase() === locale.toLowerCase());\n            }\n            return new Exports_js_3.SynthesisVoicesResult(requestId, json, undefined);\n        }\n        else {\n            return new Exports_js_3.SynthesisVoicesResult(requestId, undefined, `Error: ${response.status}: ${response.statusText}`);\n        }\n    }\n}\nexports.SpeechSynthesizer = SpeechSynthesizer;\n\n//# sourceMappingURL=SpeechSynthesizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechTranslationConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechTranslationConfig.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeechTranslationConfigImpl = exports.SpeechTranslationConfig = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Speech translation configuration.\n * @class SpeechTranslationConfig\n */\nclass SpeechTranslationConfig extends Exports_js_2.SpeechConfig {\n    /**\n     * Creates an instance of recognizer config.\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Static instance of SpeechTranslationConfig returned by passing a subscription key and service region.\n     * @member SpeechTranslationConfig.fromSubscription\n     * @function\n     * @public\n     * @param {string} subscriptionKey - The subscription key.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechTranslationConfig} The speech translation config.\n     */\n    static fromSubscription(subscriptionKey, region) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const ret = new SpeechTranslationConfigImpl();\n        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, region);\n        return ret;\n    }\n    /**\n     * Static instance of SpeechTranslationConfig returned by passing authorization token and service region.\n     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n     * expires, the caller needs to refresh it by setting the property authorizationToken with a new\n     * valid token. Otherwise, all the recognizers created by this SpeechTranslationConfig instance\n     * will encounter errors during recognition.\n     * As configuration values are copied when creating a new recognizer, the new token value will not apply\n     * to recognizers that have already been created.\n     * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer\n     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n     * @member SpeechTranslationConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param {string} authorizationToken - The authorization token.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechTranslationConfig} The speech translation config.\n     */\n    static fromAuthorizationToken(authorizationToken, region) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, \"region\");\n        const ret = new SpeechTranslationConfigImpl();\n        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);\n        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, region);\n        return ret;\n    }\n    /**\n     * Creates an instance of the speech config with specified host and subscription key.\n     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.\n     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n     * Note: To use an authorization token with fromHost, use fromHost(URL),\n     * and then set the AuthorizationToken property on the created SpeechConfig instance.\n     * Note: Added in version 1.9.0.\n     * @member SpeechConfig.fromHost\n     * @function\n     * @public\n     * @param {URL} host - The service endpoint to connect to. Format is \"protocol://host:port\" where \":port\" is optional.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromHost(hostName, subscriptionKey) {\n        Contracts_js_1.Contracts.throwIfNull(hostName, \"hostName\");\n        const speechImpl = new SpeechTranslationConfigImpl();\n        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, hostName.protocol + \"//\" + hostName.hostname + (hostName.port === \"\" ? \"\" : \":\" + hostName.port));\n        if (undefined !== subscriptionKey) {\n            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech translation config with specified endpoint and subscription key.\n     * This method is intended only for users who use a non-standard service endpoint or paramters.\n     * Note: The query properties specified in the endpoint URL are not changed, even if they are\n     * set by any other APIs. For example, if language is defined in the uri as query parameter\n     * \"language=de-DE\", and also set by the speechRecognitionLanguage property, the language\n     * setting in uri takes precedence, and the effective language is \"de-DE\".\n     * Only the properties that are not specified in the endpoint URL can be set by other APIs.\n     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n     * fromEndpoint method, and then set authorizationToken=\"token\" on the created SpeechConfig instance to\n     * use the authorization token.\n     * @member SpeechTranslationConfig.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} endpoint - The service endpoint to connect to.\n     * @param {string} subscriptionKey - The subscription key.\n     * @returns {SpeechTranslationConfig} A speech config instance.\n     */\n    static fromEndpoint(endpoint, subscriptionKey) {\n        Contracts_js_1.Contracts.throwIfNull(endpoint, \"endpoint\");\n        Contracts_js_1.Contracts.throwIfNull(subscriptionKey, \"subscriptionKey\");\n        const ret = new SpeechTranslationConfigImpl();\n        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);\n        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n        return ret;\n    }\n}\nexports.SpeechTranslationConfig = SpeechTranslationConfig;\n/**\n * @private\n * @class SpeechTranslationConfigImpl\n */\nclass SpeechTranslationConfigImpl extends SpeechTranslationConfig {\n    constructor() {\n        super();\n        this.privSpeechProperties = new Exports_js_2.PropertyCollection();\n        this.outputFormat = Exports_js_2.OutputFormat.Simple;\n    }\n    /**\n     * Gets/Sets the authorization token.\n     * If this is set, subscription key is ignored.\n     * User needs to make sure the provided authorization token is valid and not expired.\n     * @member SpeechTranslationConfigImpl.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} value - The authorization token.\n     */\n    set authorizationToken(value) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, value);\n    }\n    /**\n     * Sets the speech recognition language.\n     * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @param {string} value - The authorization token.\n     */\n    set speechRecognitionLanguage(value) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, value);\n    }\n    /**\n     * Gets the speech recognition language.\n     * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @return {string} The speechRecognitionLanguage.\n     */\n    get speechRecognitionLanguage() {\n        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage]);\n    }\n    /**\n     * @member SpeechTranslationConfigImpl.prototype.subscriptionKey\n     * @function\n     * @public\n     */\n    get subscriptionKey() {\n        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_Key]);\n    }\n    /**\n     * Gets the output format\n     * @member SpeechTranslationConfigImpl.prototype.outputFormat\n     * @function\n     * @public\n     */\n    get outputFormat() {\n        // eslint-disable-next-line\n        return Exports_js_2.OutputFormat[this.privSpeechProperties.getProperty(Exports_js_1.OutputFormatPropertyName, undefined)];\n    }\n    /**\n     * Gets/Sets the output format\n     * @member SpeechTranslationConfigImpl.prototype.outputFormat\n     * @function\n     * @public\n     */\n    set outputFormat(value) {\n        this.privSpeechProperties.setProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_2.OutputFormat[value]);\n    }\n    /**\n     * Gets the endpoint id.\n     * @member SpeechTranslationConfigImpl.prototype.endpointId\n     * @function\n     * @public\n     */\n    get endpointId() {\n        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId);\n    }\n    /**\n     * Gets/Sets the endpoint id.\n     * @member SpeechTranslationConfigImpl.prototype.endpointId\n     * @function\n     * @public\n     */\n    set endpointId(value) {\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, value);\n    }\n    /**\n     * Add a (text) target language to translate into.\n     * @member SpeechTranslationConfigImpl.prototype.addTargetLanguage\n     * @function\n     * @public\n     * @param {string} value - The language such as de-DE\n     */\n    addTargetLanguage(value) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, \"value\");\n        const languages = this.targetLanguages;\n        if (!languages.includes(value)) {\n            languages.push(value);\n            this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n        }\n    }\n    /**\n     * Gets the (text) target language to translate into.\n     * @member SpeechTranslationConfigImpl.prototype.targetLanguages\n     * @function\n     * @public\n     * @param {string} value - The language such as de-DE\n     */\n    get targetLanguages() {\n        if (this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n            return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(\",\");\n        }\n        else {\n            return [];\n        }\n    }\n    /**\n     * Gets the voice name.\n     * @member SpeechTranslationConfigImpl.prototype.voiceName\n     * @function\n     * @public\n     */\n    get voiceName() {\n        return this.getProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_TranslationVoice]);\n    }\n    /**\n     * Gets/Sets the voice of the translated language, enable voice synthesis output.\n     * @member SpeechTranslationConfigImpl.prototype.voiceName\n     * @function\n     * @public\n     * @param {string} value - The name of the voice.\n     */\n    set voiceName(value) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationVoice, value);\n    }\n    /**\n     * Provides the region.\n     * @member SpeechTranslationConfigImpl.prototype.region\n     * @function\n     * @public\n     * @returns {string} The region.\n     */\n    get region() {\n        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);\n    }\n    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);\n        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);\n        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);\n        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);\n    }\n    /**\n     * Gets an arbitrary property value.\n     * @member SpeechTranslationConfigImpl.prototype.getProperty\n     * @function\n     * @public\n     * @param {string} name - The name of the property.\n     * @param {string} def - The default value of the property in case it is not set.\n     * @returns {string} The value of the property.\n     */\n    getProperty(name, def) {\n        return this.privSpeechProperties.getProperty(name, def);\n    }\n    /**\n     * Gets/Sets an arbitrary property value.\n     * @member SpeechTranslationConfigImpl.prototype.setProperty\n     * @function\n     * @public\n     * @param {string | PropertyId} name - The name of the property to set.\n     * @param {string} value - The value of the property.\n     */\n    setProperty(name, value) {\n        this.privSpeechProperties.setProperty(name, value);\n    }\n    /**\n     * Provides access to custom properties.\n     * @member SpeechTranslationConfigImpl.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The properties.\n     */\n    get properties() {\n        return this.privSpeechProperties;\n    }\n    /**\n     * Dispose of associated resources.\n     * @member SpeechTranslationConfigImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n    setServiceProperty(name, value) {\n        const currentProperties = JSON.parse(this.privSpeechProperties.getProperty(Exports_js_1.ServicePropertiesPropertyName, \"{}\"));\n        currentProperties[name] = value;\n        this.privSpeechProperties.setProperty(Exports_js_1.ServicePropertiesPropertyName, JSON.stringify(currentProperties));\n    }\n    setProfanity(profanity) {\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_ProfanityOption, Exports_js_2.ProfanityOption[profanity]);\n    }\n    enableAudioLogging() {\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EnableAudioLogging, \"true\");\n    }\n    requestWordLevelTimestamps() {\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"true\");\n    }\n    enableDictation() {\n        this.privSpeechProperties.setProperty(Exports_js_1.ForceDictationPropertyName, \"true\");\n    }\n    get speechSynthesisLanguage() {\n        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthLanguage);\n    }\n    set speechSynthesisLanguage(language) {\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthLanguage, language);\n    }\n    get speechSynthesisVoiceName() {\n        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthVoice);\n    }\n    set speechSynthesisVoiceName(voice) {\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthVoice, voice);\n    }\n    get speechSynthesisOutputFormat() {\n        // eslint-disable-next-line\n        return Exports_js_2.SpeechSynthesisOutputFormat[this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];\n    }\n    set speechSynthesisOutputFormat(format) {\n        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthOutputFormat, Exports_js_2.SpeechSynthesisOutputFormat[format]);\n    }\n}\nexports.SpeechTranslationConfigImpl = SpeechTranslationConfigImpl;\n\n//# sourceMappingURL=SpeechTranslationConfig.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechTranslationConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisResult.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisResult.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisResult = void 0;\n/**\n * Base class for synthesis results\n * @class SynthesisResult\n * Added in version 1.20.0\n */\nclass SynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, errorDetails, properties) {\n        this.privResultId = resultId;\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privProperties = properties;\n    }\n    /**\n     * Specifies the result identifier.\n     * @member SynthesisResult.prototype.resultId\n     * @function\n     * @public\n     * @returns {string} Specifies the result identifier.\n     */\n    get resultId() {\n        return this.privResultId;\n    }\n    /**\n     * Specifies status of the result.\n     * @member SynthesisResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} Specifies status of the result.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * In case of an unsuccessful synthesis, provides details of the occurred error.\n     * @member SynthesisResult.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} a brief description of an error.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * The set of properties exposed in the result.\n     * @member SynthesisResult.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The set of properties exposed in the result.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n}\nexports.SynthesisResult = SynthesisResult;\n\n//# sourceMappingURL=SynthesisResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisVoicesResult.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisVoicesResult.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisVoicesResult = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines result of speech synthesis.\n * @class SynthesisVoicesResult\n * Added in version 1.20.0\n */\nclass SynthesisVoicesResult extends Exports_js_1.SynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param requestId - result id for request.\n     * @param json - json payload from endpoint.\n     */\n    constructor(requestId, json, errorDetails) {\n        if (Array.isArray(json)) {\n            super(requestId, Exports_js_1.ResultReason.VoicesListRetrieved, undefined, new Exports_js_1.PropertyCollection());\n            this.privVoices = [];\n            for (const item of json) {\n                this.privVoices.push(new Exports_js_1.VoiceInfo(item));\n            }\n        }\n        else {\n            super(requestId, Exports_js_1.ResultReason.Canceled, errorDetails ? errorDetails : \"Error information unavailable\", new Exports_js_1.PropertyCollection());\n        }\n    }\n    /**\n     * The list of voices\n     * @member SynthesisVoicesResult.prototype.voices\n     * @function\n     * @public\n     * @returns {VoiceInfo[]} List of synthesized voices.\n     */\n    get voices() {\n        return this.privVoices;\n    }\n}\nexports.SynthesisVoicesResult = SynthesisVoicesResult;\n\n//# sourceMappingURL=SynthesisVoicesResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisVoicesResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SynthesisRequest = exports.Synthesizer = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass Synthesizer {\n    /**\n     * Creates and initializes an instance of a Recognizer\n     * @constructor\n     * @param {SpeechConfig} speechConfig - The speech config to initialize the synthesizer.\n     */\n    constructor(speechConfig) {\n        const speechConfigImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n        this.privProperties = speechConfigImpl.properties.clone();\n        this.privDisposed = false;\n        this.privSynthesizing = false;\n        this.synthesisRequestQueue = new Exports_js_2.Queue();\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member Synthesizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member Synthesizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * The collection of properties and their values defined for this Synthesizer.\n     * @member Synthesizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechSynthesizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Indicates if auto detect source language is enabled\n     * @member Synthesizer.prototype.autoDetectSourceLanguage\n     * @function\n     * @public\n     * @returns {boolean} if auto detect source language is enabled\n     */\n    get autoDetectSourceLanguage() {\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages) === Exports_js_1.AutoDetectSourceLanguagesOpenRangeOptionName;\n    }\n    buildSsml(text) {\n        const languageToDefaultVoice = {\n            [\"af-ZA\"]: \"af-ZA-AdriNeural\",\n            [\"am-ET\"]: \"am-ET-AmehaNeural\",\n            [\"ar-AE\"]: \"ar-AE-FatimaNeural\",\n            [\"ar-BH\"]: \"ar-BH-AliNeural\",\n            [\"ar-DZ\"]: \"ar-DZ-AminaNeural\",\n            [\"ar-EG\"]: \"ar-EG-SalmaNeural\",\n            [\"ar-IQ\"]: \"ar-IQ-BasselNeural\",\n            [\"ar-JO\"]: \"ar-JO-SanaNeural\",\n            [\"ar-KW\"]: \"ar-KW-FahedNeural\",\n            [\"ar-LY\"]: \"ar-LY-ImanNeural\",\n            [\"ar-MA\"]: \"ar-MA-JamalNeural\",\n            [\"ar-QA\"]: \"ar-QA-AmalNeural\",\n            [\"ar-SA\"]: \"ar-SA-HamedNeural\",\n            [\"ar-SY\"]: \"ar-SY-AmanyNeural\",\n            [\"ar-TN\"]: \"ar-TN-HediNeural\",\n            [\"ar-YE\"]: \"ar-YE-MaryamNeural\",\n            [\"bg-BG\"]: \"bg-BG-BorislavNeural\",\n            [\"bn-BD\"]: \"bn-BD-NabanitaNeural\",\n            [\"bn-IN\"]: \"bn-IN-BashkarNeural\",\n            [\"ca-ES\"]: \"ca-ES-JoanaNeural\",\n            [\"cs-CZ\"]: \"cs-CZ-AntoninNeural\",\n            [\"cy-GB\"]: \"cy-GB-AledNeural\",\n            [\"da-DK\"]: \"da-DK-ChristelNeural\",\n            [\"de-AT\"]: \"de-AT-IngridNeural\",\n            [\"de-CH\"]: \"de-CH-JanNeural\",\n            [\"de-DE\"]: \"de-DE-KatjaNeural\",\n            [\"el-GR\"]: \"el-GR-AthinaNeural\",\n            [\"en-AU\"]: \"en-AU-NatashaNeural\",\n            [\"en-CA\"]: \"en-CA-ClaraNeural\",\n            [\"en-GB\"]: \"en-GB-LibbyNeural\",\n            [\"en-HK\"]: \"en-HK-SamNeural\",\n            [\"en-IE\"]: \"en-IE-ConnorNeural\",\n            [\"en-IN\"]: \"en-IN-NeerjaNeural\",\n            [\"en-KE\"]: \"en-KE-AsiliaNeural\",\n            [\"en-NG\"]: \"en-NG-AbeoNeural\",\n            [\"en-NZ\"]: \"en-NZ-MitchellNeural\",\n            [\"en-PH\"]: \"en-PH-JamesNeural\",\n            [\"en-SG\"]: \"en-SG-LunaNeural\",\n            [\"en-TZ\"]: \"en-TZ-ElimuNeural\",\n            [\"en-US\"]: \"en-US-AvaMultilingualNeural\",\n            [\"en-ZA\"]: \"en-ZA-LeahNeural\",\n            [\"es-AR\"]: \"es-AR-ElenaNeural\",\n            [\"es-BO\"]: \"es-BO-MarceloNeural\",\n            [\"es-CL\"]: \"es-CL-CatalinaNeural\",\n            [\"es-CO\"]: \"es-CO-GonzaloNeural\",\n            [\"es-CR\"]: \"es-CR-JuanNeural\",\n            [\"es-CU\"]: \"es-CU-BelkysNeural\",\n            [\"es-DO\"]: \"es-DO-EmilioNeural\",\n            [\"es-EC\"]: \"es-EC-AndreaNeural\",\n            [\"es-ES\"]: \"es-ES-AlvaroNeural\",\n            [\"es-GQ\"]: \"es-GQ-JavierNeural\",\n            [\"es-GT\"]: \"es-GT-AndresNeural\",\n            [\"es-HN\"]: \"es-HN-CarlosNeural\",\n            [\"es-MX\"]: \"es-MX-DaliaNeural\",\n            [\"es-NI\"]: \"es-NI-FedericoNeural\",\n            [\"es-PA\"]: \"es-PA-MargaritaNeural\",\n            [\"es-PE\"]: \"es-PE-AlexNeural\",\n            [\"es-PR\"]: \"es-PR-KarinaNeural\",\n            [\"es-PY\"]: \"es-PY-MarioNeural\",\n            [\"es-SV\"]: \"es-SV-LorenaNeural\",\n            [\"es-US\"]: \"es-US-AlonsoNeural\",\n            [\"es-UY\"]: \"es-UY-MateoNeural\",\n            [\"es-VE\"]: \"es-VE-PaolaNeural\",\n            [\"et-EE\"]: \"et-EE-AnuNeural\",\n            [\"fa-IR\"]: \"fa-IR-DilaraNeural\",\n            [\"fi-FI\"]: \"fi-FI-SelmaNeural\",\n            [\"fil-PH\"]: \"fil-PH-AngeloNeural\",\n            [\"fr-BE\"]: \"fr-BE-CharlineNeural\",\n            [\"fr-CA\"]: \"fr-CA-SylvieNeural\",\n            [\"fr-CH\"]: \"fr-CH-ArianeNeural\",\n            [\"fr-FR\"]: \"fr-FR-DeniseNeural\",\n            [\"ga-IE\"]: \"ga-IE-ColmNeural\",\n            [\"gl-ES\"]: \"gl-ES-RoiNeural\",\n            [\"gu-IN\"]: \"gu-IN-DhwaniNeural\",\n            [\"he-IL\"]: \"he-IL-AvriNeural\",\n            [\"hi-IN\"]: \"hi-IN-MadhurNeural\",\n            [\"hr-HR\"]: \"hr-HR-GabrijelaNeural\",\n            [\"hu-HU\"]: \"hu-HU-NoemiNeural\",\n            [\"id-ID\"]: \"id-ID-ArdiNeural\",\n            [\"is-IS\"]: \"is-IS-GudrunNeural\",\n            [\"it-IT\"]: \"it-IT-IsabellaNeural\",\n            [\"ja-JP\"]: \"ja-JP-NanamiNeural\",\n            [\"jv-ID\"]: \"jv-ID-DimasNeural\",\n            [\"kk-KZ\"]: \"kk-KZ-AigulNeural\",\n            [\"km-KH\"]: \"km-KH-PisethNeural\",\n            [\"kn-IN\"]: \"kn-IN-GaganNeural\",\n            [\"ko-KR\"]: \"ko-KR-SunHiNeural\",\n            [\"lo-LA\"]: \"lo-LA-ChanthavongNeural\",\n            [\"lt-LT\"]: \"lt-LT-LeonasNeural\",\n            [\"lv-LV\"]: \"lv-LV-EveritaNeural\",\n            [\"mk-MK\"]: \"mk-MK-AleksandarNeural\",\n            [\"ml-IN\"]: \"ml-IN-MidhunNeural\",\n            [\"mr-IN\"]: \"mr-IN-AarohiNeural\",\n            [\"ms-MY\"]: \"ms-MY-OsmanNeural\",\n            [\"mt-MT\"]: \"mt-MT-GraceNeural\",\n            [\"my-MM\"]: \"my-MM-NilarNeural\",\n            [\"nb-NO\"]: \"nb-NO-PernilleNeural\",\n            [\"nl-BE\"]: \"nl-BE-ArnaudNeural\",\n            [\"nl-NL\"]: \"nl-NL-ColetteNeural\",\n            [\"pl-PL\"]: \"pl-PL-AgnieszkaNeural\",\n            [\"ps-AF\"]: \"ps-AF-GulNawazNeural\",\n            [\"pt-BR\"]: \"pt-BR-FranciscaNeural\",\n            [\"pt-PT\"]: \"pt-PT-DuarteNeural\",\n            [\"ro-RO\"]: \"ro-RO-AlinaNeural\",\n            [\"ru-RU\"]: \"ru-RU-SvetlanaNeural\",\n            [\"si-LK\"]: \"si-LK-SameeraNeural\",\n            [\"sk-SK\"]: \"sk-SK-LukasNeural\",\n            [\"sl-SI\"]: \"sl-SI-PetraNeural\",\n            [\"so-SO\"]: \"so-SO-MuuseNeural\",\n            [\"sr-RS\"]: \"sr-RS-NicholasNeural\",\n            [\"su-ID\"]: \"su-ID-JajangNeural\",\n            [\"sv-SE\"]: \"sv-SE-SofieNeural\",\n            [\"sw-KE\"]: \"sw-KE-RafikiNeural\",\n            [\"sw-TZ\"]: \"sw-TZ-DaudiNeural\",\n            [\"ta-IN\"]: \"ta-IN-PallaviNeural\",\n            [\"ta-LK\"]: \"ta-LK-KumarNeural\",\n            [\"ta-SG\"]: \"ta-SG-AnbuNeural\",\n            [\"te-IN\"]: \"te-IN-MohanNeural\",\n            [\"th-TH\"]: \"th-TH-PremwadeeNeural\",\n            [\"tr-TR\"]: \"tr-TR-AhmetNeural\",\n            [\"uk-UA\"]: \"uk-UA-OstapNeural\",\n            [\"ur-IN\"]: \"ur-IN-GulNeural\",\n            [\"ur-PK\"]: \"ur-PK-AsadNeural\",\n            [\"uz-UZ\"]: \"uz-UZ-MadinaNeural\",\n            [\"vi-VN\"]: \"vi-VN-HoaiMyNeural\",\n            [\"zh-CN\"]: \"zh-CN-XiaoxiaoNeural\",\n            [\"zh-HK\"]: \"zh-HK-HiuMaanNeural\",\n            [\"zh-TW\"]: \"zh-TW-HsiaoChenNeural\",\n            [\"zu-ZA\"]: \"zu-ZA-ThandoNeural\",\n        };\n        let language = this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthLanguage, \"en-US\");\n        let voice = this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthVoice, \"\");\n        let ssml = Synthesizer.XMLEncode(text);\n        if (this.autoDetectSourceLanguage) {\n            language = \"en-US\";\n        }\n        else {\n            voice = voice || languageToDefaultVoice[language];\n        }\n        if (voice) {\n            ssml = `<voice name='${voice}'>${ssml}</voice>`;\n        }\n        ssml = `<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xmlns:emo='http://www.w3.org/2009/10/emotionml' xml:lang='${language}'>${ssml}</speak>`;\n        return ssml;\n    }\n    /**\n     * This method performs cleanup of resources.\n     * The Boolean parameter disposing indicates whether the method is called\n     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).\n     * Derived classes should override this method to dispose resource if needed.\n     * @member Synthesizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - Flag to request disposal.\n     */\n    async dispose(disposing) {\n        if (this.privDisposed) {\n            return;\n        }\n        if (disposing) {\n            if (this.privAdapter) {\n                await this.privAdapter.dispose();\n            }\n        }\n        this.privDisposed = true;\n    }\n    async adapterSpeak() {\n        if (!this.privDisposed && !this.privSynthesizing) {\n            this.privSynthesizing = true;\n            const request = await this.synthesisRequestQueue.dequeue();\n            return this.privAdapter.Speak(request.text, request.isSSML, request.requestId, request.cb, request.err, request.dataStream);\n        }\n    }\n    createSynthesizerConfig(speechConfig) {\n        return new Exports_js_1.SynthesizerConfig(speechConfig, this.privProperties);\n    }\n    // Does the generic synthesizer setup that is common across all synthesizer types.\n    implCommonSynthesizeSetup() {\n        let osPlatform = (typeof window !== \"undefined\") ? \"Browser\" : \"Node\";\n        let osName = \"unknown\";\n        let osVersion = \"unknown\";\n        if (typeof navigator !== \"undefined\") {\n            osPlatform = osPlatform + \"/\" + navigator.platform;\n            osName = navigator.userAgent;\n            osVersion = navigator.appVersion;\n        }\n        const synthesizerConfig = this.createSynthesizerConfig(new Exports_js_1.SpeechServiceConfig(new Exports_js_1.Context(new Exports_js_1.OS(osPlatform, osName, osVersion))));\n        const subscriptionKey = this.privProperties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Key, undefined);\n        const authentication = (subscriptionKey && subscriptionKey !== \"\") ?\n            new Exports_js_1.CognitiveSubscriptionKeyAuthentication(subscriptionKey) :\n            new Exports_js_1.CognitiveTokenAuthentication(() => {\n                const authorizationToken = this.privProperties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            }, () => {\n                const authorizationToken = this.privProperties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            });\n        this.privAdapter = this.createSynthesisAdapter(authentication, this.privConnectionFactory, synthesizerConfig);\n        this.privRestAdapter = this.createRestSynthesisAdapter(authentication, synthesizerConfig);\n    }\n    static XMLEncode(text) {\n        return text.replace(/&/g, \"&amp;\")\n            .replace(/</g, \"&lt;\")\n            .replace(/>/g, \"&gt;\")\n            .replace(/\"/g, \"&quot;\")\n            .replace(/'/g, \"&apos;\");\n    }\n}\nexports.Synthesizer = Synthesizer;\nclass SynthesisRequest {\n    constructor(requestId, text, isSSML, cb, err, dataStream) {\n        this.requestId = requestId;\n        this.text = text;\n        this.isSSML = isSSML;\n        this.cb = cb;\n        this.err = err;\n        this.dataStream = dataStream;\n    }\n}\nexports.SynthesisRequest = SynthesisRequest;\n\n//# sourceMappingURL=Synthesizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationImpl = exports.Conversation = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass Conversation {\n    constructor() {\n        return;\n    }\n    /**\n     * Create a conversation\n     * @param speechConfig\n     * @param cb\n     * @param err\n     */\n    static createConversationAsync(speechConfig, arg2, arg3, arg4) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"config\"));\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig.region, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"SpeechServiceConnection_Region\"));\n        if (!speechConfig.subscriptionKey && !speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceAuthorization_Token])) {\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig.subscriptionKey, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"SpeechServiceConnection_Key\"));\n        }\n        let conversationImpl;\n        let cb;\n        let err;\n        if (typeof arg2 === \"string\") {\n            conversationImpl = new ConversationImpl(speechConfig, arg2);\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            Exports_js_2.marshalPromiseToCallbacks((async () => { })(), arg3, arg4);\n        }\n        else {\n            conversationImpl = new ConversationImpl(speechConfig);\n            cb = arg2;\n            err = arg3;\n            conversationImpl.createConversationAsync((() => {\n                if (!!cb) {\n                    cb();\n                }\n            }), (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        return conversationImpl;\n    }\n}\nexports.Conversation = Conversation;\nclass ConversationImpl extends Conversation {\n    /**\n     * Create a conversation impl\n     * @param speechConfig\n     * @param {string} id - optional conversationId\n     */\n    constructor(speechConfig, id) {\n        super();\n        this.privErrors = Exports_js_1.ConversationConnectionConfig.restErrors;\n        /** websocket callbacks */\n        /* eslint-disable @typescript-eslint/typedef */\n        this.onConnected = (e) => {\n            this.privIsConnected = true;\n            try {\n                if (!!this.privConversationTranslator?.sessionStarted) {\n                    this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onDisconnected = (e) => {\n            try {\n                if (!!this.privConversationTranslator?.sessionStopped) {\n                    this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n            finally {\n                void this.close(false);\n            }\n        };\n        this.onCanceled = (r, e) => {\n            try {\n                if (!!this.privConversationTranslator?.canceled) {\n                    this.privConversationTranslator.canceled(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantUpdateCommandReceived = (r, e) => {\n            try {\n                const updatedParticipant = this.privParticipants.getParticipant(e.id);\n                if (updatedParticipant !== undefined) {\n                    switch (e.key) {\n                        case Exports_js_1.ConversationTranslatorCommandTypes.changeNickname:\n                            updatedParticipant.displayName = e.value;\n                            break;\n                        case Exports_js_1.ConversationTranslatorCommandTypes.setUseTTS:\n                            updatedParticipant.isUsingTts = e.value;\n                            break;\n                        case Exports_js_1.ConversationTranslatorCommandTypes.setProfanityFiltering:\n                            updatedParticipant.profanity = e.value;\n                            break;\n                        case Exports_js_1.ConversationTranslatorCommandTypes.setMute:\n                            updatedParticipant.isMuted = e.value;\n                            break;\n                        case Exports_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages:\n                            updatedParticipant.translateToLanguages = e.value;\n                            break;\n                    }\n                    this.privParticipants.addOrUpdateParticipant(updatedParticipant);\n                    if (!!this.privConversationTranslator) {\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.Updated, [this.toParticipant(updatedParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onLockRoomCommandReceived = () => {\n            // TODO\n        };\n        this.onMuteAllCommandReceived = (r, e) => {\n            try {\n                this.privParticipants.participants.forEach((p) => p.isMuted = (p.isHost ? false : e.isMuted));\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.Updated, this.toParticipants(false), e.sessionId));\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantJoinCommandReceived = (r, e) => {\n            try {\n                const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);\n                if (newParticipant !== undefined) {\n                    if (!!this.privConversationTranslator) {\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantLeaveCommandReceived = (r, e) => {\n            try {\n                const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);\n                if (ejectedParticipant !== undefined) {\n                    // remove the participant from the internal participants list\n                    this.privParticipants.deleteParticipant(e.participant.id);\n                    if (!!this.privConversationTranslator) {\n                        // notify subscribers that the participant has left the conversation\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onTranslationReceived = (r, e) => {\n            try {\n                switch (e.command) {\n                    case Exports_js_1.ConversationTranslatorMessageTypes.final:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.transcribed(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                    case Exports_js_1.ConversationTranslatorMessageTypes.partial:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.transcribing(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                    case Exports_js_1.ConversationTranslatorMessageTypes.instantMessage:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.textMessageReceived(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantsListReceived = (r, e) => {\n            try {\n                // check if the session token needs to be updated\n                if (e.sessionToken !== undefined && e.sessionToken !== null) {\n                    this.privRoom.token = e.sessionToken;\n                }\n                // save the participants\n                this.privParticipants.participants = [...e.participants];\n                // enable the conversation\n                if (this.privParticipants.me !== undefined) {\n                    this.privIsReady = true;\n                }\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.JoinedConversation, this.toParticipants(true), e.sessionId));\n                }\n                // if this is the host, update the nickname if needed\n                if (this.me.isHost) {\n                    const nickname = this.privConversationTranslator?.properties.getProperty(Exports_js_3.PropertyId.ConversationTranslator_Name);\n                    if (nickname !== undefined && nickname.length > 0 && nickname !== this.me.displayName) {\n                        // issue a change nickname request\n                        this.changeNicknameAsync(nickname);\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onConversationExpiration = (r, e) => {\n            try {\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.conversationExpiration(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.privIsConnected = false;\n        this.privIsDisposed = false;\n        this.privConversationId = \"\";\n        this.privProperties = new Exports_js_3.PropertyCollection();\n        this.privManager = new Exports_js_1.ConversationManager();\n        // check the speech language\n        const language = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        if (!language) {\n            speechConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage], Exports_js_1.ConversationConnectionConfig.defaultLanguageCode);\n        }\n        this.privLanguage = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        if (!id) {\n            // check the target language(s)\n            if (speechConfig.targetLanguages.length === 0) {\n                speechConfig.addTargetLanguage(this.privLanguage);\n            }\n            // check the profanity setting: speech and conversationTranslator should be in sync\n            const profanity = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceResponse_ProfanityOption]);\n            if (!profanity) {\n                speechConfig.setProfanity(Exports_js_3.ProfanityOption.Masked);\n            }\n            // check the nickname: it should pass this regex: ^\\w+([\\s-][\\w\\(\\)]+)*$\"\n            // TODO: specify the regex required. Nicknames must be unique or get the duplicate nickname error\n            // TODO: check what the max length is and if a truncation is required or if the service handles it without an error\n            let hostNickname = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.ConversationTranslator_Name]);\n            if (hostNickname === undefined || hostNickname === null) {\n                hostNickname = \"Host\";\n            }\n            Contracts_js_1.Contracts.throwIfNullOrTooLong(hostNickname, \"nickname\", 50);\n            Contracts_js_1.Contracts.throwIfNullOrTooShort(hostNickname, \"nickname\", 2);\n            speechConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.ConversationTranslator_Name], hostNickname);\n        }\n        else {\n            this.privConversationId = id;\n        }\n        // save the speech config for future usage\n        this.privConfig = speechConfig;\n        // save the config properties\n        const configImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNull(configImpl, \"speechConfig\");\n        this.privProperties = configImpl.properties.clone();\n        this.privIsConnected = false;\n        this.privParticipants = new Exports_js_1.InternalParticipants();\n        this.privIsReady = false;\n        this.privTextMessageMaxLength = 1000;\n    }\n    // get the internal data about a conversation\n    get room() {\n        return this.privRoom;\n    }\n    // get the wrapper for connecting to the websockets\n    get connection() {\n        return this.privConversationRecognizer; // this.privConnection;\n    }\n    // get the config\n    get config() {\n        return this.privConfig;\n    }\n    // get the conversation Id\n    get conversationId() {\n        return this.privRoom ? this.privRoom.roomId : this.privConversationId;\n    }\n    // get the properties\n    get properties() {\n        return this.privProperties;\n    }\n    // get the speech language\n    get speechRecognitionLanguage() {\n        return this.privLanguage;\n    }\n    get isMutedByHost() {\n        return this.privParticipants.me?.isHost ? false : this.privParticipants.me?.isMuted;\n    }\n    get isConnected() {\n        return this.privIsConnected && this.privIsReady;\n    }\n    get participants() {\n        return this.toParticipants(true);\n    }\n    get me() {\n        return this.toParticipant(this.privParticipants.me);\n    }\n    get host() {\n        return this.toParticipant(this.privParticipants.host);\n    }\n    get transcriberRecognizer() {\n        return this.privTranscriberRecognizer;\n    }\n    get conversationInfo() {\n        const convId = this.conversationId;\n        const p = this.participants.map((part) => ({\n            id: part.id,\n            preferredLanguage: part.preferredLanguage,\n            voice: part.voice\n        }));\n        const props = {};\n        for (const key of Exports_js_1.ConversationConnectionConfig.transcriptionEventKeys) {\n            const val = this.properties.getProperty(key, \"\");\n            if (val !== \"\") {\n                props[key] = val;\n            }\n        }\n        const info = { id: convId, participants: p, conversationProperties: props };\n        return info;\n    }\n    get canSend() {\n        return this.privIsConnected && !this.privParticipants.me?.isMuted;\n    }\n    get canSendAsHost() {\n        return this.privIsConnected && this.privParticipants.me?.isHost;\n    }\n    // get / set the speech auth token\n    // eslint-disable-next-line @typescript-eslint/member-ordering\n    get authorizationToken() {\n        return this.privToken;\n    }\n    set authorizationToken(value) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, \"authorizationToken\");\n        this.privToken = value;\n    }\n    set conversationTranslator(conversationTranslator) {\n        this.privConversationTranslator = conversationTranslator;\n    }\n    onToken(token) {\n        this.privConversationTranslator.onToken(token);\n    }\n    /**\n     * Create a new conversation as Host\n     * @param cb\n     * @param err\n     */\n    createConversationAsync(cb, err) {\n        try {\n            if (!!this.privConversationRecognizer) {\n                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);\n            }\n            this.privManager.createOrJoin(this.privProperties, undefined, ((room) => {\n                if (!room) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);\n                }\n                this.privRoom = room;\n                this.handleCallback(cb, err);\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Starts a new conversation as host.\n     * @param cb\n     * @param err\n     */\n    startConversationAsync(cb, err) {\n        try {\n            // check if there is already a recognizer\n            if (!!this.privConversationRecognizer) {\n                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);\n            }\n            // check if there is conversation data available\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);\n            // connect to the conversation websocket\n            this.privParticipants.meId = this.privRoom.participantId;\n            this.privConversationRecognizer = Exports_js_1.ConversationRecognizerFactory.fromConfig(this, this.privConfig);\n            // Because ConversationTranslator manually sets up and manages the connection, Conversation\n            // has to forward serviceRecognizer connection events that usually get passed automatically\n            this.privConversationRecognizer.connected = this.onConnected;\n            this.privConversationRecognizer.disconnected = this.onDisconnected;\n            this.privConversationRecognizer.canceled = this.onCanceled;\n            this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;\n            this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;\n            this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;\n            this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;\n            this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;\n            this.privConversationRecognizer.translationReceived = this.onTranslationReceived;\n            this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;\n            this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;\n            this.privConversationRecognizer.connect(this.privRoom.token, (() => {\n                this.handleCallback(cb, err);\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Join a conversation as a participant.\n     * @param { IParticipant } participant - participant to add\n     * @param cb\n     * @param err\n     */\n    addParticipantAsync(participant, cb, err) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(participant, \"Participant\");\n        Exports_js_2.marshalPromiseToCallbacks(this.addParticipantImplAsync(participant), cb, err);\n    }\n    /**\n     * Join a conversation as a participant.\n     * @param conversation\n     * @param nickname\n     * @param lang\n     * @param cb\n     * @param err\n     */\n    joinConversationAsync(conversationId, nickname, lang, cb, err) {\n        try {\n            // TODO\n            // if (!!this.privConversationRecognizer) {\n            //     throw new Error(this.privErrors.permissionDeniedStart);\n            // }\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(conversationId, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversationId\"));\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace(\"{arg}\", \"language\"));\n            // join the conversation\n            this.privManager.createOrJoin(this.privProperties, conversationId, ((room) => {\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);\n                this.privRoom = room;\n                this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;\n                // join callback\n                if (!!cb) {\n                    cb(room.cognitiveSpeechAuthToken);\n                }\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Deletes a conversation\n     * @param cb\n     * @param err\n     */\n    deleteConversationAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.deleteConversationImplAsync(), cb, err);\n    }\n    async deleteConversationImplAsync() {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);\n        await this.privManager.leave(this.privProperties, this.privRoom.token);\n        this.dispose();\n    }\n    /**\n     * Issues a request to close the client websockets\n     * @param cb\n     * @param err\n     */\n    endConversationAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.endConversationImplAsync(), cb, err);\n    }\n    endConversationImplAsync() {\n        return this.close(true);\n    }\n    /**\n     * Issues a request to lock the conversation\n     * @param cb\n     * @param err\n     */\n    lockConversationAsync(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"lock\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getLockCommand(true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to mute the conversation\n     * @param cb\n     * @param err\n     */\n    muteAllParticipantsAsync(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the user's permissions\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"mute\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to mute a participant in the conversation\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    muteParticipantAsync(userId, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the connection is open (host + participant can perform the mute command)\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // if not host, check the participant is not muting another participant\n            if (!this.me.isHost && this.me.id !== userId) {\n                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"mute\")), err);\n            }\n            // check the user exists\n            const exists = this.privParticipants.getParticipantIndex(userId);\n            if (exists === -1) {\n                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to remove a participant from the conversation\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    removeParticipantAsync(userId, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            if (!!this.privTranscriberRecognizer && userId.hasOwnProperty(\"id\")) {\n                // Assume this is a transcription participant\n                Exports_js_2.marshalPromiseToCallbacks(this.removeParticipantImplAsync(userId), cb, err);\n            }\n            else {\n                Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n                if (!this.canSendAsHost) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"remove\")), err);\n                }\n                let participantId = \"\";\n                if (typeof userId === \"string\") {\n                    participantId = userId;\n                }\n                else if (userId.hasOwnProperty(\"id\")) {\n                    const participant = userId;\n                    participantId = participant.id;\n                }\n                else if (userId.hasOwnProperty(\"userId\")) {\n                    const user = userId;\n                    participantId = user.userId;\n                }\n                Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n                // check the participant exists\n                const index = this.participants.findIndex((p) => p.id === participantId);\n                if (index === -1) {\n                    this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n                }\n                if (!!this.privConversationRecognizer) {\n                    this.privConversationRecognizer.sendRequest(this.getEjectCommand(participantId), (() => {\n                        this.handleCallback(cb, err);\n                    }), ((error) => {\n                        this.handleError(error, err);\n                    }));\n                }\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unlock the conversation\n     * @param cb\n     * @param err\n     */\n    unlockConversationAsync(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"unlock\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getLockCommand(false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unmute all participants in the conversation\n     * @param cb\n     * @param err\n     */\n    unmuteAllParticipantsAsync(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"unmute all\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unmute a participant in the conversation\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    unmuteParticipantAsync(userId, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the connection is open (host + participant can perform the mute command)\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // if not host, check the participant is not muting another participant\n            if (!this.me.isHost && this.me.id !== userId) {\n                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"mute\")), err);\n            }\n            // check the user exists\n            const exists = this.privParticipants.getParticipantIndex(userId);\n            if (exists === -1) {\n                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Send a text message\n     * @param message\n     * @param cb\n     * @param err\n     */\n    sendTextMessageAsync(message, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace(\"{arg}\", \"message\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // TODO: is a max length check required?\n            if (message.length > this.privTextMessageMaxLength) {\n                this.handleError(new Error(this.privErrors.invalidArgs.replace(\"{arg}\", \"message length\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMessageCommand(message), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Set translated to languages\n     * @param {string[]} languages - languages to translate to\n     * @param cb\n     * @param err\n     */\n    setTranslatedLanguagesAsync(languages, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfArrayEmptyOrWhitespace(languages, this.privErrors.invalidArgs.replace(\"{arg}\", \"languages\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getSetTranslateToLanguagesCommand(languages), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Change nickname\n     * @param {string} nickname - new nickname for the room\n     * @param cb\n     * @param err\n     */\n    changeNicknameAsync(nickname, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getChangeNicknameCommand(nickname), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose() {\n        if (this.isDisposed) {\n            return;\n        }\n        this.privIsDisposed = true;\n        if (!!this.config) {\n            this.config.close();\n        }\n        this.privConfig = undefined;\n        this.privLanguage = undefined;\n        this.privProperties = undefined;\n        this.privRoom = undefined;\n        this.privToken = undefined;\n        this.privManager = undefined;\n        this.privIsConnected = false;\n        this.privIsReady = false;\n        this.privParticipants = undefined;\n    }\n    async connectTranscriberRecognizer(recognizer) {\n        if (!!this.privTranscriberRecognizer) {\n            await this.privTranscriberRecognizer.close();\n        }\n        await recognizer.enforceAudioGating();\n        this.privTranscriberRecognizer = recognizer;\n        this.privTranscriberRecognizer.conversation = this;\n    }\n    getKeepAlive() {\n        const nickname = (!!this.me) ? this.me.displayName : \"default_nickname\";\n        return JSON.stringify({\n            id: \"0\",\n            nickname,\n            participantId: this.privRoom.participantId,\n            roomId: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.keepAlive\n        });\n    }\n    /* eslint-enable @typescript-eslint/typedef */\n    addParticipantImplAsync(participant) {\n        const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);\n        if (newParticipant !== undefined) {\n            if (!!this.privTranscriberRecognizer) {\n                const conversationInfo = this.conversationInfo;\n                conversationInfo.participants = [participant];\n                return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, \"join\");\n            }\n        }\n    }\n    removeParticipantImplAsync(participant) {\n        this.privParticipants.deleteParticipant(participant.id);\n        const conversationInfo = this.conversationInfo;\n        conversationInfo.participants = [participant];\n        return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, \"leave\");\n    }\n    async close(dispose) {\n        try {\n            this.privIsConnected = false;\n            await this.privConversationRecognizer?.close();\n            this.privConversationRecognizer = undefined;\n            if (!!this.privConversationTranslator) {\n                this.privConversationTranslator.dispose();\n            }\n        }\n        catch (e) {\n            // ignore error\n            throw e;\n        }\n        if (dispose) {\n            this.dispose();\n        }\n    }\n    /** Helpers */\n    handleCallback(cb, err) {\n        if (!!cb) {\n            try {\n                cb();\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n            cb = undefined;\n        }\n    }\n    handleError(error, err) {\n        if (!!err) {\n            if (error instanceof Error) {\n                const typedError = error;\n                err(typedError.name + \": \" + typedError.message);\n            }\n            else {\n                err(error);\n            }\n        }\n    }\n    /** Participant Helpers */\n    toParticipants(includeHost) {\n        const participants = this.privParticipants.participants.map((p) => (this.toParticipant(p)));\n        if (!includeHost) {\n            return participants.filter((p) => p.isHost === false);\n        }\n        else {\n            return participants;\n        }\n    }\n    toParticipant(p) {\n        return new Exports_js_3.Participant(p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);\n    }\n    getMuteAllCommand(isMuted) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.setMuteAll,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: isMuted\n        });\n    }\n    getMuteCommand(participantId, isMuted) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.setMute,\n            // eslint-disable-next-line object-shorthand\n            participantId: participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: isMuted\n        });\n    }\n    getLockCommand(isLocked) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.setLockState,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: isLocked\n        });\n    }\n    getEjectCommand(participantId) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.ejectParticipant,\n            // eslint-disable-next-line object-shorthand\n            participantId: participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n        });\n    }\n    getSetTranslateToLanguagesCommand(languages) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: languages\n        });\n    }\n    getChangeNicknameCommand(nickname) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, \"nickname\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.changeNickname,\n            nickname,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: nickname\n        });\n    }\n    getMessageCommand(message) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, \"message\");\n        return JSON.stringify({\n            participantId: this.privRoom.participantId,\n            roomId: this.privRoom.roomId,\n            text: message,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.instantMessage\n        });\n    }\n}\nexports.ConversationImpl = ConversationImpl;\n\n//# sourceMappingURL=Conversation.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationCommon.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationCommon.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationCommon = void 0;\nclass ConversationCommon {\n    constructor(audioConfig) {\n        this.privAudioConfig = audioConfig;\n    }\n    handleCallback(cb, err) {\n        if (!!cb) {\n            try {\n                cb();\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n            cb = undefined;\n        }\n    }\n    handleError(error, err) {\n        if (!!err) {\n            if (error instanceof Error) {\n                const typedError = error;\n                err(typedError.name + \": \" + typedError.message);\n            }\n            else {\n                err(error);\n            }\n        }\n    }\n}\nexports.ConversationCommon = ConversationCommon;\n\n//# sourceMappingURL=ConversationCommon.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationCommon.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationExpirationEventArgs.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationExpirationEventArgs.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationExpirationEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass ConversationExpirationEventArgs extends Exports_js_1.SessionEventArgs {\n    constructor(expirationTime, sessionId) {\n        super(sessionId);\n        this.privExpirationTime = expirationTime;\n    }\n    /** How much longer until the conversation expires (in minutes). */\n    get expirationTime() {\n        return this.privExpirationTime;\n    }\n}\nexports.ConversationExpirationEventArgs = ConversationExpirationEventArgs;\n\n//# sourceMappingURL=ConversationExpirationEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationExpirationEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js":
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js ***!
  \*******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationParticipantsChangedEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass ConversationParticipantsChangedEventArgs extends Exports_js_1.SessionEventArgs {\n    constructor(reason, participants, sessionId) {\n        super(sessionId);\n        this.privReason = reason;\n        this.privParticipant = participants;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get participants() {\n        return this.privParticipant;\n    }\n}\nexports.ConversationParticipantsChangedEventArgs = ConversationParticipantsChangedEventArgs;\n\n//# sourceMappingURL=ConversationParticipantsChangedEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriber.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriber.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranscriber = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Performs speech recognition with speaker separation from microphone, file, or other audio input streams, and gets transcribed text as result.\n * @class ConversationTranscriber\n */\nclass ConversationTranscriber extends Exports_js_3.Recognizer {\n    /**\n     * ConversationTranscriber constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    constructor(speechConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        super(audioConfig, speechConfigImpl.properties, new Exports_js_1.ConversationTranscriberConnectionFactory());\n        this.privProperties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, \"2\");\n        this.privDisposedRecognizer = false;\n    }\n    /**\n     * ConversationTranscriber constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n        const recognizer = new ConversationTranscriber(speechConfig, audioConfig);\n        return recognizer;\n    }\n    /**\n     * Gets the endpoint id of a customized speech model that is used for transcription.\n     * @member ConversationTranscriber.prototype.endpointId\n     * @function\n     * @public\n     * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.\n     */\n    get endpointId() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_EndpointId, \"00000000-0000-0000-0000-000000000000\");\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member ConversationTranscriber.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member ConversationTranscriber.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * Gets the spoken language of transcription.\n     * @member ConversationTranscriber.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} The spoken language of transcription.\n     */\n    get speechRecognitionLanguage() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * Gets the output format of transcription.\n     * @member ConversationTranscriber.prototype.outputFormat\n     * @function\n     * @public\n     * @returns {OutputFormat} The output format of transcription.\n     */\n    get outputFormat() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        if (this.properties.getProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]) === Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]) {\n            return Exports_js_3.OutputFormat.Simple;\n        }\n        else {\n            return Exports_js_3.OutputFormat.Detailed;\n        }\n    }\n    /**\n     * The collection of properties and their values defined for this conversation transcriber.\n     * @member ConversationTranscriber.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Starts conversation transcription, until stopTranscribingAsync() is called.\n     * User must subscribe to events to receive transcription results.\n     * @member ConversationTranscriber.prototype.startTranscribingAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the transcription has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startTranscribingAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(Exports_js_1.RecognitionMode.Conversation), cb, err);\n    }\n    /**\n     * Stops conversation transcription.\n     * @member ConversationTranscriber.prototype.stopTranscribingAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the transcription has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopTranscribingAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member ConversationTranscriber.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        Exports_js_2.marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member SpeechRecognizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    async dispose(disposing) {\n        if (this.privDisposedRecognizer) {\n            return;\n        }\n        if (disposing) {\n            this.privDisposedRecognizer = true;\n            await this.implRecognizerStop();\n        }\n        await super.dispose(disposing);\n    }\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        recognizerConfig.isSpeakerDiarizationEnabled = true;\n        return new Exports_js_1.ConversationTranscriptionServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n}\nexports.ConversationTranscriber = ConversationTranscriber;\n\n//# sourceMappingURL=ConversationTranscriber.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriber.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriptionResult.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriptionResult.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranscriptionResult = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines result of conversation transcription.\n * @class ConversationTranscriptionResult\n */\nclass ConversationTranscriptionResult extends Exports_js_1.RecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @public\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} language - Primary Language detected, if provided.\n     * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param {string} speakerId - speaker id for conversation transcription.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);\n        this.privSpeakerId = speakerId;\n    }\n    /**\n     * speaker id\n     * @member ConversationTranscriptionResult.prototype.speakerId\n     * @function\n     * @public\n     * @returns {string} id of speaker in given result\n     */\n    get speakerId() {\n        return this.privSpeakerId;\n    }\n}\nexports.ConversationTranscriptionResult = ConversationTranscriptionResult;\n\n//# sourceMappingURL=ConversationTranscriptionResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriptionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js":
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js ***!
  \*******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranslationCanceledEventArgs = void 0;\nconst CancellationEventArgsBase_js_1 = __webpack_require__(/*! ../CancellationEventArgsBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js\");\nclass ConversationTranslationCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {\n}\nexports.ConversationTranslationCanceledEventArgs = ConversationTranslationCanceledEventArgs;\n\n//# sourceMappingURL=ConversationTranslationCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationEventArgs.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationEventArgs.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranslationEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass ConversationTranslationEventArgs extends Exports_js_1.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {ConversationTranslationResult} result - The translation recognition result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the recognition result.\n     * @returns {ConversationTranslationResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\nexports.ConversationTranslationEventArgs = ConversationTranslationEventArgs;\n\n//# sourceMappingURL=ConversationTranslationEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationResult.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationResult.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranslationResult = void 0;\nconst TranslationRecognitionResult_js_1 = __webpack_require__(/*! ../TranslationRecognitionResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js\");\nclass ConversationTranslationResult extends TranslationRecognitionResult_js_1.TranslationRecognitionResult {\n    constructor(participantId, translations, originalLanguage, resultId, reason, text, duration, offset, errorDetails, json, properties) {\n        super(translations, resultId, reason, text, duration, offset, undefined, undefined, errorDetails, json, properties);\n        this.privId = participantId;\n        this.privOrigLang = originalLanguage;\n    }\n    /**\n     * The unique identifier for the participant this result is for.\n     */\n    get participantId() {\n        return this.privId;\n    }\n    /**\n     * The original language this result was in.\n     */\n    get originalLang() {\n        return this.privOrigLang;\n    }\n}\nexports.ConversationTranslationResult = ConversationTranslationResult;\n\n//# sourceMappingURL=ConversationTranslationResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslator.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslator.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConversationTranslator = exports.SpeechState = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst ConversationTranslatorConnectionFactory_js_1 = __webpack_require__(/*! ../../common.speech/Transcription/ConversationTranslatorConnectionFactory.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Conversation_js_1 = __webpack_require__(/*! ./Conversation.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js\");\nvar SpeechState;\n(function (SpeechState) {\n    SpeechState[SpeechState[\"Inactive\"] = 0] = \"Inactive\";\n    SpeechState[SpeechState[\"Connecting\"] = 1] = \"Connecting\";\n    SpeechState[SpeechState[\"Connected\"] = 2] = \"Connected\";\n})(SpeechState = exports.SpeechState || (exports.SpeechState = {}));\n// child class of TranslationRecognizer meant only for use with ConversationTranslator\nclass ConversationTranslationRecognizer extends Exports_js_3.TranslationRecognizer {\n    constructor(speechConfig, audioConfig, translator, convGetter) {\n        super(speechConfig, audioConfig, new ConversationTranslatorConnectionFactory_js_1.ConversationTranslatorConnectionFactory(convGetter));\n        this.privSpeechState = SpeechState.Inactive;\n        if (!!translator) {\n            this.privTranslator = translator;\n            this.sessionStarted = () => {\n                this.privSpeechState = SpeechState.Connected;\n            };\n            this.sessionStopped = () => {\n                this.privSpeechState = SpeechState.Inactive;\n            };\n            this.recognizing = (tr, e) => {\n                if (!!this.privTranslator.recognizing) {\n                    this.privTranslator.recognizing(this.privTranslator, e);\n                }\n            };\n            // eslint-disable-next-line @typescript-eslint/no-misused-promises\n            this.recognized = async (tr, e) => {\n                // if there is an error connecting to the conversation service from the speech service the error will be returned in the ErrorDetails field.\n                if (e.result?.errorDetails) {\n                    await this.cancelSpeech();\n                    // TODO: format the error message contained in 'errorDetails'\n                    this.fireCancelEvent(e.result.errorDetails);\n                }\n                else {\n                    if (!!this.privTranslator.recognized) {\n                        this.privTranslator.recognized(this.privTranslator, e);\n                    }\n                }\n                return;\n            };\n            // eslint-disable-next-line @typescript-eslint/no-misused-promises\n            this.canceled = async () => {\n                if (this.privSpeechState !== SpeechState.Inactive) {\n                    try {\n                        await this.cancelSpeech();\n                    }\n                    catch (error) {\n                        this.privSpeechState = SpeechState.Inactive;\n                    }\n                }\n            };\n        }\n    }\n    get state() {\n        return this.privSpeechState;\n    }\n    set state(newState) {\n        this.privSpeechState = newState;\n    }\n    set authentication(token) {\n        this.privReco.authentication = token;\n    }\n    onConnection() {\n        this.privSpeechState = SpeechState.Connected;\n    }\n    async onCancelSpeech() {\n        this.privSpeechState = SpeechState.Inactive;\n        await this.cancelSpeech();\n    }\n    /**\n     * Fire a cancel event\n     * @param error\n     */\n    fireCancelEvent(error) {\n        try {\n            if (!!this.privTranslator.canceled) {\n                const cancelEvent = new Exports_js_4.ConversationTranslationCanceledEventArgs(Exports_js_3.CancellationReason.Error, error, Exports_js_3.CancellationErrorCode.RuntimeError);\n                this.privTranslator.canceled(this.privTranslator, cancelEvent);\n            }\n        }\n        catch (e) {\n            //\n        }\n    }\n    async cancelSpeech() {\n        try {\n            this.stopContinuousRecognitionAsync();\n            await this.privReco?.disconnect();\n            this.privSpeechState = SpeechState.Inactive;\n        }\n        catch (e) {\n            // ignore the error\n        }\n    }\n}\n/**\n * Join, leave or connect to a conversation.\n */\nclass ConversationTranslator extends Exports_js_4.ConversationCommon {\n    constructor(audioConfig) {\n        super(audioConfig);\n        this.privErrors = Exports_js_1.ConversationConnectionConfig.restErrors;\n        this.privIsDisposed = false;\n        this.privIsSpeaking = false;\n        this.privPlaceholderKey = \"abcdefghijklmnopqrstuvwxyz012345\";\n        this.privPlaceholderRegion = \"westus\";\n        this.privProperties = new Exports_js_3.PropertyCollection();\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get speechRecognitionLanguage() {\n        return this.privSpeechRecognitionLanguage;\n    }\n    get participants() {\n        return this.privConversation?.participants;\n    }\n    get canSpeak() {\n        // is there a Conversation websocket available and has the Recognizer been set up\n        if (!this.privConversation.isConnected || !this.privCTRecognizer) {\n            return false;\n        }\n        // is the user already speaking\n        if (this.privIsSpeaking || this.privCTRecognizer.state === SpeechState.Connected || this.privCTRecognizer.state === SpeechState.Connecting) {\n            return false;\n        }\n        // is the user muted\n        if (this.privConversation.isMutedByHost) {\n            return false;\n        }\n        return true;\n    }\n    onToken(token) {\n        this.privCTRecognizer.authentication = token;\n    }\n    setServiceProperty(name, value) {\n        const currentProperties = JSON.parse(this.privProperties.getProperty(Exports_js_1.ServicePropertiesPropertyName, \"{}\"));\n        currentProperties[name] = value;\n        this.privProperties.setProperty(Exports_js_1.ServicePropertiesPropertyName, JSON.stringify(currentProperties));\n    }\n    joinConversationAsync(conversation, nickname, param1, param2, param3) {\n        try {\n            if (typeof conversation === \"string\") {\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversation id\"));\n                Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n                if (!!this.privConversation) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedStart), param3);\n                }\n                let lang = param1;\n                if (lang === undefined || lang === null || lang === \"\") {\n                    lang = Exports_js_1.ConversationConnectionConfig.defaultLanguageCode;\n                }\n                // create a placeholder config\n                this.privSpeechTranslationConfig = Exports_js_3.SpeechTranslationConfig.fromSubscription(this.privPlaceholderKey, this.privPlaceholderRegion);\n                this.privSpeechTranslationConfig.setProfanity(Exports_js_3.ProfanityOption.Masked);\n                this.privSpeechTranslationConfig.addTargetLanguage(lang);\n                this.privSpeechTranslationConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage], lang);\n                this.privSpeechTranslationConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.ConversationTranslator_Name], nickname);\n                const propertyIdsToCopy = [\n                    Exports_js_3.PropertyId.SpeechServiceConnection_Host,\n                    Exports_js_3.PropertyId.ConversationTranslator_Host,\n                    Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint,\n                    Exports_js_3.PropertyId.SpeechServiceConnection_ProxyHostName,\n                    Exports_js_3.PropertyId.SpeechServiceConnection_ProxyPassword,\n                    Exports_js_3.PropertyId.SpeechServiceConnection_ProxyPort,\n                    Exports_js_3.PropertyId.SpeechServiceConnection_ProxyUserName,\n                    \"ConversationTranslator_MultiChannelAudio\",\n                    \"ConversationTranslator_Region\"\n                ];\n                for (const prop of propertyIdsToCopy) {\n                    const value = this.privProperties.getProperty(prop);\n                    if (value) {\n                        const key = typeof prop === \"string\" ? prop : Exports_js_3.PropertyId[prop];\n                        this.privSpeechTranslationConfig.setProperty(key, value);\n                    }\n                }\n                const currentProperties = JSON.parse(this.privProperties.getProperty(Exports_js_1.ServicePropertiesPropertyName, \"{}\"));\n                for (const prop of Object.keys(currentProperties)) {\n                    this.privSpeechTranslationConfig.setServiceProperty(prop, currentProperties[prop], Exports_js_3.ServicePropertyChannel.UriQueryParameter);\n                }\n                // join the conversation\n                this.privConversation = new Conversation_js_1.ConversationImpl(this.privSpeechTranslationConfig);\n                this.privConversation.conversationTranslator = this;\n                this.privConversation.joinConversationAsync(conversation, nickname, lang, ((result) => {\n                    if (!result) {\n                        this.handleError(new Error(this.privErrors.permissionDeniedConnect), param3);\n                    }\n                    this.privSpeechTranslationConfig.authorizationToken = result;\n                    this.privConversation.room.isHost = false;\n                    // connect to the ws\n                    this.privConversation.startConversationAsync((() => {\n                        this.handleCallback(param2, param3);\n                    }), ((error) => {\n                        this.handleError(error, param3);\n                    }));\n                }), ((error) => {\n                    this.handleError(error, param3);\n                }));\n            }\n            else if (typeof conversation === \"object\") {\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversation id\"));\n                Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n                // save the nickname\n                this.privProperties.setProperty(Exports_js_3.PropertyId.ConversationTranslator_Name, nickname);\n                // ref the conversation object\n                this.privConversation = conversation;\n                // ref the conversation translator object\n                this.privConversation.conversationTranslator = this;\n                this.privConversation.room.isHost = true;\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedConnect);\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);\n                this.privSpeechTranslationConfig = conversation.config;\n                this.handleCallback(param1, param2);\n            }\n            else {\n                this.handleError(new Error(this.privErrors.invalidArgs.replace(\"{arg}\", \"invalid conversation type\")), param2);\n            }\n        }\n        catch (error) {\n            this.handleError(error, typeof param1 === \"string\" ? param3 : param2);\n        }\n    }\n    /**\n     * Leave the conversation\n     * @param cb\n     * @param err\n     */\n    leaveConversationAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks((async () => {\n            // stop the speech websocket\n            await this.cancelSpeech();\n            // stop the websocket\n            await this.privConversation.endConversationImplAsync();\n            // https delete request\n            await this.privConversation.deleteConversationImplAsync();\n            this.dispose();\n        })(), cb, err);\n    }\n    /**\n     * Send a text message\n     * @param message\n     * @param cb\n     * @param err\n     */\n    sendTextMessageAsync(message, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace(\"{arg}\", message));\n            this.privConversation.sendTextMessageAsync(message, cb, err);\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Start speaking\n     * @param cb\n     * @param err\n     */\n    startTranscribingAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks((async () => {\n            try {\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);\n                if (this.privCTRecognizer === undefined) {\n                    await this.connectTranslatorRecognizer();\n                }\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privCTRecognizer, this.privErrors.permissionDeniedSend);\n                if (!this.canSpeak) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n                }\n                await this.startContinuousRecognition();\n                this.privIsSpeaking = true;\n            }\n            catch (error) {\n                this.privIsSpeaking = false;\n                await this.cancelSpeech();\n                throw error;\n            }\n        })(), cb, err);\n    }\n    /**\n     * Stop speaking\n     * @param cb\n     * @param err\n     */\n    stopTranscribingAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks((async () => {\n            try {\n                if (!this.privIsSpeaking) {\n                    // stop speech\n                    await this.cancelSpeech();\n                    return;\n                }\n                // stop the recognition but leave the websocket open\n                this.privIsSpeaking = false;\n                await new Promise((resolve, reject) => {\n                    this.privCTRecognizer.stopContinuousRecognitionAsync(resolve, reject);\n                });\n            }\n            catch (error) {\n                await this.cancelSpeech();\n            }\n        })(), cb, err);\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose(reason, success, err) {\n        Exports_js_2.marshalPromiseToCallbacks((async () => {\n            if (this.isDisposed && !this.privIsSpeaking) {\n                return;\n            }\n            await this.cancelSpeech();\n            this.privIsDisposed = true;\n            this.privSpeechTranslationConfig.close();\n            this.privSpeechRecognitionLanguage = undefined;\n            this.privProperties = undefined;\n            this.privAudioConfig = undefined;\n            this.privSpeechTranslationConfig = undefined;\n            this.privConversation.dispose();\n            this.privConversation = undefined;\n        })(), success, err);\n    }\n    /**\n     * Cancel the speech websocket\n     */\n    async cancelSpeech() {\n        try {\n            this.privIsSpeaking = false;\n            await this.privCTRecognizer?.onCancelSpeech();\n            this.privCTRecognizer = undefined;\n        }\n        catch (e) {\n            // ignore the error\n        }\n    }\n    /**\n     * Connect to the speech translation recognizer.\n     * Currently there is no language validation performed before sending the SpeechLanguage code to the service.\n     * If it's an invalid language the raw error will be: 'Error during WebSocket handshake: Unexpected response code: 400'\n     * e.g. pass in 'fr' instead of 'fr-FR', or a text-only language 'cy'\n     */\n    async connectTranslatorRecognizer() {\n        try {\n            if (this.privAudioConfig === undefined) {\n                this.privAudioConfig = Exports_js_3.AudioConfig.fromDefaultMicrophoneInput();\n            }\n            // clear the temp subscription key if it's a participant joining\n            if (this.privSpeechTranslationConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_Key])\n                === this.privPlaceholderKey) {\n                this.privSpeechTranslationConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_Key], \"\");\n            }\n            const convGetter = () => this.privConversation;\n            this.privCTRecognizer = new ConversationTranslationRecognizer(this.privSpeechTranslationConfig, this.privAudioConfig, this, convGetter);\n        }\n        catch (error) {\n            await this.cancelSpeech();\n            throw error;\n        }\n    }\n    /**\n     * Handle the start speaking request\n     */\n    startContinuousRecognition() {\n        return new Promise((resolve, reject) => {\n            this.privCTRecognizer.startContinuousRecognitionAsync(resolve, reject);\n        });\n    }\n}\nexports.ConversationTranslator = ConversationTranslator;\n\n//# sourceMappingURL=ConversationTranslator.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslator.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nvar Conversation_js_1 = __webpack_require__(/*! ./Conversation.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js\");\nObject.defineProperty(exports, \"Conversation\", ({ enumerable: true, get: function () { return Conversation_js_1.Conversation; } }));\nObject.defineProperty(exports, \"ConversationImpl\", ({ enumerable: true, get: function () { return Conversation_js_1.ConversationImpl; } }));\nvar ConversationCommon_js_1 = __webpack_require__(/*! ./ConversationCommon.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationCommon.js\");\nObject.defineProperty(exports, \"ConversationCommon\", ({ enumerable: true, get: function () { return ConversationCommon_js_1.ConversationCommon; } }));\nvar ConversationExpirationEventArgs_js_1 = __webpack_require__(/*! ./ConversationExpirationEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationExpirationEventArgs.js\");\nObject.defineProperty(exports, \"ConversationExpirationEventArgs\", ({ enumerable: true, get: function () { return ConversationExpirationEventArgs_js_1.ConversationExpirationEventArgs; } }));\nvar ConversationParticipantsChangedEventArgs_js_1 = __webpack_require__(/*! ./ConversationParticipantsChangedEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js\");\nObject.defineProperty(exports, \"ConversationParticipantsChangedEventArgs\", ({ enumerable: true, get: function () { return ConversationParticipantsChangedEventArgs_js_1.ConversationParticipantsChangedEventArgs; } }));\nvar ConversationTranslationCanceledEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranslationCanceledEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js\");\nObject.defineProperty(exports, \"ConversationTranslationCanceledEventArgs\", ({ enumerable: true, get: function () { return ConversationTranslationCanceledEventArgs_js_1.ConversationTranslationCanceledEventArgs; } }));\nvar ConversationTranslationEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranslationEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationEventArgs.js\");\nObject.defineProperty(exports, \"ConversationTranslationEventArgs\", ({ enumerable: true, get: function () { return ConversationTranslationEventArgs_js_1.ConversationTranslationEventArgs; } }));\nvar ConversationTranslationResult_js_1 = __webpack_require__(/*! ./ConversationTranslationResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationResult.js\");\nObject.defineProperty(exports, \"ConversationTranslationResult\", ({ enumerable: true, get: function () { return ConversationTranslationResult_js_1.ConversationTranslationResult; } }));\nvar ConversationTranslator_js_1 = __webpack_require__(/*! ./ConversationTranslator.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslator.js\");\nObject.defineProperty(exports, \"ConversationTranslator\", ({ enumerable: true, get: function () { return ConversationTranslator_js_1.ConversationTranslator; } }));\nvar ConversationTranscriber_js_1 = __webpack_require__(/*! ./ConversationTranscriber.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriber.js\");\nObject.defineProperty(exports, \"ConversationTranscriber\", ({ enumerable: true, get: function () { return ConversationTranscriber_js_1.ConversationTranscriber; } }));\nvar IParticipant_js_1 = __webpack_require__(/*! ./IParticipant.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/IParticipant.js\");\nObject.defineProperty(exports, \"Participant\", ({ enumerable: true, get: function () { return IParticipant_js_1.Participant; } }));\nObject.defineProperty(exports, \"User\", ({ enumerable: true, get: function () { return IParticipant_js_1.User; } }));\nvar ParticipantChangedReason_js_1 = __webpack_require__(/*! ./ParticipantChangedReason.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ParticipantChangedReason.js\");\nObject.defineProperty(exports, \"ParticipantChangedReason\", ({ enumerable: true, get: function () { return ParticipantChangedReason_js_1.ParticipantChangedReason; } }));\nvar Meeting_js_1 = __webpack_require__(/*! ./Meeting.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Meeting.js\");\nObject.defineProperty(exports, \"Meeting\", ({ enumerable: true, get: function () { return Meeting_js_1.Meeting; } }));\nObject.defineProperty(exports, \"MeetingImpl\", ({ enumerable: true, get: function () { return Meeting_js_1.MeetingImpl; } }));\nvar MeetingTranscriptionCanceledEventArgs_js_1 = __webpack_require__(/*! ./MeetingTranscriptionCanceledEventArgs.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriptionCanceledEventArgs.js\");\nObject.defineProperty(exports, \"MeetingTranscriptionCanceledEventArgs\", ({ enumerable: true, get: function () { return MeetingTranscriptionCanceledEventArgs_js_1.MeetingTranscriptionCanceledEventArgs; } }));\nvar MeetingTranscriber_js_1 = __webpack_require__(/*! ./MeetingTranscriber.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriber.js\");\nObject.defineProperty(exports, \"MeetingTranscriber\", ({ enumerable: true, get: function () { return MeetingTranscriber_js_1.MeetingTranscriber; } }));\nvar ConversationTranscriptionResult_js_1 = __webpack_require__(/*! ./ConversationTranscriptionResult.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriptionResult.js\");\nObject.defineProperty(exports, \"ConversationTranscriptionResult\", ({ enumerable: true, get: function () { return ConversationTranscriptionResult_js_1.ConversationTranscriptionResult; } }));\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/IParticipant.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/IParticipant.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Participant = exports.User = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass User {\n    constructor(userId) {\n        this.privUserId = userId;\n    }\n    get userId() {\n        return this.privUserId;\n    }\n}\nexports.User = User;\nclass Participant {\n    constructor(id, avatar, displayName, isHost, isMuted, isUsingTts, preferredLanguage, voice) {\n        this.privId = id;\n        this.privAvatar = avatar;\n        this.privDisplayName = displayName;\n        this.privIsHost = isHost;\n        this.privIsMuted = isMuted;\n        this.privIsUsingTts = isUsingTts;\n        this.privPreferredLanguage = preferredLanguage;\n        this.privVoice = voice;\n        this.privProperties = new Exports_js_1.PropertyCollection();\n    }\n    get avatar() {\n        return this.privAvatar;\n    }\n    get displayName() {\n        return this.privDisplayName;\n    }\n    get id() {\n        return this.privId;\n    }\n    get preferredLanguage() {\n        return this.privPreferredLanguage;\n    }\n    get isHost() {\n        return this.privIsHost;\n    }\n    get isMuted() {\n        return this.privIsMuted;\n    }\n    get isUsingTts() {\n        return this.privIsUsingTts;\n    }\n    get voice() {\n        return this.privVoice;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    static From(id, language, voice) {\n        return new Participant(id, \"\", id, false, false, false, language, voice);\n    }\n}\nexports.Participant = Participant;\n\n//# sourceMappingURL=IParticipant.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/IParticipant.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Meeting.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Meeting.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MeetingImpl = exports.Meeting = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nclass Meeting {\n    constructor() {\n        return;\n    }\n    /**\n     * Create a meeting\n     * @param speechConfig\n     * @param meetingId\n     * @param cb\n     * @param err\n     */\n    static createMeetingAsync(speechConfig, meetingId, arg3, arg4) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"config\"));\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig.region, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"SpeechServiceConnection_Region\"));\n        Contracts_js_1.Contracts.throwIfNull(meetingId, \"meetingId\");\n        if (meetingId.length === 0) {\n            throw new Error(\"meetingId cannot be empty\");\n        }\n        if (!speechConfig.subscriptionKey && !speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceAuthorization_Token])) {\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig.subscriptionKey, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"SpeechServiceConnection_Key\"));\n        }\n        const meetingImpl = new MeetingImpl(speechConfig, meetingId);\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        Exports_js_2.marshalPromiseToCallbacks((async () => { })(), arg3, arg4);\n        return meetingImpl;\n    }\n}\nexports.Meeting = Meeting;\nclass MeetingImpl extends Meeting {\n    /**\n     * Create a Meeting impl\n     * @param speechConfig\n     * @param {string} id - optional conversationId\n     */\n    constructor(speechConfig, id) {\n        super();\n        this.privErrors = Exports_js_1.ConversationConnectionConfig.restErrors;\n        /** websocket callbacks */\n        /* eslint-disable @typescript-eslint/typedef */\n        this.onConnected = (e) => {\n            this.privIsConnected = true;\n            try {\n                if (!!this.privConversationTranslator?.sessionStarted) {\n                    this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onDisconnected = (e) => {\n            try {\n                if (!!this.privConversationTranslator?.sessionStopped) {\n                    this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n            finally {\n                void this.close(false);\n            }\n        };\n        this.onCanceled = (r, e) => {\n            try {\n                if (!!this.privConversationTranslator?.canceled) {\n                    this.privConversationTranslator.canceled(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantUpdateCommandReceived = (r, e) => {\n            try {\n                const updatedParticipant = this.privParticipants.getParticipant(e.id);\n                if (updatedParticipant !== undefined) {\n                    switch (e.key) {\n                        case Exports_js_1.ConversationTranslatorCommandTypes.changeNickname:\n                            updatedParticipant.displayName = e.value;\n                            break;\n                        case Exports_js_1.ConversationTranslatorCommandTypes.setUseTTS:\n                            updatedParticipant.isUsingTts = e.value;\n                            break;\n                        case Exports_js_1.ConversationTranslatorCommandTypes.setProfanityFiltering:\n                            updatedParticipant.profanity = e.value;\n                            break;\n                        case Exports_js_1.ConversationTranslatorCommandTypes.setMute:\n                            updatedParticipant.isMuted = e.value;\n                            break;\n                        case Exports_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages:\n                            updatedParticipant.translateToLanguages = e.value;\n                            break;\n                    }\n                    this.privParticipants.addOrUpdateParticipant(updatedParticipant);\n                    if (!!this.privConversationTranslator) {\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.Updated, [this.toParticipant(updatedParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onLockRoomCommandReceived = () => {\n            // TODO\n        };\n        this.onMuteAllCommandReceived = (r, e) => {\n            try {\n                this.privParticipants.participants.forEach((p) => p.isMuted = (p.isHost ? false : e.isMuted));\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.Updated, this.toParticipants(false), e.sessionId));\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantJoinCommandReceived = (r, e) => {\n            try {\n                const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);\n                if (newParticipant !== undefined) {\n                    if (!!this.privConversationTranslator) {\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantLeaveCommandReceived = (r, e) => {\n            try {\n                const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);\n                if (ejectedParticipant !== undefined) {\n                    // remove the participant from the internal participants list\n                    this.privParticipants.deleteParticipant(e.participant.id);\n                    if (!!this.privConversationTranslator) {\n                        // notify subscribers that the participant has left the conversation\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onTranslationReceived = (r, e) => {\n            try {\n                switch (e.command) {\n                    case Exports_js_1.ConversationTranslatorMessageTypes.final:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.transcribed(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                    case Exports_js_1.ConversationTranslatorMessageTypes.partial:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.transcribing(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                    case Exports_js_1.ConversationTranslatorMessageTypes.instantMessage:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.textMessageReceived(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantsListReceived = (r, e) => {\n            try {\n                // check if the session token needs to be updated\n                if (e.sessionToken !== undefined && e.sessionToken !== null) {\n                    this.privRoom.token = e.sessionToken;\n                }\n                // save the participants\n                this.privParticipants.participants = [...e.participants];\n                // enable the conversation\n                if (this.privParticipants.me !== undefined) {\n                    this.privIsReady = true;\n                }\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.JoinedConversation, this.toParticipants(true), e.sessionId));\n                }\n                // if this is the host, update the nickname if needed\n                if (this.me.isHost) {\n                    const nickname = this.privConversationTranslator?.properties.getProperty(Exports_js_3.PropertyId.ConversationTranslator_Name);\n                    if (nickname !== undefined && nickname.length > 0 && nickname !== this.me.displayName) {\n                        // issue a change nickname request\n                        this.changeNicknameAsync(nickname);\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onConversationExpiration = (r, e) => {\n            try {\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.conversationExpiration(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.privIsConnected = false;\n        this.privIsDisposed = false;\n        this.privConversationId = \"\";\n        this.privProperties = new Exports_js_3.PropertyCollection();\n        this.privManager = new Exports_js_1.ConversationManager();\n        // check the speech language\n        const language = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        if (!language) {\n            speechConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage], Exports_js_1.ConversationConnectionConfig.defaultLanguageCode);\n        }\n        this.privLanguage = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);\n        this.privConversationId = id;\n        // save the speech config for future usage\n        this.privConfig = speechConfig;\n        // save the config properties\n        const configImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNull(configImpl, \"speechConfig\");\n        this.privProperties = configImpl.properties.clone();\n        this.privIsConnected = false;\n        this.privParticipants = new Exports_js_1.InternalParticipants();\n        this.privIsReady = false;\n        this.privTextMessageMaxLength = 1000;\n    }\n    // get the internal data about a conversation\n    get room() {\n        return this.privRoom;\n    }\n    // get the wrapper for connecting to the websockets\n    get connection() {\n        return this.privConversationRecognizer; // this.privConnection;\n    }\n    // get the config\n    get config() {\n        return this.privConfig;\n    }\n    // get the meeting Id\n    get meetingId() {\n        return this.privRoom ? this.privRoom.roomId : this.privConversationId;\n    }\n    // get the properties\n    get properties() {\n        return this.privProperties;\n    }\n    // get the speech language\n    get speechRecognitionLanguage() {\n        return this.privLanguage;\n    }\n    get isMutedByHost() {\n        return this.privParticipants.me?.isHost ? false : this.privParticipants.me?.isMuted;\n    }\n    get isConnected() {\n        return this.privIsConnected && this.privIsReady;\n    }\n    get participants() {\n        return this.toParticipants(true);\n    }\n    get me() {\n        return this.toParticipant(this.privParticipants.me);\n    }\n    get host() {\n        return this.toParticipant(this.privParticipants.host);\n    }\n    get transcriberRecognizer() {\n        return this.privTranscriberRecognizer;\n    }\n    get meetingInfo() {\n        const convId = this.meetingId;\n        const p = this.participants.map((part) => ({\n            id: part.id,\n            preferredLanguage: part.preferredLanguage,\n            voice: part.voice\n        }));\n        const props = {};\n        for (const key of Exports_js_1.ConversationConnectionConfig.transcriptionEventKeys) {\n            const val = this.properties.getProperty(key, \"\");\n            if (val !== \"\") {\n                props[key] = val;\n            }\n        }\n        const info = { id: convId, participants: p, meetingProperties: props };\n        return info;\n    }\n    get canSend() {\n        return this.privIsConnected && !this.privParticipants.me?.isMuted;\n    }\n    get canSendAsHost() {\n        return this.privIsConnected && this.privParticipants.me?.isHost;\n    }\n    // get / set the speech auth token\n    // eslint-disable-next-line @typescript-eslint/member-ordering\n    get authorizationToken() {\n        return this.privToken;\n    }\n    set authorizationToken(value) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, \"authorizationToken\");\n        this.privToken = value;\n    }\n    /**\n     * Create a new meeting as Host\n     * @param cb\n     * @param err\n     */\n    createMeetingAsync(cb, err) {\n        try {\n            if (!!this.privConversationRecognizer) {\n                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);\n            }\n            this.privManager.createOrJoin(this.privProperties, undefined, ((room) => {\n                if (!room) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);\n                }\n                this.privRoom = room;\n                this.handleCallback(cb, err);\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Starts a new meeting as host.\n     * @param cb\n     * @param err\n     */\n    startMeetingAsync(cb, err) {\n        try {\n            // check if there is already a recognizer\n            if (!!this.privConversationRecognizer) {\n                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);\n            }\n            // check if there is conversation data available\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);\n            // connect to the conversation websocket\n            this.privParticipants.meId = this.privRoom.participantId;\n            // Because ConversationTranslator manually sets up and manages the connection, Conversation\n            // has to forward serviceRecognizer connection events that usually get passed automatically\n            this.privConversationRecognizer.connected = this.onConnected;\n            this.privConversationRecognizer.disconnected = this.onDisconnected;\n            this.privConversationRecognizer.canceled = this.onCanceled;\n            this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;\n            this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;\n            this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;\n            this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;\n            this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;\n            this.privConversationRecognizer.translationReceived = this.onTranslationReceived;\n            this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;\n            this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;\n            this.privConversationRecognizer.connect(this.privRoom.token, (() => {\n                this.handleCallback(cb, err);\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Join a meeting as a participant.\n     * @param { IParticipant } participant - participant to add\n     * @param cb\n     * @param err\n     */\n    addParticipantAsync(participant, cb, err) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(participant, \"Participant\");\n        Exports_js_2.marshalPromiseToCallbacks(this.addParticipantImplAsync(participant), cb, err);\n    }\n    /**\n     * Join a meeting as a participant.\n     * @param meeting\n     * @param nickname\n     * @param lang\n     * @param cb\n     * @param err\n     */\n    joinMeetingAsync(meetingId, nickname, lang, cb, err) {\n        try {\n            // TODO\n            // if (!!this.privConversationRecognizer) {\n            //     throw new Error(this.privErrors.permissionDeniedStart);\n            // }\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(meetingId, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversationId\"));\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace(\"{arg}\", \"language\"));\n            // join the conversation\n            this.privManager.createOrJoin(this.privProperties, meetingId, ((room) => {\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);\n                this.privRoom = room;\n                this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;\n                // join callback\n                if (!!cb) {\n                    cb(room.cognitiveSpeechAuthToken);\n                }\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Deletes a meeting\n     * @param cb\n     * @param err\n     */\n    deleteMeetingAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.deleteMeetingImplAsync(), cb, err);\n    }\n    async deleteMeetingImplAsync() {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);\n        await this.privManager.leave(this.privProperties, this.privRoom.token);\n        this.dispose();\n    }\n    /**\n     * Issues a request to close the client websockets\n     * @param cb\n     * @param err\n     */\n    endMeetingAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.endMeetingImplAsync(), cb, err);\n    }\n    endMeetingImplAsync() {\n        return this.close(true);\n    }\n    /**\n     * Issues a request to lock the conversation\n     * @param cb\n     * @param err\n     */\n    lockMeetingAsync(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"lock\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getLockCommand(true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to mute the meeting\n     * @param cb\n     * @param err\n     */\n    muteAllParticipantsAsync(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the user's permissions\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"mute\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to mute a participant in the meeting\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    muteParticipantAsync(userId, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the connection is open (host + participant can perform the mute command)\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // if not host, check the participant is not muting another participant\n            if (!this.me.isHost && this.me.id !== userId) {\n                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"mute\")), err);\n            }\n            // check the user exists\n            const exists = this.privParticipants.getParticipantIndex(userId);\n            if (exists === -1) {\n                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to remove a participant from the conversation\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    removeParticipantAsync(userId, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            if (!!this.privTranscriberRecognizer && userId.hasOwnProperty(\"id\")) {\n                // Assume this is a transcription participant\n                Exports_js_2.marshalPromiseToCallbacks(this.removeParticipantImplAsync(userId), cb, err);\n            }\n            else {\n                Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n                if (!this.canSendAsHost) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"remove\")), err);\n                }\n                let participantId = \"\";\n                if (typeof userId === \"string\") {\n                    participantId = userId;\n                }\n                else if (userId.hasOwnProperty(\"id\")) {\n                    const participant = userId;\n                    participantId = participant.id;\n                }\n                else if (userId.hasOwnProperty(\"userId\")) {\n                    const user = userId;\n                    participantId = user.userId;\n                }\n                Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n                // check the participant exists\n                const index = this.participants.findIndex((p) => p.id === participantId);\n                if (index === -1) {\n                    this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n                }\n                if (!!this.privConversationRecognizer) {\n                    this.privConversationRecognizer.sendRequest(this.getEjectCommand(participantId), (() => {\n                        this.handleCallback(cb, err);\n                    }), ((error) => {\n                        this.handleError(error, err);\n                    }));\n                }\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unlock the meeting\n     * @param cb\n     * @param err\n     */\n    unlockMeetingAsync(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"unlock\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getLockCommand(false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unmute all participants in the meeting\n     * @param cb\n     * @param err\n     */\n    unmuteAllParticipantsAsync(cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"unmute all\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unmute a participant in the meeting\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    unmuteParticipantAsync(userId, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the connection is open (host + participant can perform the mute command)\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // if not host, check the participant is not muting another participant\n            if (!this.me.isHost && this.me.id !== userId) {\n                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"mute\")), err);\n            }\n            // check the user exists\n            const exists = this.privParticipants.getParticipantIndex(userId);\n            if (exists === -1) {\n                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Send a text message\n     * @param message\n     * @param cb\n     * @param err\n     */\n    sendTextMessageAsync(message, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace(\"{arg}\", \"message\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // TODO: is a max length check required?\n            if (message.length > this.privTextMessageMaxLength) {\n                this.handleError(new Error(this.privErrors.invalidArgs.replace(\"{arg}\", \"message length\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMessageCommand(message), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Set translated to languages\n     * @param {string[]} languages - languages to translate to\n     * @param cb\n     * @param err\n     */\n    setTranslatedLanguagesAsync(languages, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfArrayEmptyOrWhitespace(languages, this.privErrors.invalidArgs.replace(\"{arg}\", \"languages\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getSetTranslateToLanguagesCommand(languages), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Change nickname\n     * @param {string} nickname - new nickname for the room\n     * @param cb\n     * @param err\n     */\n    changeNicknameAsync(nickname, cb, err) {\n        try {\n            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);\n            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getChangeNicknameCommand(nickname), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose() {\n        if (this.isDisposed) {\n            return;\n        }\n        this.privIsDisposed = true;\n        if (!!this.config) {\n            this.config.close();\n        }\n        this.privConfig = undefined;\n        this.privLanguage = undefined;\n        this.privProperties = undefined;\n        this.privRoom = undefined;\n        this.privToken = undefined;\n        this.privManager = undefined;\n        this.privIsConnected = false;\n        this.privIsReady = false;\n        this.privParticipants = undefined;\n    }\n    async connectTranscriberRecognizer(recognizer) {\n        if (!!this.privTranscriberRecognizer) {\n            await this.privTranscriberRecognizer.close();\n        }\n        await recognizer.enforceAudioGating();\n        this.privTranscriberRecognizer = recognizer;\n        this.privTranscriberRecognizer.meeting = this;\n    }\n    getKeepAlive() {\n        const nickname = (!!this.me) ? this.me.displayName : \"default_nickname\";\n        return JSON.stringify({\n            id: \"0\",\n            nickname,\n            participantId: this.privRoom.participantId,\n            roomId: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.keepAlive\n        });\n    }\n    /* eslint-enable @typescript-eslint/typedef */\n    addParticipantImplAsync(participant) {\n        const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);\n        if (newParticipant !== undefined) {\n            if (!!this.privTranscriberRecognizer) {\n                const meetingInfo = this.meetingInfo;\n                meetingInfo.participants = [participant];\n                return this.privTranscriberRecognizer.pushMeetingEvent(meetingInfo, \"join\");\n            }\n        }\n    }\n    removeParticipantImplAsync(participant) {\n        this.privParticipants.deleteParticipant(participant.id);\n        const meetingInfo = this.meetingInfo;\n        meetingInfo.participants = [participant];\n        return this.privTranscriberRecognizer.pushMeetingEvent(meetingInfo, \"leave\");\n    }\n    async close(dispose) {\n        try {\n            this.privIsConnected = false;\n            await this.privConversationRecognizer?.close();\n            this.privConversationRecognizer = undefined;\n            if (!!this.privConversationTranslator) {\n                this.privConversationTranslator.dispose();\n            }\n        }\n        catch (e) {\n            // ignore error\n            throw e;\n        }\n        if (dispose) {\n            this.dispose();\n        }\n    }\n    /** Helpers */\n    handleCallback(cb, err) {\n        if (!!cb) {\n            try {\n                cb();\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n            cb = undefined;\n        }\n    }\n    handleError(error, err) {\n        if (!!err) {\n            if (error instanceof Error) {\n                const typedError = error;\n                err(typedError.name + \": \" + typedError.message);\n            }\n            else {\n                err(error);\n            }\n        }\n    }\n    /** Participant Helpers */\n    toParticipants(includeHost) {\n        const participants = this.privParticipants.participants.map((p) => (this.toParticipant(p)));\n        if (!includeHost) {\n            return participants.filter((p) => p.isHost === false);\n        }\n        else {\n            return participants;\n        }\n    }\n    toParticipant(p) {\n        return new Exports_js_3.Participant(p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);\n    }\n    getMuteAllCommand(isMuted) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"meetingd\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.setMuteAll,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: isMuted\n        });\n    }\n    getMuteCommand(participantId, isMuted) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.setMute,\n            // eslint-disable-next-line object-shorthand\n            participantId: participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: isMuted\n        });\n    }\n    getLockCommand(isLocked) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"meetingId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.setLockState,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: isLocked\n        });\n    }\n    getEjectCommand(participantId) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"meetingId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.ejectParticipant,\n            // eslint-disable-next-line object-shorthand\n            participantId: participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n        });\n    }\n    getSetTranslateToLanguagesCommand(languages) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"meetingId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: languages\n        });\n    }\n    getChangeNicknameCommand(nickname) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"meetingId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, \"nickname\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: Exports_js_1.ConversationTranslatorCommandTypes.changeNickname,\n            nickname,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,\n            value: nickname\n        });\n    }\n    getMessageCommand(message) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"meetingId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, \"message\");\n        return JSON.stringify({\n            participantId: this.privRoom.participantId,\n            roomId: this.privRoom.roomId,\n            text: message,\n            type: Exports_js_1.ConversationTranslatorMessageTypes.instantMessage\n        });\n    }\n}\nexports.MeetingImpl = MeetingImpl;\n\n//# sourceMappingURL=Meeting.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Meeting.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriber.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriber.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MeetingTranscriber = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ../Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\nconst Exports_js_4 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js\");\nclass MeetingTranscriber {\n    /**\n     * MeetingTranscriber constructor.\n     * @constructor\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    constructor(audioConfig) {\n        this.privAudioConfig = audioConfig;\n        this.privProperties = new Exports_js_3.PropertyCollection();\n        this.privRecognizer = undefined;\n        this.privDisposedRecognizer = false;\n    }\n    /**\n     * Gets the spoken language of recognition.\n     * @member MeetingTranscriber.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} The spoken language of recognition.\n     */\n    get speechRecognitionLanguage() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * The collection of properties and their values defined for this MeetingTranscriber.\n     * @member MeetingTranscriber.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this MeetingTranscriber.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * @Internal\n     * Internal data member to support fromRecognizer* pattern methods on other classes.\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    get internalData() {\n        return this.privRecognizer.internalData;\n    }\n    /**\n     * @Deprecated\n     * @Obsolete\n     * Please use the Connection.fromRecognizer pattern to obtain a connection object\n     */\n    get connection() {\n        return Exports_js_3.Connection.fromRecognizer(this.privRecognizer);\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member MeetingTranscriber.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member MeetingTranscriber.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * @param {Meeting} meeting - meeting to be recognized\n     */\n    joinMeetingAsync(meeting, cb, err) {\n        /* eslint-disable no-console */\n        // console.log(\">> MeetingTranscriber::joinMeetingAsync\");\n        /* eslint-enable no-console */\n        const meetingImpl = meeting;\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(Exports_js_4.MeetingImpl, \"Meeting\");\n        // ref the meeting object\n        // create recognizer and subscribe to recognizer events\n        this.privRecognizer = new Exports_js_1.TranscriberRecognizer(meeting.config, this.privAudioConfig);\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRecognizer, \"Recognizer\");\n        this.privRecognizer.connectMeetingCallbacks(this);\n        Exports_js_2.marshalPromiseToCallbacks(meetingImpl.connectTranscriberRecognizer(this.privRecognizer), cb, err);\n    }\n    /**\n     * Starts meeting transcription, until stopTranscribingAsync() is called.\n     * User must subscribe to events to receive transcription results.\n     * @member MeetingTranscriber.prototype.startTranscribingAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the transcription has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startTranscribingAsync(cb, err) {\n        this.privRecognizer.startContinuousRecognitionAsync(cb, err);\n    }\n    /**\n     * Starts meeting transcription, until stopTranscribingAsync() is called.\n     * User must subscribe to events to receive transcription results.\n     * @member MeetingTranscriber.prototype.stopTranscribingAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the transcription has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopTranscribingAsync(cb, err) {\n        this.privRecognizer.stopContinuousRecognitionAsync(cb, err);\n    }\n    /**\n     * Leave the current meeting. After this is called, you will no longer receive any events.\n     */\n    leaveMeetingAsync(cb, err) {\n        this.privRecognizer.disconnectCallbacks();\n        // eslint-disable-next-line\n        Exports_js_2.marshalPromiseToCallbacks((async () => { return; })(), cb, err);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member MeetingTranscriber.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n        Exports_js_2.marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member MeetingTranscriber.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    async dispose(disposing) {\n        if (this.privDisposedRecognizer) {\n            return;\n        }\n        if (!!this.privRecognizer) {\n            await this.privRecognizer.close();\n            this.privRecognizer = undefined;\n        }\n        if (disposing) {\n            this.privDisposedRecognizer = true;\n        }\n    }\n}\nexports.MeetingTranscriber = MeetingTranscriber;\n\n//# sourceMappingURL=MeetingTranscriber.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriber.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriptionCanceledEventArgs.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriptionCanceledEventArgs.js ***!
  \****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MeetingTranscriptionCanceledEventArgs = void 0;\nconst CancellationEventArgsBase_js_1 = __webpack_require__(/*! ../CancellationEventArgsBase.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js\");\nclass MeetingTranscriptionCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {\n}\nexports.MeetingTranscriptionCanceledEventArgs = MeetingTranscriptionCanceledEventArgs;\n\n//# sourceMappingURL=MeetingTranscriptionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriptionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ParticipantChangedReason.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ParticipantChangedReason.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ParticipantChangedReason = void 0;\nvar ParticipantChangedReason;\n(function (ParticipantChangedReason) {\n    /** Participant has joined the conversation. */\n    ParticipantChangedReason[ParticipantChangedReason[\"JoinedConversation\"] = 0] = \"JoinedConversation\";\n    /** Participant has left the conversation. This could be voluntary, or involuntary\n     * (e.g. they are experiencing networking issues).\n     */\n    ParticipantChangedReason[ParticipantChangedReason[\"LeftConversation\"] = 1] = \"LeftConversation\";\n    /** The participants' state has changed (e.g. they became muted, changed their nickname). */\n    ParticipantChangedReason[ParticipantChangedReason[\"Updated\"] = 2] = \"Updated\";\n})(ParticipantChangedReason = exports.ParticipantChangedReason || (exports.ParticipantChangedReason = {}));\n\n//# sourceMappingURL=ParticipantChangedReason.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ParticipantChangedReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionCanceledEventArgs.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionCanceledEventArgs.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationRecognitionCanceledEventArgs = void 0;\n/**\n * Define payload of speech recognition canceled result events.\n * @class TranslationRecognitionCanceledEventArgs\n */\nclass TranslationRecognitionCanceledEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} sessionid - The session id.\n     * @param {CancellationReason} cancellationReason - The cancellation reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {TranslationRecognitionResult} result - The result.\n     */\n    constructor(sessionid, cancellationReason, errorDetails, errorCode, result) {\n        this.privCancelReason = cancellationReason;\n        this.privErrorDetails = errorDetails;\n        this.privResult = result;\n        this.privSessionId = sessionid;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n    /**\n     * Specifies the session identifier.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId\n     * @function\n     * @public\n     * @returns {string} the session identifier.\n     */\n    get sessionId() {\n        return this.privSessionId;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privCancelReason;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\nexports.TranslationRecognitionCanceledEventArgs = TranslationRecognitionCanceledEventArgs;\n\n//# sourceMappingURL=TranslationRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionEventArgs.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionEventArgs.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationRecognitionEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Translation text result event arguments.\n * @class TranslationRecognitionEventArgs\n */\nclass TranslationRecognitionEventArgs extends Exports_js_1.RecognitionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {TranslationRecognitionResult} result - The translation recognition result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member TranslationRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\nexports.TranslationRecognitionEventArgs = TranslationRecognitionEventArgs;\n\n//# sourceMappingURL=TranslationRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationRecognitionResult = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Translation text result.\n * @class TranslationRecognitionResult\n */\nclass TranslationRecognitionResult extends Exports_js_1.SpeechRecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {Translations} translations - The translations.\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} language - Primary Language detected, if provided.\n     * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(translations, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);\n        this.privTranslations = translations;\n    }\n    static fromSpeechRecognitionResult(result) {\n        return new TranslationRecognitionResult(undefined, result.resultId, result.reason, result.text, result.duration, result.offset, result.language, result.languageDetectionConfidence, result.errorDetails, result.json, result.properties);\n    }\n    /**\n     * Presents the translation results. Each item in the dictionary represents\n     * a translation result in one of target languages, where the key is the name\n     * of the target language, in BCP-47 format, and the value is the translation\n     * text in the specified language.\n     * @member TranslationRecognitionResult.prototype.translations\n     * @function\n     * @public\n     * @returns {Translations} the current translation map that holds all translations requested.\n     */\n    get translations() {\n        return this.privTranslations;\n    }\n}\nexports.TranslationRecognitionResult = TranslationRecognitionResult;\n\n//# sourceMappingURL=TranslationRecognitionResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognizer.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognizer.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationRecognizer = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js\");\nconst Connection_js_1 = __webpack_require__(/*! ./Connection.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_3 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Translation recognizer\n * @class TranslationRecognizer\n */\nclass TranslationRecognizer extends Exports_js_3.Recognizer {\n    /**\n     * Initializes an instance of the TranslationRecognizer.\n     * @constructor\n     * @param {SpeechTranslationConfig} speechConfig - Set of properties to configure this recognizer.\n     * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer\n     * @param {IConnectionFactory} connectionFactory - An optional connection factory to use to generate the endpoint URIs, headers to set, etc...\n     */\n    constructor(speechConfig, audioConfig, connectionFactory) {\n        const configImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNull(configImpl, \"speechConfig\");\n        super(audioConfig, configImpl.properties, connectionFactory || new Exports_js_1.TranslationConnectionFactory());\n        this.privDisposedTranslationRecognizer = false;\n        if (this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {\n            Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice]);\n        }\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages]);\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);\n    }\n    /**\n     * TranslationRecognizer constructor.\n     * @constructor\n     * @param {SpeechTranslationConfig} speechTranslationConfig - an set of initial properties for this recognizer\n     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    static FromConfig(speechTranslationConfig, autoDetectSourceLanguageConfig, audioConfig) {\n        const speechTranslationConfigImpl = speechTranslationConfig;\n        autoDetectSourceLanguageConfig.properties.mergeTo(speechTranslationConfigImpl.properties);\n        return new TranslationRecognizer(speechTranslationConfig, audioConfig);\n    }\n    /**\n     * Gets the language name that was set when the recognizer was created.\n     * @member TranslationRecognizer.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} Gets the language name that was set when the recognizer was created.\n     */\n    get speechRecognitionLanguage() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * Gets target languages for translation that were set when the recognizer was created.\n     * The language is specified in BCP-47 format. The translation will provide translated text for each of language.\n     * @member TranslationRecognizer.prototype.targetLanguages\n     * @function\n     * @public\n     * @returns {string[]} Gets target languages for translation that were set when the recognizer was created.\n     */\n    get targetLanguages() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(\",\");\n    }\n    /**\n     * Gets the name of output voice.\n     * @member TranslationRecognizer.prototype.voiceName\n     * @function\n     * @public\n     * @returns {string} the name of output voice.\n     */\n    get voiceName() {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);\n    }\n    /**\n     * The collection of properties and their values defined for this TranslationRecognizer.\n     * @member TranslationRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this TranslationRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member TranslationRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member TranslationRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} value - Authorization token.\n     */\n    set authorizationToken(value) {\n        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, value);\n    }\n    /**\n     * Starts recognition and translation, and stops after the first utterance is recognized.\n     * The task returns the translation text as result.\n     * Note: recognizeOnceAsync returns when the first utterance has been recognized, so it is suitable only\n     * for single shot recognition like command or query. For long-running recognition,\n     * use startContinuousRecognitionAsync() instead.\n     * @member TranslationRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the result when the translation has completed.\n     * @param err - Callback invoked in case of an error.\n     */\n    recognizeOnceAsync(cb, err) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n        Exports_js_2.marshalPromiseToCallbacks(this.recognizeOnceAsyncImpl(Exports_js_1.RecognitionMode.Interactive), cb, err);\n    }\n    /**\n     * Starts recognition and translation, until stopContinuousRecognitionAsync() is called.\n     * User must subscribe to events to receive translation results.\n     * @member TranslationRecognizer.prototype.startContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the translation has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startContinuousRecognitionAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.startContinuousRecognitionAsyncImpl(Exports_js_1.RecognitionMode.Conversation), cb, err);\n    }\n    /**\n     * Stops continuous recognition and translation.\n     * @member TranslationRecognizer.prototype.stopContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the translation has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopContinuousRecognitionAsync(cb, err) {\n        Exports_js_2.marshalPromiseToCallbacks(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    /**\n     * dynamically remove a language from list of target language\n     * (can be used while recognition is ongoing)\n     * @member TranslationRecognizer.prototype.removeTargetLanguage\n     * @function\n     * @param lang - language to be removed\n     * @public\n     */\n    removeTargetLanguage(lang) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(lang, \"language to be removed\");\n        if (this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n            const languages = this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(\",\");\n            const index = languages.indexOf(lang);\n            if (index > -1) {\n                languages.splice(index, 1);\n                this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n                this.updateLanguages(languages);\n            }\n        }\n    }\n    /**\n     * dynamically add a language to list of target language\n     * (can be used while recognition is ongoing)\n     * @member TranslationRecognizer.prototype.addTargetLanguage\n     * @function\n     * @param lang - language to be added\n     * @public\n     */\n    addTargetLanguage(lang) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(lang, \"language to be added\");\n        let languages = [];\n        if (this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n            languages = this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(\",\");\n            if (!languages.includes(lang)) {\n                languages.push(lang);\n                this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n            }\n        }\n        else {\n            this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, lang);\n            languages = [lang];\n        }\n        this.updateLanguages(languages);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member TranslationRecognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n        Exports_js_2.marshalPromiseToCallbacks(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * handles ConnectionEstablishedEvent for conversation translation scenarios.\n     * @member TranslationRecognizer.prototype.onConnection\n     * @function\n     * @public\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    onConnection() { }\n    async dispose(disposing) {\n        if (this.privDisposedTranslationRecognizer) {\n            return;\n        }\n        this.privDisposedTranslationRecognizer = true;\n        if (disposing) {\n            await this.implRecognizerStop();\n            await super.dispose(disposing);\n        }\n    }\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        return new Exports_js_1.TranslationServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n    updateLanguages(languages) {\n        const conn = Connection_js_1.Connection.fromRecognizer(this);\n        if (!!conn) {\n            conn.setMessageProperty(\"speech.context\", \"translationcontext\", { to: languages });\n            conn.sendMessageAsync(\"event\", JSON.stringify({\n                id: \"translation\",\n                name: \"updateLanguage\",\n                to: languages\n            }));\n        }\n    }\n}\nexports.TranslationRecognizer = TranslationRecognizer;\n\n//# sourceMappingURL=TranslationRecognizer.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisEventArgs.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationSynthesisEventArgs = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Translation Synthesis event arguments\n * @class TranslationSynthesisEventArgs\n */\nclass TranslationSynthesisEventArgs extends Exports_js_1.SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {TranslationSynthesisResult} result - The translation synthesis result.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, sessionId) {\n        super(sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the translation synthesis result.\n     * @member TranslationSynthesisEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\nexports.TranslationSynthesisEventArgs = TranslationSynthesisEventArgs;\n\n//# sourceMappingURL=TranslationSynthesisEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisResult.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TranslationSynthesisResult = void 0;\n/**\n * Defines translation synthesis result, i.e. the voice output of the translated\n * text in the target language.\n * @class TranslationSynthesisResult\n */\nclass TranslationSynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {ResultReason} reason - The synthesis reason.\n     * @param {ArrayBuffer} audio - The audio data.\n     */\n    constructor(reason, audio) {\n        this.privReason = reason;\n        this.privAudio = audio;\n    }\n    /**\n     * Translated text in the target language.\n     * @member TranslationSynthesisResult.prototype.audio\n     * @function\n     * @public\n     * @returns {ArrayBuffer} Translated audio in the target language.\n     */\n    get audio() {\n        return this.privAudio;\n    }\n    /**\n     * The synthesis status.\n     * @member TranslationSynthesisResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} The synthesis status.\n     */\n    get reason() {\n        return this.privReason;\n    }\n}\nexports.TranslationSynthesisResult = TranslationSynthesisResult;\n\n//# sourceMappingURL=TranslationSynthesisResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Translations.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Translations.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Translations = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Represents collection of parameters and their values.\n * @class Translations\n */\nclass Translations {\n    constructor() {\n        // Use an PropertyCollection internally, just wrapping it to hide the | enum syntax it has.\n        this.privMap = new Exports_js_1.PropertyCollection();\n    }\n    /**\n     * Get the languages in the object in a String array.\n     * @member Translations.prototype.languages\n     * @function\n     * @public\n     * @returns {string[]} languages in translations object.\n     */\n    get languages() {\n        return this.privMap.keys;\n    }\n    /**\n     * Returns the parameter value in type String. The parameter must have the same type as String.\n     * Currently only String, int and bool are allowed.\n     * If the name is not available, the specified defaultValue is returned.\n     * @member Translations.prototype.get\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} def - The default value which is returned if the parameter is not available in the collection.\n     * @returns {string} value of the parameter.\n     */\n    get(key, def) {\n        return this.privMap.getProperty(key, def);\n    }\n    /**\n     * Sets the String value of the parameter specified by name.\n     * @member Translations.prototype.set\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} value - The value of the parameter.\n     */\n    set(key, value) {\n        this.privMap.setProperty(key, value);\n    }\n}\nexports.Translations = Translations;\n\n//# sourceMappingURL=Translations.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Translations.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TurnStatusReceivedEventArgs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TurnStatusReceivedEventArgs.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TurnStatusReceivedEventArgs = void 0;\nconst TurnStatusPayload_js_1 = __webpack_require__(/*! ../common.speech/ServiceMessages/TurnStatusPayload.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TurnStatusPayload.js\");\n/**\n * Defines contents of received message/events.\n * @class TurnStatusReceivedEventArgs\n */\nclass TurnStatusReceivedEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} turnStatus - The JSON-encoded turn status message.\n     */\n    constructor(turnStatus) {\n        this.privTurnStatus = TurnStatusPayload_js_1.TurnStatusResponsePayload.fromJSON(turnStatus);\n    }\n    /**\n     * Gets the interaction identifier associated with this turn status event.\n     * @member TurnStatusReceivedEventArgs.prototype.interactionId\n     * @function\n     * @public\n     * @returns {any} the received interaction id.\n     */\n    get interactionId() {\n        return this.privTurnStatus.interactionId;\n    }\n    /**\n     * Gets the conversation identifier associated with this turn status event.\n     * @member TurnStatusReceivedEventArgs.prototype.conversationId\n     * @function\n     * @public\n     * @returns {any} the received conversation id.\n     */\n    get conversationId() {\n        return this.privTurnStatus.conversationId;\n    }\n    /**\n     * Gets the received turn status code.\n     * @member TurnStatusReceivedEventArgs.prototype.statusCode\n     * @function\n     * @public\n     * @returns {number} the received turn status.\n     */\n    get statusCode() {\n        return this.privTurnStatus.statusCode; // eslint-disable-line @typescript-eslint/no-unsafe-return\n    }\n}\nexports.TurnStatusReceivedEventArgs = TurnStatusReceivedEventArgs;\n\n//# sourceMappingURL=TurnStatusReceivedEventArgs.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TurnStatusReceivedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceInfo.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceInfo.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceInfo = exports.SynthesisVoiceType = exports.SynthesisVoiceGender = void 0;\n/**\n * Defines the gender of synthesis voices.\n * Added in version 1.20.0.\n */\nvar SynthesisVoiceGender;\n(function (SynthesisVoiceGender) {\n    /** Gender unknown */\n    SynthesisVoiceGender[SynthesisVoiceGender[\"Unknown\"] = 0] = \"Unknown\";\n    /** Female voice */\n    SynthesisVoiceGender[SynthesisVoiceGender[\"Female\"] = 1] = \"Female\";\n    /** Male voice */\n    SynthesisVoiceGender[SynthesisVoiceGender[\"Male\"] = 2] = \"Male\";\n    /** Neutral voice */\n    SynthesisVoiceGender[SynthesisVoiceGender[\"Neutral\"] = 3] = \"Neutral\";\n})(SynthesisVoiceGender = exports.SynthesisVoiceGender || (exports.SynthesisVoiceGender = {}));\nvar SynthesisVoiceType;\n(function (SynthesisVoiceType) {\n    SynthesisVoiceType[SynthesisVoiceType[\"OnlineNeural\"] = 1] = \"OnlineNeural\";\n    SynthesisVoiceType[SynthesisVoiceType[\"OnlineStandard\"] = 2] = \"OnlineStandard\";\n    SynthesisVoiceType[SynthesisVoiceType[\"OfflineNeural\"] = 3] = \"OfflineNeural\";\n    SynthesisVoiceType[SynthesisVoiceType[\"OfflineStandard\"] = 4] = \"OfflineStandard\";\n})(SynthesisVoiceType = exports.SynthesisVoiceType || (exports.SynthesisVoiceType = {}));\nconst GENDER_LOOKUP = {\n    [SynthesisVoiceGender[SynthesisVoiceGender.Neutral]]: SynthesisVoiceGender.Neutral,\n    [SynthesisVoiceGender[SynthesisVoiceGender.Male]]: SynthesisVoiceGender.Male,\n    [SynthesisVoiceGender[SynthesisVoiceGender.Female]]: SynthesisVoiceGender.Female,\n};\n/**\n * Information about Speech Synthesis voice\n * Added in version 1.20.0.\n * @class VoiceInfo\n */\nclass VoiceInfo {\n    constructor(json) {\n        this.privStyleList = [];\n        if (!!json) {\n            this.privName = json.Name;\n            this.privLocale = json.Locale;\n            this.privShortName = json.ShortName;\n            this.privLocaleName = json.LocaleName;\n            this.privDisplayName = json.DisplayName;\n            this.privLocalName = json.LocalName;\n            this.privVoiceType = json.VoiceType.endsWith(\"Standard\") ? SynthesisVoiceType.OnlineStandard : SynthesisVoiceType.OnlineNeural;\n            this.privGender = GENDER_LOOKUP[json.Gender] || SynthesisVoiceGender.Unknown;\n            if (!!json.StyleList && Array.isArray(json.StyleList)) {\n                for (const style of json.StyleList) {\n                    this.privStyleList.push(style);\n                }\n            }\n            this.privSampleRateHertz = json.SampleRateHertz;\n            this.privStatus = json.Status;\n            if (json.ExtendedPropertyMap) {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                this.privExtendedPropertyMap = json.ExtendedPropertyMap;\n            }\n            this.privWordsPerMinute = json.WordsPerMinute;\n            if (Array.isArray(json.SecondaryLocaleList)) {\n                this.privSecondaryLocaleList = [...json.SecondaryLocaleList];\n            }\n            if (Array.isArray(json.RolePlayList)) {\n                this.privRolePlayList = [...json.RolePlayList];\n            }\n        }\n    }\n    get name() {\n        return this.privName;\n    }\n    get locale() {\n        return this.privLocale;\n    }\n    get shortName() {\n        return this.privShortName;\n    }\n    get displayName() {\n        return this.privDisplayName;\n    }\n    get localName() {\n        return this.privLocalName;\n    }\n    get localeName() {\n        return this.privLocaleName;\n    }\n    get gender() {\n        return this.privGender;\n    }\n    get voiceType() {\n        return this.privVoiceType;\n    }\n    get styleList() {\n        return this.privStyleList;\n    }\n    get sampleRateHertz() {\n        return this.privSampleRateHertz;\n    }\n    get status() {\n        return this.privStatus;\n    }\n    get extendedPropertyMap() {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n        return this.privExtendedPropertyMap;\n    }\n    get wordsPerMinute() {\n        return this.privWordsPerMinute;\n    }\n    get secondaryLocaleList() {\n        return this.privSecondaryLocaleList;\n    }\n    get rolePlayList() {\n        return this.privRolePlayList;\n    }\n}\nexports.VoiceInfo = VoiceInfo;\n\n//# sourceMappingURL=VoiceInfo.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceInfo.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfile.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfile.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceProfile = void 0;\n/**\n * Defines Voice Profile class for Speaker Recognition\n * @class VoiceProfile\n */\nclass VoiceProfile {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} profileId - profileId of this Voice Profile.\n     * @param {VoiceProfileType} profileType - profileType of this Voice Profile.\n     */\n    constructor(profileId, profileType) {\n        this.privId = profileId;\n        this.privProfileType = profileType;\n    }\n    /**\n     * profileId of this Voice Profile instance\n     * @member VoiceProfile.prototype.profileId\n     * @function\n     * @public\n     * @returns {string} profileId of this Voice Profile instance.\n     */\n    get profileId() {\n        return this.privId;\n    }\n    /**\n     * profileType of this Voice Profile instance\n     * @member VoiceProfile.prototype.profileType\n     * @function\n     * @public\n     * @returns {VoiceProfileType} profile type of this Voice Profile instance.\n     */\n    get profileType() {\n        return this.privProfileType;\n    }\n}\nexports.VoiceProfile = VoiceProfile;\n\n//# sourceMappingURL=VoiceProfile.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfile.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileClient.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileClient.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceProfileClient = void 0;\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst AudioConfig_js_1 = __webpack_require__(/*! ./Audio/AudioConfig.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Defines VoiceProfileClient class for Speaker Recognition\n * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)\n * @class VoiceProfileClient\n */\nclass VoiceProfileClient extends Exports_js_2.Recognizer {\n    /**\n     * VoiceProfileClient constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer (authentication key, region, &c)\n     */\n    constructor(speechConfig) {\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig, \"speechConfig\");\n        const speechConfigImpl = speechConfig;\n        Contracts_js_1.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n        super(AudioConfig_js_1.AudioConfig.fromStreamInput(Exports_js_2.AudioInputStream.createPushStream()), speechConfigImpl.properties, new Exports_js_1.VoiceProfileConnectionFactory());\n        this.privProperties = speechConfigImpl.properties.clone();\n        this.privVoiceAdapter = this.privReco;\n        this.privDisposedVoiceAdapter = false;\n    }\n    /**\n     * The collection of properties and their values defined for this VoiceProfileClient.\n     * @member VoiceProfileClient.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this VoiceProfileClient.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member VoiceProfileClient.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member VoiceProfileClient.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * Create a speaker recognition voice profile\n     * @member VoiceProfileClient.prototype.createProfileAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfileType} profileType Type of Voice Profile to be created\n     * @param {string} lang Language string (locale) for Voice Profile\n     * @return {Promise<VoiceProfile>} - Promise of a VoiceProfile.\n     */\n    async createProfileAsync(profileType, lang) {\n        const profileIds = await this.privVoiceAdapter.createProfile(profileType, lang);\n        return new Exports_js_2.VoiceProfile(profileIds[0], profileType);\n    }\n    /**\n     * Get current information of a voice profile\n     * @member VoiceProfileClient.prototype.retrieveEnrollmentResultAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfile} profile Voice Profile to retrieve info for\n     * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.\n     */\n    async retrieveEnrollmentResultAsync(profile) {\n        return this.privVoiceAdapter.retrieveEnrollmentResult(profile);\n    }\n    /**\n     * Get all voice profiles on account with given voice profile type\n     * @member VoiceProfileClient.prototype.getAllProfilesAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfileType} profileType profile type (identification/verification) for which to list profiles\n     * @return {Promise<VoiceProfileEnrollmentResult[]>} - Promise of an array of VoiceProfileEnrollmentResults.\n     */\n    async getAllProfilesAsync(profileType) {\n        return this.privVoiceAdapter.getAllProfiles(profileType);\n        /*\n        const result: { json: { value: EnrollmentResultJSON[] } } = await this.privAdapter.getProfiles(profileType);\n        if (profileType === VoiceProfileType.TextIndependentIdentification) {\n            return VoiceProfileEnrollmentResult.FromIdentificationProfileList(result.json);\n        }\n        return VoiceProfileEnrollmentResult.FromVerificationProfileList(result.json);\n        */\n    }\n    /**\n     * Get valid authorization phrases for voice profile enrollment\n     * @member VoiceProfileClient.prototype.getActivationPhrasesAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfileType} profileType Profile Type to get activation phrases for\n     * @param {string} lang Language string (locale) for Voice Profile\n     */\n    async getActivationPhrasesAsync(profileType, lang) {\n        return this.privVoiceAdapter.getActivationPhrases(profileType, lang);\n    }\n    /**\n     * Create a speaker recognition voice profile\n     * @member VoiceProfileClient.prototype.enrollProfileAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfile} profile Voice Profile to create enrollment for\n     * @param {AudioConfig} audioConfig source info from which to create enrollment\n     * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.\n     */\n    async enrollProfileAsync(profile, audioConfig) {\n        const configImpl = audioConfig;\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(configImpl, \"audioConfig\");\n        this.audioConfig = audioConfig;\n        this.privVoiceAdapter.SpeakerAudioSource = configImpl;\n        return this.privVoiceAdapter.enrollProfile(profile);\n    }\n    /**\n     * Delete a speaker recognition voice profile\n     * @member VoiceProfileClient.prototype.deleteProfileAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfile} profile Voice Profile to be deleted\n     * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.\n     */\n    async deleteProfileAsync(profile) {\n        return this.privVoiceAdapter.deleteProfile(profile);\n    }\n    /**\n     * Remove all enrollments for a speaker recognition voice profile\n     * @member VoiceProfileClient.prototype.resetProfileAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfile} profile Voice Profile to be reset\n     * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.\n     */\n    async resetProfileAsync(profile) {\n        return this.privVoiceAdapter.resetProfile(profile);\n    }\n    /**\n     * Clean up object and close underlying connection\n     * @member VoiceProfileClient.prototype.close\n     * @function\n     * @async\n     * @public\n     */\n    async close() {\n        await this.dispose(true);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioImpl = audioConfig;\n        return new Exports_js_1.VoiceServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);\n    }\n    async dispose(disposing) {\n        if (this.privDisposedVoiceAdapter) {\n            return;\n        }\n        this.privDisposedVoiceAdapter = true;\n        if (disposing) {\n            await super.dispose(disposing);\n        }\n    }\n    createRecognizerConfig(speechConfig) {\n        return new Exports_js_1.RecognizerConfig(speechConfig, this.properties);\n    }\n    getResult(result, successReason) {\n        const response = new Exports_js_2.VoiceProfileResult(result.ok ? successReason : Exports_js_2.ResultReason.Canceled, result.statusText);\n        return (response);\n    }\n}\nexports.VoiceProfileClient = VoiceProfileClient;\n\n//# sourceMappingURL=VoiceProfileClient.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileClient.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileEnrollmentResult.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileEnrollmentResult.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceProfileEnrollmentCancellationDetails = exports.VoiceProfileEnrollmentResult = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Output format\n * @class VoiceProfileEnrollmentResult\n */\nclass VoiceProfileEnrollmentResult {\n    constructor(reason, json, statusText) {\n        this.privReason = reason;\n        this.privProperties = new Exports_js_2.PropertyCollection();\n        if (this.privReason !== Exports_js_2.ResultReason.Canceled) {\n            if (!!json) {\n                this.privDetails = JSON.parse(json);\n                if (this.privDetails.enrollmentStatus.toLowerCase() === \"enrolling\") {\n                    this.privReason = Exports_js_2.ResultReason.EnrollingVoiceProfile;\n                }\n            }\n        }\n        else {\n            this.privErrorDetails = statusText;\n            this.privProperties.setProperty(Exports_js_1.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[Exports_js_2.CancellationErrorCode.ServiceError]);\n        }\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get enrollmentsCount() {\n        return this.privDetails.enrollmentsCount;\n    }\n    get enrollmentsLength() {\n        return this.privDetails.enrollmentsLength;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get enrollmentResultDetails() {\n        return this.privDetails;\n    }\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    static FromIdentificationProfileList(json) {\n        const results = [];\n        for (const item of json.value) {\n            const reason = item.enrollmentStatus.toLowerCase() === \"enrolling\" ?\n                Exports_js_2.ResultReason.EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === \"enrolled\" ?\n                Exports_js_2.ResultReason.EnrolledVoiceProfile : Exports_js_2.ResultReason.Canceled;\n            const result = new VoiceProfileEnrollmentResult(reason, null, null);\n            result.privDetails = this.getIdentificationDetails(item);\n            results.push(result);\n        }\n        return results;\n    }\n    static FromVerificationProfileList(json) {\n        const results = [];\n        for (const item of json.value) {\n            const reason = item.enrollmentStatus.toLowerCase() === \"enrolling\" ?\n                Exports_js_2.ResultReason.EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === \"enrolled\" ?\n                Exports_js_2.ResultReason.EnrolledVoiceProfile : Exports_js_2.ResultReason.Canceled;\n            const result = new VoiceProfileEnrollmentResult(reason, null, null);\n            result.privDetails = this.getVerificationDetails(item);\n            results.push(result);\n        }\n        return results;\n    }\n    static getIdentificationDetails(json) {\n        return {\n            audioLength: json.audioLength ? parseFloat(json.audioLength) : 0,\n            audioSpeechLength: json.audioSpeechLength ? parseFloat(json.audioSpeechLength) : 0,\n            enrollmentStatus: json.enrollmentStatus,\n            enrollmentsCount: json.enrollmentsCount || 0,\n            enrollmentsLength: json.enrollmentsLength ? parseFloat(json.enrollmentsLength) : 0,\n            enrollmentsSpeechLength: json.enrollmentsSpeechLength ? parseFloat(json.enrollmentsSpeechLength) : 0,\n            profileId: json.profileId || json.identificationProfileId,\n            remainingEnrollmentsSpeechLength: json.remainingEnrollmentsSpeechLength ? parseFloat(json.remainingEnrollmentsSpeechLength) : 0\n        };\n    }\n    static getVerificationDetails(json) {\n        return {\n            audioLength: json.audioLength ? parseFloat(json.audioLength) : 0,\n            audioSpeechLength: json.audioSpeechLength ? parseFloat(json.audioSpeechLength) : 0,\n            enrollmentStatus: json.enrollmentStatus,\n            enrollmentsCount: json.enrollmentsCount,\n            enrollmentsLength: json.enrollmentsLength ? parseFloat(json.enrollmentsLength) : 0,\n            enrollmentsSpeechLength: json.enrollmentsSpeechLength ? parseFloat(json.enrollmentsSpeechLength) : 0,\n            profileId: json.profileId || json.verificationProfileId,\n            remainingEnrollmentsCount: json.remainingEnrollments || json.remainingEnrollmentsCount,\n            remainingEnrollmentsSpeechLength: json.remainingEnrollmentsSpeechLength ? parseFloat(json.remainingEnrollmentsSpeechLength) : 0\n        };\n    }\n}\nexports.VoiceProfileEnrollmentResult = VoiceProfileEnrollmentResult;\n/**\n * @class VoiceProfileEnrollmentCancellationDetails\n */\nclass VoiceProfileEnrollmentCancellationDetails extends Exports_js_2.CancellationDetailsBase {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of VoiceProfileEnrollmentCancellationDetails object for the canceled VoiceProfileEnrollmentResult.\n     * @member VoiceProfileEnrollmentCancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {VoiceProfileEnrollmentResult} result - The result that was canceled.\n     * @returns {VoiceProfileEnrollmentCancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        const reason = Exports_js_2.CancellationReason.Error;\n        let errorCode = Exports_js_2.CancellationErrorCode.NoError;\n        if (!!result.properties) {\n            errorCode = Exports_js_2.CancellationErrorCode[result.properties.getProperty(Exports_js_1.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[Exports_js_2.CancellationErrorCode.NoError])]; //eslint-disable-line\n        }\n        return new VoiceProfileEnrollmentCancellationDetails(reason, result.errorDetails, errorCode);\n    }\n}\nexports.VoiceProfileEnrollmentCancellationDetails = VoiceProfileEnrollmentCancellationDetails;\n\n//# sourceMappingURL=VoiceProfileEnrollmentResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileEnrollmentResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfilePhraseResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfilePhraseResult.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceProfilePhraseResult = void 0;\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_1 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Output format\n * @class VoiceProfilePhraseResult\n */\nclass VoiceProfilePhraseResult extends Exports_js_1.VoiceProfileResult {\n    constructor(reason, statusText, type, phraseArray) {\n        super(reason, statusText);\n        this.privPhrases = [];\n        Contracts_js_1.Contracts.throwIfNullOrUndefined(phraseArray, \"phrase array\");\n        this.privType = type;\n        if (!!phraseArray && !!phraseArray[0]) {\n            this.privPhrases = phraseArray;\n        }\n    }\n    get phrases() {\n        return this.privPhrases;\n    }\n    get type() {\n        return this.privType;\n    }\n}\nexports.VoiceProfilePhraseResult = VoiceProfilePhraseResult;\n\n//# sourceMappingURL=VoiceProfilePhraseResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfilePhraseResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileResult.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileResult.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceProfileCancellationDetails = exports.VoiceProfileResult = void 0;\n/* eslint-disable max-classes-per-file */\nconst Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js\");\nconst Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js\");\nconst Exports_js_2 = __webpack_require__(/*! ./Exports.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js\");\n/**\n * Output format\n * @class VoiceProfileResult\n */\nclass VoiceProfileResult {\n    constructor(reason, statusText) {\n        this.privReason = reason;\n        this.privProperties = new Exports_js_2.PropertyCollection();\n        if (reason === Exports_js_2.ResultReason.Canceled) {\n            Contracts_js_1.Contracts.throwIfNullOrUndefined(statusText, \"statusText\");\n            this.privErrorDetails = statusText;\n            this.privProperties.setProperty(Exports_js_1.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[Exports_js_2.CancellationErrorCode.ServiceError]);\n        }\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\nexports.VoiceProfileResult = VoiceProfileResult;\n/**\n * @class VoiceProfileCancellationDetails\n */\nclass VoiceProfileCancellationDetails extends Exports_js_2.CancellationDetailsBase {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of VoiceProfileCancellationDetails object for the canceled VoiceProfileResult.\n     * @member VoiceProfileCancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {VoiceProfileResult} result - The result that was canceled.\n     * @returns {VoiceProfileCancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        const reason = Exports_js_2.CancellationReason.Error;\n        let errorCode = Exports_js_2.CancellationErrorCode.NoError;\n        if (!!result.properties) {\n            errorCode = Exports_js_2.CancellationErrorCode[result.properties.getProperty(Exports_js_1.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[Exports_js_2.CancellationErrorCode.NoError])]; //eslint-disable-line\n        }\n        return new VoiceProfileCancellationDetails(reason, result.errorDetails, errorCode);\n    }\n}\nexports.VoiceProfileCancellationDetails = VoiceProfileCancellationDetails;\n\n//# sourceMappingURL=VoiceProfileResult.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileType.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileType.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VoiceProfileType = void 0;\n/**\n * Output format\n * @class VoiceProfileType\n */\nvar VoiceProfileType;\n(function (VoiceProfileType) {\n    /**\n     * Text independent speaker identification\n     * @member VoiceProfileType.TextIndependentIdentification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextIndependentIdentification\"] = 0] = \"TextIndependentIdentification\";\n    /**\n     * Text dependent speaker verification\n     * @member VoiceProfileType.TextDependentVerification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextDependentVerification\"] = 1] = \"TextDependentVerification\";\n    /**\n     * Text independent speaker verification\n     * @member VoiceProfileType.TextIndependentVerification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextIndependentVerification\"] = 2] = \"TextIndependentVerification\";\n})(VoiceProfileType = exports.VoiceProfileType || (exports.VoiceProfileType = {}));\n\n//# sourceMappingURL=VoiceProfileType.js.map\n\n\n//# sourceURL=webpack://unacast/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceProfileType.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   NIL: () => (/* reexport safe */ _nil_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]),\n/* harmony export */   parse: () => (/* reexport safe */ _parse_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"]),\n/* harmony export */   stringify: () => (/* reexport safe */ _stringify_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]),\n/* harmony export */   v1: () => (/* reexport safe */ _v1_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   v3: () => (/* reexport safe */ _v3_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]),\n/* harmony export */   v4: () => (/* reexport safe */ _v4_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]),\n/* harmony export */   v5: () => (/* reexport safe */ _v5_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   validate: () => (/* reexport safe */ _validate_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"]),\n/* harmony export */   version: () => (/* reexport safe */ _version_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])\n/* harmony export */ });\n/* harmony import */ var _v1_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./v1.js */ \"./node_modules/uuid/dist/esm-browser/v1.js\");\n/* harmony import */ var _v3_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./v3.js */ \"./node_modules/uuid/dist/esm-browser/v3.js\");\n/* harmony import */ var _v4_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./v4.js */ \"./node_modules/uuid/dist/esm-browser/v4.js\");\n/* harmony import */ var _v5_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./v5.js */ \"./node_modules/uuid/dist/esm-browser/v5.js\");\n/* harmony import */ var _nil_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./nil.js */ \"./node_modules/uuid/dist/esm-browser/nil.js\");\n/* harmony import */ var _version_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./version.js */ \"./node_modules/uuid/dist/esm-browser/version.js\");\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n/* harmony import */ var _parse_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./parse.js */ \"./node_modules/uuid/dist/esm-browser/parse.js\");\n\n\n\n\n\n\n\n\n\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/index.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/md5.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/md5.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/*\n * Browser-compatible JavaScript MD5\n *\n * Modification of JavaScript MD5\n * https://github.com/blueimp/JavaScript-MD5\n *\n * Copyright 2011, Sebastian Tschan\n * https://blueimp.net\n *\n * Licensed under the MIT license:\n * https://opensource.org/licenses/MIT\n *\n * Based on\n * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message\n * Digest Algorithm, as defined in RFC 1321.\n * Version 2.2 Copyright (C) Paul Johnston 1999 - 2009\n * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet\n * Distributed under the BSD License\n * See http://pajhome.org.uk/crypt/md5 for more info.\n */\nfunction md5(bytes) {\n  if (typeof bytes === 'string') {\n    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape\n\n    bytes = new Uint8Array(msg.length);\n\n    for (let i = 0; i < msg.length; ++i) {\n      bytes[i] = msg.charCodeAt(i);\n    }\n  }\n\n  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));\n}\n/*\n * Convert an array of little-endian words to an array of bytes\n */\n\n\nfunction md5ToHexEncodedArray(input) {\n  const output = [];\n  const length32 = input.length * 32;\n  const hexTab = '0123456789abcdef';\n\n  for (let i = 0; i < length32; i += 8) {\n    const x = input[i >> 5] >>> i % 32 & 0xff;\n    const hex = parseInt(hexTab.charAt(x >>> 4 & 0x0f) + hexTab.charAt(x & 0x0f), 16);\n    output.push(hex);\n  }\n\n  return output;\n}\n/**\n * Calculate output length with padding and bit length\n */\n\n\nfunction getOutputLength(inputLength8) {\n  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;\n}\n/*\n * Calculate the MD5 of an array of little-endian words, and a bit length.\n */\n\n\nfunction wordsToMd5(x, len) {\n  /* append padding */\n  x[len >> 5] |= 0x80 << len % 32;\n  x[getOutputLength(len) - 1] = len;\n  let a = 1732584193;\n  let b = -271733879;\n  let c = -1732584194;\n  let d = 271733878;\n\n  for (let i = 0; i < x.length; i += 16) {\n    const olda = a;\n    const oldb = b;\n    const oldc = c;\n    const oldd = d;\n    a = md5ff(a, b, c, d, x[i], 7, -680876936);\n    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);\n    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);\n    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);\n    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);\n    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);\n    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);\n    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);\n    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);\n    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);\n    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);\n    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);\n    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);\n    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);\n    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);\n    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);\n    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);\n    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);\n    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);\n    b = md5gg(b, c, d, a, x[i], 20, -373897302);\n    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);\n    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);\n    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);\n    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);\n    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);\n    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);\n    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);\n    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);\n    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);\n    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);\n    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);\n    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);\n    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);\n    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);\n    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);\n    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);\n    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);\n    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);\n    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);\n    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);\n    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);\n    d = md5hh(d, a, b, c, x[i], 11, -358537222);\n    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);\n    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);\n    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);\n    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);\n    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);\n    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);\n    a = md5ii(a, b, c, d, x[i], 6, -198630844);\n    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);\n    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);\n    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);\n    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);\n    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);\n    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);\n    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);\n    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);\n    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);\n    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);\n    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);\n    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);\n    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);\n    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);\n    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);\n    a = safeAdd(a, olda);\n    b = safeAdd(b, oldb);\n    c = safeAdd(c, oldc);\n    d = safeAdd(d, oldd);\n  }\n\n  return [a, b, c, d];\n}\n/*\n * Convert an array bytes to an array of little-endian words\n * Characters >255 have their high-byte silently ignored.\n */\n\n\nfunction bytesToWords(input) {\n  if (input.length === 0) {\n    return [];\n  }\n\n  const length8 = input.length * 8;\n  const output = new Uint32Array(getOutputLength(length8));\n\n  for (let i = 0; i < length8; i += 8) {\n    output[i >> 5] |= (input[i / 8] & 0xff) << i % 32;\n  }\n\n  return output;\n}\n/*\n * Add integers, wrapping at 2^32. This uses 16-bit operations internally\n * to work around bugs in some JS interpreters.\n */\n\n\nfunction safeAdd(x, y) {\n  const lsw = (x & 0xffff) + (y & 0xffff);\n  const msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n  return msw << 16 | lsw & 0xffff;\n}\n/*\n * Bitwise rotate a 32-bit number to the left.\n */\n\n\nfunction bitRotateLeft(num, cnt) {\n  return num << cnt | num >>> 32 - cnt;\n}\n/*\n * These functions implement the four basic operations the algorithm uses.\n */\n\n\nfunction md5cmn(q, a, b, x, s, t) {\n  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);\n}\n\nfunction md5ff(a, b, c, d, x, s, t) {\n  return md5cmn(b & c | ~b & d, a, b, x, s, t);\n}\n\nfunction md5gg(a, b, c, d, x, s, t) {\n  return md5cmn(b & d | c & ~d, a, b, x, s, t);\n}\n\nfunction md5hh(a, b, c, d, x, s, t) {\n  return md5cmn(b ^ c ^ d, a, b, x, s, t);\n}\n\nfunction md5ii(a, b, c, d, x, s, t) {\n  return md5cmn(c ^ (b | ~d), a, b, x, s, t);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (md5);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/md5.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/native.js":
/*!******************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/native.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  randomUUID\n});\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/native.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/nil.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/nil.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ('00000000-0000-0000-0000-000000000000');\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/nil.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/parse.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/parse.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n\nfunction parse(uuid) {\n  if (!(0,_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  let v;\n  const arr = new Uint8Array(16); // Parse ########-....-....-....-............\n\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff; // Parse ........-####-....-....-............\n\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff; // Parse ........-....-####-....-............\n\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff; // Parse ........-....-....-####-............\n\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff; // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (parse);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/parse.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/regex.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/regex.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/regex.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/rng.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/rng.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ rng)\n/* harmony export */ });\n// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nlet getRandomValues;\nconst rnds8 = new Uint8Array(16);\nfunction rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);\n\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n\n  return getRandomValues(rnds8);\n}\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/rng.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/sha1.js":
/*!****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/sha1.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n// Adapted from Chris Veness' SHA1 code at\n// http://www.movable-type.co.uk/scripts/sha1.html\nfunction f(s, x, y, z) {\n  switch (s) {\n    case 0:\n      return x & y ^ ~x & z;\n\n    case 1:\n      return x ^ y ^ z;\n\n    case 2:\n      return x & y ^ x & z ^ y & z;\n\n    case 3:\n      return x ^ y ^ z;\n  }\n}\n\nfunction ROTL(x, n) {\n  return x << n | x >>> 32 - n;\n}\n\nfunction sha1(bytes) {\n  const K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6];\n  const H = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];\n\n  if (typeof bytes === 'string') {\n    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape\n\n    bytes = [];\n\n    for (let i = 0; i < msg.length; ++i) {\n      bytes.push(msg.charCodeAt(i));\n    }\n  } else if (!Array.isArray(bytes)) {\n    // Convert Array-like to Array\n    bytes = Array.prototype.slice.call(bytes);\n  }\n\n  bytes.push(0x80);\n  const l = bytes.length / 4 + 2;\n  const N = Math.ceil(l / 16);\n  const M = new Array(N);\n\n  for (let i = 0; i < N; ++i) {\n    const arr = new Uint32Array(16);\n\n    for (let j = 0; j < 16; ++j) {\n      arr[j] = bytes[i * 64 + j * 4] << 24 | bytes[i * 64 + j * 4 + 1] << 16 | bytes[i * 64 + j * 4 + 2] << 8 | bytes[i * 64 + j * 4 + 3];\n    }\n\n    M[i] = arr;\n  }\n\n  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);\n  M[N - 1][14] = Math.floor(M[N - 1][14]);\n  M[N - 1][15] = (bytes.length - 1) * 8 & 0xffffffff;\n\n  for (let i = 0; i < N; ++i) {\n    const W = new Uint32Array(80);\n\n    for (let t = 0; t < 16; ++t) {\n      W[t] = M[i][t];\n    }\n\n    for (let t = 16; t < 80; ++t) {\n      W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1);\n    }\n\n    let a = H[0];\n    let b = H[1];\n    let c = H[2];\n    let d = H[3];\n    let e = H[4];\n\n    for (let t = 0; t < 80; ++t) {\n      const s = Math.floor(t / 20);\n      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] >>> 0;\n      e = d;\n      d = c;\n      c = ROTL(b, 30) >>> 0;\n      b = a;\n      a = T;\n    }\n\n    H[0] = H[0] + a >>> 0;\n    H[1] = H[1] + b >>> 0;\n    H[2] = H[2] + c >>> 0;\n    H[3] = H[3] + d >>> 0;\n    H[4] = H[4] + e >>> 0;\n  }\n\n  return [H[0] >> 24 & 0xff, H[0] >> 16 & 0xff, H[0] >> 8 & 0xff, H[0] & 0xff, H[1] >> 24 & 0xff, H[1] >> 16 & 0xff, H[1] >> 8 & 0xff, H[1] & 0xff, H[2] >> 24 & 0xff, H[2] >> 16 & 0xff, H[2] >> 8 & 0xff, H[2] & 0xff, H[3] >> 24 & 0xff, H[3] >> 16 & 0xff, H[3] >> 8 & 0xff, H[3] & 0xff, H[4] >> 24 & 0xff, H[4] >> 16 & 0xff, H[4] >> 8 & 0xff, H[4] & 0xff];\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (sha1);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/sha1.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/stringify.js":
/*!*********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/stringify.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   unsafeStringify: () => (/* binding */ unsafeStringify)\n/* harmony export */ });\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\n\nconst byteToHex = [];\n\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\n\nfunction unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];\n}\n\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!(0,_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (stringify);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/stringify.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v1.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v1.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/esm-browser/rng.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n\n // **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nlet _nodeId;\n\nlet _clockseq; // Previous uuid creation time\n\n\nlet _lastMSecs = 0;\nlet _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details\n\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node || _nodeId;\n  let clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])();\n\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n    }\n\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n\n\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)\n\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression\n\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n\n\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  } // Per 4.2.1.2 Throw error if too many uuids are requested\n\n\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n\n  msecs += 12219292800000; // `time_low`\n\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff; // `time_mid`\n\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff; // `time_high_and_version`\n\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n\n  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n\n  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`\n\n  b[i++] = clockseq & 0xff; // `node`\n\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf || (0,_stringify_js__WEBPACK_IMPORTED_MODULE_1__.unsafeStringify)(b);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v1);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/v1.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v3.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v3.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _v35_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./v35.js */ \"./node_modules/uuid/dist/esm-browser/v35.js\");\n/* harmony import */ var _md5_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./md5.js */ \"./node_modules/uuid/dist/esm-browser/md5.js\");\n\n\nconst v3 = (0,_v35_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('v3', 0x30, _md5_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v3);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/v3.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v35.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v35.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DNS: () => (/* binding */ DNS),\n/* harmony export */   URL: () => (/* binding */ URL),\n/* harmony export */   \"default\": () => (/* binding */ v35)\n/* harmony export */ });\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n/* harmony import */ var _parse_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./parse.js */ \"./node_modules/uuid/dist/esm-browser/parse.js\");\n\n\n\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n\n  return bytes;\n}\n\nconst DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nconst URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nfunction v35(name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    var _namespace;\n\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n\n    if (typeof namespace === 'string') {\n      namespace = (0,_parse_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(namespace);\n    }\n\n    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    } // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n\n\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n\n    if (buf) {\n      offset = offset || 0;\n\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n\n      return buf;\n    }\n\n    return (0,_stringify_js__WEBPACK_IMPORTED_MODULE_1__.unsafeStringify)(bytes);\n  } // Function#name is not settable on some platforms (#270)\n\n\n  try {\n    generateUUID.name = name; // eslint-disable-next-line no-empty\n  } catch (err) {} // For CommonJS default export support\n\n\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/v35.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v4.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v4.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _native_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./native.js */ \"./node_modules/uuid/dist/esm-browser/native.js\");\n/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/esm-browser/rng.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n\n\n\n\nfunction v4(options, buf, offset) {\n  if (_native_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].randomUUID && !buf && !options) {\n    return _native_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].randomUUID();\n  }\n\n  options = options || {};\n  const rnds = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return (0,_stringify_js__WEBPACK_IMPORTED_MODULE_2__.unsafeStringify)(rnds);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v4);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/v4.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v5.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v5.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _v35_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./v35.js */ \"./node_modules/uuid/dist/esm-browser/v35.js\");\n/* harmony import */ var _sha1_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./sha1.js */ \"./node_modules/uuid/dist/esm-browser/sha1.js\");\n\n\nconst v5 = (0,_v35_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('v5', 0x50, _sha1_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v5);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/v5.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/validate.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/validate.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _regex_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./regex.js */ \"./node_modules/uuid/dist/esm-browser/regex.js\");\n\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].test(uuid);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (validate);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/validate.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/version.js":
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/version.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n\nfunction version(uuid) {\n  if (!(0,_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  return parseInt(uuid.slice(14, 15), 16);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (version);\n\n//# sourceURL=webpack://unacast/./node_modules/uuid/dist/esm-browser/version.js?");

/***/ }),

/***/ "./src/main/const.ts":
/*!***************************!*\
  !*** ./src/main/const.ts ***!
  \***************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.electronEvent = void 0;\nexports.electronEvent = {\n    /** ã‚µãƒ¼ãƒãƒ¼èµ·å‹• */\n    START_SERVER: 'start-server',\n    /** ã‚µãƒ¼ãƒãƒ¼åœæ­¢ */\n    STOP_SERVER: 'stop-server',\n    /** Configé©ç”¨ */\n    APPLY_CONFIG: 'apply-config',\n    /** ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º */\n    SHOW_ALERT: 'show-alert',\n    SAVE_CONFIG: 'save-config',\n    /** æ£’èª­ã¿å†ç”Ÿ */\n    PLAY_TAMIYASU: 'play-tamiyasu',\n    /** ãƒ¬ã‚¹ç€ä¿¡éŸ³å†ç”Ÿ */\n    PLAY_SOUND_START: 'play-sound-start',\n    PLAY_SOUND_END: 'play-sound-end',\n    WAIT_YOMIKO_TIME: 'wait-yomiko-time',\n    SPEAK_WAV: 'speak-wav',\n    ABORT_WAV: 'abort-wav',\n    SPEAKING_END: 'speaking-end',\n    // VOICEVOX ã®èª­ã¿è¾¼ã¿ renderer â†’ main\n    LOAD_VOICEVOX: 'load-voicevox',\n    // VOICEVOX ã®çŠ¶æ…‹æ›´æ–° renderer â† main\n    UPDATE_VOICEVOX_CONFIG: 'update-voicevox-config',\n    /** ã‚³ãƒ¡ãƒ³ãƒˆè¡¨ç¤º */\n    SHOW_COMMENT: 'show-comment',\n    /** ã‚³ãƒ¡ãƒ³ãƒˆæ¬„åˆæœŸåŒ– */\n    CLEAR_COMMENT: 'clear-comment',\n    /** ç¿»è¨³ã‚³ãƒ¡ãƒ³ãƒˆè¡¨ç¤º */\n    SHOW_COMMENT_TL: 'show_comment_translate',\n    /** ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã®è¿”ä¿¡ */\n    START_SERVER_REPLY: 'start-server-reply',\n    /** å¼·åˆ¶çš„ã«ç«¯ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« */\n    FORCE_SCROLL: 'FORCE_SCROLL',\n    /** ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–° */\n    UPDATE_STATUS: 'UPDATE_STATUS',\n    /** ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ */\n    COMMENT_TEST: 'COMMENT_TEST',\n    /** ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ */\n    PREVIEW_IMAGE: 'PREVIEW_IMAGE',\n    /** Azure Speech To text **/\n    AZURE_STT_START: 'azure-stt-start',\n    AZURE_STT_STOP: 'azure-stt-stop',\n    AZURE_STT_EVENT: 'azure-stt-event',\n};\n\n\n//# sourceURL=webpack://unacast/./src/main/const.ts?");

/***/ }),

/***/ "./src/renderer/azureStt.ts":
/*!**********************************!*\
  !*** ./src/renderer/azureStt.ts ***!
  \**********************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n// ãƒžã‚¤ã‚¯ã‹ã‚‰ã®å…¥åŠ›ã¯ Renderer å´ã§ã—ã‹ã§ããªã„ã®ã§ã€ã“ã¡ã‚‰ã§èªè­˜å…¨ä½“ã‚’è¡Œã†\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst electron_1 = __importDefault(__webpack_require__(/*! electron */ \"electron\"));\nconst renderer_1 = __importDefault(__webpack_require__(/*! electron-log/renderer */ \"./node_modules/electron-log/renderer.js\"));\nconst logger = renderer_1.default.scope('renderer-azureStt');\nconst const_1 = __webpack_require__(/*! ../main/const */ \"./src/main/const.ts\");\nconst microsoft_cognitiveservices_speech_sdk_1 = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/microsoft.cognitiveservices.speech.sdk.js\");\nconst ipcRenderer = electron_1.default.ipcRenderer;\nlet speechRecognizer;\nconst start = (key, region, language, inputDevice) => {\n    logger.info('starting text recognition from microphone.');\n    const speechConfig = microsoft_cognitiveservices_speech_sdk_1.SpeechConfig.fromSubscription(key, region);\n    speechConfig.speechRecognitionLanguage = language;\n    const audioConfig = microsoft_cognitiveservices_speech_sdk_1.AudioConfig.fromMicrophoneInput(inputDevice === '' ? undefined : inputDevice);\n    const startTime = Date.now();\n    const recognizer = new microsoft_cognitiveservices_speech_sdk_1.SpeechRecognizer(speechConfig, audioConfig);\n    recognizer.recognized = (s, e) => {\n        if (e.result.text) {\n            logger.debug('text recognized:' + e.result.text);\n            ipcRenderer.send(const_1.electronEvent.AZURE_STT_EVENT, 'comment', { date: new Date(startTime + e.result.offset / 10000).toLocaleString(), text: e.result.text });\n        }\n    };\n    recognizer.canceled = (s, e) => {\n        logger.warn('text recognition is canceled.');\n        if (e.reason == microsoft_cognitiveservices_speech_sdk_1.CancellationReason.Error) {\n            ipcRenderer.send(const_1.electronEvent.AZURE_STT_EVENT, 'error', { date: new Date(startTime + e.offset / 10000).toLocaleString(), text: 'Speech recognition error.' });\n        }\n        recognizer.stopContinuousRecognitionAsync();\n        if (speechRecognizer === recognizer) {\n            speechRecognizer = undefined;\n        }\n    };\n    recognizer.sessionStopped = (s, e) => {\n        logger.warn('text recognition session is stopped.');\n        recognizer.stopContinuousRecognitionAsync();\n        if (speechRecognizer === recognizer) {\n            speechRecognizer = undefined;\n        }\n    };\n    speechRecognizer = recognizer;\n    recognizer.startContinuousRecognitionAsync();\n    ipcRenderer.send(const_1.electronEvent.AZURE_STT_EVENT, 'end');\n};\nconst stop = () => {\n    if (speechRecognizer) {\n        speechRecognizer.stopContinuousRecognitionAsync();\n        speechRecognizer = undefined;\n    }\n};\nipcRenderer.on(const_1.electronEvent.AZURE_STT_START, (event, arg) => {\n    logger.debug('DOM Content Loaded');\n    start(arg.key, arg.region, arg.language, arg.inputDevice);\n});\nipcRenderer.on(const_1.electronEvent.AZURE_STT_STOP, (event) => {\n    stop();\n});\n\n\n//# sourceURL=webpack://unacast/./src/renderer/azureStt.ts?");

/***/ }),

/***/ "?3dbe":
/*!********************!*\
  !*** ws (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://unacast/ws_(ignored)?");

/***/ }),

/***/ "?875c":
/*!****************************!*\
  !*** agent-base (ignored) ***!
  \****************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://unacast/agent-base_(ignored)?");

/***/ }),

/***/ "?a523":
/*!***********************************!*\
  !*** https-proxy-agent (ignored) ***!
  \***********************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://unacast/https-proxy-agent_(ignored)?");

/***/ }),

/***/ "electron":
/*!***************************!*\
  !*** external "electron" ***!
  \***************************/
/***/ ((module) => {

"use strict";
module.exports = require("electron");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("fs");

/***/ }),

/***/ "net":
/*!**********************!*\
  !*** external "net" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("net");

/***/ }),

/***/ "tls":
/*!**********************!*\
  !*** external "tls" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("tls");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module is referenced by other modules so it can't be inlined
/******/ 	var __webpack_exports__ = __webpack_require__("./src/renderer/azureStt.ts");
/******/ 	
/******/ })()
;